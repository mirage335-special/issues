
Please generate a point-by-point brief yet exhaustive human readable changelog specific to new features and functionality that may not have been adequately tested, so users can be aware of potential related issues and developers can be aware of what code is relevant to correct. I will refine this changelog, so it is more important to briefly draw my attention to everything that might need inclusion, and to keep each point brief so nothing specific gets buried in the noise.



From  b03e7eb / b03e7ebecae692f2c8436243f32f0a7037e6c03c  to  HEAD / e91f860 / e91f860c23f0bfa51f7f00203a78789bbd0d077e  . The commit after the beginning b03e7eb of this history  b03e7eb...e91f860  is  e34fcc6e / e34fcc6efb643641f97d37797d553f70096832bb

```bash
git log --oneline b03e7eb..e91f860
```
```log
e91f860c Draft.
1ff12517 Draft.
fdc919eb Compile.
41b4400b Correction.
a997382c Draft.
46ed98a8 Draft - documentation, corrections, network outage resilience.
430c6a6f Correction.
3780ca94 DRAFT - python-devel , pythonCurrent-devel , _if_cygwin quiet default , python_wheels replacement submodule , install_certs , nix_python . Draft . Corrections .
6ac6b6e4 Draft - remove msw_python_wheels .
70d13047 WIP - submodules.
62c89ee0 DRAFT - nix python .
7077c2cc Documentation.
56e687b0 Draft - Python virtualization lock file.
ce9bdf20 Draft.
e1eee841 Draft.
6469299b Draft.
ab102d6e Draft.
12bd0bcb Draft.
d08e8414 Compile.
83f69ca7 Corrections. DRAFT - VIRTUAL_ENV_PROMPT .
eac10c89 DRAFT - dumbpath .
f1d51a1d Draft.
1ffed03d Compile.
dad013cd Draft - venv . Upstream.
10c0bc8f Draft - python3 dummy wrapper script.
a32a15b4 Compile.
2dd7030f Upstream.
3de92ac7 Correction - msw_python_wheels submodule URL .
af163620 Draft.
f53ff793 Draft - install_dependencies_msw_python .
d9df7797 Compile.
cb4cc9bf Draft - python prompt.
b12346b5 DRAFT - MSW native python prompt.
60c38771 Draft - changes to lean.py , disable alias pointing to builtin python in MSW case.
3d6f260c Draft.
728b922f Draft. Upstream.
cb6972a9 Draft.
2bf585a2 Draft.
f467416c Draft.
c5d34327 DRAFT.
158389f8 Draft.
d19d9818 DRAFT.
3e5fe38e Draft.
83ece852 Draft.
16cd796e Draft.
c97bad2d Draft.
a296c23b Draft.
5ebe98ec Draft.
c5097415 WIP.
89d98b7c Upstream.
a33ccede Draft.
18432721 Draft.
9a4fd9a4 Draft.
ac98df3d Draft.
f465cbdf DRAFT - GIT_CEILING_DIRECTORIES , condition on git subdirectory existence during setupUbiquitous .
7a2f7d20 Draft.
86f9fe7f Experiment.
e10d790d Draft.
fe3f2999 Experiment.
6e8896bf Documentation.
31e1bcf2 Draft.
30828f49 Upstream.
10474f00 Draft.
104abe01 Draft.
780b1cc0 Draft.
1b671795 Draft.
53f3a9df Draft.
029e11ec Experiment.
bef1aab4 Experiment.
9ae61460 Experiment.
e41591be Draft.
49adef3b Experiment.
8f7d299a Draft.
5469d146 Draft.
f9e74016 Draft.
46b80ac6 Correction.
4654f34a Draft.
3254b6c7 Draft.
07b7d64d Draft.
d6d18a8c Draft.
33d9c2a6 Draft.
e390d814 Experiment.
5feb09d5 Draft.
f3386728 Experiment.
066a742a Draft.
a1b76399 Experiment.
3814d4ca Experiment.
371a20bd Draft.
3be0f40c Draft.
d9c8ca2f Experiment.
a8f03433 Experiment.
24dbe4a5 Draft.
1c0fa69e Draft.
8be6e145 Draft.
51d104ff DRAFT.
48ccadec DRAFT - _write_configure_git_safe_directory_if_admin_owned .
f22a7e4b DRAFT.
ecd99562 DRAFT. Documentation.
a49b64e0 Correction.
ab8e6bf0 Correction.
77401f09 Draft - install hf cli with ubcp .
46597d29 Draft.
3e4f4176 Draft.
6d6caa7e Draft. Upstream.
4868a344 Upstream.
771993f6 Draft.
bb4304b6 Documentation.
a10a63c6 Draft - import _bashrc .
e6f9735b Draft - additional factory directories. Correction - format maxdepth . Correction - currentIteration limit semanticAssist .
8fc83f2f Draft. Draft - format_trial . Upstream.
96d6dc0f Correction - skip if first line of functionLine will already be first line .
e9b0871c Correction.
35ac70e3 Documentation.
2f4eafcb Upstream.
188e4b35 Draft - corrections.
6affd676 Compile.
77afe3b0 Draft - factory.
764d7bb4 Compile.
ffcd3062 Draft - format distill semanticAssist to JSONL . Upstream.
95e9723d Compile.
a0789e22 Draft - distill semanticAssist .
64fb738e Draft.
c5af4d21 Correction.
927e7db5 Draft - knowledge , semanticAssist .
6fcdc66a Documentation.
da949f70 Compile - ai dataset .
728d936e Draft.
43b7fb55 Draft.
fa31af60 Draft.
2fe09e0e Draft - ai _convert-bash .
2b736207 Draft - AI corpus . Documentation - placeholder for _doc-wget_githubRelease . Upstream - researchEngine .
6ffcd800 Correction.
fdb1d04c Draft - fromTag single page skip . Compile.
8dc59e58 DRAFT - _curl_githubAPI_releases_join-skip , disconnect aria2c from interactive terminal.
82d0576f DRAFT.
dd427a5d Draft. Documentation.
99fb4c06 DRAFT - destroy_lock .
9d639e24 Draft - currentURL_typeSelected for future use if needed to set current_curl_args , current_axel_args , etc .
7fb5b035 DRAFT.
a05dab74 DRAFT - header parameter to accept octet stream.
f2e5298d DRAFT - theoretically aria2c compatible GH_TOKEN parameters.
307fd70e Correction - aria2c does not support GitHub API URL requiring use of GH_TOKEN .
3b963584 Correction - aria2c does not support GitHub API URL requiring use of GH_TOKEN .
ae4bd3b7 Draft - analysis tag by tag rather than report by report .
f6c531d5 Documentation.
47cedeb6 Compile.
ed59256c Draft - rename incorrect use of currentReleaseLabel to currentReleaseTag for wget_githubRelease_tag .
bc5ee245 Correction.
c2c739c4 Draft.
ca0947bb Draft.
57124741 Correction.
d70dac11 Draft - fromTag-analysisReport . Draft - _build_fallback_upgrade-ubcp-fetch-fromTag . Experiment. Upstream.
d18cd423 Correction.
c65d95a7 Correction.
f12addd6 Draft - build.yml uses fetch-fromTag .
ba04f07a Compile.
3c8cba34 Correction.
2c5e15e6 Draft - conserve API calls without GH_TOKEN .
67624ad3 Draft - _wget_githubRelease-fromTag_join , parallel .
a3b8b993 Draft. Correction.
a1922cd8 Draft - improve jq syntax.
f13a417a Draft.
6be17587 Draft - wget_githubRelease_tag .
467b25bb Draft.
aa8657c3 Correction - diagnostic message.
3be61db6 Upstream.
31da65bb Correction.
b6d30e15 Correction.
c944dd69 Untracked file.
1df73c66 Draft.
748b4a3f Documentation. Draft.
b0ee5171 Draft.
13fd2427 Draft - _backend_override.
e34fcc6e Draft - _gitFresh_enable , ub_dryRun , ubdistChRoot , gitCompendium  . Documentation. Upstream.
```

Diff may be somewhat misleading: some code may have been de-duplicated or moved rather than deleted entirely.
```bash
git diff b03e7eb..e91f860 -- ./lean.py
```
```diff
diff --git a/lean.py b/lean.py
index ace6cc26..a67be530 100755
--- a/lean.py
+++ b/lean.py
@@ -182,48 +182,58 @@ import os
 #os.system("$HOME/.ubcore/ubiquitous_bash/ubcore.sh _bash -i ")
 #currentArguments = [currentArguments] if isinstance(currentArguments, str) else currentArguments
 #print(['ubiquitous_bash.sh', '_bash'] + currentArguments)
-def _bash(currentArguments = ['-i'], currentPrint = False, current_ubiquitous_bash = "ubiquitous_bash.sh"):
-	if current_ubiquitous_bash == "ubiquitous_bash.sh":
-		if os.path.exists(os.environ['HOME'] + "/.ubcore/ubiquitous_bash/ubcore.sh"):
-			current_ubiquitous_bash = (os.environ['HOME'] + "/.ubcore/ubiquitous_bash/ubcore.sh")
-	if current_ubiquitous_bash == "ubiquitous_bash.sh":
-		if os.path.exists("/cygdrive/c/core/infrastructure/ubiquitous_bash/ubcore.sh"):
-			current_ubiquitous_bash = "/cygdrive/c/core/infrastructure/ubiquitous_bash/ubcore.sh"
-	if current_ubiquitous_bash == "ubiquitous_bash.sh":
-		if os.path.exists("/cygdrive/c/core/infrastructure/lean/lean.sh"):
-			current_ubiquitous_bash = "/cygdrive/c/core/infrastructure/lean/lean.sh"
-	currentArguments = ['-i'] if currentArguments == '-i' else currentArguments
-	if isinstance(currentArguments, str):
-		# WARNING: Discouraged.
-		if not currentArguments == '-i':
-			currentProc = subprocess.Popen(current_ubiquitous_bash + " _bash " + currentArguments, stdout=subprocess.PIPE, universal_newlines=True, shell=True)
-			(currentOut, currentErr) = currentProc.communicate()
-			currentProc.wait()
-			currentOut = currentOut.rstrip('\n')
-			if currentPrint == True:
-				print(currentOut)
-				return (currentOut), currentProc.returncode
-		else:
-			currentProc = subprocess.Popen(current_ubiquitous_bash + " _bash " + currentArguments, universal_newlines=True, shell=True)
-			(currentOut, currentErr) = currentProc.communicate()
-			currentProc.wait()
-		return (currentOut), currentProc.returncode
-	else:
-		if not currentArguments == ['-i']:
-			currentArguments = [currentArguments] if isinstance(currentArguments, str) else currentArguments
-			currentProc = subprocess.Popen([current_ubiquitous_bash, '_bash'] + currentArguments, stdout=subprocess.PIPE, universal_newlines=True)
-			(currentOut, currentErr) = currentProc.communicate()
-			currentProc.wait()
-			currentOut = currentOut.rstrip('\n')
-			if currentPrint == True:
-				print(currentOut)
-				return (currentOut), currentProc.returncode
-		else:
-			currentArguments = [currentArguments] if isinstance(currentArguments, str) else currentArguments
-			currentProc = subprocess.Popen([current_ubiquitous_bash, '_bash'] + currentArguments, universal_newlines=True)
-			(currentOut, currentErr) = currentProc.communicate()
-			currentProc.wait()
-		return (currentOut), currentProc.returncode
+# ATTENTION: WARNING: Enjoy this python code. The '_bash' and '_bin' function are quite possibly, even probably, and for actual reasons for every line of code being annoying, the worst python code that will ever be written by people. In plainer language, only mess with parts of this code for which you have stopped to fully understand exactly why every negation, if/else, return, print, etc, is in the exact order that it is.
+def _bash(currentArguments = ['-i'], currentPrint = False, current_ubiquitous_bash = "ubiquitous_bash.sh", interactive=True):
+    if current_ubiquitous_bash == "ubiquitous_bash.sh":
+        if os.path.exists(os.environ.get("scriptCall_bash_msw", "").replace('\\', '/')):
+            current_ubiquitous_bash = os.environ.get("scriptCall_bash_msw", "").replace('\\', '/')
+    if current_ubiquitous_bash == "ubiquitous_bash.sh":
+        if os.path.exists(os.environ.get("scriptAbsoluteLocation", "")):
+            current_ubiquitous_bash = os.environ.get("scriptAbsoluteLocation", "")
+    if current_ubiquitous_bash == "ubiquitous_bash.sh":
+        if os.path.exists(os.environ['HOME'] + "/.ubcore/ubiquitous_bash/ubcore.sh"):
+            current_ubiquitous_bash = (os.environ['HOME'] + "/.ubcore/ubiquitous_bash/ubcore.sh")
+    if current_ubiquitous_bash == "ubiquitous_bash.sh":
+        if os.path.exists("/cygdrive/c/core/infrastructure/ubiquitous_bash/ubcore.sh"):
+            current_ubiquitous_bash = "/cygdrive/c/core/infrastructure/ubiquitous_bash/ubcore.sh"
+    if current_ubiquitous_bash == "ubiquitous_bash.sh":
+        if os.path.exists("/cygdrive/c/core/infrastructure/ubiquitous_bash/lean.sh"):
+            current_ubiquitous_bash = "/cygdrive/c/core/infrastructure/ubiquitous_bash/lean.sh"
+    currentArguments = ['-i'] if currentArguments == '-i' else currentArguments
+    if isinstance(currentArguments, str):
+    # WARNING: Discouraged.
+        if not ( ( currentArguments == '-i' ) or ( currentArguments == '' ) or ( interactive == True ) ):
+            # ATTENTION: WARNING: Use of 'stdout=subprocess.PIPE' is NOT compatible with interactive shell!
+            currentProc = subprocess.Popen(current_ubiquitous_bash + " _bash " + currentArguments, stdout=subprocess.PIPE, universal_newlines=True, shell=True)
+            (currentOut, currentErr) = currentProc.communicate()
+            currentProc.wait()
+            currentOut = currentOut.rstrip('\n')
+            if currentPrint == True:
+                print(currentOut)
+                return (currentOut), currentProc.returncode
+        else:
+            currentProc = subprocess.Popen(current_ubiquitous_bash + " _bash " + currentArguments, universal_newlines=True, shell=True)
+            (currentOut, currentErr) = currentProc.communicate()
+            currentProc.wait()
+        return (currentOut), currentProc.returncode
+    else:
+        if not ( ( currentArguments == ['-i'] ) or ( currentArguments == [''] ) or ( interactive == True ) ):
+            currentArguments = [currentArguments] if isinstance(currentArguments, str) else currentArguments
+            # ATTENTION: WARNING: Use of 'stdout=subprocess.PIPE' is NOT compatible with interactive shell!
+            currentProc = subprocess.Popen([current_ubiquitous_bash, '_bash'] + currentArguments, stdout=subprocess.PIPE, universal_newlines=True)
+            (currentOut, currentErr) = currentProc.communicate()
+            currentProc.wait()
+            currentOut = currentOut.rstrip('\n')
+            if currentPrint == True:
+                print(currentOut)
+                return (currentOut), currentProc.returncode
+        else:
+            if ( currentArguments == [''] ): currentArguments = ['-i']
+            currentArguments = [currentArguments] if isinstance(currentArguments, str) else currentArguments
+            currentProc = subprocess.Popen([current_ubiquitous_bash, '_bash'] + currentArguments, universal_newlines=True)
+            (currentOut, currentErr) = currentProc.communicate()
+            currentProc.wait()
+        return (currentOut), currentProc.returncode



@@ -247,48 +257,61 @@ import os
 #_bin('_bash')
 #print( _bin('_false', False)[1] )
 #_bin("_getScriptAbsoluteLocation", True, os.path.expanduser("~/core/infrastructure/ubiquitous_bash/ubiquitous_bash.sh"))
-def _bin(currentArguments = [''], currentPrint = False, current_ubiquitous_bash = "ubiquitous_bash.sh"):
-	if current_ubiquitous_bash == "ubiquitous_bash.sh":
-		if os.path.exists(os.environ['HOME'] + "/.ubcore/ubiquitous_bash/ubcore.sh"):
-			current_ubiquitous_bash = (os.environ['HOME'] + "/.ubcore/ubiquitous_bash/ubcore.sh")
-	if current_ubiquitous_bash == "ubiquitous_bash.sh":
-		if os.path.exists("/cygdrive/c/core/infrastructure/ubiquitous_bash/ubcore.sh"):
-			current_ubiquitous_bash = "/cygdrive/c/core/infrastructure/ubiquitous_bash/ubcore.sh"
-	if current_ubiquitous_bash == "ubiquitous_bash.sh":
-		if os.path.exists("/cygdrive/c/core/infrastructure/lean/lean.sh"):
-			current_ubiquitous_bash = "/cygdrive/c/core/infrastructure/lean/lean.sh"
-	currentArguments = [''] if currentArguments == '' else currentArguments
-	if isinstance(currentArguments, str):
-		# WARNING: Discouraged.
-		if not ( ( currentArguments == '/bin/bash -i' ) or ( currentArguments == '/bin/bash' ) ):
-			currentProc = subprocess.Popen(current_ubiquitous_bash + " _bin " + currentArguments, stdout=subprocess.PIPE, universal_newlines=True, shell=True)
-			(currentOut, currentErr) = currentProc.communicate()
-			currentProc.wait()
-			currentOut = currentOut.rstrip('\n')
-			if currentPrint == True:
-				print(currentOut)
-				return (currentOut), currentProc.returncode
-		else:
-			currentProc = subprocess.Popen(current_ubiquitous_bash + " _bin " + currentArguments, universal_newlines=True, shell=True)
-			(currentOut, currentErr) = currentProc.communicate()
-			currentProc.wait()
-		return (currentOut), currentProc.returncode
-	else:
-		if not (  ( currentArguments == ['/bin/bash', '-i'] ) or ( currentArguments == ['/bin/bash'] ) or ( currentArguments == ['_qalculate', ''] ) or ( currentArguments == ['_qalculate'] ) or ( currentArguments == ['_octave', ''] ) or ( currentArguments == ['_octave'] )  ):
-			currentArguments = [currentArguments] if isinstance(currentArguments, str) else currentArguments
-			currentProc = subprocess.Popen([current_ubiquitous_bash, '_bin'] + currentArguments, stdout=subprocess.PIPE, universal_newlines=True)
-			(currentOut, currentErr) = currentProc.communicate()
-			currentProc.wait()
-			currentOut = currentOut.rstrip('\n')
-			if currentPrint == True:
-				print(currentOut)
-				return (currentOut), currentProc.returncode
-		else:
-			currentArguments = [currentArguments] if isinstance(currentArguments, str) else currentArguments
-			currentProc = subprocess.Popen([current_ubiquitous_bash, '_bin'] + currentArguments, universal_newlines=True)
-			(currentOut, currentErr) = currentProc.communicate()
-			currentProc.wait()
-		return (currentOut), currentProc.returncode
+# ATTENTION: WARNING: Enjoy this python code. The '_bash' and '_bin' function are quite possibly, even probably, and for actual reasons for every line of code being annoying, the worst python code that will ever be written by people. In plainer language, only mess with parts of this code for which you have stopped to fully understand exactly why every negation, if/else, return, print, etc, is in the exact order that it is.
+def _bin(currentArguments = [''], currentPrint = False, current_ubiquitous_bash = "ubiquitous_bash.sh", interactive=False):
+    if current_ubiquitous_bash == "ubiquitous_bash.sh":
+        if os.path.exists(os.environ.get("scriptCall_bash_msw", "").replace('\\', '/')):
+            current_ubiquitous_bash = os.environ.get("scriptCall_bash_msw", "").replace('\\', '/')
+    if current_ubiquitous_bash == "ubiquitous_bash.sh":
+        if os.path.exists(os.environ.get("scriptAbsoluteLocation", "")):
+            current_ubiquitous_bash = os.environ.get("scriptAbsoluteLocation", "")
+    if current_ubiquitous_bash == "ubiquitous_bash.sh":
+        if os.path.exists(os.environ['HOME'] + "/.ubcore/ubiquitous_bash/ubcore.sh"):
+            current_ubiquitous_bash = (os.environ['HOME'] + "/.ubcore/ubiquitous_bash/ubcore.sh")
+    if current_ubiquitous_bash == "ubiquitous_bash.sh":
+        if os.path.exists("/cygdrive/c/core/infrastructure/ubiquitous_bash/ubcore.sh"):
+            current_ubiquitous_bash = "/cygdrive/c/core/infrastructure/ubiquitous_bash/ubcore.sh"
+    if current_ubiquitous_bash == "ubiquitous_bash.sh":
+        if os.path.exists("/cygdrive/c/core/infrastructure/ubiquitous_bash/lean.sh"):
+            current_ubiquitous_bash = "/cygdrive/c/core/infrastructure/ubiquitous_bash/lean.sh"
+    # ATTENTION: Comment out next python line of code to test this code with an empty string.
+    #./lean.py "_bin('', currentPrint=True)"
+    currentArguments = [''] if currentArguments == '' else currentArguments
+    if isinstance(currentArguments, str):
+        # WARNING: Discouraged.
+        if not ( ( ( currentArguments == '/bin/bash -i' ) or ( currentArguments == '/bin/bash' ) or ( currentArguments == '_bash' ) or ( currentArguments == '' ) ) or ( interactive == True ) ) :
+            # ATTENTION: WARNING: Use of 'stdout=subprocess.PIPE' is NOT compatible with interactive shell!
+            currentProc = subprocess.Popen(current_ubiquitous_bash + " _bin " + currentArguments, stdout=subprocess.PIPE, universal_newlines=True, shell=True)
+            (currentOut, currentErr) = currentProc.communicate()
+            currentProc.wait()
+            currentOut = currentOut.rstrip('\n')
+            if currentPrint == True:
+                print(currentOut)
+                return (currentOut), currentProc.returncode
+        else:
+            if ( currentArguments == '' ): currentArguments = '_bash'
+            currentProc = subprocess.Popen(current_ubiquitous_bash + " _bin " + currentArguments, universal_newlines=True, shell=True)
+            (currentOut, currentErr) = currentProc.communicate()
+            currentProc.wait()
+        return (currentOut), currentProc.returncode
+    else:
+        if not ( ( ( currentArguments == ['/bin/bash', '-i'] ) or ( currentArguments == ['/bin/bash'] ) or ( currentArguments == ['_bash'] ) or ( currentArguments == ['_bash', '-i'] ) or ( currentArguments == ['_qalculate', ''] ) or ( currentArguments == ['_qalculate'] ) or ( currentArguments == ['_octave', ''] ) or ( currentArguments == ['_octave'] ) or ( currentArguments == [''] ) ) or ( interactive == True ) ):
+            currentArguments = [currentArguments] if isinstance(currentArguments, str) else currentArguments
+            # ATTENTION: WARNING: Use of 'stdout=subprocess.PIPE' is NOT compatible with interactive shell!
+            currentProc = subprocess.Popen([current_ubiquitous_bash, '_bin'] + currentArguments, stdout=subprocess.PIPE, universal_newlines=True)
+            (currentOut, currentErr) = currentProc.communicate()
+            currentProc.wait()
+            currentOut = currentOut.rstrip('\n')
+            if currentPrint == True:
+                print(currentOut)
+                return (currentOut), currentProc.returncode
+        else:
+            if ( currentArguments == [''] ): currentArguments = ['_bash']
+            currentArguments = [currentArguments] if isinstance(currentArguments, str) else currentArguments
+            currentProc = subprocess.Popen([current_ubiquitous_bash, '_bin'] + currentArguments, universal_newlines=True)
+            (currentOut, currentErr) = currentProc.communicate()
+            currentProc.wait()
+        return (currentOut), currentProc.returncode

 # ATTENTION: Only intended for indirect calls.
 # https://stackoverflow.com/questions/5067604/determine-function-name-from-within-that-function-without-using-traceback
@@ -364,15 +387,54 @@ def _octave(currentString = [], currentArguments = [], currentPrint = False, cur



-import readline # optional, will allow Up/Down/History in the console
+if sys.platform == 'win32':
+    try:
+        import pyreadline3 as readline
+    except ImportError:
+        readline = None
+else:
+    try:
+        import readline # optional, will allow Up/Down/History in the console
+    except ImportError:
+        readline = None
 import code
+
+# ATTRIBUTION-AI: ChatGPT o3  2025-04-19
+def _enable_readline():
+    """
+    Make sure arrow keys, history and TAB completion work in the
+    interpreter that we embed with code.InteractiveConsole.
+    """
+    try:
+        import readline, rlcompleter, atexit, os
+        # basic key bindings
+        readline.parse_and_bind('tab: complete')
+        # persistent history file
+        histfile = os.path.expanduser('~/.pyhistory')
+        if os.path.exists(histfile):
+            readline.read_history_file(histfile)
+        atexit.register(readline.write_history_file, histfile)
+    except ImportError:
+        # readline (or pyreadline on Windows) is not available
+        pass
+
+
+
+
 #_python()
 # https://stackoverflow.com/questions/5597836/embed-create-an-interactive-python-shell-inside-a-python-program
 def _python():
-	variables = globals().copy()
-	variables.update(locals())
-	shell = code.InteractiveConsole(variables)
-	shell.interact()
+    _enable_readline()
+    variables = globals().copy()
+    variables.update(locals())
+    shell = code.InteractiveConsole(variables)
+    # ATTRIBUTION-AI: ChatGPT 4.1  2025-04-19
+    if os.name == 'nt':  # True on Windows
+        print(" Press Ctrl+D twice (or Ctrl+Z then Enter) to exit this Python shell.")
+    if os.name == 'posix':
+        print(" Press Ctrl+D twice (or Ctrl+Z then Enter) to exit this Python shell.")
+    # ATTRIBUTION: NOT AI !
+    shell.interact()



@@ -381,33 +443,117 @@ import os
 import socket
 import string
 import re
-#if sys.hexversion < 0x03060000:
-#	exit(1)
-# https://www.codementor.io/@arpitbhayani/personalize-your-python-prompt-13ts4kw6za
-# https://stackoverflow.com/questions/4271740/how-can-i-use-python-to-get-the-system-hostname
-# https://bugs.python.org/issue20359
-#os.environ['PWD']
-#os.path.expanduser(os.getcwd())
-#\033[0;35;47mpython-%d\033[0m
-#return "\033[92mIn [%d]:\033[0m " % (self.line)
-#return ">>> "
-#return "\033[1;94m|\033[91m#:\033[1;93m%s\033[1;92m@%s\033[1;94m)-%s(\033[1;95m\033[0;35;47mpython-%s\033[0m\033[1;94m)\033[1;96m|\n\033[1;94m|\033[1;97m[%s]\n\033[1;94m|\033[1;96m%d\033[1;94m) \033[1;96m>\033[0m " % (os.getenv('USER','root'), socket.gethostname(), os.environ.get('prompt_cloudNetName', ''), hex(sys.hexversion), re.sub('^%s' % os.environ['HOME'], '~', os.path.expanduser(os.getcwd()) ), self.line)
-#return "\033[1;94m|\033[91m#:\033[1;93m%s\033[1;92m@%s\033[1;94m)-%s(\033[1;95m\033[0;35;47mpython-%s\033[0m\033[1;94m)\033[1;96m|\n\033[1;94m|\033[1;97m[%s]\n\033[1;94m|%d\033[1;94m) \033[1;96m>\033[0m " % (os.getenv('USER','root'), socket.gethostname(), os.environ.get('prompt_cloudNetName', ''), hex(sys.hexversion), re.sub('^%s' % os.environ['HOME'], '~', os.path.expanduser(os.getcwd()) ), self.line)
-#os.environ['USER']
-#os.getenv('USER','root')
-class ubPythonPS1(object):
-	def __init__(self):
-		self.line = 0
-
-	def __str__(self):
-		self.line += 1
-		if self.line == 1:
-			return "\x01\033[1;94m\x02|\x01\033[91m\x02#:\x01\033[1;93m\x02%s\x01\033[1;92m\x02@%s\x01\033[1;94m\x02)-%s(\x01\033[1;95m\x02\x01\033[0;35;47m\x02python-%s\x01\033[0m\x02\x01\033[1;94m\x02)\x01\033[1;96m\x02|\n\x01\033[1;94m\x02|\x01\033[1;97m\x02[%s]\n\x01\033[1;94m\x02|\x01\033[1;96m\x02%d\x01\033[1;94m\x02) \x01\033[1;96m\x02>\x01\033[0m\x02 " % (os.getenv('USER','root'), socket.gethostname(), os.environ.get('prompt_cloudNetName', ''), hex(sys.hexversion), re.sub('^%s' % os.environ['HOME'], '~', os.path.expanduser(os.getcwd()) ), self.line)
-		else:
-			return "\x01\033[1;94m\x02|\x01\033[91m\x02#:\x01\033[1;93m\x02%s\x01\033[1;92m\x02@%s\x01\033[1;94m\x02)-%s(\x01\033[1;95m\x02\x01\033[0;35;47m\x02python-%s\x01\033[0m\x02\x01\033[1;94m\x02)\x01\033[1;96m\x02|\n\x01\033[1;94m\x02|\x01\033[1;97m\x02[%s]\n\x01\033[1;94m\x02|%d\x01\033[1;94m\x02) \x01\033[1;96m\x02>\x01\033[0m\x02 " % (os.getenv('USER','root'), socket.gethostname(), os.environ.get('prompt_cloudNetName', ''), hex(sys.hexversion), re.sub('^%s' % os.environ['HOME'], '~', os.path.expanduser(os.getcwd()) ), self.line)
-
-sys.ps1 = ubPythonPS1()
-sys.ps2 = "\x01\033[0;96m\x02|...\x01\033[0m\x02 "
+
+# ATTRIBUTION-AI: OpRt_.nvidia/llama-3.1-nemotron-ultra-253b-v1:free  2025-04-18  (partially)
+# Determine if running on Windows
+is_windows = os.name == 'nt'
+
+# ATTRIBUTION-AI: OpRt_.nvidia/llama-3.1-nemotron-ultra-253b-v1:free  2025-04-18  (partially)
+# Attempt to import colorama if on Windows
+use_colorama = False
+if is_windows:
+    try:
+        from colorama import init, Fore, Back, Style
+        init(autoreset=True)
+        use_colorama = True
+    except ImportError:
+        pass  # Silently proceed without colorama if import fails
+
+# Color definitions (use ANSI if not on Windows or colorama is not used)
+if use_colorama:
+    # ATTRIBUTION-AI: OpRt_.nvidia/llama-3.1-nemotron-ultra-253b-v1:free  2025-04-18  (partially)  ( also the preceeding line  if use_colorama:  )
+    class ubPythonPS1(object):
+        def __init__(self):
+            self.line = 0
+
+        def __str__(self):
+            self.line += 1
+            user = os.getenv('USER', 'root')
+            hostname = socket.gethostname()
+            cloud_net_name = os.environ.get('prompt_cloudNetName', '')
+            #py_version = f"v{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}"
+            ## ATTRIBUTION-AI: OpRt_.nvidia/llama-3.1-nemotron-ultra-253b-v1:free  2025-04-19
+            #py_version = f"v{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}" if not os.getenv('VIRTUAL_ENV_PROMPT') else os.getenv('VIRTUAL_ENV_PROMPT', '')
+            # ATTRIBUTION-AI: ChatGPT o3  2025-04-19
+            py_version = os.getenv("VIRTUAL_ENV_PROMPT") or f"Python-v{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}"
+            cwd = os.path.expanduser(os.getcwd())
+
+            home_dir = os.environ.get('HOME', os.environ.get('USERPROFILE', ''))
+            if home_dir:
+                cwd = re.sub(f'^{re.escape(home_dir)}', '~', cwd)
+
+            # Color definitions (matched to ANSI colors)
+            blue = Fore.BLUE
+            red = Fore.RED
+            green = Fore.GREEN  # Hostname color
+            yellow = Fore.YELLOW
+            magenta = Fore.MAGENTA  # Python version color
+            cyan = Fore.CYAN
+            white = Fore.WHITE
+            reset = Style.RESET_ALL
+            bg_white = Back.WHITE
+
+            if self.line == 1:
+                prompt = (
+                    f"{blue}|{red}#{red}:{yellow}{user}{green}@{green}{hostname}{blue})-{cloud_net_name}({magenta}{bg_white}{py_version}{reset}{blue}){cyan}|\n"
+                    #f"{blue}|{white}[{cwd}]\n"
+                    f"{white}{cwd}\n"
+                    f"{blue}|{cyan}{self.line}{blue}) {cyan}> {reset}"
+                )
+            else:
+                prompt = (
+                    f"{blue}|{red}#{red}:{yellow}{user}{green}@{green}{hostname}{blue})-{cloud_net_name}({magenta}{bg_white}{py_version}{reset}{blue}){cyan}|\n"
+                    #f"{blue}|{white}[{cwd}]\n"
+                    f"{white}{cwd}\n"
+                    f"{blue}|{blue}{self.line}{blue}) {cyan}> {reset}"
+                )
+            return prompt
+
+    sys.ps1 = ubPythonPS1()
+    sys.ps2 = f"{Fore.CYAN}|...{Style.RESET_ALL} "
+else:
+    # ATTRIBUTION: NOT AI !
+    #if sys.hexversion < 0x03060000:
+    #	exit(1)
+    # https://www.codementor.io/@arpitbhayani/personalize-your-python-prompt-13ts4kw6za
+    # https://stackoverflow.com/questions/4271740/how-can-i-use-python-to-get-the-system-hostname
+    # https://bugs.python.org/issue20359
+    #os.environ['PWD']
+    #os.path.expanduser(os.getcwd())
+    #\033[0;35;47mpython-%d\033[0m
+    #return "\033[92mIn [%d]:\033[0m " % (self.line)
+    #return ">>> "
+    #return "\033[1;94m|\033[91m#:\033[1;93m%s\033[1;92m@%s\033[1;94m)-%s(\033[1;95m\033[0;35;47mpython-%s\033[0m\033[1;94m)\033[1;96m|\n\033[1;94m|\033[1;97m[%s]\n\033[1;94m|\033[1;96m%d\033[1;94m) \033[1;96m>\033[0m " % (os.getenv('USER','root'), socket.gethostname(), os.environ.get('prompt_cloudNetName', ''), hex(sys.hexversion), re.sub('^%s' % os.environ['HOME'], '~', os.path.expanduser(os.getcwd()) ), self.line)
+    #return "\033[1;94m|\033[91m#:\033[1;93m%s\033[1;92m@%s\033[1;94m)-%s(\033[1;95m\033[0;35;47mpython-%s\033[0m\033[1;94m)\033[1;96m|\n\033[1;94m|\033[1;97m[%s]\n\033[1;94m|%d\033[1;94m) \033[1;96m>\033[0m " % (os.getenv('USER','root'), socket.gethostname(), os.environ.get('prompt_cloudNetName', ''), hex(sys.hexversion), re.sub('^%s' % os.environ['HOME'], '~', os.path.expanduser(os.getcwd()) ), self.line)
+    #os.environ['USER']
+    #os.getenv('USER','root')
+    class ubPythonPS1(object):
+        def __init__(self):
+            self.line = 0
+
+        def __str__(self):
+            self.line += 1
+            if self.line == 1:
+                #return "\x01\033[1;94m\x02|\x01\033[91m\x02#:\x01\033[1;93m\x02%s\x01\033[1;92m\x02@%s\x01\033[1;94m\x02)-%s(\x01\033[1;95m\x02\x01\033[0;35;47m\x02python-%s\x01\033[0m\x02\x01\033[1;94m\x02)\x01\033[1;96m\x02|\n\x01\033[1;94m\x02|\x01\033[1;97m\x02[%s]\n\x01\033[1;94m\x02|\x01\033[1;96m\x02%d\x01\033[1;94m\x02) \x01\033[1;96m\x02>\x01\033[0m\x02 " % (os.getenv('USER','root'), socket.gethostname(), os.environ.get('prompt_cloudNetName', ''), hex(sys.hexversion), re.sub('^%s' % os.environ['HOME'], '~', os.path.expanduser(os.getcwd()) ), self.line)
+                #return "\x01\033[1;94m\x02|\x01\033[91m\x02#:\x01\033[1;93m\x02%s\x01\033[1;92m\x02@%s\x01\033[1;94m\x02)-%s(\x01\033[1;95m\x02\x01\033[0;35;47m\x02python-%s\x01\033[0m\x02\x01\033[1;94m\x02)\x01\033[1;96m\x02|\n\x01\033[1;97m\x02%s\n\x01\033[1;94m\x02|\x01\033[1;96m\x02%d\x01\033[1;94m\x02) \x01\033[1;96m\x02>\x01\033[0m\x02 " % (os.getenv('USER','root'), socket.gethostname(), os.environ.get('prompt_cloudNetName', ''), hex(sys.hexversion), re.sub('^%s' % os.environ['HOME'], '~', os.path.expanduser(os.getcwd()) ), self.line)
+                # ATTRIBUTION-AI: OpRt_.nvidia/llama-3.1-nemotron-ultra-253b-v1:free  2025-04-19
+                return "\x01\033[1;94m\x02|\x01\033[91m\x02#:\x01\033[1;93m\x02%s\x01\033[1;92m\x02@%s\x01\033[1;94m\x02)-%s(\x01\033[1;95m\x02\x01\033[0;35;47m\x02python-%s\x01\033[0m\x02\x01\033[1;94m\x02)\x01\033[1;96m\x02|\n\x01\033[1;97m\x02%s\n\x01\033[1;94m\x02|\x01\033[1;96m\x02%d\x01\033[1;94m\x02) \x01\033[1;96m\x02>\x01\033[0m\x02 " % (os.getenv('USER','root'), socket.gethostname(), os.environ.get('prompt_cloudNetName', ''), hex(sys.hexversion) if 'VIRTUAL_ENV_PROMPT' not in os.environ or not os.environ['VIRTUAL_ENV_PROMPT'] else os.environ['VIRTUAL_ENV_PROMPT'], re.sub('^%s' % os.environ['HOME'], '~', os.path.expanduser(os.getcwd()) ), self.line)
+            else:
+                #return "\x01\033[1;94m\x02|\x01\033[91m\x02#:\x01\033[1;93m\x02%s\x01\033[1;92m\x02@%s\x01\033[1;94m\x02)-%s(\x01\033[1;95m\x02\x01\033[0;35;47m\x02python-%s\x01\033[0m\x02\x01\033[1;94m\x02)\x01\033[1;96m\x02|\n\x01\033[1;94m\x02|\x01\033[1;97m\x02[%s]\n\x01\033[1;94m\x02|%d\x01\033[1;94m\x02) \x01\033[1;96m\x02>\x01\033[0m\x02 " % (os.getenv('USER','root'), socket.gethostname(), os.environ.get('prompt_cloudNetName', ''), hex(sys.hexversion), re.sub('^%s' % os.environ['HOME'], '~', os.path.expanduser(os.getcwd()) ), self.line)
+                #return "\x01\033[1;94m\x02|\x01\033[91m\x02#:\x01\033[1;93m\x02%s\x01\033[1;92m\x02@%s\x01\033[1;94m\x02)-%s(\x01\033[1;95m\x02\x01\033[0;35;47m\x02python-%s\x01\033[0m\x02\x01\033[1;94m\x02)\x01\033[1;96m\x02|\n\x01\033[1;97m\x02%s\n\x01\033[1;94m\x02|%d\x01\033[1;94m\x02) \x01\033[1;96m\x02>\x01\033[0m\x02 " % (os.getenv('USER','root'), socket.gethostname(), os.environ.get('prompt_cloudNetName', ''), hex(sys.hexversion), re.sub('^%s' % os.environ['HOME'], '~', os.path.expanduser(os.getcwd()) ), self.line)
+                # ATTRIBUTION-AI: OpRt_.nvidia/llama-3.1-nemotron-ultra-253b-v1:free  2025-04-19
+                return "\x01\033[1;94m\x02|\x01\033[91m\x02#:\x01\033[1;93m\x02%s\x01\033[1;92m\x02@%s\x01\033[1;94m\x02)-%s(\x01\033[1;95m\x02\x01\033[0;35;47m\x02python-%s\x01\033[0m\x02\x01\033[1;94m\x02)\x01\033[1;96m\x02|\n\x01\033[1;97m\x02%s\n\x01\033[1;94m\x02|%d\x01\033[1;94m\x02) \x01\033[1;96m\x02>\x01\033[0m\x02 " % (os.getenv('USER','root'), socket.gethostname(), os.environ.get('prompt_cloudNetName', ''), hex(sys.hexversion) if 'VIRTUAL_ENV_PROMPT' not in os.environ or not os.environ['VIRTUAL_ENV_PROMPT'] else os.environ['VIRTUAL_ENV_PROMPT'], re.sub('^%s' % os.environ['HOME'], '~', os.path.expanduser(os.getcwd()) ), self.line)
+
+    sys.ps1 = ubPythonPS1()
+    sys.ps2 = "\x01\033[0;96m\x02|...\x01\033[0m\x02 "
+
+
+# ATTRIBUTION-AI: OpRt_.nvidia/llama-3.1-nemotron-ultra-253b-v1:free  2025-04-18 (only the next line  if is_windows and not use_colorama:  )
+if is_windows and not use_colorama:
+    # ATTRIBUTION: NOT AI !
+    # https://www.codementor.io/@arpitbhayani/personalize-your-python-prompt-13ts4kw6za
+    sys.ps1 = '>>> '
+    sys.ps2 = '... '

 #_python()

```

```bash
git diff b03e7eb..e91f860 -- ./ubiquitous_bash.sh
```
```diff
diff --git a/ubiquitous_bash.sh b/ubiquitous_bash.sh
index 4a66375d..44581035 100755
--- a/ubiquitous_bash.sh
+++ b/ubiquitous_bash.sh
@@ -36,7 +36,7 @@ _ub_cksum_special_derivativeScripts_contents() {
 #export ub_setScriptChecksum_disable='true'
 ( [[ -e "$0".nck ]] || [[ "${BASH_SOURCE[0]}" != "${0}" ]] || [[ "$1" == '--profile' ]] || [[ "$1" == '--script' ]] || [[ "$1" == '--call' ]] || [[ "$1" == '--return' ]] || [[ "$1" == '--devenv' ]] || [[ "$1" == '--shell' ]] || [[ "$1" == '--bypass' ]] || [[ "$1" == '--parent' ]] || [[ "$1" == '--embed' ]] || [[ "$1" == '--compressed' ]] || [[ "$0" == "/bin/bash" ]] || [[ "$0" == "-bash" ]] || [[ "$0" == "/usr/bin/bash" ]] || [[ "$0" == "bash" ]] ) && export ub_setScriptChecksum_disable='true'
 export ub_setScriptChecksum_header='2591634041'
-export ub_setScriptChecksum_contents='179971738'
+export ub_setScriptChecksum_contents='3755649542'

 # CAUTION: Symlinks may cause problems. Disable this test for such cases if necessary.
 # WARNING: Performance may be crucial here.
@@ -650,7 +650,7 @@ _____special_live_dent_restore() {

 # WARNING: Multiple reasons to instead consider direct detection by other commands -  ' uname -a | grep -i cygwin > /dev/null 2>&1 ' , ' [[ -e '/cygdrive' ]] ' , etc .
 _if_cygwin() {
-	if uname -a | grep -i cygwin > /dev/null 2>&1
+	if uname -a 2>/dev/null | grep -i cygwin > /dev/null 2>&1
 	then
 		return 0
 	fi
@@ -747,8 +747,212 @@ then
 fi


+
 if _if_cygwin
 then
+	# ATTRIBUTION-AI: ChatGPT 4.5-preview  2025-04-11  with knowledge ubiquitous_bash, etc
+	# Prioritizes native git binaries if available. Mostly a disadvantage over the Cygwin/MSW git binaries, but adds more usable git-lfs , and works surprisingly well, apparently still defaulting to: Cygwin HOME '.gitconfig' , Cygwin '/usr/bin/ssh' , correctly understanding the overrides of '_gitBest' , etc.
+	#  Alternatives:
+	#   git-lfs compiled for Cygwin/MSW - requires installing 'go' compiler for Cygwin/MSW
+	#   git fetch commands - manual effort
+	#   wrapper script to detect git lfs error and retry with subsequent separate fetch - technically possible
+	#   avoid git-lfs - usually sufficient
+	_override_msw_git() {
+		local git_path="/cygdrive/c/Program Files/Git/cmd"
+
+		# Optionally iterate through additional drive letters:
+		# for drive in c ; do
+		# for drive in c d e f g h i j k l m n o p q r s t u v w D E F G H I J K L M N O P Q R S T U V W ; do
+		#   local git_path="/cygdrive/${drive}/Program Files/Git/cmd"
+		#   if [ -d "${git_path}" ]; then
+		#     break
+		#   fi
+		# done
+
+		[ -d "$git_path" ] || return 0  # Return quietly if the git_path is not a directory
+
+		# ATTENTION: To use with 'ops.sh' or similar if necessary, appropriate, and safe.
+		export PATH_pre_override_git="$PATH"
+
+		local path_entry entry IFS=':'
+		local new_path=""
+
+		for entry in $PATH ; do
+			# Skip adding if this entry matches git_path exactly
+			[ "$entry" = "$git_path" ] && continue
+
+			# Append current entry to the new_path
+			if [ -z "$new_path" ]; then
+				new_path="$entry"
+			else
+				new_path="${new_path}:${entry}"
+			fi
+		done
+
+		# Finally, explicitly prepend the git path
+		export PATH="${git_path}:${new_path}"
+
+		#( _messagePlain_probe_var PATH >&2 ) > /dev/null
+		#( _messagePlain_probe_var PATH_pre_override_git >&2 ) > /dev/null
+
+		# CAUTION: DANGER: MSW native git binaries can perceive 'parent directories' outside the 'root' directory provided by Cygwin, equivalent to calling git binaries through remote (eg. SSH, etc) commands to a filesystem encapsulating a ChRoot !
+		#  This function limits that behavior, especially for 'ubiquitous_bash' projects with MSW installers shipping standalone 'ubcp' environments.
+		_override_msw_git_CEILING() {
+			# On the unusual occasion "$scriptLocal" is defined as something other than "$scriptAbsoluteFolder"/_local, the 'ubcp' directory is not expected to have been included as a standard subdirectory under any other definition of "$scriptLocal" . Since this information is only used to add redundant configuration (ie. directories are not created, etc), no issues should be possible.
+			#current_script_ubcp_msw=$(cygpath -w "$scriptLocal")
+			current_script_ubcp_msw=$(cygpath -w "$scriptAbsoluteFolder"/_local)
+			current_script_ubcp_msw_escaped="${current_script_ubcp_msw//\\/\\\\}"
+			current_script_ubcp_msw_slash="${current_script_ubcp_msw//\\/\/}"
+
+			# ONLY for the MSW git binaries override case (if "$git_path" is not valid, this function will already return before this)
+			export GIT_CEILING_DIRECTORIES="/home/root/.ubcore/ubiquitous_bash;/home/root/.ubcore;/home/root;/cygdrive;/cygdrive/d/a/ubiquitous_bash/ubiquitous_bash;/cygdrive/c/a/ubiquitous_bash/ubiquitous_bash;C:\core\infrastructure\ubcp\cygwin;C:\q\p\zCore\infrastructure\ubiquitous_bash\_local\ubcp\cygwin;C:\core\infrastructure\extendedInterface\_local\ubcp;C:\core\infrastructure\ubDistBuild\_local\ubcp"
+
+			[[ "$scriptAbsoluteFolder" != "" ]] && export GIT_CEILING_DIRECTORIES="$GIT_CEILING_DIRECTORIES"';'"$current_script_ubcp_msw"
+		}
+		#export -f _override_msw_git_CEILING
+		_override_msw_git_CEILING
+	}
+	# CAUTION: Early in the script for a reason! Changing the PATH drastically later has been known to cause WSL 'bash' to override Cygwin 'bash' with very obviously unpredictable results.
+	#  ATTENTION: There would be a '_test' function in 'ubiquitous_bash' for this, but the state of 'wsl' which may not be installed with 'ubdist', etc, is not necessarily predictable enough for a simple PASS/FAIL .
+	#if [[ "$1" != "_setupUbiquitous" ]] && [[ "$ub_under_setupUbiquitous" != "true" ]]
+	#then
+		_override_msw_git
+		#_override_msw_git_CEILING
+	#fi
+
+	# ATTRIBUTION-AI: ChatGPT 4.5-preview  2025-04-11  with knowledge ubiquitous_bash, etc  (partially)
+	# ATTRIBUTION-AI: ChatGPT 4o  2025-04-12  web search  (partially)
+	# ATTRIBUTION-AI: ChatGPT o3-mini-high  2025-04-12
+	_write_configure_git_safe_directory_if_admin_owned_sequence() {
+		local functionEntryPWD="$PWD"
+
+		# DUBIOUS
+		local functionEntry_GIT_DIR="$GIT_DIR"
+		local functionEntry_GIT_WORK_TREE="$GIT_WORK_TREE"
+		local functionEntry_GIT_INDEX_FILE="$GIT_INDEX_FILE"
+		local functionEntry_GIT_OBJECT_DIRECTORY="$GIT_OBJECT_DIRECTORY"
+		#local functionEntry_GIT_ALTERNATE_OBJECT_DIRECTORIES="$GIT_ALTERNATE_OBJECT_DIRECTORIES"
+		local functionEntry_GIT_CONFIG="$GIT_CONFIG"
+		local functionEntry_GIT_CONFIG_GLOBAL="$GIT_CONFIG_GLOBAL"
+		local functionEntry_GIT_CONFIG_SYSTEM="$GIT_CONFIG_SYSTEM"
+		local functionEntry_GIT_CONFIG_NOSYSTEM="$GIT_CONFIG_NOSYSTEM"
+		#local functionEntry_GIT_AUTHOR_NAME="$GIT_AUTHOR_NAME"
+		#local functionEntry_GIT_AUTHOR_EMAIL="$GIT_AUTHOR_EMAIL"
+		#local functionEntry_GIT_AUTHOR_DATE="$GIT_AUTHOR_DATE"
+		#local functionEntry_GIT_COMMITTER_NAME="$GIT_COMMITTER_NAME"
+		#local functionEntry_GIT_COMMITTER_EMAIL="$GIT_COMMITTER_EMAIL"
+		#local functionEntry_GIT_COMMITTER_DATE="$GIT_COMMITTER_DATE"
+		#local functionEntry_GIT_EDITOR="$GIT_EDITOR"
+		#local functionEntry_GIT_PAGER="$GIT_PAGER"
+		local functionEntry_GIT_NAMESPACE="$GIT_NAMESPACE"
+		local functionEntry_GIT_CEILING_DIRECTORIES="$GIT_CEILING_DIRECTORIES"
+		local functionEntry_GIT_DISCOVERY_ACROSS_FILESYSTEM="$GIT_DISCOVERY_ACROSS_FILESYSTEM"
+		#local functionEntry_GIT_SSL_NO_VERIFY="$GIT_SSL_NO_VERIFY"
+		#local functionEntry_GIT_SSH="$GIT_SSH"
+		#local functionEntry_GIT_SSH_COMMAND="$GIT_SSH_COMMAND"
+
+		git config --global --add safe.directory "$1"
+		#if [[ $(type -p git) != '/usr/bin/git' ]]
+		#then
+			##git config --global --add safe.directory "$2"
+			git config --global --add safe.directory "$3"
+			git config --global --add safe.directory "$4"
+		#fi
+
+		cd "$functionEntryPWD"
+
+		# DUBIOUS
+		GIT_DIR="$functionEntry_GIT_DIR"
+		GIT_WORK_TREE="$functionEntry_GIT_WORK_TREE"
+		GIT_INDEX_FILE="$functionEntry_GIT_INDEX_FILE"
+		GIT_OBJECT_DIRECTORY="$functionEntry_GIT_OBJECT_DIRECTORY"
+		#GIT_ALTERNATE_OBJECT_DIRECTORIES="$functionEntry_GIT_ALTERNATE_OBJECT_DIRECTORIES"
+		GIT_CONFIG="$functionEntry_GIT_CONFIG"
+		GIT_CONFIG_GLOBAL="$functionEntry_GIT_CONFIG_GLOBAL"
+		GIT_CONFIG_SYSTEM="$functionEntry_GIT_CONFIG_SYSTEM"
+		GIT_CONFIG_NOSYSTEM="$functionEntry_GIT_CONFIG_NOSYSTEM"
+		#GIT_AUTHOR_NAME="$functionEntry_GIT_AUTHOR_NAME"
+		#GIT_AUTHOR_EMAIL="$functionEntry_GIT_AUTHOR_EMAIL"
+		#GIT_AUTHOR_DATE="$functionEntry_GIT_AUTHOR_DATE"
+		#GIT_COMMITTER_NAME="$functionEntry_GIT_COMMITTER_NAME"
+		#GIT_COMMITTER_EMAIL="$functionEntry_GIT_COMMITTER_EMAIL"
+		#GIT_COMMITTER_DATE="$functionEntry_GIT_COMMITTER_DATE"
+		#GIT_EDITOR="$functionEntry_GIT_EDITOR"
+		#GIT_PAGER="$functionEntry_GIT_PAGER"
+		GIT_NAMESPACE="$functionEntry_GIT_NAMESPACE"
+		GIT_CEILING_DIRECTORIES="$functionEntry_GIT_CEILING_DIRECTORIES"
+		GIT_DISCOVERY_ACROSS_FILESYSTEM="$functionEntry_GIT_DISCOVERY_ACROSS_FILESYSTEM"
+		#GIT_SSL_NO_VERIFY="$functionEntry_GIT_SSL_NO_VERIFY"
+		#GIT_SSH="$functionEntry_GIT_SSH"
+		#GIT_SSH_COMMAND="$functionEntry_GIT_SSH_COMMAND"
+
+		return 0
+	}
+
+	# ATTRIBUTION-AI: ChatGPT 4.5-preview  2025-04-11  with knowledge ubiquitous_bash, etc  (partially)
+	# CAUTION: NOT sufficient to call this function only during installation (as Administrator, which is what normally causes this issue). If the user subsequently installs native 'git for Windows', additional '.gitconfig' entries are needed, with the different MSWindows native style path format.
+	# Historically this was apparently at least mostly not necessary until prioritizing native git binaries (if available) instead of relying on Cygwin/MSW git binaries.
+	_write_configure_git_safe_directory_if_admin_owned() {
+		local current_path="$1"
+		local win_path win_path_escaped win_path_slash cygwin_path
+		win_path="$(cygpath -w "$current_path")"
+		#cygwin_path="$(cygpath -u "$current_path")"  # explicit Cygwin POSIX path
+		win_path_escaped="${win_path//\\/\\\\}"
+		win_path_slash="${win_path//\\/\/}"
+
+		# Single call to verify Administrators ownership explicitly (fast Windows API call)
+		local owner_line
+		owner_line="$(icacls "$win_path" 2>/dev/null)"
+		if [[ "$owner_line" != *"BUILTIN\\Administrators"* ]]; then
+			# Not Administrators-owned, no further action needed, immediate return
+			return 0
+		fi
+		# Read "$HOME"/.gitconfig just once (efficient builtin file reading)
+		local gitconfig_content
+		if [[ -e "$HOME"/.gitconfig ]]; then
+			gitconfig_content="$(< "$HOME"/.gitconfig)"
+
+			## Check 1: Exact Windows path (C:\...)
+			#if [[ "$gitconfig_content" == *"[safe]"* && "$gitconfig_content" == *"directory = $win_path"* ]]; then
+				#return 0
+			#fi
+
+			## Check 2: Double-backslash-escaped Windows path (C:\\...)
+			#win_path_escaped="${win_path//\\/\\\\}"
+			#if [[ "$gitconfig_content" == *"[safe]"* && "$gitconfig_content" == *"directory = $win_path_escaped"* ]]; then
+				#return 0
+			#fi
+
+			## Check 3: Normal-slash Windows path (C:/...)
+			#win_path_slash="${win_path//\\/\/}"
+			#if [[ "$gitconfig_content" == *"[safe]"* && "$gitconfig_content" == *"directory = $win_path_slash"* ]]; then
+				#return 0
+			#fi
+
+			## Check 4: Original Cygwin POSIX path (/cygdrive/c/...)
+			#if [[ "$gitconfig_content" == *"[safe]"* && "$gitconfig_content" == *"directory = $cygwin_path"* ]]; then
+				#return 0
+			#fi
+
+			#( [[ "$gitconfig_content" == *"[safe]"* && "$gitconfig_content" == *"directory = $win_path"* ]] || [[ "$gitconfig_content" == *"[safe]"* && "$gitconfig_content" == *"directory = $win_path_escaped"* ]] || [[ "$gitconfig_content" == *"[safe]"* && "$gitconfig_content" == *"directory = $win_path_slash"* ]] ) && ( [[ "$gitconfig_content" == *"[safe]"* && "$gitconfig_content" == *"directory = $cygwin_path"* ]] ) && return 0
+
+			# Slightly more performance efficient. No expected scenario in which a MSW path has been added but a UNIX path has not.
+			( [[ "$gitconfig_content" == *"[safe]"* && "$gitconfig_content" == *"directory = $win_path"* ]] || [[ "$gitconfig_content" == *"[safe]"* && "$gitconfig_content" == *"directory = $win_path_escaped"* ]] || [[ "$gitconfig_content" == *"[safe]"* && "$gitconfig_content" == *"directory = $win_path_slash"* ]] ) && return 0
+			cygwin_path="$(cygpath -u "$current_path")"  # explicit Cygwin POSIX path
+			( [[ "$gitconfig_content" == *"[safe]"* && "$gitconfig_content" == *"directory = $cygwin_path"* ]] ) && return 0
+		fi
+
+		# Explicit message clearly communicating safe-configuration action for transparency
+		#echo "Administrators ownership detected; configuring git safe.directory entry."
+
+		# perform safe git configuration exactly once after all efficient checks
+		# CAUTION: Tested to create functionally identical log entries through both '/usr/bin/git' and native git binaries. Ensure that remains the case if making any changes.
+		#"$scriptAbsoluteLocation" _write_configure_git_safe_directory_if_admin_owned_sequence "$cygwin_path" "$win_path_escaped" "$win_path_slash" "$win_path"
+		( _write_configure_git_safe_directory_if_admin_owned_sequence "$cygwin_path" "$win_path_escaped" "$win_path_slash" "$win_path" )
+	}
+	# Must be later, after set global variable "$scriptAbsoluteFolder" .
+	#_write_configure_git_safe_directory_if_admin_owned "$scriptAbsoluteFolder"
+
 	# NOTICE: Recent versions of Cygwin seem to have replaced or omitted '/usr/bin/gpg.exe', possibly in favor of a symlink to '/usr/bin/gpg2.exe' .
 	# CAUTION: This override is specifically to ensure availability of 'gpg' binary through a function, but that could have the effect of presenting an incorrect gpg2 CLI interface to software expecting a gpg1 CLI interface.
 	 # In practice, Debian Linux seem to impose gpg v2 as the CLI interface for gpg - 'gpg --version' responds v2 .
@@ -1497,6 +1701,7 @@ _report_setup_ubcp() {


 	find /bin/ /usr/bin/ /sbin/ /usr/sbin/ | tee "$currentCygdriveC_equivalent"/core/infrastructure/ubcp-binReport > /dev/null
+	find /home/root/ | tee "$currentCygdriveC_equivalent"/core/infrastructure/ubcp-homeReport > /dev/null


 	apt-cyg show | cut -f1 -d\ | tail -n +2 | tee "$currentCygdriveC_equivalent"/core/infrastructure/ubcp-packageReport > /dev/null
@@ -2843,6 +3048,48 @@ _command_safeBackup() {



+# Suggested for files used as Inter-Process Communication (IPC) or similar indicators (eg. temporary download files recently in progress).
+# Works around files that may not be deleted by 'rm -f' when expected (ie. due to Cygwin/MSW file locking).
+# ATTRIBUTION-AI: OpRt_.deepseek/deepseek-r1-distill-llama-70b  2025-03-27  (partial)
+_destroy_lock() {
+    [[ "$1" == "" ]] && return 0
+
+    # Fraction of   2GB part file  divided by  1MB/s optical-disc write speed   .
+    local currentLockWait="1250"
+
+    local current_anyFilesExists
+    local currentFile
+
+
+    local currentIteration=0
+    for ((currentIteration=0; currentIteration<"$currentLockWait"; currentIteration++))
+    do
+        rm -f "$@" > /dev/null 2>&1
+
+        current_anyFilesExists="false"
+        for currentFile in "$@"
+        do
+            [[ -e "$currentFile" ]] && current_anyFilesExists="true"
+        done
+
+        if [[ "$current_anyFilesExists" == "false" ]]
+        then
+            return 0
+            break
+        fi
+
+        # DANGER: Does NOT use _safeEcho . Do NOT use with external input!
+        ( echo "STACK_FAIL STACK_FAIL STACK_FAIL: software: wait: rm: exists: file: ""$@" >&2 ) > /dev/null
+        sleep 1
+    done
+
+    [[ "$currentIteration" != "0" ]] && sleep 7
+    return 1
+}
+
+
+
+
 # Equivalent to 'mv -n' with an error exit status if file cannot be overwritten.
 # https://unix.stackexchange.com/questions/248544/mv-move-file-only-if-destination-does-not-exist
 _moveconfirm() {
@@ -2958,6 +3205,14 @@ _terminateMetaHostAll() {
 }

 _terminateAll() {
+	"$scriptAbsoluteLocation" _terminateAll_sequence "$@"
+}
+_terminateAll_sequence() {
+	_start
+	_terminateAll_procedure "$@"
+	_stop "$?"
+}
+_terminateAll_procedure() {
 	_terminateMetaHostAll

 	local processListFile
@@ -3944,6 +4199,7 @@ _messageFAIL() {
 	_messageError "FAIL"
 	#echo " FAIL "
 	_stop 1
+	exit 1
 	return 0
 }

@@ -11833,6 +12089,7 @@ _getMost_debian11_install() {
 	_getMost_backend_aptGetInstall xz-utils

 	_getMost_backend_aptGetInstall libreadline8
+	_getMost_backend_aptGetInstall libreadline-dev


 	_getMost_backend_aptGetInstall mkisofs
@@ -12812,6 +13069,7 @@ _getMinimal_cloud() {
 	_getMost_backend_aptGetInstall xz-utils

 	_getMost_backend_aptGetInstall libreadline8
+	_getMost_backend_aptGetInstall libreadline-dev


 	_getMost_backend_aptGetInstall mkisofs
@@ -16378,6 +16636,29 @@ _probe_prepare_abstractfs_appdir() {
 }


+
+
+# No production use (ie. not used by 'abstractfs' itself, but recommended flag variables as a standard for other scripts using 'abstractfs' to follow).
+#
+# Flag. Need 'abstractfs' (eg. ''./ubiquitous_bash.sh _abstractfs bash' ) path consistency (eg. '/dev/shm/uk4u/zjZktz7G/ubiquitous_bash.sh' ) enough to force subsequent commands (eg. ArduinoIDE) to run under Linux/WSL unless specifically exempted (eg. upload firmware under Cygwin/MSW after compile under Linux/WSL) .
+#_set_abstractfs_wsl
+_set_abstractfs_alwaysUNIXneverNative() {
+	export abstractfs_alwaysUNIXneverNative="true"
+}
+# Allow native paths (eg. 'C:\abstract/uk4u/zjZktz7G/ubiquitous_bash.sh' ) . STRONGLY DISCOURAGED, but may be default, because otherwise native MSWindows binaries would not be used by default.
+_set_abstractfs_allowNative() {
+	export abstractfs_alwaysUNIXneverNative="false"
+}
+_set_abstractfs_enable() {
+	export abstractfs_enable="true"
+}
+# Suggested default. If 'abstractfs' can be avoided, then native MSWindows binaries, etc, will be usable.
+_set_abstractfs_disable() {
+	export abstractfs_disable="true"
+}
+
+
+
 _reset_abstractfs() {
 	export abstractfs=
 	export abstractfs_base=
@@ -17301,8276 +17582,12168 @@ _resetFakeHomeEnv() {
 	_resetFakeHomeEnv_nokeep
 }

-_test_image() {
-	_mustGetSudo
-
-	_getDep losetup
-	#_getDep partprobe
-}


-# ATTENTION: WARNING: TODO: UNCOMMENT SAFE/EMPTY CONFIGURATION VARIABLES HERE IF NEEDED TO RESET ENVIRONMENT!
+# Suggested defaults. If your python code (not python itself, nor venv, etc, but filenames for files your python application uses, such as datasets, models, etc) insists on absolute paths, and you must use it under both UNIX/Linux and Cygwin/MSW, then it is probably only needed temporarily to generate static assets (ie. occasional experimental fine-tuning of the latest available AI models). In which case you can put into production under solely UNIX/Linux if necessary, and develop with Docker (ie. factory) instead.
+# tldr; UNIX/Linux for python in production, Cygwin/MSW (ie. MSW native python) for python in development, as usual, and then you won't need abstractfs .
+#
+#_set_abstractfs_alwaysUNIXneverNative
+#_set_abstractfs_disable


-###

-# ATTENTION: Override with 'ops', env, or similar.
-# DANGER: NOT respected (and possibly not needed) by some virtualization backends.
-# DANGER: Root image/device/partiton must be correct!
-# WARNING: Root/Image/Device override implies 'true' "ubVirtImageLocal" .
+# ATTENTION: EXAMPLE. Override or implement alternative with 'core.sh', 'ops.sh', or similar.
+# ATTENTION: Also create "$scriptLib"/python/lean.py .
+_msw_python() {
+    #export dependencies_msw_python=( "pyreadline3" )
+    #export packages_msw_python=( "huggingface_hub[cli]" )

-# WARNING: Implies blank "ubVirtImagePartition" .
-#export ubVirtImageIsRootPartition='true'
+    #implies sequence
+    _prepare_msw_python

-#export ubVirtImageIsDevice='true'
-#export ubVirtImageOverride='/dev/disk/by-id/identifier-part'

-# ATTENTION: Path pointing to full disk device or image, including partition table, for full booting.
-# Will take precedence over "ubVirtImageOverride" with virtualization backends capable of full booting.
-# vbox , qemu
-#export ubVirtDiskOverride='/dev/disk/by-id/identifier'
+    # ATTENTION: Dropping to an interactive shell in the midst of a bash function which provides standard output to another bash function
+    #
+    # ie. don't expect guaranteed sanity doing something like this in either bash or python
+    # echo $( echo result ; bash -i ) | tee > ./logfile.txt
+    #
+    # ALWAYS call interactively unless 'stdout' will be consumed. Functions, scripts, commands, get an interactive terminal to talk to, except very simple functions.
+    #
+    # ie. _fineTune_model  <->  Interactive Shell
+    # ie. _vector_model  <->  Interactive Shell
+    # ie. _inferenceModel | grep 'stuff' > description.txt  <->  Interactive Shell
+    # ie. result=$(_inferenceModel | grep 'correct')  <->  Non-Interactive
+    #
+    # Unfortunately, bash function calls from python do not enjoy the '$() > /dev/null 2>&1' syntactic convenience.
+    # Python calls to '_bin()' , '_bash()' , etc, must explicitly declare or implicitly default sanely whether interactive or non-interactive captured output.
+
+    # lean.py ... is a template script from 'ubiquitous_bash' for lightweight manual changes
+    #"$scriptLocal"/python_msw/lean.py   #automatically replaced with autogenerated lean.py
+    #"$scriptLib"/python_msw/lean.py    #ATTTENTION: create persistent custom lean.py here


-# ATTENTION: Explicitly override platform. Not all backends support all platforms.
-# chroot , qemu
-# x64-bios , raspbian , x64-efi
-#export ubVirtPlatformOverride='x64-bios'
+    # WARNING: May be untested.
+    #python "$scriptLib_msw"'\python\lean.py' '_bin(["sleep", "90",], True, r"'"$scriptCall_bin_msw"'")'

-###
+    #python "$scriptAbsoluteFolder_msw"'\lean.py' '_bash(["-i"], True, r"'"$scriptCall_bash_msw"'")'

+    python "$scriptAbsoluteFolder_msw"'\lean.py' '_bin(["_demo_msw_python",], True, r"'"$scriptCall_bin_msw"'", interactive=True)'

+    #python -i "$scriptAbsoluteFolder_msw"'\lean.py' '_python()'

-###
+    #_bash
+}
+_msw_python_bash() {
+    #export dependencies_msw_python=( "pyreadline3" )
+    #export packages_msw_python=( "huggingface_hub[cli]" )

-# ATTENTION: Override with 'ops' or similar.
-# WARNING: Do not override unnecessarily. Default rules are expected to accommodate typical requirements.
+    #implies sequence
+    _prepare_msw_python

-# WARNING: Only applies to imagedev (text) loopback device.
-# x64 bios , raspbian , x64 efi (respectively)
-#export ubVirtImagePartition='p1'
-#export ubVirtImagePartition='p2'
-#export ubVirtImagePartition='p3'
+    _bash
+}
+_msw_python_bin() {
+    #export dependencies_msw_python=( "pyreadline3" )
+    #export packages_msw_python=( "huggingface_hub[cli]" )

-###
+    #implies sequence
+    _prepare_msw_python

+    _bin "$@"
+}


-# ATTENTION: Override with 'ops' or similar.
-# WARNING: Prefer to avoid override in favor of overriding other relevant variables or functions.
-# DANGER: Required for safety mechanisms which may also be used by some other virtualization backends!
-# WARNING: Dependency: Should run _loopImage_imagefilename .
-# "$1" == imagedev
-# "$2" == default (if any)
-_determine_rawFileRootPartition() {
-	# DANGER: REQUIRES image/device including ONLY root partition!
-	if [[ "$ubVirtImageIsRootPartition" == 'true' ]]
-	then
-		export ubVirtImagePartition=''
-		echo "$1"
-		return 0
-	fi
-
-	if [[ "$ubVirtImagePartition" != "" ]]
-	then
-		echo "$1""$ubVirtImagePartition"
-		return 0
-	fi
-
-	if [[ "$2" != "" ]]
-	then
-		export ubVirtImagePartition="$2"
-		echo "$1""$2"
-		return 0
-	fi
-
-	#Platform defaults.
-	export ubVirtImageEFI=""
-	export ubVirtImagePartition=""
-
-	#[[ "$ubVirtPlatform" == "x64-bios" ]] && export ubVirtImagePartition=p1
-	if [[ "$ubVirtPlatform" == "x64-bios" ]]
-	then
-		export ubVirtImageBIOS=
-		export ubVirtImageEFI=
-		#export ubVirtImageNTFS=
-		#export ubVirtImageRecovery=
-		#export ubVirtImageSwap=
-		export ubVirtImageBoot=
-		export ubVirtImagePartition=p1
-	fi
-
-	if [[ "$ubVirtPlatform" == "x64-efi" ]]
-	then
-		#export ubVirtImagePartition=p3 && export ubVirtImageEFI=p2
-		export ubVirtImageBIOS=p1
-		export ubVirtImageEFI=p2
-		#export ubVirtImageNTFS=
-		#export ubVirtImageRecovery=
-		#export ubVirtImageSwap=p3
-		export ubVirtImageBoot=p4
-		export ubVirtImagePartition=p5
-	fi
-
-	#[[ "$ubVirtPlatform" == "raspbian" ]] && export ubVirtImagePartition=p2
-	if [[ "$ubVirtPlatform" == "raspbian" ]]
-	then
-		export ubVirtImageBIOS=
-		export ubVirtImageEFI=
-		#export ubVirtImageNTFS=
-		#export ubVirtImageRecovery=
-		#export ubVirtImageSwap=
-		# ### export ubVirtImageBoot=
-		export ubVirtImagePartition=p2
-	fi
-
-
-	#Default.
-	# DANGER: Do NOT set blank.
-	[[ "$ubVirtImagePartition" == "" ]] && export ubVirtImagePartition=p1
-
-	echo "$1""$ubVirtImagePartition"
-
-	return 0
+# ATTENTION: Call from '_test_prog' with 'core.sh' or similar.
+# _setup calls _test calls _test_prog
+_test_msw_python() {
+    #export dependencies_msw_python=( "pyreadline3" )
+    #export packages_msw_python=( "huggingface_hub[cli]" )
+
+    _prepare_msw_python
 }



-# ATTENTION: Override with 'ops' or similar.
-# WARNING: Uncommenting will cause losetup not to be used for 'vm.img' and similar even if symlinked to '/dev'. This will break 'ubVirtImagePartition' .
-# DANGER: Unnecessarily linking 'vm.img' or similar to device file strongly discouraged. May allow some virtualization backends to attempt to perform unsupported operations (ie. rm -f) on device file.
-_detect_deviceAsVirtImage_symlinks() {
-	#[[ -h "$scriptLocal"/vm.img ]] && readlink "$scriptLocal"/vm.img | grep ^\/dev\/\.\* > /dev/null 2>&1 && return 0
-	#[[ -h "$scriptLocal"/vm-x64.img ]] && readlink "$scriptLocal"/vm-x64.img | grep ^\/dev\/\.\* > /dev/null 2>&1 && return 0
-	#[[ -h "$scriptLocal"/vm-raspbian.img ]] && readlink "$scriptLocal"/vm-raspbian.img | grep ^\/dev\/\.\* > /dev/null 2>&1 && return 0
-
-	# WARNING: Symlinks to locations outside a home subfolder (including relative symlinks) will be presumed to be device files if uncommented.
-	#[[ -h "$scriptLocal"/vm.img ]] && ! readlink "$scriptLocal"/vm.img | grep ^\/home\/\.\* > /dev/null 2>&1 && return 0
-	#[[ -h "$scriptLocal"/vm-x64.img ]] && ! readlink "$scriptLocal"/vm-x64.img | grep ^\/home\/\.\* > /dev/null 2>&1 && return 0
-	#[[ -h "$scriptLocal"/vm-raspbian.img ]] && ! readlink "$scriptLocal"/vm-raspbian.img | grep ^\/home\/\.\* > /dev/null 2>&1 && return 0
-
-	return 1
-}


-# DANGER: Required for safety mechanisms which may also be used by some other virtualization backends!
-# DANGER: Multiple 'vm.img' variants (eg. 'vm-x64.img') available simultaneously is NOT deliberately supported and NOT safe!
-# DANGER: Multiple symlinks or other conditions may confuse this safety mechanism. Only intended to prevent casual misuse.
-# image
-# chroot
-# vbox
-# qemu
-# "$1" == imagefilename
-_detect_deviceAsVirtImage() {
-	[[ "$ubVirtImageIsDevice" != "" ]] && return 0
-	[[ "$ubVirtImageOverride" == '/dev/'* ]] && return 0
-
-	[[ "$1" == '/dev/'* ]] && return 0
-
-
-	[[ "$1" != "" ]] && [[ -h "$1" ]] && ! readlink "$1" | grep ^\/dev\/\.\* > /dev/null 2>&1 && return 1
-	[[ "$1" != "" ]] && [[ -e "$1" ]] && return 1
-	_detect_deviceAsVirtImage_symlinks "$1" && return 0
-
-	return 1
-}

-# ATTENTION: Override with 'ops' or similar.
-# WARNING: Prefer to avoid override in favor of overriding other relevant variables or functions.
-# DANGER: Required for safety mechanisms which may also be used by some other virtualization backends!
-# "$1" == imagedev
-# "$2" == imagepart
-_determine_rawIsRootPartition() {
-	[[ "$ubVirtImageIsRootPartition" == 'true' ]] && return 0
-	[[ "$1" == "$2" ]] && return 0
-	return 1
-}


-# DANGER: Required for safety mechanisms which may also be used by some other virtualization backends!
-# DANGER: Exact values of 'ubVirtPlatform' and other variables may be required by other virtualization backends!
-_loopImage_imagefilename() {
-	local current_imagefilename
-	[[ -e "$scriptLocal"/vm-raspbian.img ]] && current_imagefilename="$scriptLocal"/vm-raspbian.img && export ubVirtPlatform=raspbian
-	[[ -e "$scriptLocal"/vm-x64.img ]] && current_imagefilename="$scriptLocal"/vm-x64.img && export ubVirtPlatform=x64-bios
-	[[ -e "$scriptLocal"/vm.img ]] && current_imagefilename="$scriptLocal"/vm.img && export ubVirtPlatform=x64-bios
-	[[ "$ubVirtImageOverride" != "" ]] && current_imagefilename="$ubVirtImageOverride"
-	[[ "$ubVirtImageOverride_alternate" != "" ]] && current_imagefilename="$ubVirtImageOverride_alternate"
-
-
-	[[ "$ubVirtPlatform" == "" ]] && export ubVirtPlatform=x64-bios
-	[[ "$ubVirtPlatformOverride" != "" ]] && export ubVirtPlatform="$ubVirtPlatformOverride"
-
-	echo "$current_imagefilename"
-}


-# "$1" == imagefilename
-# "$2" == imagedev (text)
-_loopImage_procedure_losetup() {
-	# SEVERE - Disabled for more consistent behavior. Aside from now 'wasting' a loopback device, this may break any legacy uses of 'ubVirtImageOverride' .
-	#  CAUTION: TODO: Testing.
-	# WARNING: Partition names (ie. '/dev/loop1' , '/dev/loop1p1') may change (eg. to '/dev/sda' , '/dev/sda1') .
-	#  If uncommenting this functionality, also ensure 'ubVirtImageEFI' declaration (eg. used by '_createVMimage()' ) is sufficiently dynamic .
-	# WARNING: If uncommenting this functionality, also uncomment related use of '_detect_deviceAsVirtImage' within _closeLoop related functions.
-	#if _detect_deviceAsVirtImage "$1"
-	#then
-		#! [[ -e "$1" ]] && _stop 1
-		#echo "$1" > "$safeTmp"/imagedev
-		#sudo -n partprobe > /dev/null 2>&1
-
-		#_moveconfirm "$safeTmp"/imagedev "$2" > /dev/null 2>&1 || _stop 1
-		#return 0
-	#fi
-
-	sleep 1
-	sudo -n losetup -f -P --show "$1" > "$safeTmp"/imagedev 2> /dev/null || _stop 1
-	sudo -n partprobe > /dev/null 2>&1
-	sleep 1
-
-	_moveconfirm "$safeTmp"/imagedev "$2" > /dev/null 2>&1 || _stop 1
-	return 0
+# EXAMPLE. Override or implement alternative with 'core.sh', 'ops.sh', or similar.
+_prepare_msw_python() {
+    _prepare_msw_python_3
 }
-
-# DANGER: Optional parameter intended only for virtualization backends using only loopback devices without filesystem mounting (vbox) .
-# "$1" == imagedev (text)
-_loopImage_sequence() {
-	_mustGetSudo
-
-	_start
-
-	mkdir -p "$globalVirtFS"
-
-	local current_imagedev_text
-	current_imagedev_text="$1"
-	[[ "$current_imagedev_text" == "" ]] && current_imagedev_text="$scriptLocal"/imagedev
-
-	[[ -e "$current_imagedev_text" ]] && _stop 1
-
-	local current_imagefilename
-	current_imagefilename=$(_loopImage_imagefilename)
-
-	_loopImage_procedure_losetup "$current_imagefilename" "$current_imagedev_text"
-
-	_stop 0
+_prepare_msw_python_3() {
+    _prepare_msw_python_3_10
 }
+# EXAMPLE. Override or implement alternative (discouraged) with 'core.sh', 'ops.sh', or similar, if necessary.
+_prepare_msw_python_3_10() {
+    _set_msw_python_3_10

-_loopImage() {
-	if "$scriptAbsoluteLocation" _loopImage_sequence "$@"
-	then
-		return 0
-	fi
-	return 1
-}
+    # ATTENTION: implies sequence
+    local currentUID="$sessionid"

-# DANGER: Only use with backends supporting full disk booting!
-# "$1" == imagedev (text)
-_loopFull_procedure() {
-	if [[ "$ubVirtDiskOverride" == "" ]]
-	then
-		! _loopImage "$1" && _stop 1
-	else
-		! _loopImage_procedure_losetup "$ubVirtDiskOverride" "$1" && _stop 1
-	fi
-	return 0
-}
+    # ATTENTION: Do NOT enable. Prevents 'trap' cleanup of abandoned lock file.
+    #local currentUID=$(_uid 18)

-# "$1" == imagedev (text)
-_loopFull_sequence() {
-	_start
-
-	if ! _loopFull_procedure "$@"
-	then
-		_stop 1
-	fi
-
-	_stop 0
-}
+    local currentUID_length=${#currentUID}
+    local currentUID_length_plus1=$(( currentUID_length + 1 ))

-# "$1" == imagedev (text)
-_loopFull() {
-	if "$scriptAbsoluteLocation" _loopFull_sequence "$@"
-	then
-		return 0
-	fi
-
-	# Typically requires "_stop 1" .
-	return 1
-}
+    local currentPATH="$PATH"

+    _write_python_hook_local() {
+        _messagePlain_nominal 'prepare: python hook' > /dev/null >&2
+
+        local ubcore_accessoriesFile_python
+        local ubcoreDir_accessories_python
+        local ubcore_accessoriesFile_python_ubhome
+
+        ubcore_accessoriesFile_python=$(cygpath -w "$scriptLib"/python_msw/lean.py)
+        ubcoreDir_accessories_python=$(cygpath -w "$scriptLib"/python_msw)
+        ubcore_accessoriesFile_python_ubhome=$(cygpath -w "$scriptLib"/python_msw/lean.py)
+        if [[ ! -e "$ubcore_accessoriesFile_python" ]] || [[ ! -e "$ubcoreDir_accessories_python" ]] || [[ ! -e "$ubcore_accessoriesFile_python_ubhome" ]]
+        then
+            ( _messagePlain_warn 'warn: missing: scriptLib/python_msw/...' >&2 ) > /dev/null
+
+            ubcore_accessoriesFile_python=$(cygpath -w "$scriptLocal"/python_msw/lean.py)
+            ubcoreDir_accessories_python=$(cygpath -w "$scriptLocal"/python_msw)
+            ubcore_accessoriesFile_python_ubhome=$(cygpath -w "$scriptLocal"/python_msw/lean.py)
+            if [[ ! -e "$ubcore_accessoriesFile_python" ]] || [[ ! -e "$ubcoreDir_accessories_python" ]] || [[ ! -e "$ubcore_accessoriesFile_python_ubhome" ]]
+            then
+                ( _messagePlain_warn 'warn: missing: scriptLocal/python_msw/...' >&2 ) > /dev/null
+            fi
+        fi

-# ATTENTION: Override with 'ops' or similar.
-# DANGER: Allowing types other than 'ext4' (eg. fat), may allow mounting of filesystems other than an UNIX-like userspace root.
-_mountImageFS_procedure_blkid_fstype() {
-	[[ "$1" == "ext4" ]] && return 0
-	[[ "$1" == "btrfs" ]] && return 0
-
-	_stop 1
-}
+        local ubcore_ubcorerc_pythonrc="lean"
+
+        _setupUbiquitous_accessories_here-python_hook > "$scriptLocal"/python_msw/pythonrc."$currentUID"
+        if [[ ! -e "$scriptLocal"/python_msw/pythonrc ]] || ! diff --unified=3 "$scriptLocal"/python_msw/pythonrc."$currentUID" "$scriptLocal"/python_msw/pythonrc > /dev/null
+        then
+            mv -f "$scriptLocal"/python_msw/pythonrc."$currentUID" "$scriptLocal"/python_msw/pythonrc
+        else
+            rm -f "$scriptLocal"/python_msw/pythonrc."$currentUID"
+        fi
+
+        export _PYTHONSTARTUP=$(cygpath -w "$scriptLocal"/python_msw/pythonrc)
+        export PYTHONSTARTUP="$_PYTHONSTARTUP"
+    }
+    unset _PYTHONSTARTUP
+

-# "$1" == imagedev
-# "$2" == imagepart
-# "$3" == dirVirtFS (RESERVED)
-_mountImageFS_procedure_blkid() {
-	local loopdevfs
-
-	# DANGER: Must ignore/reject 'PTTYPE' field if given.
-	#if _determine_rawIsRootPartition "$1" "$2"
-	#then
-		#loopdevfs=$(eval $(sudo -n blkid "$2" | tr -dc 'a-zA-Z0-9\=\"\ \:\/\-' | awk ' { print $4 } '); echo $TYPE)
-	#else
-		#loopdevfs=$(eval $(sudo -n blkid "$2" | tr -dc 'a-zA-Z0-9\=\"\ \:\/\-' | awk ' { print $3 } '); echo $TYPE)
-	#fi
-	loopdevfs=$(sudo -n blkid -s TYPE -o value "$2" | tr -dc 'a-zA-Z0-9')
-
-	! _mountImageFS_procedure_blkid_fstype "$loopdevfs" && _stop 1
-
-	return 0
-}
+    local current_done__prepare_msw_python_procedure="false"

-# "$1" == destinationDir (default: "$globalVirtFS")
-_mountImageFS_sequence() {
-	_mustGetSudo
-
-	_start
-
-	local currentDestinationDir
-	currentDestinationDir="$1"
-	[[ "$currentDestinationDir" == "" ]] && currentDestinationDir="$globalVirtFS"
-
-	mkdir -p "$globalVirtFS"
-
-	"$scriptAbsoluteLocation" _checkForMounts "$currentDestinationDir" && _stop 1
-
-	# Include platform determination code for correct determination of partition and mounts.
-	_loopImage_imagefilename > /dev/null 2>&1
-
-	local current_imagedev
-	current_imagedev=$(cat "$scriptLocal"/imagedev)
-
-	local current_imagepart
-	current_imagepart=$(_determine_rawFileRootPartition "$current_imagedev")
-	#current_imagepart=$(_determine_rawFileRootPartition "$current_imagedev" "x64-bios")
-
-
-	_mountImageFS_procedure_blkid "$current_imagedev" "$current_imagepart" "$currentDestinationDir" || _stop 1
-
-	local loopdevfs
-	loopdevfs=$(sudo -n blkid -s TYPE -o value "$current_imagepart" | tr -dc 'a-zA-Z0-9')
-
-
-	if [[ "$loopdevfs" == "btrfs" ]] && [[ "$ub_disable_fs_compression" != "true" ]]
-	then
-		if [[ "$skimfast" == "true" ]]
-		then
-			sudo -n mount -o compress=zstd:2 "$current_imagepart" "$currentDestinationDir" || _stop 1
-		else
-			sudo -n mount -o compress=zstd:9 "$current_imagepart" "$currentDestinationDir" || _stop 1
-		fi
-	else
-		sudo -n mount "$current_imagepart" "$currentDestinationDir" || _stop 1
-	fi
-
-
-	sleep 1
-
-	! mountpoint "$currentDestinationDir" > /dev/null 2>&1 && sleep 3
-	! mountpoint "$currentDestinationDir" > /dev/null 2>&1 && sleep 6
-	! mountpoint "$currentDestinationDir" > /dev/null 2>&1 && sleep 9
-	mountpoint "$currentDestinationDir" > /dev/null 2>&1 || _stop 1
-
-	_stop 0
-}

-_mountImageFS() {
-	if "$scriptAbsoluteLocation" _mountImageFS_sequence
-	then
-		return 0
-	fi
-	return 1
-}
+    _lock_prepare_python_msw() {
+        _messagePlain_nominal 'prepare: wait: lock: _lock_prepare_python_msw' > /dev/null >&2
+        local dateA
+        local dateB
+        local dateDelta
+        while [[ $(cat "$scriptLocal"/python_msw.lock 2> /dev/null | head -c "$currentUID_length") != "$currentUID" ]]
+        do
+            if [[ ! -e "$scriptLocal"/python_msw.lock ]]
+            then
+                echo "$currentUID"$(date +%s | tr -dc '0-9') > "$scriptLocal"/python_msw.lock."$currentUID"
+                mv -f "$scriptLocal"/python_msw.lock."$currentUID" "$scriptLocal"/python_msw.lock
+            fi

-_mountImage() {
-	# Include platform determination code for correct determination of partition and mounts.
-	_loopImage_imagefilename > /dev/null 2>&1
-
-	! _loopImage && _stop 1
-	! _mountImageFS "$1" && _stop 1
-
-	return 0
-}
+            sleep 7
+            [[ $(cat "$scriptLocal"/python_msw.lock 2> /dev/null | head -c "$currentUID_length") == "$currentUID" ]] && return 0

-# "$1" == imagedev
-# "$2" == imagedev (text)
-# "$3" == imagefilename
-_unmountLoop_losetup() {
-	#if _detect_deviceAsVirtImage "$3" || [[ "$1" == '/dev/loop'* ]]
-	#if _detect_deviceAsVirtImage "$3"
-	#then
-		#! [[ -e "$1" ]] && return 1
-		#! [[ -e "$2" ]] && return 1
-		#! [[ -e "$3" ]] && return 1
-		#sudo -n partprobe > /dev/null 2>&1
-
-		##rm -f "$2" || return 1
-		#rm -f "$2"
-		#[[ -e "$2" ]] && return 1
-		#return 0
-	#fi
-
-	# DANGER: Should never happen.
-	[[ "$1" == '/dev/loop'* ]] || return 1
-
-	# WARNING: Should never happen.
-	[[ -e "$3" ]] || return 1
-
-	sudo -n losetup -d "$1" > /dev/null 2>&1 || return 1
-	sudo -n partprobe > /dev/null 2>&1
-
-	#rm -f "$2" || return 1
-	rm -f "$2"
-	[[ -e "$2" ]] && return 1
-	return 0
-}
+            _messagePlain_probe "wait: lock" > /dev/null >&2

-# DANGER: Optional parameter intended only for virtualization backends using only loopback devices without filesystem mounting (vbox) .
-# "$1" == imagedev (text)
-_umountLoop() {
-	_mustGetSudo || return 1
-
-	local current_imagedev_text
-	current_imagedev_text="$1"
-	[[ "$current_imagedev_text" == "" ]] && current_imagedev_text="$scriptLocal"/imagedev
-
-	[[ -e "$current_imagedev_text" ]] || return 1
-	local current_imagedev
-	current_imagedev=$(cat "$current_imagedev_text" 2>/dev/null)
-
-
-	# WARNING: Consistent rules required to select correct imagefilename for both _umountLoop and _loopImage regardless of VM backend or 'ops' overrides.
-	local current_imagefilename
-	current_imagefilename=$(_loopImage_imagefilename)
-
-	_unmountLoop_losetup "$current_imagedev" "$current_imagedev_text" "$current_imagefilename" || return 1
-
-	rm -f "$lock_quicktmp" > /dev/null 2>&1
-
-	return 0
-}
+            while [[ -e "$scriptLocal"/python_msw.lock ]] && [[ $(cat "$scriptLocal"/python_msw.lock 2> /dev/null | head -c "$currentUID_length") != "$currentUID" ]]
+            do
+                dateA=$(cat "$scriptLocal"/python_msw.lock 2> /dev/null | tail -c +"$currentUID_length_plus1" | tr -dc '0-9')
+                dateB=$(date +%s | tr -dc '0-9')
+                _messagePlain_probe "$dateB - $dateA"
+                dateDelta=$(bc <<< "$dateB - $dateA" 2> /dev/null)

-# DANGER: Only use with backends supporting full disk booting!
-# "$1" == imagedev (text)
-_umountFull_procedure() {
-	if [[ "$ubVirtDiskOverride" == "" ]]
-	then
-		! _umountLoop "$1" && _stop 1
-	else
-		! _unmountLoop_losetup "$ubVirtDiskOverride" "$1" "$ubVirtDiskOverride" && _stop 1
-	fi
-	return 0
-}
+                sleep 7

-_umountFull_sequence() {
-	_start
-
-	if ! _umountFull_procedure "$@"
-	then
-		_stop 1
-	fi
-
-	_stop 0
-}
+                # Normal prepare time is <<2minutes, if that.
+                [[ "$dateDelta" -gt "2700" ]] && rm -f "$scriptLocal"/python_msw.lock
+            done
+        done
+    }
+    _lock_prepare_python_msw
+    #...
+    #rm -f "$scriptLocal"/python_msw.lock
+
+    # WARNING: Do not add '-msw_python_3_10' or similar suffix to dumbpath_file . Use separate derivative projects for separate venv as normally needed for different python versions.
+    local dumbpath_file="$scriptLocal"/"$dumbpath_prefix"dumbpath.var
+    local dumbpath_contents=""
+    dumbpath_contents=$(cat "$dumbpath_file" 2> /dev/null)
+    if [[ "$dumbpath_contents" != "$dumbpath_file" ]]
+    then
+        # ATTENTION: WARNING: Anaconda is usually unnecessary, STRONGLY DISCOURAGED, and NOT automatically installed (eg. with 'ubdist/OS').
+        # Automatic installation of Anaconda is not expected useful for any purpose - only workstations for personal evaluation of open-source projects which happen to use Anaconda for a non=production purpose are expected to use Anaconda, if at all.
+        # Manual installation of Anaconda:
+        # https://docs.conda.io/projects/conda/en/latest/user-guide/install/windows.html
+        # https://docs.conda.io/projects/conda/en/latest/user-guide/install/linux.html

-_umountFull() {
-	if "$scriptAbsoluteLocation" _umountFull_sequence "$@"
-	then
-		return 0
-	fi
-
-	# Typically requires "_stop 1" .
-	return 1
-}

-# "$1" == destinationDir (default: "$globalVirtFS")
-_umountImage() {
-	_mustGetSudo || return 1
-
-	local currentDestinationDir
-	currentDestinationDir="$1"
-	[[ "$currentDestinationDir" == "" ]] && currentDestinationDir="$globalVirtFS"
-
-	sudo -n umount "$currentDestinationDir" > /dev/null 2>&1
-
-	#Uniquely, it is desirable to allow unmounting to proceed a little further if the filesystem was not mounted to begin with. Enables manual intervention.
-
-	#Filesystem must be unmounted before proceeding.
-	_readyImage "$currentDestinationDir" && sleep 1 && sudo -n umount "$currentDestinationDir" > /dev/null 2>&1
-	_readyImage "$currentDestinationDir" && sleep 3 && sudo -n umount "$currentDestinationDir" > /dev/null 2>&1
-	_readyImage "$currentDestinationDir" && sleep 9 && sudo -n umount "$currentDestinationDir" > /dev/null 2>&1
-	_readyImage "$currentDestinationDir" && return 1
-
-	! _umountLoop && return 1
-
-	return 0
-}

-_waitLoop_opening() {
-	[[ -e "$scriptLocal"/imagedev ]] && return 0
-	sleep 0.1
-	[[ -e "$scriptLocal"/imagedev ]] && return 0
-	sleep 0.3
-	for iteration in `seq 1 45`;
-	do
-		[[ -e "$scriptLocal"/imagedev ]] && return 0
-		sleep 1
-	done
-
-	return 1
-}
+

-_waitImage_opening() {
-	_readyImage "$globalVirtFS" && return 0
-	sleep 1
-	_readyImage "$globalVirtFS" && return 0
-	sleep 3
-	_readyImage "$globalVirtFS" && return 0
-	sleep 9
-	_readyImage "$globalVirtFS" && return 0
-	sleep 27
-	_readyImage "$globalVirtFS" && return 0
-	sleep 81
-	_readyImage "$globalVirtFS" && return 0
-
-	return 1
-}
+        # erase any venv, etc, which may use absolute paths
+        _messagePlain_nominal 'prepare: python_msw' > /dev/null >&2

-_waitLoop_closing() {
-	! [[ -e "$scriptLocal"/imagedev ]] && return 0
-	sleep 0.1
-	! [[ -e "$scriptLocal"/imagedev ]] && return 0
-	sleep 0.3
-	for iteration in `seq 1 45`;
-	do
-		! [[ -e "$scriptLocal"/imagedev ]] && return 0
-		sleep 1
-	done
-
-	return 1
-}
+        export safeToDeleteGit="true"
+        _safeRMR "$scriptLocal"/python_msw
+        mkdir -p "$scriptLocal"/python_msw

-_waitImage_closing() {
-	_readyImage "$globalVirtFS" || return 0
-	sleep 1
-	_readyImage "$globalVirtFS" || return 0
-	sleep 3
-	_readyImage "$globalVirtFS" || return 0
-	sleep 9
-	_readyImage "$globalVirtFS" || return 0
-	sleep 27
-	_readyImage "$globalVirtFS" || return 0
-	sleep 81
-	_readyImage "$globalVirtFS" || return 0
-
-	return 1
-}

-_readyImage() {
-	local absolute1
-	absolute1=$(_getAbsoluteLocation "$1")
-
-	mountpoint "$absolute1" > /dev/null 2>&1 || return 1
-
-	return 0
-}
+        #[[ "$current_done__prepare_msw_python_procedure" == "false" ]] &&
+        _prepare_msw_python_procedure
+        current_done__prepare_msw_python_procedure="true"

-_openImage() {
-	local returnStatus
-
-	export specialLock="$lock_open_image"
-
-	_open _waitImage_opening _mountImage
-	returnStatus="$?"
-
-	export specialLock=""
-
-	return "$returnStatus"
-}

-_closeImage() {
-	local returnStatus
-
-	export specialLock="$lock_open_image"
-
-	if [[ "$1" == "--force" ]]
-	then
-		_close --force _waitImage_closing _umountImage
-		returnStatus="$?"
-
-		export specialLock=""
-
-		return "$returnStatus"
-	fi
-
-	_close _waitImage_closing _umountImage
-	returnStatus="$?"
-
-	export specialLock=""
-
-	return "$returnStatus"
-}
+
+        # write python hook ; mv -f

-_openLoop() {
-	local returnStatus
-
-	export specialLock="$lock_loop_image"
-
-	_open _waitLoop_opening _loopImage
-	returnStatus="$?"
-
-	export specialLock=""
-
-	return "$returnStatus"
-}
+        #[[ "$_PYTHONSTARTUP" == "" ]] &&
+        _write_python_hook_local

-_closeLoop() {
-	local returnStatus
-
-	export specialLock="$lock_loop_image"
-
-	if [[ "$1" == "--force" ]]
-	then
-		_close --force _waitLoop_closing _umountLoop
-		returnStatus="$?"
-
-		export specialLock=""
-
-		return "$returnStatus"
-	fi
-
-	_close _waitLoop_closing _umountLoop
-	returnStatus="$?"
-
-	export specialLock=""
-
-	return "$returnStatus"
-}

-_testCreateFS() {
-	if _if_cygwin
-	then
-		echo 'warn: accepted: cygwin: missing: mount: mkfs'
-		return 0
-	fi
-
-	_mustGetSudo
-
-	_getDep mkfs
-	_getDep mkfs.ext4
-}
+#if false
+#then
+        # rebuild venv...
+        _messagePlain_nominal 'prepare: venv' > /dev/null >&2
+
+        mkdir -p "$scriptLocal"/python_msw/venv
+        ! cd "$scriptLocal"/python_msw/venv && _stop 1
+        python3 -m venv default_venv > /dev/null >&2

-_testCreatePartition() {
-	if _if_cygwin
-	then
-		echo 'warn: accepted: cygwin: missing: mount: parted'
-		return 0
-	fi
-
-	_mustGetSudo
-
-	_getDep parted
-	#_getDep partprobe
-}
+
+        cp -a default_venv/Scripts/activate default_venv/Scripts/activate_msw
+        dos2unix default_venv/Scripts/activate_msw
+        chmod u+x default_venv/Scripts/activate_msw

-_createRawImage_sequence() {
-	_start
-
-	export vmImageFile="$scriptLocal"/vm.img
-
-	[[ "$1" != "" ]] && export vmImageFile="$1"
-
-	local createRawImageSize
-	createRawImageSize=7636
-	[[ "$vmSize" != "" ]] && createRawImageSize="$vmSize"
-
-	[[ "$vmImageFile" == "" ]] && _stop 1
-	[[ -e "$vmImageFile" ]] && _stop 1
-
-	dd if=/dev/zero of="$vmImageFile" bs=1M count="$createRawImageSize" > /dev/null 2>&1
-
-	_stop
-}
+        #source default_venv/Scripts/activate > /dev/null >&2
+        _messagePlain_probe source default_venv/Scripts/activate_msw > /dev/null >&2
+        source default_venv/Scripts/activate_msw > /dev/null >&2
+        PATH="$currentPATH"

-_createRawImage() {
-
-	"$scriptAbsoluteLocation" _createRawImage_sequence "$@"
-
-}
+        _messagePlain_nominal 'prepare: venv: set' > /dev/null >&2
+        _set_msw_python_procedure

-_createPartition() {
-	_mustGetSudo
-
-	sudo -n parted --script "$scriptLocal"/vm.img mklabel msdos
-	sudo -n partprobe > /dev/null 2>&1
-	sudo -n parted "$scriptLocal"/vm.img --script -- mkpart primary 0% 100%
-	sudo -n partprobe > /dev/null 2>&1
-}
+        _messagePlain_probe _install_dependencies_msw_python_procedure-specific "" "" > /dev/null >&2
+        _install_dependencies_msw_python_procedure-specific "" ""
+
+        _messagePlain_probe python -c "import sys; print(sys.path)" > /dev/null >&2
+        python -c "import sys; print(sys.path)" > /dev/null >&2

+        #deactivate > /dev/null >&2
+#fi

-_createFS_sequence() {
-	_mustGetSudo
-
-	_start
-
-	mkdir -p "$globalVirtFS"
-
-	"$scriptAbsoluteLocation" _checkForMounts "$globalVirtFS" && _stop 1
-
-	local imagedev
-	imagedev=$(cat "$scriptLocal"/imagedev)
-
-	local imagepart
-	#imagepart="$imagedev"p2
-	imagepart="$imagedev"p1
-
-	local loopdevfs
-	loopdevfs=$(sudo -n blkid -s TYPE -o value "$imagepart" | tr -dc 'a-zA-Z0-9')
-	[[ "$loopdevfs" == "ext4" ]] && _stop 1
-	sudo -n mkfs.ext4 "$imagepart" > /dev/null 2>&1 || _stop 1
-
-	_stop 0
-}

-_createFS_shell() {
-	"$scriptAbsoluteLocation" _loopImage_sequence || return 1
-	"$scriptAbsoluteLocation" _createFS_sequence || return 1
-	"$scriptAbsoluteLocation" _umountImage || return 1
-	return 0
-}

-_createFS() {
-	local returnCode
-	_open true _createFS_shell
-	returnCode="$?"
-	_close true true
-
-	return "$returnCode"
-}
+        # morsels...
+        _messagePlain_nominal 'prepare: morsels: pip' > /dev/null >&2

+        _morsels_msw_pip_python_3_10




-_here_bootdisc_startup_xdg() {
-cat << 'CZXWXcRMTo8EmM8i4d'
-[Desktop Entry]
-Comment=
-Exec=sudo -n mount -t iso9660 -o ro,nofail LABEL=uk4uPhB663kVcygT0q /media/bootdisc > /dev/null ; sudo -n /media/bootdisc/rootnix.sh > /dev/null ; /media/bootdisc/cmd.sh > /dev/null
-GenericName=
-Icon=exec
-MimeType=
-Name=
-Path=
-StartupNotify=false
-Terminal=false
-TerminalOptions=
-Type=Application
-CZXWXcRMTo8EmM8i4d
-}

-_here_bootdisc_startup_systemd() {
-    cat << CZXWXcRMTo8EmM8i4d
-[Unit]
-After=xdg-desktop-autostart.target

-[Install]
-WantedBy=xdg-desktop-autostart.target

-[Service]
-Type=oneshot
-ExecStart="$1"/.config/startup.sh
-CZXWXcRMTo8EmM8i4d
-}

-_here_bootdisc_startup_script() {
-    cat << CZXWXcRMTo8EmM8i4d
-#!/usr/bin/env bash
-#export QT_QPA_PLATFORMTHEME= ; unset QT_QPA_PLATFORMTHEME ; export LANG="C"
-#export DESKTOP_SESSION=plasma
-#bash "$scriptAbsoluteLocation" _wsl_desktop-waitUp_wmctrl ; sleep 0.6
-export LANG="C"
-CZXWXcRMTo8EmM8i4d

-#dbus-run-session
-#_safeEcho_newline 'exec '"$@"' &'
-_safeEcho_newline 'sudo -n mount -t iso9660 -o ro,nofail LABEL=uk4uPhB663kVcygT0q /media/bootdisc > /dev/null ; sudo -n /media/bootdisc/rootnix.sh > /dev/null ; /media/bootdisc/cmd.sh > /dev/null'

-    cat << CZXWXcRMTo8EmM8i4d
-#disown -h \$!
-disown
-disown -a -h -r
-disown -a -r
-#rm -f "\$HOME"/.config/plasma-workspace/env/startup.sh
-#rm -f "\$HOME"/.config/startup.sh
-#sudo -n rm -f /etc/xdg/autostart/startup.desktop
-#rm -f "\$HOME"/.config/systemd/user/bootdiscStartup.service
-#bash "$scriptAbsoluteLocation" _wsl_desktop-waitDown_wmctrl
-#currentStopJobs=\$(jobs -p -r 2> /dev/null) ; [[ "\$displayStopJobs" != "" ]] && kill \$displayStopJobs > /dev/null 2>&1
-CZXWXcRMTo8EmM8i4d
-}

-_here_bootdisc_rootnix() {
-cat << 'CZXWXcRMTo8EmM8i4d'
-#!/usr/bin/env bash
+        # write > "$dumbpath_file" ; mv -f

-# https://www.howtogeek.com/803839/how-to-let-linux-scripts-detect-theyre-running-in-virtual-machines/
-# WARNING: Must be root!
-if [[ $(dmidecode -s system-product-name) == "VirtualBox" ]] && ! lsmod | grep vboxsf > /dev/null
-then
-	#! lsmod | grep vboxsf > /dev/null && /sbin/rcvboxadd cleanup
-	#/sbin/rcvboxadd quicksetup
-	/sbin/rcvboxadd setup
-fi
+        # ATTENTION: Disable (ie. comment out) to force always rebuild, packages install, etc.
+        echo "$dumbpath_file" > "$dumbpath_file"."$currentUID"
+        mv -f "$dumbpath_file"."$currentUID" "$dumbpath_file"

-if [[ "$0" != "/media/bootdisc/rootnix.sh" ]] && [[ -e "/media/bootdisc" ]]
-then
-	for iteration in `seq 1 25`;
-	do
-		! /bin/mountpoint /media/bootdisc > /dev/null 2>&1 && ! [[ -e "/media/bootdisc/rootnix.sh" ]] && sleep 6
-	done
-	sleep 0.1
-	/media/bootdisc/rootnix.sh "$@"
-	exit
-fi

-#Equivalent "fstab" entries for reference. Not used due to conflict for mountpoint, as well as lack of standard mounting options in vboxsf driver.
-#//10.0.2.4/qemu	/home/user/.pqm cifs	guest,_netdev,uid=user,user,nofail,exec		0 0
-#appFolder		/home/user/.pvb	vboxsf	uid=user,_netdev				0 0

-_mountGuestShareNIX() {
-	! /bin/mountpoint /home/user/project > /dev/null 2>&1 && /bin/mount -t vboxsf -o uid=user,_netdev appFolder /home/user/project 2>&1
-	! /bin/mountpoint /home/user/Downloads > /dev/null 2>&1 && /bin/mount -t vboxsf -o uid=user,_netdev Downloads /home/user/Downloads 2>&1
-
-	! /bin/mountpoint /home/user/project > /dev/null 2>&1 && /bin/mount -t cifs -o guest,_netdev,uid=user,user,nofail,exec '//10.0.2.4/qemu' /home/user/project > /dev/null 2>&1
-
-}
+    fi

-#http://stackoverflow.com/questions/687948/timeout-a-command-in-bash-without-unnecessary-delay
-_timeout() { ( set +b; sleep "$1" & "${@:2}" & wait -n; r=$?; kill -9 `jobs -p`; exit $r; ) }
+    [[ "$current_done__prepare_msw_python_procedure" == "false" ]] && _prepare_msw_python_procedure
+    current_done__prepare_msw_python_procedure="true"

-_uid() {
-	local uidLength
-	[[ -z "$1" ]] && uidLength=18 || uidLength="$1"
-
-	cat /dev/urandom | base64 | tr -dc 'a-zA-Z0-9' | head -c "$uidLength"
-}
+    [[ "$_PYTHONSTARTUP" == "" ]] && _write_python_hook_local

-export sessionid=$(_uid)
-[[ -d /tmp ]] && export bootTmp=/tmp		#Typical BSD
-[[ -d /dev/shm ]] && export bootTmp=/dev/shm	#Typical Linux
+#if false
+#then
+    _messagePlain_nominal 'prepare: venv: activate' > /dev/null >&2
+    ! cd "$scriptLocal"/python_msw/venv && _stop 1
+    #sourcedefault_venv/Scripts/activate > /dev/null >&2
+    _messagePlain_probe source  default_venv/Scripts/activate_msw > /dev/null >&2
+    source default_venv/Scripts/activate_msw > /dev/null >&2
+    PATH="$currentPATH"
+
+    _messagePlain_nominal 'prepare: venv: set' > /dev/null >&2
+    _set_msw_python_procedure
+
+    _messagePlain_probe python -c "import sys; print(sys.path)" > /dev/null >&2
+    python -c "import sys; print(sys.path)" > /dev/null >&2
+#fi

-echo "rootnix" > "$bootTmp"/"$sessionid".rnx
+    _messagePlain_probe _install_dependencies_msw_python_procedure-specific "" "" > /dev/null >&2
+    _install_dependencies_msw_python_procedure-specific "" ""

-#/bin/mkdir -p /home/user/.pqm
-#/bin/mkdir -p /home/user/.pvb

-/bin/mkdir -p /home/user/Downloads
-! /bin/mountpoint /home/user/Downloads && /bin/chown user:user /home/user/Downloads

-/bin/mkdir -p /home/user/project
-! /bin/mountpoint /home/user/project && /bin/chown user:user /home/user/project

-! /bin/mountpoint /home/user/project > /dev/null 2>&1 && sleep 0.1 && _mountGuestShareNIX
-! /bin/mountpoint /home/user/project > /dev/null 2>&1 && sleep 0.3 && _mountGuestShareNIX
-! /bin/mountpoint /home/user/project > /dev/null 2>&1 && sleep 1 && _mountGuestShareNIX
-! /bin/mountpoint /home/user/project > /dev/null 2>&1 && sleep 3 && _mountGuestShareNIX

-for iteration in `seq 1 15`;
-do
-	! /bin/mountpoint /home/user/project > /dev/null 2>&1 && sleep 6 && _mountGuestShareNIX
-done
+    #set ACCELERATE="%VENV_DIR%\Scripts\accelerate.exe"

-! /bin/mountpoint /home/user/project > /dev/null 2>&1 && sleep 9 && _mountGuestShareNIX
-! /bin/mountpoint /home/user/project > /dev/null 2>&1 && sleep 18 && _mountGuestShareNIX
-! /bin/mountpoint /home/user/project > /dev/null 2>&1 && sleep 27 && _mountGuestShareNIX

-CZXWXcRMTo8EmM8i4d
+    rm -f "$scriptLocal"/python_msw.lock
+    _messagePlain_nominal 'done: prepare: '${FUNCNAME[0]} > /dev/null >&2
 }

-_here_bootdisc_startupbat() {
-cat << 'CZXWXcRMTo8EmM8i4d'
-REM CALL A:\uk4uPhB6.bat
-REM CALL B:\uk4uPhB6.bat
-CALL D:\uk4uPhB6.bat
-CALL E:\uk4uPhB6.bat
-CALL F:\uk4uPhB6.bat
-CALL G:\uk4uPhB6.bat
-CALL H:\uk4uPhB6.bat
-CALL Y:\shell.bat
-CZXWXcRMTo8EmM8i4d
-}

-_here_bootdisc_shellbat() {
-cat << 'CZXWXcRMTo8EmM8i4d'
-CALL Y:\loader.bat
-CALL Y:\application.bat
-CZXWXcRMTo8EmM8i4d
-}

-#No production use.
-_here_bootdisc_loaderZbat() {
-cat << 'CZXWXcRMTo8EmM8i4d'
-net use z: /delete

-:checkMount

-net use /USER:guest z: \\VBOXSVR\root ""

-ping -n 2 127.0.0.1 > nul
-IF NOT EXIST "Z:\" GOTO checkMount
-CZXWXcRMTo8EmM8i4d
-}

-_here_bootdisc_loaderXbat() {
-cat << 'CZXWXcRMTo8EmM8i4d'
-net use x: /delete
+# EXAMPLE. Override (preferred) or implement alternative (discouraged) with 'core.sh', 'ops.sh', or similar.
+_morsels_msw_pip_python_3_10() {
+    #export packages_msw_python=( "huggingface_hub[cli]" )
+    local currentPackages_indicator_list=( "huggingface_hub[cli]" "${packages_msw_python[@]}" )
+    local currentPackages_list=( "huggingface_hub[cli]" )
+    local currentPackage

-:checkMount
+    #export nonet_available="true"
+    ( ! wget -qO- 'https://github.com' > /dev/null || ! wget -qO- 'https://pypi.org/simple/' | head > /dev/null ) && export nonet_available="true"
+    local currentIteration_nonet="0"
+    while [[ "$nonet_available" == "true" ]] && [[ "$CI" != "" ]] && [[ "$currentIteration_nonet" -lt 90 ]]
+    do
+        ( wget -qO- 'https://github.com' > /dev/null && wget -qO- 'https://pypi.org/simple/' | head > /dev/null ) && export nonet_available="" && unset nonet_available
+        let currentIteration_nonet++
+    done

-net use /USER:guest x: \\VBOXSVR\appFolder ""
-net use /USER:guest x: \\10.0.2.4\qemu ""
+    local currentWork="false"
+    for currentPackage in "${currentPackages_indicator_list[@]}"
+    do
+        ! pip show "$currentPackage" > /dev/null 2>&1 && currentWork="true"
+        #! python -m pip show "$currentPackage" > /dev/null 2>&1 && currentWork="true"
+    done
+    [[ "$currentWork" == "false" ]] && return 0

-ping -n 2 127.0.0.1 > nul
-IF NOT EXIST "X:\" GOTO checkMount
-CZXWXcRMTo8EmM8i4d
-}
+    [[ "$nonet" != "true" ]] && [[ "$nonet_available" != "true" ]] && python -m pip install --upgrade pip > /dev/null >&2

+    for currentPackage in "${currentPackages_list[@]}"
+    do
+        #,win32,win_arm64
+        [[ "$nonet" != "true" ]] && [[ "$nonet_available" != "true" ]] && pip download "$currentPackage" --platform win_amd64 --only-binary=:all: --dest "$(cygpath -w "$scriptAbsoluteFolder"/_bundle/morsels/pip)" > /dev/null >&2
+
+        pip install --no-index --find-links="$(cygpath -w "$scriptAbsoluteFolder"/_bundle/morsels/pip)" "$currentPackage" > /dev/null >&2

-#Prints "$@" with quotes around every parameter.
-_echoArgsBootdisc_MSW() {
-
-	#https://stackoverflow.com/questions/1668649/how-to-keep-quotes-in-bash-arguments
-
-	local currentCommandStringPunctuated
-	local currentCommandStringParameter
-	for currentCommandStringParameter in "$@"; do
-
-		# MSW interprets the expression \" and similar differently from UNIX.
-		#currentCommandStringParameter="${currentCommandStringParameter//\\/\\\\}"
-
-		currentCommandStringPunctuated="$currentCommandStringPunctuated \"${currentCommandStringParameter//\"/\\\"}\""
-	done
-	#_messagePlain_probe "$currentCommandStringPunctuated"
-
-	#echo -e -n '\E[0;34m '
-
-	_safeEcho "$currentCommandStringPunctuated"
-
-	#echo -e -n ' \E[0m'
-	echo
-
-	return
+        # Strongly discouraged! Avoid surprise breakage by never relying on upstream repositories.
+        #[[ "$nonet" != "true" ]] && [[ "$nonet_available" != "true" ]] && pip install "$currentPackage" > /dev/null >&2
+    done
 }

-#Prints "$@" with quotes around every parameter.
-_echoArgsBootdisc_UNIX() {
-
-	#https://stackoverflow.com/questions/1668649/how-to-keep-quotes-in-bash-arguments
-
-	local currentCommandStringPunctuated
-	local currentCommandStringParameter
-	for currentCommandStringParameter in "$@"; do
-
-		# MSW interprets the expression \" and similar differently from UNIX.
-		currentCommandStringParameter="${currentCommandStringParameter//\\/\\\\}"
-
-		currentCommandStringPunctuated="$currentCommandStringPunctuated \"${currentCommandStringParameter//\"/\\\"}\""
-	done
-	#_messagePlain_probe "$currentCommandStringPunctuated"
-
-	#echo -e -n '\E[0;34m '
-
-	_safeEcho "$currentCommandStringPunctuated"
-
-	#echo -e -n ' \E[0m'
-	echo
-
-	return
-}


-_testVirtBootdisc() {
-	! _wantGetDep genisoimage && _wantGetDep mkisofs
-
-	if ! type mkisofs > /dev/null 2>&1 && ! type genisoimage > /dev/null 2>&1
-	then
-		echo 'need mkisofs or genisoimage'
-		_stop 1
-	fi
-}

-_prepareBootdisc() {
-	mkdir -p "$hostToGuestFiles" > /dev/null 2>&1 || return 1
-	mkdir -p "$hostToGuestDir" > /dev/null 2>&1 || return 1
-	return 0
-}

-_mkisofs() {
-	if type mkisofs > /dev/null 2>&1
-	then
-		mkisofs "$@"
-		return $?
-	fi
-
-	if type genisoimage > /dev/null 2>&1
-	then
-		genisoimage "$@"
-		return $?
-	fi
-}

-_writeBootdisc() {
-	_mkisofs -V "$ubiquitousBashID" -volset "$ubiquitousBashID" -sysid "$ubiquitousBashID" -R -uid 0 -gid 0 -dir-mode 0555 -file-mode 0555 -new-dir-mode 0555 -J -hfs -o "$hostToGuestISO" "$hostToGuestFiles"
-}

-_setShareMSW_app() {
-	export sharedHostProjectDir="$sharedHostProjectDirDefault"
-	export sharedGuestProjectDir="$sharedGuestProjectDirDefault"
-
-	export sharedGuestProjectDir="X:"
-}

-#No production use. Not recommended.
-_setShareMSW_root() {
-	export sharedHostProjectDir="$sharedHostProjectDirDefault"
-	export sharedGuestProjectDir="$sharedGuestProjectDirDefault"
-
-	export sharedHostProjectDir=/
-	export sharedGuestProjectDir="Z:"
-}

-_setShareMSW() {
-	[[ "$flagShareApp" ]] && _setShareMSW_app && return
-	[[ "$flagShareApp" ]] && _setShareMSW_root && return
-	return 1
-}

-#Consider using explorer.exe to use file associations within the guest. Overload with ops to force a more specific 'preCommand'.
-_preCommand_MSW() {
-	echo 'X:'
-	echo 'cd '"$localPWD"
-	echo -e -n 'start /MAX "" "explorer.exe" '
-}

-_createHTG_MSW() {
-	_setShareMSW
-
-	export checkBaseDirRemote=""
-	_virtUser "$@"
-	#"$sharedHostProjectDir"
-	#"${processedArgs[@]}"
-
-	_here_bootdisc_startupbat >> "$hostToGuestFiles"/rootmsw.bat
-
-	_preCommand_MSW >> "$hostToGuestFiles"/application.bat
-
-	# WARNING: Not fully tested with all plausible inputs. Beware possible misinterpretations of '$' and similar characters.
-	#_safeEcho_newline "${processedArgs[@]}" >> "$hostToGuestFiles"/application.bat
-	_echoArgsBootdisc_MSW "${processedArgs[@]}" >> "$hostToGuestFiles"/application.bat
-
-	echo ""  >> "$hostToGuestFiles"/application.bat
-
-	echo -e -n >> "$hostToGuestFiles"/loader.bat
-	[[ "$flagShareApp" == "true" ]] && _here_bootdisc_loaderXbat >> "$hostToGuestFiles"/loader.bat
-	[[ "$flagShareRoot" == "true" ]] && _here_bootdisc_loaderZbat >> "$hostToGuestFiles"/loader.bat
-
-	cat "$hostToGuestFiles"/loader.bat >> "$hostToGuestFiles"/uk4uPhB6.bat
-	cat "$hostToGuestFiles"/application.bat >> "$hostToGuestFiles"/uk4uPhB6.bat
-
-	_here_bootdisc_shellbat >> "$hostToGuestFiles"/shell.bat
-
-	#https://www.cyberciti.biz/faq/howto-unix-linux-convert-dos-newlines-cr-lf-unix-text-format/
-	sed -i 's/$'"/`echo \\\r`/" "$hostToGuestFiles"/rootmsw.bat
-	sed -i 's/$'"/`echo \\\r`/" "$hostToGuestFiles"/application.bat
-	sed -i 's/$'"/`echo \\\r`/" "$hostToGuestFiles"/loader.bat
-	sed -i 's/$'"/`echo \\\r`/" "$hostToGuestFiles"/shell.bat
-	sed -i 's/$'"/`echo \\\r`/" "$hostToGuestFiles"/uk4uPhB6.bat
-}

-_setShareUNIX_app() {
-	export sharedHostProjectDir="$sharedHostProjectDirDefault"
-	export sharedGuestProjectDir="$sharedGuestProjectDirDefault"
-
-	export sharedGuestProjectDir="/home/user/project"
-}

-_setShareUNIX_root() {
-	export sharedHostProjectDir="$sharedHostProjectDirDefault"
-	export sharedGuestProjectDir="$sharedGuestProjectDirDefault"
-
-	export sharedGuestProjectDir="/home/user/project"
-	export sharedHostProjectDir=/
-}

-_setShareUNIX() {
-	[[ "$flagShareApp" ]] && _setShareUNIX_app && return
-	[[ "$flagShareApp" ]] && _setShareUNIX_root && return
-	return 1
-}

-_createHTG_UNIX() {
-	_setShareUNIX
-
-	export checkBaseDirRemote=""
-	_virtUser "$@"
-	#"$sharedHostProjectDir"
-	#"${processedArgs[@]}"
-
-	_here_bootdisc_startup_xdg >> "$hostToGuestFiles"/startup.desktop
-
-	_here_bootdisc_rootnix >> "$hostToGuestFiles"/rootnix.sh
-
-	echo '#!/usr/bin/env bash' >> "$hostToGuestFiles"/cmd.sh
-	echo "export localPWD=""$localPWD" >> "$hostToGuestFiles"/cmd.sh
-
-	# WARNING: Not fully tested with all plausible inputs. Beware possible misinterpretations of '$' and similar characters.
-	#_safeEcho_newline "/media/bootdisc/ubiquitous_bash.sh _dropBootdisc ${processedArgs[@]}" >> "$hostToGuestFiles"/cmd.sh
-	echo -n "/media/bootdisc/ubiquitous_bash.sh _dropBootdisc " >> "$hostToGuestFiles"/cmd.sh
-	_echoArgsBootdisc_UNIX "${processedArgs[@]}" >> "$hostToGuestFiles"/cmd.sh
-
-}

-_commandBootdisc() {
-	_prepareBootdisc || return 1
-
-	export flagShareRoot="false"
-
-	#Rigiorously ensure flags will be set properly.
-	[[ "$flagShareRoot" != "true" ]] && export flagShareRoot="false"
-	[[ "$flagShareRoot" != "true" ]] && export flagShareApp="true"
-
-	#Include ubiquitous_bash itself.
-	cp "$scriptAbsoluteLocation" "$hostToGuestFiles"/
-	"$scriptBin"/.ubrgbin.sh _ubrgbin_cpA "$scriptBin" "$hostToGuestFiles"/_bin
-
-	#Process for MSW.
-	_createHTG_MSW "$@"
-
-	#Process for UNIX.
-	_createHTG_UNIX "$@"
-
-	#Ensure permissions are correctly set.
-	chmod 0755 "$hostToGuestFiles"/_bin/*
-	chmod 0755 "$hostToGuestFiles"/*.sh
-	chmod 0755 "$hostToGuestFiles"/*.desktop
-	chmod 0755 "$hostToGuestFiles"/*.bat
-	#chmod 0755 "$hostToGuestFiles"/*
-
-	_writeBootdisc || return 1
-}

-_dropBootdisc() {
-	#Detect MSW/Cygwin architecture.
-		#Check for QEMU type shared directory, mount if present.
-		#Check for VBox type shared directory, mount if present.
-
-	#Detect UNIX architecture.
-	if ! uname -a | grep -i cygwin > /dev/null 2>&1
-	then
-		#Attempt to wait for QEMU or VBox type shared directory.
-		! mountpoint /home/user/project > /dev/null 2>&1 && sleep 0.3
-		! mountpoint /home/user/project > /dev/null 2>&1 && sleep 1
-		! mountpoint /home/user/project > /dev/null 2>&1 && sleep 3
-
-		for iteration in `seq 1 15`;
-		do
-			! /bin/mountpoint /home/user/project > /dev/null 2>&1 && sleep 6
-		done
-
-		! mountpoint /home/user/project > /dev/null 2>&1 && sleep 9
-		! mountpoint /home/user/project > /dev/null 2>&1 && sleep 18
-		! mountpoint /home/user/project > /dev/null 2>&1 && sleep 27
-		! mountpoint /home/user/project > /dev/null 2>&1 && sleep 36
-	fi
-	sleep 0.3
-
-	[[ -e "$HOME"/.config/plasma-workspace/env/profile.sh ]] && /bin/bash "$HOME"/.config/plasma-workspace/env/profile.sh

-	cd "$localPWD"
-
-	"$@"
-}





-# TODO Launch "_fromImage", transfering "/home/user" to archive, then transfering this archive to "/etc/skel" .
-_importHomeUser() {
-	true
-}

-_exportHomeUser() {
-	true
+
+_discover-msw_python() {
+    _discover_procedure-msw_python "$@"
+    if [[ "$lib_dir_msw_python_wheels" != "" ]]
+    then
+        export lib_dir_msw_python_wheels_msw=$(cygpath -w "$lib_dir_msw_python_wheels")
+        if [[ "$_PATH_pythonDir" != "" ]]
+        then
+            export lib_dir_msw_python_wheels_relevant="$lib_dir_msw_python_wheels_msw"
+        else
+            export lib_dir_msw_python_wheels_relevant="$lib_dir_msw_python_wheels"
+        fi
+        return 0
+    fi
+    export lib_dir_msw_python_wheels_msw=""
+    unset lib_dir_msw_python_wheels_msw
+    export lib_dir_msw_python_wheels_relevant=""
+    unset lib_dir_msw_python_wheels_relevant
+    return 1
 }
+_discover_procedure-msw_python() {
+    export lib_dir_msw_python_wheels
+
+    export lib_dir_msw_python_wheels="$scriptAbsoluteFolder"/.python_wheels/msw
+    if [[ -e "$lib_dir_msw_python_wheels" ]]
+    then
+        . "$lib_dir_msw_python_wheels"/_msw_python_wheels.sh
+        return 0
+    fi
+    export lib_dir_msw_python_wheels="$scriptLocal"/.python_wheels/msw
+    if [[ -e "$lib_dir_msw_python_wheels" ]]
+    then
+        . "$lib_dir_msw_python_wheels"/_msw_python_wheels.sh
+        return 0
+    fi
+    export lib_dir_msw_python_wheels="$scriptLib"/.python_wheels/msw
+    if [[ -e "$lib_dir_msw_python_wheels" ]]
+    then
+        . "$lib_dir_msw_python_wheels"/_msw_python_wheels.sh
+        return 0
+    fi

-# TODO To be used by "_userChRoot", binding "/home/user", as an alternative to copying "/etc/skel" .
-_bindHomeUser() {
-	true
+
+    export lib_dir_msw_python_wheels="$scriptLib"/ubiquitous_bash/_lib/.python_wheels/msw
+    if [[ -e "$lib_dir_msw_python_wheels" ]]
+    then
+        . "$lib_dir_msw_python_wheels"/_msw_python_wheels.sh
+        return 0
+    fi
+    export lib_dir_msw_python_wheels="$scriptLib"/ubDistBuild/_lib/ubiquitous_bash/_lib/.python_wheels/msw
+    if [[ -e "$lib_dir_msw_python_wheels" ]]
+    then
+        . "$lib_dir_msw_python_wheels"/_msw_python_wheels.sh
+        return 0
+    fi
+
+    export lib_dir_msw_python_wheels=""
+    unset lib_dir_msw_python_wheels
 }
+_install_dependencies_msw_python_procedure-specific() {
+    _messagePlain_nominal 'install: dependencies' > /dev/null >&2

-_unbindHomeUser() {
-	true
+    _discover-msw_python
+
+    # Not all of these packages are necessary for dist/OS other than native MSWindows.
+    #export dependencies_msw_python=( "pyreadline3" )
+    local currentPackages_list=( "pyreadline3" "colorama" "${dependencies_msw_python[@]}" )
+    local currentPackage
+
+    #export nonet_available="true"
+    ( ! wget -qO- 'https://github.com' > /dev/null || ! wget -qO- 'https://pypi.org/simple/' | head > /dev/null ) && export nonet_available="true"
+    local currentIteration_nonet="0"
+    while [[ "$nonet_available" == "true" ]] && [[ "$CI" != "" ]] && [[ "$currentIteration_nonet" -lt 90 ]]
+    do
+        ( wget -qO- 'https://github.com' > /dev/null && wget -qO- 'https://pypi.org/simple/' | head > /dev/null ) && export nonet_available="" && unset nonet_available
+        let currentIteration_nonet++
+    done
+
+
+    if [[ "$nonet" != "true" ]] && [[ "$nonet_available" != "true" ]]
+    then
+        _pip_upgrade() {
+            local currentUpgrade="false"
+            for currentPackage in "${currentPackages_list[@]}"
+            do
+                ! "$1"pip show "$currentPackage" > /dev/null 2>&1 && currentUpgrade="true"
+                #! "$2"python -m pip show "$currentPackage" > /dev/null 2>&1 && currentUpgrade="true"
+            done
+            [[ "$currentUpgrade" == "false" ]] && return 0
+            "$2"python -m pip install --upgrade pip > /dev/null >&2
+        }
+        _pip_upgrade "$1" "$2"
+    fi
+
+
+    if [[ "$nonet" != "true" ]] && [[ "$nonet_available" != "true" ]]
+    then
+
+        if [[ "$lib_dir_msw_python_wheels" != "" ]]
+        then
+            # ATTRIBUTION-AI: ChatGPT o3  2025-04-19  (partially)
+            _pip_download() {
+                "$1"pip show "$3" > /dev/null 2>&1 && return 0
+                #"$2"python -m pip show "$3" > /dev/null 2>&1 && return 0
+
+                #--python-version 3.1
+                "$1"pip download "$3" --platform win_amd64 --only-binary=:all: --dest "$lib_dir_msw_python_wheels_relevant" > /dev/null >&2
+                #"$1"pip download "$3" --platform win32 --only-binary=:all: --dest "$lib_dir_msw_python_wheels_relevant" > /dev/null >&2
+                "$1"pip download "$3" --platform win_arm64 --only-binary=:all: --dest "$lib_dir_msw_python_wheels_relevant" > /dev/null >&2
+
+                #"$2"python -m pip download "$3" --platform win_amd64 --only-binary=:all: --dest "$lib_dir_msw_python_wheels_relevant" > /dev/null >&2
+                #"$2"python -m pip download "$3" --platform win32 --only-binary=:all: --dest "$lib_dir_msw_python_wheels_relevant" > /dev/null >&2
+                #"$2"python -m pip download "$3" --platform win_arm64 --only-binary=:all: --dest "$lib_dir_msw_python_wheels_relevant" > /dev/null >&2
+            }
+
+            for currentPackage in "${currentPackages_list[@]}"
+            do
+                _pip_download "$1" "$2" "$currentPackage"
+            done
+        fi
+    fi
+
+
+    if [[ "$lib_dir_msw_python_wheels_relevant" != "" ]]
+    then
+        _pip_install_nonet() {
+            "$1"pip show "$3" > /dev/null 2>&1 && return 0
+            #"$2"python -m pip show "$3" > /dev/null 2>&1 && return 0
+
+            "$1"pip install --no-index --find-links="$lib_dir_msw_python_wheels_relevant" "$3" > /dev/null >&2
+            #"$2"python -m pip install --no-index --find-links="$lib_dir_msw_python_wheels_relevant" "$3" > /dev/null >&2
+        }
+        for currentPackage in "${currentPackages_list[@]}"
+        do
+            _pip_install_nonet "$1" "$2" "$currentPackage"
+        done
+    fi
+
+    if [[ "$nonet" != "true" ]] && [[ "$nonet_available" != "true" ]]
+    then
+        _pip_install() {
+            "$1"pip show "$3" > /dev/null 2>&1 && return 0
+            #"$2"python -m pip show "$3" > /dev/null 2>&1 && return 0
+
+            "$1"pip install "$3" > /dev/null >&2
+            #"$2"python -m pip install "$3" > /dev/null >&2
+        }
+        for currentPackage in "${currentPackages_list[@]}"
+        do
+            _pip_install "$1" "$2" "$currentPackage"
+        done
+    fi
+
+    return 0
 }
+_install_dependencies_msw_python_sequence-specific() {
+    _messageNormal '     install: dependencies: '"$1" > /dev/null >&2
+    _start

+    "$1"
+    if [[ ! -e "$_PATH_pythonDir" ]]
+    then
+        ( _messagePlain_warn 'warn: skip: missing: python: '"$1" >&2 ) > /dev/null
+        _stop 1
+    fi
+
+    _install_dependencies_msw_python_procedure-specific

-_test_transferimage() {
-	_mustGetSudo
-
-	_getDep rsync
+    _stop
+}
+_install_dependencies_msw_python() {
+    "$scriptAbsoluteLocation" _install_dependencies_msw_python_sequence-specific _set_msw_python_3_10
 }

-_toImage() {
-	_findInfrastructure_virtImage ${FUNCNAME[0]} "$@"
-	[[ "$ubVirtImageLocal" == "false" ]] && return
-
-	#_openImage || return 1
-	_openChRoot || return 1
-
-	#rsync -avx -A -X "$1" "$globalVirtFS"/"$2"
-	rsync -avx "$1" "$globalVirtFS"/"$2"
+
+
+
+_prepare_msw_python_procedure() {
+    local currentUID=$(_uid)
+
+    if [[ ! -e "$_PATH_pythonDir"/python3 ]] && [[ $(find "$_PATH_pythonDir" -maxdepth 1 -iname 'python3' -type f -print -quit 2>/dev/null | tr -dc 'a-zA-Z0-9') == "" ]]
+    then
+        echo '#!/usr/bin/env bash
+        python "$@"' > "$_PATH_pythonDir"/python3."$currentUID"
+        chmod u+x "$_PATH_pythonDir"/python3."$currentUID"
+        mv -f "$_PATH_pythonDir"/python3."$currentUID" "$_PATH_pythonDir"/python3
+        chmod u+x "$_PATH_pythonDir"/python3
+    fi
+
+
+    mkdir -p "$scriptLocal"
+
+    mkdir -p "$scriptLocal"/python_msw
+
+    # In practice, 'pip' morsels may be all that is needed (ie. using 'pip' morsels for venv installation).
+    mkdir -p "$scriptAbsoluteFolder"/_bundle/morsels
+    mkdir -p "$scriptAbsoluteFolder"/_bundle/morsels/pip
+
+    mkdir -p "$scriptAbsoluteFolder"/_bundle/morsels/venv
+    mkdir -p "$scriptAbsoluteFolder"/_bundle/morsels/accelerate
+
+    # STRONGLY DISCOURAGED!
+    mkdir -p "$scriptAbsoluteFolder"/_bundle/morsels/conda
+
+    if [[ ! -e "$scriptLocal"/python_msw/lean.py ]] || ! diff --unified=3 "$scriptAbsoluteFolder"/lean.py "$scriptLocal"/python_msw/lean.py > /dev/null
+    then
+        cp -f "$scriptAbsoluteFolder"/lean.py "$scriptLocal"/python_msw/lean.py."$currentUID" > /dev/null 2>&1
+        mv -f "$scriptLocal"/python_msw/lean.py."$currentUID" "$scriptLocal"/python_msw/lean.py
+        if [[ ! -e "$scriptLocal"/python_msw/lean.py ]]
+        then
+            cp -f "$scriptLib"/ubiquitous_bash/lean.py "$scriptLocal"/python_msw/lean.py."$currentUID"
+            mv -f "$scriptLocal"/python_msw/lean.py."$currentUID" "$scriptLocal"/python_msw/lean.py
+        fi
+    fi
+    [[ ! -e "$scriptLocal"/python_msw/lean.py ]] && ( _messagePlain_warn 'warn: missing: scriptLocal/python_msw/lean.py' >&2 ) > /dev/null
+
+
+    _install_dependencies_msw_python_procedure-specific "" ""
+
+    return 0
 }

-_toImageDir() {
-	mkdir -p "$globalVirtFS"/"$2"
-	_toImage "$1" "$2"
+
+
+
+# UNIX/Linux of course has no need for such overrides, having normal Python installations in directories in PATH and no distinction between native/MSW and Cygwin/MSW binaries .
+_override_msw_path_python_procedure() {
+		local path_entry entry IFS=':'
+		local new_path=""
+		for entry in $PATH ; do
+			# Skip adding if this entry matches current_binaries_path exactly
+			[ "$entry" = "$current_binaries_path" ] && continue
+
+			# Append current entry to the new_path
+			if [ -z "$new_path" ]; then
+				new_path="$entry"
+			else
+				new_path="${new_path}:${entry}"
+			fi
+		done
+
+		# Finally, explicitly prepend the git path
+		export PATH="${current_binaries_path}:${new_path}"
+
+        [[ "$1" == "" ]] && export _PATH_pythonDir="$current_binaries_path"
+
+        [[ "$1" != "" ]] && ( _messagePlain_probe_var PATH >&2 ) > /dev/null
+
+        return 0
 }
+_detect_msw_path_python() {
+        current_binaries_path="$1"

-_fromImage() {
-	#_openImage || return 1
-	_openChRoot || return 1
-
-	#rsync -avx -A -X "$globalVirtFS""$1" "$2"
-	rsync -avx "$globalVirtFS""$1" "$2"
+        ! [[ -d "$current_binaries_path" ]] && ( _messagePlain_warn 'warn: missing: python: '"$1" >&2 ) && return 1
+
+        ( _messagePlain_good 'success: found: python: '"$1" >&2 ) > /dev/null
 }
+_detect_msw_path_python-localappdata() {
+        current_binaries_path=$(cygpath -u "$LOCALAPPDATA")
+        current_binaries_path="$current_binaries_path"/"$1"

-_fromImageDir() {
-	mkdir -p "$2"
-	_fromImage "$1" "$2"
+        ! [[ -d "$current_binaries_path" ]] && ( _messagePlain_warn 'warn: missing: python: '"$1" >&2 ) && return 1
+
+        ( _messagePlain_good 'success: found: python: '"$1" >&2 ) > /dev/null
 }
+_override_msw_path_python_3_10() {
+    _messagePlain_nominal 'override: '${FUNCNAME[0]}

-_imageToArc() {
-	[[ "$globalArcFS" == "" ]] && return 1
-	[[ "$globalArcFS" == "/" ]] && return 1
-
-	mkdir -p "$globalArcFS" || return 1
-
-	_fromImageDir /home/user/. "$globalArcFS"/home/user
-	_fromImageDir /etc/skel/. "$globalArcFS"/etc/skel
+    local current_binaries_path=""
+
+    # WARNING: Python 'embed' package may not be tested. Use the installer instead.
+
+    _detect_msw_path_python "$scriptLib"/msw/python-3.10.11-embed-amd64
+    [[ "$?" == "0" ]] && [[ -d "$current_binaries_path" ]] && _override_msw_path_python_procedure && return 0
+
+    _detect_msw_path_python "$scriptLocal"/msw/python-3.10.11-embed-amd64
+    [[ "$?" == "0" ]] && [[ -d "$current_binaries_path" ]] && _override_msw_path_python_procedure && return 0
+
+    _detect_msw_path_python-localappdata "Programs/Python/python-3.10.11-embed-amd64"
+    [[ "$?" == "0" ]] && [[ -d "$current_binaries_path" ]] && _override_msw_path_python_procedure && return 0
+
+    _detect_msw_path_python-localappdata "Programs/Python/Python310"
+    [[ "$?" == "0" ]] && [[ -d "$current_binaries_path" ]] && _override_msw_path_python_procedure && return 0
+
+
+    ( _messagePlain_bad 'FAIL: missing: python: '${FUNCNAME[0]} >&2 ) > /dev/null
+    ( _messagePlain_request 'request: install: https://www.python.org/ftp/python/3.10.11/python-3.10.11-amd64.exe' >&2 ) > /dev/null
+    #( _messagePlain_request 'request: install: https://www.python.org/ftp/python/3.10.11/python-3.10.11-embed-amd64.zip' >&2 ) > /dev/null
+    #( _messagePlain_request 'request: extract: '"$scriptLib"/msw/ >&2 ) > /dev/null
+    #( _messagePlain_request 'request: extract: '"$scriptLocal"/msw/ >&2 ) > /dev/null
+    #( _messagePlain_request 'request: extract: '"$LOCALAPPDATA"'Programs/Python' >&2 ) > /dev/null
+    _messageFAIL >&2
 }

-_imageFromArc() {
-	[[ "$globalArcFS" == "" ]] && return 1
-	[[ "$globalArcFS" == "/" ]] && return 1
-
-	mkdir -p "$globalArcFS" || return 1
-
-	_toImageDir "$globalArcFS"/home/user/. /home/user
-	_toImageDir "$globalArcFS"/etc/skel/. /etc/skel
+# CAUTION: Called by _setupUbiquitous_accessories_here-python_hook .
+_set_msw_python_procedure() {
+    # WARNING: Invalid variables for 'python...embed' .
+    export _pythonLib=$(find "$_PATH_pythonDir" -iname 'Lib' -type d -print -quit)
+    export _pythonSitePackages=$(find "$_PATH_pythonDir" -iname 'site-packages' -type d -print -quit)
+    export _pythonPip_file=$(find "$_PATH_pythonDir" -iname 'pip3.exe' -type f -print -quit)
+    export _pythonPip=$([[ "$_pythonPip_file" != "" ]] && _getAbsoluteFolder "$_pythonPip_file")
+    export _pythonPipInstaller_file=$(find "$_PATH_pythonDir" -iname 'get-pip.py' -type f -print -quit)
+
+    # DUBIOUS
+    export _transformersCache="$scriptLocal"/transformers-cache
+
+
+    #export _python=$(find "$_PATH_pythonDir" -iname 'python.exe' -type f -print -quit)
+
+    #export _accelerate=$(find "$_PATH_pythonDir" -iname 'accelerate.exe' -type f -print -quit)
+
+
+    [[ ! -e "$_pythonLib" ]] && ( _messagePlain_bad 'bad: missing: $_pythonLib' >&2 ) > /dev/null && _messageFAIL >&2
+    [[ ! -e "$_pythonSitePackages" ]] && ( _messagePlain_bad 'bad: missing: $_pythonLib' >&2 ) > /dev/null && _messageFAIL >&2
+    [[ ! -e "$_pythonPip_file" ]] && ( _messagePlain_bad 'bad: missing: $_pythonLib' >&2 ) > /dev/null && _messageFAIL >&2
+    [[ ! -e "$_pythonPip" ]] && ( _messagePlain_bad 'bad: missing: $_pythonLib' >&2 ) > /dev/null && _messageFAIL >&2
+    #[[ ! -e "$_pythonPipInstaller_file" ]] && ( _messagePlain_bad 'bad: missing: $_pythonLib' >&2 ) > /dev/null && _messageFAIL >&2
+
+    local current_binaries_path
+    current_binaries_path="$_PATH_pythonDir"
+    _override_msw_path_python_procedure "_PATH_pythonDir"
+
+    current_binaries_path="$_pythonPip"
+    _override_msw_path_python_procedure "pip"
+
+    local VIRTUAL_ENV_unix
+    [[ "$VIRTUAL_ENV" != "" ]] && VIRTUAL_ENV_unix=$(cygpath -u "$VIRTUAL_ENV")
+    VIRTUAL_ENV_unix="$VIRTUAL_ENV_unix"/Scripts
+    if [[ -e "$VIRTUAL_ENV_unix" ]]
+    then
+        export _pythonLib=$(find "$VIRTUAL_ENV_unix"/.. -iname 'Lib' -type d -print -quit)
+        export _pythonSitePackages=$(find "$VIRTUAL_ENV_unix"/.. -iname 'site-packages' -type d -print -quit)
+        export _pythonPip_file=$(find "$VIRTUAL_ENV_unix" -iname 'pip3.exe' -type f -print -quit)
+        export _pythonPip=$([[ "$_pythonPip_file" != "" ]] && _getAbsoluteFolder "$_pythonPip_file")
+        export _pythonPipInstaller_file=$(find "$VIRTUAL_ENV_unix" -iname 'get-pip.py' -type f -print -quit)
+
+
+        #export _python=$(find "$_PATH_pythonDir" -iname 'python.exe' -type f -print -quit)
+
+        #export _accelerate=$(find "$_PATH_pythonDir" -iname 'accelerate.exe' -type f -print -quit)
+
+
+        [[ ! -e "$_pythonLib" ]] && ( _messagePlain_bad 'bad: missing: $_pythonLib' >&2 ) > /dev/null && _messageFAIL >&2
+        [[ ! -e "$_pythonSitePackages" ]] && ( _messagePlain_bad 'bad: missing: $_pythonLib' >&2 ) > /dev/null && _messageFAIL >&2
+        [[ ! -e "$_pythonPip_file" ]] && ( _messagePlain_bad 'bad: missing: $_pythonLib' >&2 ) > /dev/null && _messageFAIL >&2
+        [[ ! -e "$_pythonPip" ]] && ( _messagePlain_bad 'bad: missing: $_pythonLib' >&2 ) > /dev/null && _messageFAIL >&2
+        #[[ ! -e "$_pythonPipInstaller_file" ]] && ( _messagePlain_bad 'bad: missing: $_pythonLib' >&2 ) > /dev/null && _messageFAIL >&2
+
+
+        current_binaries_path="$VIRTUAL_ENV_unix"
+        _override_msw_path_python_procedure "VIRTUAL_ENV"
+
+        current_binaries_path="$_pythonPip"
+        _override_msw_path_python_procedure "VIRTUAL_ENV_pip"
+    fi
+
+    unset PYTHONHOME
+    export PYTHONSTARTUP="$_PYTHONSTARTUP"
+
+    return 0
 }

-#Example. Translates permissions and copies ".arduino" directory.
-_buildFromImage() {
-	_mustGetSudo
-
-	[[ "$globalBuildDir" == "" ]] && return 1
-	[[ "$globalBuildDir" == "/" ]] && return 1
-
-	mkdir -p "$globalBuildDir" || return 1
-
-	sudo -n "$scriptAbsoluteLocation" _fromImageDir /home/user/.arduino/. "$globalBuildDir"/.arduino
-	#sudo -n "$scriptAbsoluteLocation" _fromImageDir /etc/skel/.arduino/. "$globalBuildDir"/.arduino
-
-	_safePath "$globalBuildDir"/.arduino && sudo -n chown -R "$USER":"$GROUP" "$globalBuildDir"/.arduino
+set_msw_python() {
+    _set_msw_python_3_10 "$@"
 }
+_set_msw_python_3_10() {
+    _override_msw_path_python_3_10 "$@"

-#Example. Translates permissions and copies ".arduino" directory.
-_buildToImage() {
-	_mustGetSudo
-
-	[[ "$globalBuildDir" == "" ]] && return 1
-	[[ "$globalBuildDir" == "/" ]] && return 1
-
-	mkdir -p "$globalBuildDir" || return 1
-
-	sudo -n "$scriptAbsoluteLocation" _toImageDir "$globalBuildDir"/.arduino/. /home/user/.arduino
-	sudo -n "$scriptAbsoluteLocation" _toImageDir "$globalBuildDir"/.arduino/. /etc/skel/.arduino
-
-	_chroot chown -R user:user /home/user/.arduino
-	_chroot chown -R root:root /etc/skel/.arduino
+    _set_msw_python_procedure "$@"
 }


-_testChRoot() {
-	_mustGetSudo
-
-	_testGosu || _stop 1
-
-	_checkDep gosu-armel
-	_checkDep gosu-amd64
-	_checkDep gosu-i386
-
-	_getDep id
-
-	_getDep mount
-	_getDep umount
-	_getDep mountpoint
-
-	_getDep unionfs-fuse
-
+
+_demo_msw_python() {
+    _messagePlain_nominal 'demo: '${FUNCNAME[0]} > /dev/null >&2
+    sleep 0.6
+    "$@"
+    _bash
 }

-#Lists all chrooted processes. First parameter is chroot directory. Script might need to run as root.
-#Techniques originally released by other authors at http://forums.grsecurity.net/viewtopic.php?f=3&t=1632 .
-#"$1" == ChRoot Dir
-_listprocChRoot() {
-	local absolute1
-	absolute1=$(_getAbsoluteLocation "$1")
-	PROCS=""
-	local currentProcess
-	# CAUTION: Rarely necessary. Avoid relying on this if possible.
-	for currentProcess in `ps -o pid -A`; do
-		if [ "`sudo -n readlink /proc/$currentProcess/root`" = "$absolute1" ]; then
-			PROCS="$PROCS"" ""$currentProcess"
-		fi
-	done
-	echo "$PROCS"
+
+# STRONGLY DISCOURAGED
+
+
+
+
+
+# Suggested defaults. If your python code (not python itself, nor venv, etc, but filenames for files your python application uses, such as datasets, models, etc) insists on absolute paths, and you must use it under both UNIX/Linux and Cygwin/MSW, then it is probably only needed temporarily to generate static assets (ie. occasional experimental fine-tuning of the latest available AI models). In which case you can put into production under solely UNIX/Linux if necessary, and develop with Docker (ie. factory) instead.
+# tldr; UNIX/Linux for python in production, Cygwin/MSW (ie. MSW native python) for python in development, as usual, and then you won't need abstractfs .
+#
+#_set_abstractfs_alwaysUNIXneverNative
+#_set_abstractfs_disable
+
+
+
+# ATTENTION: EXAMPLE. Override or implement alternative with 'core.sh', 'ops.sh', or similar.
+# ATTENTION: Also create "$scriptLib"/python/lean.py .
+_nix_python() {
+    export dependencies_nix_python=( "readline" )
+    export packages_nix_python=( "huggingface_hub[cli]" )
+
+    #implies sequence
+    _prepare_nix_python
+
+
+    # ATTENTION: Dropping to an interactive shell in the midst of a bash function which provides standard output to another bash function
+    #
+    # ie. don't expect guaranteed sanity doing something like this in either bash or python
+    # echo $( echo result ; bash -i ) | tee > ./logfile.txt
+    #
+    # ALWAYS call interactively unless 'stdout' will be consumed. Functions, scripts, commands, get an interactive terminal to talk to, except very simple functions.
+    #
+    # ie. _fineTune_model  <->  Interactive Shell
+    # ie. _vector_model  <->  Interactive Shell
+    # ie. _inferenceModel | grep 'stuff' > description.txt  <->  Interactive Shell
+    # ie. result=$(_inferenceModel | grep 'correct')  <->  Non-Interactive
+    #
+    # Unfortunately, bash function calls from python do not enjoy the '$() > /dev/null 2>&1' syntactic convenience.
+    # Python calls to '_bin()' , '_bash()' , etc, must explicitly declare or implicitly default sanely whether interactive or non-interactive captured output.
+
+    # lean.py ... is a template script from 'ubiquitous_bash' for lightweight manual changes
+    #"$scriptLocal"/python_nix/lean.py   #automatically replaced with autogenerated lean.py
+    #"$scriptLib"/python_nix/lean.py    #ATTTENTION: create persistent custom lean.py here
+
+
+    # WARNING: May be untested.
+
+    # "$scriptCall_bin" # _bin.bat (replace "$scriptAbsoluteLocation")
+    # "$scriptCall_bin" # _bash.bat (replace "$scriptAbsoluteLocation")
+
+    #python "$scriptLib"'/python/lean.py' '_bin(["sleep", "90",], True, r"'"$scriptAbsoluteLocation"'")'
+
+    #python "$scriptAbsoluteFolder"'/lean.py' '_bash(["-i"], True, r"'"$scriptAbsoluteLocation"'")'
+
+    python "$scriptAbsoluteFolder"'/lean.py' '_bin(["_demo_nix_python",], True, r"'"$scriptAbsoluteLocation"'", interactive=True)'
+
+    #python -i "$scriptAbsoluteFolder"'/lean.py' '_python()'
+
+    #_bash
 }
+_nix_python_bash() {
+    #export dependencies_nix_python=( "readline" )
+    #export packages_nix_python=( "huggingface_hub[cli]" )

-_killprocChRoot() {
-	local chrootKillSignal
-	chrootKillSignal="$1"
-
-	local chrootKillDir
-	chrootKillDir="$2"
-
-	chrootprocs=( $(_listprocChRoot "$2") )
-	[[ "${chrootprocs[0]}" == "" ]] && return 0
-	sudo -n kill -"$chrootKillSignal" "${chrootprocs[@]}" >/dev/null
-	sleep 0.1
-
-	chrootprocs=( $(_listprocChRoot "$2") )
-	[[ "${chrootprocs[0]}" == "" ]] && return 0
-	sudo -n kill -"$chrootKillSignal" "${chrootprocs[@]}" >/dev/null
-	sleep 0.3
-
-	[[ "$EMERGENCYSHUTDOWN" == "true" ]] && return 1
-
-	chrootprocs=( $(_listprocChRoot "$2") )
-	[[ "${chrootprocs[0]}" == "" ]] && return 0
-	sudo -n kill -"$chrootKillSignal" "${chrootprocs[@]}" >/dev/null
-	sleep 1
-
-	chrootprocs=( $(_listprocChRoot "$2") )
-	[[ "${chrootprocs[0]}" == "" ]] && return 0
-	sudo -n kill -"$chrootKillSignal" "${chrootprocs[@]}" >/dev/null
-	sleep 3
-
-	chrootprocs=( $(_listprocChRoot "$2") )
-	[[ "${chrootprocs[0]}" == "" ]] && return 0
-	sudo -n kill -"$chrootKillSignal" "${chrootprocs[@]}" >/dev/null
-	sleep 9
-
-	#chrootprocs=( $(_listprocChRoot "$2") )
-	#[[ "${chrootprocs[0]}" == "" ]] && return 0
-	#sudo -n kill -"$chrootKillSignal" "${chrootprocs[@]}" >/dev/null 2>&1
-	#sleep 18
+    #implies sequence
+    _prepare_nix_python
+
+    _bash
 }
+_nix_python_bin() {
+    #export dependencies_nix_python=( "readline" )
+    #export packages_nix_python=( "huggingface_hub[cli]" )

-#End user and diagnostic function, shuts down all processes in a chroot.
-_stopChRoot() {
-	_mustGetSudo
-
-	local absolute1
-	absolute1=$(_getAbsoluteLocation "$1")
-
-	echo "TERMinating all chrooted processes."
-
-	_killprocChRoot "TERM" "$absolute1"
-
-	echo "KILLing all chrooted processes."
-
-	_killprocChRoot "KILL" "$absolute1"
-
-	echo "Remaining chrooted processes."
-	_listprocChRoot "$absolute1"
-
-	echo '-----'
-
+    #implies sequence
+    _prepare_nix_python
+
+    _bin "$@"
 }


-# May override with 'ops.sh' or similar. Future development intended. Currently, creating an image of a physical device is strongly recommended instead.
-_detect_deviceAsChRootImage() {
-	false
-
-	# TODO: Determine if "$ubVirtImageOverride" or "$scriptLocal" points to a device file (typically under '/dev').
-	# TODO: Should call separate function _detect_deviceAsVirtImage .
-	# DANGER: Functions under 'mountimage.sh' must also respect this.
+# ATTENTION: Call from '_test_prog' with 'core.sh' or similar.
+# _setup calls _test calls _test_prog
+_test_nix_python() {
+    #export dependencies_nix_python=( "readline" )
+    #export packages_nix_python=( "huggingface_hub[cli]" )
+
+    _prepare_nix_python
 }


-#"$1" == ChRoot Dir
-_mountChRoot() {
+
+
+
+
+
+
+
+
+# EXAMPLE. Override or implement alternative with 'core.sh', 'ops.sh', or similar.
+_prepare_nix_python() {
+    _prepare_nix_python_3
+}
+# EXAMPLE. Override or implement alternative (discouraged) with 'core.sh', 'ops.sh', or similar, if necessary.
+_prepare_nix_python_3() {
+    _set_nix_python_3
+
+    # ATTENTION: implies sequence
+    local currentUID="$sessionid"
+
+    # ATTENTION: Do NOT enable. Prevents 'trap' cleanup of abandoned lock file.
+    #local currentUID=$(_uid 18)
+
+    local currentUID_length=${#currentUID}
+    local currentUID_length_plus1=$(( currentUID_length + 1 ))
+
+    local currentPATH="$PATH"
+
+    _write_python_hook_local() {
+        _messagePlain_nominal 'prepare: python hook' > /dev/null >&2
+
+        local ubcore_accessoriesFile_python
+        local ubcoreDir_accessories_python
+        local ubcore_accessoriesFile_python_ubhome
+
+        ubcore_accessoriesFile_python="$scriptLib"/python_nix/lean.py
+        ubcoreDir_accessories_python="$scriptLib"/python_nix
+        ubcore_accessoriesFile_python_ubhome="$scriptLib"/python_nix/lean.py
+        if [[ ! -e "$ubcore_accessoriesFile_python" ]] || [[ ! -e "$ubcoreDir_accessories_python" ]] || [[ ! -e "$ubcore_accessoriesFile_python_ubhome" ]]
+        then
+            ( _messagePlain_warn 'warn: missing: scriptLib/python_nix/...' >&2 ) > /dev/null
+
+            ubcore_accessoriesFile_python="$scriptLocal"/python_nix/lean.py
+            ubcoreDir_accessories_python="$scriptLocal"/python_nix
+            ubcore_accessoriesFile_python_ubhome="$scriptLocal"/python_nix/lean.py
+            if [[ ! -e "$ubcore_accessoriesFile_python" ]] || [[ ! -e "$ubcoreDir_accessories_python" ]] || [[ ! -e "$ubcore_accessoriesFile_python_ubhome" ]]
+            then
+                ( _messagePlain_warn 'warn: missing: scriptLocal/python_nix/...' >&2 ) > /dev/null
+            fi
+        fi
+
+        local ubcore_ubcorerc_pythonrc="lean"
+
+        _setupUbiquitous_accessories_here-python_hook > "$scriptLocal"/python_nix/pythonrc."$currentUID"
+        if [[ ! -e "$scriptLocal"/python_nix/pythonrc ]] || ! diff --unified=3 "$scriptLocal"/python_nix/pythonrc."$currentUID" "$scriptLocal"/python_nix/pythonrc > /dev/null
+        then
+            mv -f "$scriptLocal"/python_nix/pythonrc."$currentUID" "$scriptLocal"/python_nix/pythonrc
+        else
+            rm -f "$scriptLocal"/python_nix/pythonrc."$currentUID"
+        fi
+
+        export _PYTHONSTARTUP="$scriptLocal"/python_nix/pythonrc
+        export PYTHONSTARTUP="$_PYTHONSTARTUP"
+    }
+    unset _PYTHONSTARTUP
+
+
+    local current_done__prepare_nix_python_procedure="false"
+
+
+    _lock_prepare_python_nix() {
+        _messagePlain_nominal 'prepare: wait: lock: _lock_prepare_python_nix' > /dev/null >&2
+        local dateA
+        local dateB
+        local dateDelta
+        while [[ $(cat "$scriptLocal"/python_nix.lock 2> /dev/null | head -c "$currentUID_length") != "$currentUID" ]]
+        do
+            if [[ ! -e "$scriptLocal"/python_nix.lock ]]
+            then
+                echo "$currentUID"$(date +%s | tr -dc '0-9') > "$scriptLocal"/python_nix.lock."$currentUID"
+                mv -f "$scriptLocal"/python_nix.lock."$currentUID" "$scriptLocal"/python_nix.lock
+            fi
+
+            sleep 7
+            [[ $(cat "$scriptLocal"/python_nix.lock 2> /dev/null | head -c "$currentUID_length") == "$currentUID" ]] && return 0
+
+            _messagePlain_probe "wait: lock" > /dev/null >&2
+
+            while [[ -e "$scriptLocal"/python_nix.lock ]] && [[ $(cat "$scriptLocal"/python_nix.lock 2> /dev/null | head -c "$currentUID_length") != "$currentUID" ]]
+            do
+                dateA=$(cat "$scriptLocal"/python_nix.lock 2> /dev/null | tail -c +"$currentUID_length_plus1" | tr -dc '0-9')
+                dateB=$(date +%s | tr -dc '0-9')
+                _messagePlain_probe "$dateB - $dateA"
+                dateDelta=$(bc <<< "$dateB - $dateA" 2> /dev/null)
+
+                sleep 7
+
+                # Normal prepare time is <<2minutes, if that.
+                [[ "$dateDelta" -gt "2700" ]] && rm -f "$scriptLocal"/python_nix.lock
+            done
+        done
+    }
+    _lock_prepare_python_nix
+    #...
+    #rm -f "$scriptLocal"/python_nix.lock
+
+    # WARNING: Do not add '-msw_python_3_10' or similar suffix to dumbpath_file . Use separate derivative projects for separate venv as normally needed for different python versions.
+    local dumbpath_file="$scriptLocal"/"$dumbpath_prefix"dumbpath.var
+    local dumbpath_contents=""
+    dumbpath_contents=$(cat "$dumbpath_file" 2> /dev/null)
+    if [[ "$dumbpath_contents" != "$dumbpath_file" ]]
+    then
+        # ATTENTION: WARNING: Anaconda is usually unnecessary, STRONGLY DISCOURAGED, and NOT automatically installed (eg. with 'ubdist/OS').
+        # Automatic installation of Anaconda is not expected useful for any purpose - only workstations for personal evaluation of open-source projects which happen to use Anaconda for a non=production purpose are expected to use Anaconda, if at all.
+        # Manual installation of Anaconda:
+        # https://docs.conda.io/projects/conda/en/latest/user-guide/install/windows.html
+        # https://docs.conda.io/projects/conda/en/latest/user-guide/install/linux.html
+
+
+
+
+
+        # erase any venv, etc, which may use absolute paths
+        _messagePlain_nominal 'prepare: python_nix' > /dev/null >&2
+
+        export safeToDeleteGit="true"
+        _safeRMR "$scriptLocal"/python_nix
+        mkdir -p "$scriptLocal"/python_nix
+
+
+        #[[ "$current_done__prepare_nix_python_procedure" == "false" ]] &&
+        _prepare_nix_python_procedure
+        current_done__prepare_nix_python_procedure="true"
+
+
+
+        # write python hook ; mv -f
+
+        #[[ "$_PYTHONSTARTUP" == "" ]] &&
+        _write_python_hook_local
+
+
+#if false
+#then
+        # rebuild venv...
+        _messagePlain_nominal 'prepare: venv' > /dev/null >&2
+
+        mkdir -p "$scriptLocal"/python_nix/venv
+        ! cd "$scriptLocal"/python_nix/venv && _stop 1
+        python3 -m venv default_venv > /dev/null >&2
+
+
+        cp -a default_venv/bin/activate default_venv/bin/activate_nix
+        #dos2unix default_venv/bin/activate_nix
+        chmod u+x default_venv/bin/activate_nix
+
+        #source default_venv/bin/activate > /dev/null >&2
+        _messagePlain_probe source default_venv/bin/activate_nix > /dev/null >&2
+        source default_venv/bin/activate_nix > /dev/null >&2
+        #PATH="$currentPATH"
+
+        _messagePlain_nominal 'prepare: venv: set' > /dev/null >&2
+        _set_nix_python_procedure
+
+        _messagePlain_probe _install_dependencies_nix_python_procedure-specific "" "" > /dev/null >&2
+        _install_dependencies_nix_python_procedure-specific "" ""
+
+        _messagePlain_probe python -c "import sys; print(sys.path)" > /dev/null >&2
+        python -c "import sys; print(sys.path)" > /dev/null >&2
+
+        #deactivate > /dev/null >&2
+#fi
+
+
+
+        # morsels...
+        _messagePlain_nominal 'prepare: morsels: pip' > /dev/null >&2
+
+        _morsels_nix_pip_python_3
+
+
+
+
+
+
+
+
+
+
+
+        # write > "$dumbpath_file" ; mv -f
+
+        # ATTENTION: Disable (ie. comment out) to force always rebuild, packages install, etc.
+        echo "$dumbpath_file" > "$dumbpath_file"."$currentUID"
+        mv -f "$dumbpath_file"."$currentUID" "$dumbpath_file"
+
+
+
+    fi
+
+    [[ "$current_done__prepare_nix_python_procedure" == "false" ]] && _prepare_nix_python_procedure
+    current_done__prepare_nix_python_procedure="true"
+
+    [[ "$_PYTHONSTARTUP" == "" ]] && _write_python_hook_local
+
+#if false
+#then
+    _messagePlain_nominal 'prepare: venv: activate' > /dev/null >&2
+    ! cd "$scriptLocal"/python_nix/venv && _stop 1
+    #source default_venv/bin/activate > /dev/null >&2
+    _messagePlain_probe source default_venv/bin/activate_nix > /dev/null >&2
+    source default_venv/bin/activate_nix > /dev/null >&2
+    #PATH="$currentPATH"
+
+    _messagePlain_nominal 'prepare: venv: set' > /dev/null >&2
+    _set_nix_python_procedure
+
+    _messagePlain_probe python -c "import sys; print(sys.path)" > /dev/null >&2
+    python -c "import sys; print(sys.path)" > /dev/null >&2
+#fi
+
+    _messagePlain_probe _install_dependencies_nix_python_procedure-specific "" "" > /dev/null >&2
+    _install_dependencies_nix_python_procedure-specific "" ""
+
+
+
+
+
+    #set ACCELERATE="%VENV_DIR%\Scripts\accelerate.exe"
+
+
+    rm -f "$scriptLocal"/python_nix.lock
+    _messagePlain_nominal 'done: prepare: '${FUNCNAME[0]} > /dev/null >&2
+}
+
+
+
+
+
+
+
+# EXAMPLE. Override (preferred) or implement alternative (discouraged) with 'core.sh', 'ops.sh', or similar.
+_morsels_nix_pip_python_3() {
+    #export packages_nix_python=( "huggingface_hub[cli]" )
+    local currentPackages_indicator_list=( "huggingface_hub[cli]" "${packages_nix_python[@]}" )
+    local currentPackages_list=( "huggingface_hub[cli]" )
+    local currentPackage
+
+    #export nonet_available="true"
+    ( ! wget -qO- 'https://github.com' > /dev/null || ! wget -qO- 'https://pypi.org/simple/' | head > /dev/null ) && export nonet_available="true"
+    local currentIteration_nonet="0"
+    while [[ "$nonet_available" == "true" ]] && [[ "$CI" != "" ]] && [[ "$currentIteration_nonet" -lt 90 ]]
+    do
+        ( wget -qO- 'https://github.com' > /dev/null && wget -qO- 'https://pypi.org/simple/' | head > /dev/null ) && export nonet_available="" && unset nonet_available
+        let currentIteration_nonet++
+    done
+
+    local currentWork="false"
+    for currentPackage in "${currentPackages_indicator_list[@]}"
+    do
+        ! pip show "$currentPackage" > /dev/null 2>&1 && currentWork="true"
+        #! python -m pip show "$currentPackage" > /dev/null 2>&1 && currentWork="true"
+    done
+    [[ "$currentWork" == "false" ]] && return 0
+
+    #[[ "$nonet" != "true" ]] && [[ "$nonet_available" != "true" ]] && python -m pip install --upgrade pip > /dev/null >&2
+    [[ "$nonet" != "true" ]] && [[ "$nonet_available" != "true" ]] && python -m pip install --upgrade pip > /dev/null 2>&1
+    [[ "$nonet" != "true" ]] && [[ "$nonet_available" != "true" ]] && sudo -n python -m pip install --upgrade pip > /dev/null 2>&1
+
+    for currentPackage in "${currentPackages_list[@]}"
+    do
+        #,win32,win_arm64
+        [[ "$nonet" != "true" ]] && [[ "$nonet_available" != "true" ]] && pip download "$currentPackage" --platform win_amd64 --only-binary=:all: --dest "$scriptAbsoluteFolder"/_bundle/morsels/pip > /dev/null >&2
+
+        #pip install --no-index --find-links="$scriptAbsoluteFolder"/_bundle/morsels/pip "$currentPackage" > /dev/null >&2
+        pip install --no-index --find-links="$scriptAbsoluteFolder"/_bundle/morsels/pip "$currentPackage" > /dev/null 2>&1
+        sudo -n pip install --no-index --find-links="$scriptAbsoluteFolder"/_bundle/morsels/pip "$currentPackage" > /dev/null 2>&1
+
+        # Strongly discouraged! Avoid surprise breakage by never relying on upstream repositories.
+        #[[ "$nonet" != "true" ]] && [[ "$nonet_available" != "true" ]] && pip install "$currentPackage" > /dev/null >&2
+    done
+
+    #sudo -n env DEBIAN_FRONTEND=noninteractive apt-get install --install-recommends -y libreadline-dev > /dev/null 2>&1
+}
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+# Workaround for pip using the newest saved non-binary wheel package (usually a .tar...) regardless of compatibility.
+_special_nix_pip_install_nonet_sequence() {
+    _start
+
+    #"$1"pip install --no-index --find-links="$lib_dir_nix_python_wheels" "$3" > /dev/null >&2
+    #"$1"pip install --no-index --no-build-isolation --find-links="$lib_dir_nix_python_wheels" "$3" > /dev/null >&2
+
+    cp "$lib_dir_nix_python_wheels"/*.whl "$safeTmp"/
+
+    local currentFile
+    local currentFile_basename
+    #for currentFile in "$lib_dir_nix_python_wheels"/"$3"*
+    for currentFile in $(ls -1 "$lib_dir_nix_python_wheels"/"$3"* | sort -V -r)
+    do
+        currentFile_basename=$(basename "$currentFile")
+        cp -f "$currentFile" "$safeTmp"/"$currentFile_basename"
+
+        "$1"pip install --no-index --find-links="$safeTmp" "$3" > /dev/null >&2
+        "$1"pip install --no-index --no-build-isolation --find-links="$safeTmp" "$3" > /dev/null >&2
+
+        rm -f "$safeTmp"/"$currentFile_basename"
+    done
+
+    _stop
+}
+
+
+
+_discover-nix_python() {
+    _discover_procedure-nix_python "$@"
+}
+_discover_procedure-nix_python() {
+    export lib_dir_nix_python_wheels
+
+    export lib_dir_nix_python_wheels="$scriptAbsoluteFolder"/.python_wheels/nix
+    if [[ -e "$lib_dir_nix_python_wheels" ]]
+    then
+        . "$lib_dir_nix_python_wheels"/_nix_python_wheels.sh
+        return 0
+    fi
+    export lib_dir_nix_python_wheels="$scriptLocal"/.python_wheels/nix
+    if [[ -e "$lib_dir_nix_python_wheels" ]]
+    then
+        . "$lib_dir_nix_python_wheels"/_nix_python_wheels.sh
+        return 0
+    fi
+    export lib_dir_nix_python_wheels="$scriptLib"/.python_wheels/nix
+    if [[ -e "$lib_dir_nix_python_wheels" ]]
+    then
+        . "$lib_dir_nix_python_wheels"/_nix_python_wheels.sh
+        return 0
+    fi
+
+
+    export lib_dir_nix_python_wheels="$scriptLib"/ubiquitous_bash/_lib/.python_wheels/nix
+    if [[ -e "$lib_dir_nix_python_wheels" ]]
+    then
+        . "$lib_dir_nix_python_wheels"/_nix_python_wheels.sh
+        return 0
+    fi
+    export lib_dir_nix_python_wheels="$scriptLib"/ubDistBuild/_lib/ubiquitous_bash/_lib/.python_wheels/nix
+    if [[ -e "$lib_dir_nix_python_wheels" ]]
+    then
+        . "$lib_dir_nix_python_wheels"/_nix_python_wheels.sh
+        return 0
+    fi
+
+    export lib_dir_nix_python_wheels=""
+    unset lib_dir_nix_python_wheels
+}
+_install_dependencies_nix_python_procedure-specific() {
+    _messagePlain_nominal 'install: dependencies' > /dev/null >&2
+
+    _discover-nix_python
+
+    # Not all of these packages if any are necessary (ie. may be dummy packages just to test the system).
+    #export dependencies_nix_python=( "readline" )
+    local currentPackages_list=("setuptools" "readline" "colorama" "${dependencies_nix_python[@]}" )
+    local currentPackage
+
+    #export nonet_available="true"
+    ( ! wget -qO- 'https://github.com' > /dev/null || ! wget -qO- 'https://pypi.org/simple/' | head > /dev/null ) && export nonet_available="true"
+    local currentIteration_nonet="0"
+    while [[ "$nonet_available" == "true" ]] && [[ "$CI" != "" ]] && [[ "$currentIteration_nonet" -lt 90 ]]
+    do
+        ( wget -qO- 'https://github.com' > /dev/null && wget -qO- 'https://pypi.org/simple/' | head > /dev/null ) && export nonet_available="" && unset nonet_available
+        let currentIteration_nonet++
+    done
+
+
+    if [[ "$nonet" != "true" ]] && [[ "$nonet_available" != "true" ]]
+    then
+        _pip_upgrade() {
+            local currentUpgrade="false"
+            for currentPackage in "${currentPackages_list[@]}"
+            do
+                ! "$1"pip show "$currentPackage" > /dev/null 2>&1 && currentUpgrade="true"
+                #! "$2"python -m pip show "$currentPackage" > /dev/null 2>&1 && currentUpgrade="true"
+            done
+            [[ "$currentUpgrade" == "false" ]] && return 0
+            "$2"python -m pip install --upgrade pip > /dev/null >&2
+        }
+        _pip_upgrade "$1" "$2"
+    fi
+
+
+    if [[ "$nonet" != "true" ]] && [[ "$nonet_available" != "true" ]]
+    then
+
+        if [[ "$lib_dir_nix_python_wheels" != "" ]]
+        then
+            # ATTRIBUTION-AI: ChatGPT o3  2025-04-19  (partially)
+            _pip_download() {
+                "$1"pip show "$3" > /dev/null 2>&1 && return 0
+                #"$2"python -m pip show "$3" > /dev/null 2>&1 && return 0
+
+                #--no-deps
+                #--python-version 3.1
+                "$1"pip download "$3" --platform linux_x86_64 --no-deps --dest "$lib_dir_nix_python_wheels" > /dev/null >&2
+                #"$1"pip download "$3" --platform manylinux2014_x86_64 --no-deps --dest "$lib_dir_nix_python_wheels" > /dev/null >&2
+                "$1"pip download "$3" --platform manylinux1 --no-deps --dest "$lib_dir_nix_python_wheels" > /dev/null >&2
+                "$1"pip download "$3" --platform any --no-deps --dest "$lib_dir_nix_python_wheels" > /dev/null >&2
+
+                #"$2"python -m pip download "$3" --platform linux_x86_64 --no-deps --dest "$lib_dir_nix_python_wheels" > /dev/null >&2
+                #"$2"python -m pip download "$3" --platform manylinux2014_x86_64 --no-deps --dest "$lib_dir_nix_python_wheels" > /dev/null >&2
+                #"$2"python -m pip download "$3" --platform manylinux1 --no-deps --dest "$lib_dir_nix_python_wheels" > /dev/null >&2
+                #"$2"python -m pip download "$3" --platform any --no-deps --dest "$lib_dir_nix_python_wheels" > /dev/null >&2
+
+
+                "$1"pip download "$3" --platform linux_x86_64 --only-binary=:all: --dest "$lib_dir_nix_python_wheels" > /dev/null >&2
+                #"$1"pip download "$3" --platform manylinux2014_x86_64 --only-binary=:all: --dest "$lib_dir_nix_python_wheels" > /dev/null >&2
+                "$1"pip download "$3" --platform manylinux1 --only-binary=:all: --dest "$lib_dir_nix_python_wheels" > /dev/null >&2
+                "$1"pip download "$3" --platform any --only-binary=:all: --dest "$lib_dir_nix_python_wheels" > /dev/null >&2
+
+                #"$2"python -m pip download "$3" --platform linux_x86_64 --only-binary=:all: --dest "$lib_dir_nix_python_wheels" > /dev/null >&2
+                #"$2"python -m pip download "$3" --platform manylinux2014_x86_64 --only-binary=:all: --dest "$lib_dir_nix_python_wheels" > /dev/null >&2
+                #"$2"python -m pip download "$3" --platform manylinux1 --only-binary=:all: --dest "$lib_dir_nix_python_wheels" > /dev/null >&2
+                #"$2"python -m pip download "$3" --platform any --only-binary=:all: --dest "$lib_dir_nix_python_wheels" > /dev/null >&2
+            }
+
+            for currentPackage in "${currentPackages_list[@]}"
+            do
+                _pip_download "$1" "$2" "$currentPackage"
+            done
+        fi
+    fi
+
+
+    if [[ "$lib_dir_nix_python_wheels" != "" ]]
+    then
+        _pip_install_nonet() {
+            "$1"pip show "$3" > /dev/null 2>&1 && return 0
+            #"$2"python -m pip show "$3" > /dev/null 2>&1 && return 0
+
+            #"$1"pip install --no-index --find-links="$lib_dir_nix_python_wheels" "$3" > /dev/null >&2
+            #"$1"pip install --no-index --no-build-isolation --find-links="$lib_dir_nix_python_wheels" "$3" > /dev/null >&2
+            "$scriptAbsoluteLocation" _special_nix_pip_install_nonet_sequence "$@"
+            #"$2"python -m pip install --no-index --find-links="$lib_dir_nix_python_wheels" "$3" > /dev/null >&2
+        }
+        for currentPackage in "${currentPackages_list[@]}"
+        do
+            _pip_install_nonet "$1" "$2" "$currentPackage"
+        done
+    fi
+
+    if [[ "$nonet" != "true" ]] && [[ "$nonet_available" != "true" ]]
+    then
+        _pip_install() {
+            "$1"pip show "$3" > /dev/null 2>&1 && return 0
+            #"$2"python -m pip show "$3" > /dev/null 2>&1 && return 0
+
+            "$1"pip install "$3" > /dev/null >&2
+            #"$2"python -m pip install "$3" > /dev/null >&2
+        }
+        for currentPackage in "${currentPackages_list[@]}"
+        do
+            _pip_install "$1" "$2" "$currentPackage"
+        done
+    fi
+
+    sudo -n env DEBIAN_FRONTEND=noninteractive apt-get install --install-recommends -y libreadline-dev > /dev/null 2>&1
+
+    for currentPackage in "${currentPackages_list[@]}"
+    do
+        pip show "$currentPackage" > /dev/null 2>&1 && return 0
+    done
+    return 1
+}
+_install_dependencies_nix_python_sequence-specific() {
+    _messageNormal '     install: dependencies: '"$1" > /dev/null >&2
+    _start
+
+    "$1"
+
+    _install_dependencies_nix_python_procedure-specific
+
+    _stop
+}
+_install_dependencies_nix_python() {
+    "$scriptAbsoluteLocation" _install_dependencies_nix_python_sequence-specific _set_nix_python_3
+}
+
+
+
+
+_prepare_nix_python_procedure() {
+    local currentUID=$(_uid)
+
+
+    mkdir -p "$scriptLocal"
+
+    mkdir -p "$scriptLocal"/python_nix
+
+    # In practice, 'pip' morsels may be all that is needed (ie. using 'pip' morsels for venv installation).
+    mkdir -p "$scriptAbsoluteFolder"/_bundle/morsels
+    mkdir -p "$scriptAbsoluteFolder"/_bundle/morsels/pip
+
+    mkdir -p "$scriptAbsoluteFolder"/_bundle/morsels/venv
+    mkdir -p "$scriptAbsoluteFolder"/_bundle/morsels/accelerate
+
+    # STRONGLY DISCOURAGED!
+    mkdir -p "$scriptAbsoluteFolder"/_bundle/morsels/conda
+
+    if [[ ! -e "$scriptLocal"/python_nix/lean.py ]] || ! diff --unified=3 "$scriptAbsoluteFolder"/lean.py "$scriptLocal"/python_nix/lean.py > /dev/null
+    then
+        cp -f "$scriptAbsoluteFolder"/lean.py "$scriptLocal"/python_nix/lean.py."$currentUID" > /dev/null 2>&1
+        mv -f "$scriptLocal"/python_nix/lean.py."$currentUID" "$scriptLocal"/python_nix/lean.py
+        if [[ ! -e "$scriptLocal"/python_nix/lean.py ]]
+        then
+            cp -f "$scriptLib"/ubiquitous_bash/lean.py "$scriptLocal"/python_nix/lean.py."$currentUID"
+            mv -f "$scriptLocal"/python_nix/lean.py."$currentUID" "$scriptLocal"/python_nix/lean.py
+        fi
+    fi
+    [[ ! -e "$scriptLocal"/python_nix/lean.py ]] && ( _messagePlain_warn 'warn: missing: scriptLocal/python_nix/lean.py' >&2 ) > /dev/null
+
+
+    _install_dependencies_nix_python_procedure-specific "" "" > /dev/null 2>&1
+
+    return 0
+}
+
+
+
+
+
+# CAUTION: May be called by _setupUbiquitous_accessories_here-python_hook .
+_set_nix_python_procedure() {
+
+    #export PATH="$VIRTUAL_ENV/"bin":$PATH"
+
+
+    # DUBIOUS
+    #export _transformersCache="$scriptLocal"/transformers-cache
+
+    # DUBIOUS
+    #export _accelerate=$(find "$???" -iname 'accelerate.exe' -type f -print -quit)
+
+    #unset PYTHONHOME
+    #export PYTHONSTARTUP="$_PYTHONSTARTUP"
+
+    return 0
+}
+
+set_nix_python() {
+    _set_nix_python_3 "$@"
+}
+_set_nix_python_3() {
+    python() {
+        #python3.11 "$@"
+        python3 "$@"
+    }
+    pip() {
+        #pip3.11 "$@"
+        pip3 "$@"
+    }
+
+    _set_nix_python_procedure "$@"
+}
+
+
+
+_demo_nix_python() {
+    _messagePlain_nominal 'demo: '${FUNCNAME[0]} > /dev/null >&2
+    sleep 0.6
+    "$@"
+    _bash
+}
+
+
+
+# ATTENTION: EXAMPLE. Override or implement alternative with 'core.sh', 'ops.sh', or similar.
+# ATTENTION: Also create "$scriptLib"/python/lean.py .
+_special_packages() {
+    #export dependencies_nix_python=( "readline" )
+    #export packages_nix_python=( "huggingface_hub[cli]" )
+
+    #export dependencies_msw_python=( "pyreadline3" )
+    #export packages_msw_python=( "huggingface_hub[cli]" )
+
+    #export dependencies_cyg_python=( "readline" )
+    #export packages_cyg_python=( "huggingface_hub[cli]" )
+
+    true
+}
+_special_python() {
+    _special_packages
+
+    if _if_cygwin
+    then
+        _msw_python "$@"
+        return
+    fi
+
+    _nix_python "$@"
+    return
+}
+# ATTENTION: Call from '_test_prog' with 'core.sh' or similar.
+# _setup calls _test calls _test_prog
+_test_special_python() {
+    _special_packages
+
+    if _if_cygwin
+    then
+        _test_msw_python "$@"
+        return
+    fi
+
+    _test_nix_python "$@"
+    return
+}
+
+
+_test_image() {
 	_mustGetSudo

-	[[ ! -e "$1" ]] && sleep 3
-	[[ ! -e "$1" ]] && return 1
-
-	local absolute1
-	absolute1=$(_getAbsoluteLocation "$1")
-
-	[[ "$absolute1" == "" ]] && return 1
-	[[ "$absolute1" == "/" ]] && return 1
-	[[ ! -e "$absolute1" ]] && return 1
-
-	_bindMountManager "/dev" "$absolute1"/dev
-
-	#_bindMountManager "/proc" "$absolute1"/proc
-	sudo -n mkdir -p "$absolute1"/proc
-	sudo -n mount -t proc none "$absolute1"/proc
-
-	_bindMountManager "/sys" "$absolute1"/sys
-
-	_bindMountManager "/dev/pts" "$absolute1"/dev/pts
-
-	_bindMountManager "/tmp" "$absolute1"/tmp
-
-	#Provide an shm filesystem at /dev/shm.
-	sudo -n mkdir -p "$absolute1"/dev/shm
-	sudo -n mount -t tmpfs -o size=4G tmpfs "$absolute1"/dev/shm
-
-	#Install ubiquitous_bash itself to chroot.
-	sudo -n mkdir -p "$absolute1"/usr/local/bin/
-	sudo -n mkdir -p "$absolute1"/usr/local/share/ubcore/bin/
-
-	sudo -n cp "$scriptAbsoluteLocation" "$absolute1"/usr/local/bin/ubiquitous_bash.sh
-	sudo -n chmod 0755 "$absolute1"/usr/local/bin/ubiquitous_bash.sh
-	sudo -n chown root:root "$absolute1"/usr/local/bin/ubiquitous_bash.sh
-
-	if [[ -e "$scriptAbsoluteFolder"/lean.sh ]]
+	_getDep losetup
+	#_getDep partprobe
+}
+
+
+# ATTENTION: WARNING: TODO: UNCOMMENT SAFE/EMPTY CONFIGURATION VARIABLES HERE IF NEEDED TO RESET ENVIRONMENT!
+
+
+###
+
+# ATTENTION: Override with 'ops', env, or similar.
+# DANGER: NOT respected (and possibly not needed) by some virtualization backends.
+# DANGER: Root image/device/partiton must be correct!
+# WARNING: Root/Image/Device override implies 'true' "ubVirtImageLocal" .
+
+# WARNING: Implies blank "ubVirtImagePartition" .
+#export ubVirtImageIsRootPartition='true'
+
+#export ubVirtImageIsDevice='true'
+#export ubVirtImageOverride='/dev/disk/by-id/identifier-part'
+
+# ATTENTION: Path pointing to full disk device or image, including partition table, for full booting.
+# Will take precedence over "ubVirtImageOverride" with virtualization backends capable of full booting.
+# vbox , qemu
+#export ubVirtDiskOverride='/dev/disk/by-id/identifier'
+
+
+# ATTENTION: Explicitly override platform. Not all backends support all platforms.
+# chroot , qemu
+# x64-bios , raspbian , x64-efi
+#export ubVirtPlatformOverride='x64-bios'
+
+###
+
+
+
+###
+
+# ATTENTION: Override with 'ops' or similar.
+# WARNING: Do not override unnecessarily. Default rules are expected to accommodate typical requirements.
+
+# WARNING: Only applies to imagedev (text) loopback device.
+# x64 bios , raspbian , x64 efi (respectively)
+#export ubVirtImagePartition='p1'
+#export ubVirtImagePartition='p2'
+#export ubVirtImagePartition='p3'
+
+###
+
+
+
+# ATTENTION: Override with 'ops' or similar.
+# WARNING: Prefer to avoid override in favor of overriding other relevant variables or functions.
+# DANGER: Required for safety mechanisms which may also be used by some other virtualization backends!
+# WARNING: Dependency: Should run _loopImage_imagefilename .
+# "$1" == imagedev
+# "$2" == default (if any)
+_determine_rawFileRootPartition() {
+	# DANGER: REQUIRES image/device including ONLY root partition!
+	if [[ "$ubVirtImageIsRootPartition" == 'true' ]]
 	then
-		sudo -n cp "$scriptAbsoluteFolder"/lean.sh "$absolute1"/usr/local/bin/lean.sh
-		sudo -n chmod 0755 "$absolute1"/usr/local/bin/lean.sh
-		sudo -n chown root:root "$absolute1"/usr/local/bin/lean.sh
+		export ubVirtImagePartition=''
+		echo "$1"
+		return 0
 	fi

-	sudo -n cp "$scriptBin"/gosu-armel "$absolute1"/usr/local/share/ubcore/bin/gosu-armel
-	sudo -n cp "$scriptBin"/gosu-amd64 "$absolute1"/usr/local/share/ubcore/bin/gosu-amd64
-	sudo -n cp "$scriptBin"/gosu-i386 "$absolute1"/usr/local/share/ubcore/bin/gosu-i386
-	sudo -n chmod 0755 "$absolute1"/usr/local/share/ubcore/bin/*
-	sudo -n chown root:root "$absolute1"/usr/local/share/ubcore/bin/*
+	if [[ "$ubVirtImagePartition" != "" ]]
+	then
+		echo "$1""$ubVirtImagePartition"
+		return 0
+	fi

-	#Workaround NetworkManager stealing /etc/resolv.conf with broken symlink.
-	if ! _chroot test -f /etc/resolv.conf
+	if [[ "$2" != "" ]]
 	then
-		sudo -n mv "$absolute1"/etc/resolv.conf "$absolute1"/etc/resolv.conf.bak > /dev/null 2>&1
-		sudo -n rm -f "$absolute1"/etc/resolv.conf > /dev/null 2>&1
+		export ubVirtImagePartition="$2"
+		echo "$1""$2"
+		return 0
 	fi

+	#Platform defaults.
+	export ubVirtImageEFI=""
+	export ubVirtImagePartition=""

-	if [[ -e "$absolute1"/etc/resolv.conf ]] && [[ ! -e "$absolute1"/etc/resolv.conf.host ]] && [[ -e /etc/resolv.conf ]]
+	#[[ "$ubVirtPlatform" == "x64-bios" ]] && export ubVirtImagePartition=p1
+	if [[ "$ubVirtPlatform" == "x64-bios" ]]
 	then
-		sudo -n cp --no-clobber "$absolute1"/etc/resolv.conf "$absolute1"/etc/resolv.conf.guest.bak
-		sudo -n mv -n "$absolute1"/etc/resolv.conf "$absolute1"/etc/resolv.conf.guest
-
-		#if [[ ! -e "$absolute1"/etc/resolv.conf.host ]]
-		#then
-			sudo -n cp --no-clobber -L /etc/resolv.conf "$absolute1"/etc/resolv.conf.host
-			#sudo -n cat /etc/resolv.conf | sudo tee "$absolute1"/etc/resolv.conf.host > /dev/null 2>&1
-		#fi
-
-		sudo -n mv -f "$absolute1"/etc/resolv.conf.host "$absolute1"/etc/resolv.conf
+		export ubVirtImageBIOS=
+		export ubVirtImageEFI=
+		#export ubVirtImageNTFS=
+		#export ubVirtImageRecovery=
+		#export ubVirtImageSwap=
+		export ubVirtImageBoot=
+		export ubVirtImagePartition=p1
 	fi

-	if ! grep '8\.8\.8\.8' "$absolute1"/etc/resolv.conf > /dev/null 2>&1
+	if [[ "$ubVirtPlatform" == "x64-efi" ]]
 	then
-		echo 'nameserver 8.8.8.8' | sudo -n tee -a "$absolute1"/etc/resolv.conf > /dev/null 2>&1
+		#export ubVirtImagePartition=p3 && export ubVirtImageEFI=p2
+		export ubVirtImageBIOS=p1
+		export ubVirtImageEFI=p2
+		#export ubVirtImageNTFS=
+		#export ubVirtImageRecovery=
+		#export ubVirtImageSwap=p3
+		export ubVirtImageBoot=p4
+		export ubVirtImagePartition=p5
 	fi

-	if ! grep '2001\:4860\:4860\:\:8888' "$absolute1"/etc/resolv.conf > /dev/null 2>&1
+	#[[ "$ubVirtPlatform" == "raspbian" ]] && export ubVirtImagePartition=p2
+	if [[ "$ubVirtPlatform" == "raspbian" ]]
 	then
-		echo 'nameserver 2001:4860:4860::8888' | sudo -n tee -a "$absolute1"/etc/resolv.conf > /dev/null 2>&1
+		export ubVirtImageBIOS=
+		export ubVirtImageEFI=
+		#export ubVirtImageNTFS=
+		#export ubVirtImageRecovery=
+		#export ubVirtImageSwap=
+		# ### export ubVirtImageBoot=
+		export ubVirtImagePartition=p2
 	fi


-	if ! grep 'deleteme_chrootHost_hostname' "$absolute1"/etc/resolv.conf > /dev/null 2>&1
-	then
-		echo '127.0.0.1 '"$HOSTNAME"' deleteme_chrootHost_hostname' | sudo -n tee -a "$absolute1"/etc/hosts > /dev/null 2>&1
-	fi
+	#Default.
+	# DANGER: Do NOT set blank.
+	[[ "$ubVirtImagePartition" == "" ]] && export ubVirtImagePartition=p1
+
+	echo "$1""$ubVirtImagePartition"
+
+	return 0
+}


-	if _set_ingredients
-	then
-		sudo -n mkdir -p "$absolute1"/mnt/ingredients
-		_bindMountManager "$ub_INGREDIENTS" "$absolute1"/mnt/ingredients
-	fi
+
+# ATTENTION: Override with 'ops' or similar.
+# WARNING: Uncommenting will cause losetup not to be used for 'vm.img' and similar even if symlinked to '/dev'. This will break 'ubVirtImagePartition' .
+# DANGER: Unnecessarily linking 'vm.img' or similar to device file strongly discouraged. May allow some virtualization backends to attempt to perform unsupported operations (ie. rm -f) on device file.
+_detect_deviceAsVirtImage_symlinks() {
+	#[[ -h "$scriptLocal"/vm.img ]] && readlink "$scriptLocal"/vm.img | grep ^\/dev\/\.\* > /dev/null 2>&1 && return 0
+	#[[ -h "$scriptLocal"/vm-x64.img ]] && readlink "$scriptLocal"/vm-x64.img | grep ^\/dev\/\.\* > /dev/null 2>&1 && return 0
+	#[[ -h "$scriptLocal"/vm-raspbian.img ]] && readlink "$scriptLocal"/vm-raspbian.img | grep ^\/dev\/\.\* > /dev/null 2>&1 && return 0

-	return 0
+	# WARNING: Symlinks to locations outside a home subfolder (including relative symlinks) will be presumed to be device files if uncommented.
+	#[[ -h "$scriptLocal"/vm.img ]] && ! readlink "$scriptLocal"/vm.img | grep ^\/home\/\.\* > /dev/null 2>&1 && return 0
+	#[[ -h "$scriptLocal"/vm-x64.img ]] && ! readlink "$scriptLocal"/vm-x64.img | grep ^\/home\/\.\* > /dev/null 2>&1 && return 0
+	#[[ -h "$scriptLocal"/vm-raspbian.img ]] && ! readlink "$scriptLocal"/vm-raspbian.img | grep ^\/home\/\.\* > /dev/null 2>&1 && return 0
+
+	return 1
 }

-#"$1" == ChRoot Dir
-_umountChRoot() {
-	_mustGetSudo
+
+# DANGER: Required for safety mechanisms which may also be used by some other virtualization backends!
+# DANGER: Multiple 'vm.img' variants (eg. 'vm-x64.img') available simultaneously is NOT deliberately supported and NOT safe!
+# DANGER: Multiple symlinks or other conditions may confuse this safety mechanism. Only intended to prevent casual misuse.
+# image
+# chroot
+# vbox
+# qemu
+# "$1" == imagefilename
+_detect_deviceAsVirtImage() {
+	[[ "$ubVirtImageIsDevice" != "" ]] && return 0
+	[[ "$ubVirtImageOverride" == '/dev/'* ]] && return 0

-	[[ ! -e "$1" ]] && return 1
+	[[ "$1" == '/dev/'* ]] && return 0

-	local absolute1
-	absolute1=$(_getAbsoluteLocation "$1")

-	#_set_ingredients &&
-	mountpoint "$absolute1"/mnt/ingredients > /dev/null 2>&1 && _wait_umount "$absolute1"/mnt/ingredients
-
-	# && [[ -e "$absolute1"/etc/resolv.conf ]]
-	if [[ -e "$absolute1"/etc/resolv.conf.guest ]] && [[ ! -e "$absolute1"/etc/resolv.conf.host ]]
-	then
-		sudo -n mv -f "$absolute1"/etc/resolv.conf.guest "$absolute1"/etc/resolv.conf
-	fi
-
-
-	if grep 'deleteme_chrootHost_hostname' "$absolute1"/etc/resolv.conf > /dev/null 2>&1
-	then
-		sudo -n grep -v 'deleteme_chrootHost_hostname' "$absolute1"/etc/hosts | sudo -n tee "$absolute1"/etc/hosts.guest > /dev/null 2>&1
-		sudo -n mv -f "$absolute1"/etc/hosts.guest "$absolute1"/etc/hosts
-	fi
-
-	_wait_umount "$absolute1"/home/"$virtGuestUser"/project >/dev/null 2>&1
-	_wait_umount "$absolute1"/home/"$virtGuestUser" >/dev/null 2>&1
-	_wait_umount "$absolute1"/root/project >/dev/null 2>&1
-	_wait_umount "$absolute1"/root >/dev/null 2>&1
-
-	_wait_umount "$absolute1"/dev/shm
-	_wait_umount "$absolute1"/dev/pts
-
-
-	if [[ -e "$absolute1"/proc/sys/fs/binfmt_misc ]] && mountpoint "$absolute1"/proc/sys/fs/binfmt_misc > /dev/null 2>&1
-	then
-		_wait_umount "$absolute1"/proc/sys/fs/binfmt_misc
-	fi
-
-
-	sudo -n umount "$absolute1"/proc
-	_wait_umount "$absolute1"/sys
-
-	_wait_umount "$absolute1"/tmp
-
-	_wait_umount "$absolute1"/dev
-
-	if mountpoint "$absolute1"/proc > /dev/null 2>&1
-	then
-		sleep 6
-		if mountpoint "$absolute1"/proc > /dev/null 2>&1
-		then
-			sudo -n umount "$absolute1"/proc
-			if mountpoint "$absolute1"/proc > /dev/null 2>&1
-			then
-				sleep 6
-				if mountpoint "$absolute1"/proc > /dev/null 2>&1
-				then
-					sudo -n umount "$absolute1"/proc
-
-					sleep 1
-					mountpoint "$absolute1"/proc > /dev/null 2>&1 && _wait_umount "$absolute1"/proc
-				fi
-			fi
-		fi
-	fi
+	[[ "$1" != "" ]] && [[ -h "$1" ]] && ! readlink "$1" | grep ^\/dev\/\.\* > /dev/null 2>&1 && return 1
+	[[ "$1" != "" ]] && [[ -e "$1" ]] && return 1
+	_detect_deviceAsVirtImage_symlinks "$1" && return 0

-	# Full umount of chroot directory may be done by standard '_umountImage'.
-	#_wait_umount "$absolute1" >/dev/null 2>&1
+	return 1
 }

-_readyChRoot() {
-
-	local absolute1
-	absolute1=$(_getAbsoluteLocation "$1")
-
-	#mountpoint "$absolute1" > /dev/null 2>&1 || return 1
-
-	mountpoint "$absolute1"/dev > /dev/null 2>&1 || return 1
-	mountpoint "$absolute1"/proc > /dev/null 2>&1 || return 1
-	mountpoint "$absolute1"/sys > /dev/null 2>&1 || return 1
-
-	mountpoint "$absolute1"/dev/pts > /dev/null 2>&1 || return 1
-
-	mountpoint "$absolute1"/tmp > /dev/null 2>&1 || return 1
+# ATTENTION: Override with 'ops' or similar.
+# WARNING: Prefer to avoid override in favor of overriding other relevant variables or functions.
+# DANGER: Required for safety mechanisms which may also be used by some other virtualization backends!
+# "$1" == imagedev
+# "$2" == imagepart
+_determine_rawIsRootPartition() {
+	[[ "$ubVirtImageIsRootPartition" == 'true' ]] && return 0
+	[[ "$1" == "$2" ]] && return 0
+	return 1
+}
+
+
+# DANGER: Required for safety mechanisms which may also be used by some other virtualization backends!
+# DANGER: Exact values of 'ubVirtPlatform' and other variables may be required by other virtualization backends!
+_loopImage_imagefilename() {
+	local current_imagefilename
+	[[ -e "$scriptLocal"/vm-raspbian.img ]] && current_imagefilename="$scriptLocal"/vm-raspbian.img && export ubVirtPlatform=raspbian
+	[[ -e "$scriptLocal"/vm-x64.img ]] && current_imagefilename="$scriptLocal"/vm-x64.img && export ubVirtPlatform=x64-bios
+	[[ -e "$scriptLocal"/vm.img ]] && current_imagefilename="$scriptLocal"/vm.img && export ubVirtPlatform=x64-bios
+	[[ "$ubVirtImageOverride" != "" ]] && current_imagefilename="$ubVirtImageOverride"
+	[[ "$ubVirtImageOverride_alternate" != "" ]] && current_imagefilename="$ubVirtImageOverride_alternate"

-	mountpoint "$absolute1"/dev/shm > /dev/null 2>&1 || return 1

-	return 0
+	[[ "$ubVirtPlatform" == "" ]] && export ubVirtPlatform=x64-bios
+	[[ "$ubVirtPlatformOverride" != "" ]] && export ubVirtPlatform="$ubVirtPlatformOverride"

+	echo "$current_imagefilename"
 }

-# ATTENTION: Override with "core.sh" or similar.
-# WARNING: Must return true to complete mount/umount procedure.
-_mountChRoot_image_raspbian_prog() {
-	true
-
-	#local current_imagedev
-	#current_imagedev=$(cat "$scriptLocal"/imagedev)
+
+# "$1" == imagefilename
+# "$2" == imagedev (text)
+_loopImage_procedure_losetup() {
+	# SEVERE - Disabled for more consistent behavior. Aside from now 'wasting' a loopback device, this may break any legacy uses of 'ubVirtImageOverride' .
+	#  CAUTION: TODO: Testing.
+	# WARNING: Partition names (ie. '/dev/loop1' , '/dev/loop1p1') may change (eg. to '/dev/sda' , '/dev/sda1') .
+	#  If uncommenting this functionality, also ensure 'ubVirtImageEFI' declaration (eg. used by '_createVMimage()' ) is sufficiently dynamic .
+	# WARNING: If uncommenting this functionality, also uncomment related use of '_detect_deviceAsVirtImage' within _closeLoop related functions.
+	#if _detect_deviceAsVirtImage "$1"
+	#then
+		#! [[ -e "$1" ]] && _stop 1
+		#echo "$1" > "$safeTmp"/imagedev
+		#sudo -n partprobe > /dev/null 2>&1
+
+		#_moveconfirm "$safeTmp"/imagedev "$2" > /dev/null 2>&1 || _stop 1
+		#return 0
+	#fi

-	#mkdir -p "$globalVirtFS"/../boot
-	#sudo -n mount "$current_imagedev"p1 "$globalVirtFS"/../boot
+	sleep 1
+	sudo -n losetup -f -P --show "$1" > "$safeTmp"/imagedev 2> /dev/null || _stop 1
+	sudo -n partprobe > /dev/null 2>&1
+	sleep 1

+	_moveconfirm "$safeTmp"/imagedev "$2" > /dev/null 2>&1 || _stop 1
 	return 0
 }

-_mountChRoot_image_raspbian() {
+# DANGER: Optional parameter intended only for virtualization backends using only loopback devices without filesystem mounting (vbox) .
+# "$1" == imagedev (text)
+_loopImage_sequence() {
 	_mustGetSudo

 	_start

-	mkdir -p "$chrootDir"
-
-	"$scriptAbsoluteLocation" _checkForMounts "$chrootDir" && _stop 1
+	mkdir -p "$globalVirtFS"

+	local current_imagedev_text
+	current_imagedev_text="$1"
+	[[ "$current_imagedev_text" == "" ]] && current_imagedev_text="$scriptLocal"/imagedev

-	! _mountImage "$chrootDir" && _stop 1
+	[[ -e "$current_imagedev_text" ]] && _stop 1

+	local current_imagefilename
+	current_imagefilename=$(_loopImage_imagefilename)

+	_loopImage_procedure_losetup "$current_imagefilename" "$current_imagedev_text"

-	_mountChRoot "$chrootDir"
+	_stop 0
+}
+
+_loopImage() {
+	if "$scriptAbsoluteLocation" _loopImage_sequence "$@"
+	then
+		return 0
+	fi
+	return 1
+}
+
+# DANGER: Only use with backends supporting full disk booting!
+# "$1" == imagedev (text)
+_loopFull_procedure() {
+	if [[ "$ubVirtDiskOverride" == "" ]]
+	then
+		! _loopImage "$1" && _stop 1
+	else
+		! _loopImage_procedure_losetup "$ubVirtDiskOverride" "$1" && _stop 1
+	fi
+	return 0
+}
+
+# "$1" == imagedev (text)
+_loopFull_sequence() {
+	_start

-	_readyChRoot "$chrootDir" || _stop 1
+	if ! _loopFull_procedure "$@"
+	then
+		_stop 1
+	fi

-	sudo -n cp /usr/bin/qemu-arm-static "$chrootDir"/usr/bin/
-	sudo -n cp /usr/bin/qemu-armeb-static "$chrootDir"/usr/bin/
+	_stop 0
+}
+
+# "$1" == imagedev (text)
+_loopFull() {
+	if "$scriptAbsoluteLocation" _loopFull_sequence "$@"
+	then
+		return 0
+	fi

-	sudo -n cp --no-clobber "$chrootDir"/etc/ld.so.preload "$chrootDir"/etc/ld.so.preload.orig
-	echo | sudo -n tee "$chrootDir"/etc/ld.so.preload > /dev/null 2>&1
+	# Typically requires "_stop 1" .
+	return 1
+}
+
+
+# ATTENTION: Override with 'ops' or similar.
+# DANGER: Allowing types other than 'ext4' (eg. fat), may allow mounting of filesystems other than an UNIX-like userspace root.
+_mountImageFS_procedure_blkid_fstype() {
+	[[ "$1" == "ext4" ]] && return 0
+	[[ "$1" == "btrfs" ]] && return 0

+	_stop 1
+}
+
+# "$1" == imagedev
+# "$2" == imagepart
+# "$3" == dirVirtFS (RESERVED)
+_mountImageFS_procedure_blkid() {
+	local loopdevfs

-	local chrootimagedev
-	chrootimagedev=$(cat "$scriptLocal"/imagedev)
-	! _mountChRoot_image_raspbian_prog "$chrootimagedev" && _stop 1
+	# DANGER: Must ignore/reject 'PTTYPE' field if given.
+	#if _determine_rawIsRootPartition "$1" "$2"
+	#then
+		#loopdevfs=$(eval $(sudo -n blkid "$2" | tr -dc 'a-zA-Z0-9\=\"\ \:\/\-' | awk ' { print $4 } '); echo $TYPE)
+	#else
+		#loopdevfs=$(eval $(sudo -n blkid "$2" | tr -dc 'a-zA-Z0-9\=\"\ \:\/\-' | awk ' { print $3 } '); echo $TYPE)
+	#fi
+	loopdevfs=$(sudo -n blkid -s TYPE -o value "$2" | tr -dc 'a-zA-Z0-9')

+	! _mountImageFS_procedure_blkid_fstype "$loopdevfs" && _stop 1

 	return 0
 }

-_umountChRoot_directory_raspbian() {
-
+# "$1" == destinationDir (default: "$globalVirtFS")
+_mountImageFS_sequence() {
 	_mustGetSudo

-	mkdir -p "$chrootDir"
-
-	sudo -n cp "$chrootDir"/etc/ld.so.preload.orig "$chrootDir"/etc/ld.so.preload
-
-}
-
-_mountChRoot_image_x64_efi() {
-	[[ "$ubVirtPlatform" != "x64-efi" ]] && return 1
-	[[ "$ubVirtImageEFI" == "" ]] && return 1
+	_start

-	local current_imagedev
-	current_imagedev=$(cat "$scriptLocal"/imagedev)
+	local currentDestinationDir
+	currentDestinationDir="$1"
+	[[ "$currentDestinationDir" == "" ]] && currentDestinationDir="$globalVirtFS"

-	_determine_rawFileRootPartition "$current_imagedev" > /dev/null 2>&1
+	mkdir -p "$globalVirtFS"

-	local loopdevfs
-	loopdevfs=$(sudo -n blkid -s TYPE -o value "$current_imagedev""$ubVirtImageEFI" | tr -dc 'a-zA-Z0-9')
+	"$scriptAbsoluteLocation" _checkForMounts "$currentDestinationDir" && _stop 1

-	! [[ "$loopdevfs" == "vfat" ]] && _stop 1
+	# Include platform determination code for correct determination of partition and mounts.
+	_loopImage_imagefilename > /dev/null 2>&1

+	local current_imagedev
+	current_imagedev=$(cat "$scriptLocal"/imagedev)

-	sudo -n mkdir -p "$globalVirtFS"/boot/efi
+	local current_imagepart
+	current_imagepart=$(_determine_rawFileRootPartition "$current_imagedev")
+	#current_imagepart=$(_determine_rawFileRootPartition "$current_imagedev" "x64-bios")

-	sudo -n mount "$current_imagedev""$ubVirtImageEFI" "$globalVirtFS"/boot/efi

-	return 0
-}
-
-# ATTENTION: Override with "core.sh" or similar.
-# WARNING: Must return true to complete mount/umount procedure.
-# By default attempts to mount EFI partition as specified by "$current_imagedev""$ubVirtImageEFI" .
-_mountChRoot_image_x64_prog() {
-	true
+	_mountImageFS_procedure_blkid "$current_imagedev" "$current_imagepart" "$currentDestinationDir" || _stop 1

-	#export ubVirtPlatformOverride='x64-efi'
-	#export ubVirtImageBIOS=p1
-	#export ubVirtImageEFI=p2
-	#export ubVirtImageNTFS=
-	#export ubVirtImageRecovery=
-	#export ubVirtImageSwap=p3
-	#export ubVirtImageBoot=p4
-	#export ubVirtImagePartition=p5
+	local loopdevfs
+	loopdevfs=$(sudo -n blkid -s TYPE -o value "$current_imagepart" | tr -dc 'a-zA-Z0-9')

-	local current_imagedev
-	current_imagedev=$(cat "$scriptLocal"/imagedev)

-	if [[ "$ubVirtImageBoot" != "" ]]
+	if [[ "$loopdevfs" == "btrfs" ]] && [[ "$ub_disable_fs_compression" != "true" ]]
 	then
-		sudo -n mkdir -p "$globalVirtFS"/boot
-		if ! sudo -n mount "$current_imagedev""$ubVirtImageBoot" "$globalVirtFS"/boot
+		if [[ "$skimfast" == "true" ]]
 		then
-			_stop 1
+			sudo -n mount -o compress=zstd:2 "$current_imagepart" "$currentDestinationDir" || _stop 1
+		else
+			sudo -n mount -o compress=zstd:9 "$current_imagepart" "$currentDestinationDir" || _stop 1
 		fi
+	else
+		sudo -n mount "$current_imagepart" "$currentDestinationDir" || _stop 1
 	fi


-	if [[ "$ubVirtPlatform" == "x64-efi" ]]
+	sleep 1
+
+	! mountpoint "$currentDestinationDir" > /dev/null 2>&1 && sleep 3
+	! mountpoint "$currentDestinationDir" > /dev/null 2>&1 && sleep 6
+	! mountpoint "$currentDestinationDir" > /dev/null 2>&1 && sleep 9
+	mountpoint "$currentDestinationDir" > /dev/null 2>&1 || _stop 1
+
+	_stop 0
+}
+
+_mountImageFS() {
+	if "$scriptAbsoluteLocation" _mountImageFS_sequence
 	then
-		_mountChRoot_image_x64_efi "$@"
-		return
+		return 0
 	fi
+	return 1
+}
+
+_mountImage() {
+	# Include platform determination code for correct determination of partition and mounts.
+	_loopImage_imagefilename > /dev/null 2>&1
+
+	! _loopImage && _stop 1
+	! _mountImageFS "$1" && _stop 1

 	return 0
 }

-# ATTENTION: Mounts image containing only root partiton.
-_mountChRoot_image_x64() {
-	_mustGetSudo
-
-	_start
+# "$1" == imagedev
+# "$2" == imagedev (text)
+# "$3" == imagefilename
+_unmountLoop_losetup() {
+	#if _detect_deviceAsVirtImage "$3" || [[ "$1" == '/dev/loop'* ]]
+	#if _detect_deviceAsVirtImage "$3"
+	#then
+		#! [[ -e "$1" ]] && return 1
+		#! [[ -e "$2" ]] && return 1
+		#! [[ -e "$3" ]] && return 1
+		#sudo -n partprobe > /dev/null 2>&1
+
+		##rm -f "$2" || return 1
+		#rm -f "$2"
+		#[[ -e "$2" ]] && return 1
+		#return 0
+	#fi

-	mkdir -p "$chrootDir"
+	# DANGER: Should never happen.
+	[[ "$1" == '/dev/loop'* ]] || return 1

-	"$scriptAbsoluteLocation" _checkForMounts "$chrootDir" && _stop 1
+	# WARNING: Should never happen.
+	[[ -e "$3" ]] || return 1

+	sudo -n losetup -d "$1" > /dev/null 2>&1 || return 1
+	sudo -n partprobe > /dev/null 2>&1

-	! _mountImage "$chrootDir" && _stop 1
+	#rm -f "$2" || return 1
+	rm -f "$2"
+	[[ -e "$2" ]] && return 1
+	return 0
+}
+
+# DANGER: Optional parameter intended only for virtualization backends using only loopback devices without filesystem mounting (vbox) .
+# "$1" == imagedev (text)
+_umountLoop() {
+	_mustGetSudo || return 1

+	local current_imagedev_text
+	current_imagedev_text="$1"
+	[[ "$current_imagedev_text" == "" ]] && current_imagedev_text="$scriptLocal"/imagedev

+	[[ -e "$current_imagedev_text" ]] || return 1
+	local current_imagedev
+	current_imagedev=$(cat "$current_imagedev_text" 2>/dev/null)

-	_mountChRoot "$chrootDir"

-	_readyChRoot "$chrootDir" || _stop 1
+	# WARNING: Consistent rules required to select correct imagefilename for both _umountLoop and _loopImage regardless of VM backend or 'ops' overrides.
+	local current_imagefilename
+	current_imagefilename=$(_loopImage_imagefilename)

+	_unmountLoop_losetup "$current_imagedev" "$current_imagedev_text" "$current_imagefilename" || return 1

-	local chrootimagedev
-	chrootimagedev=$(cat "$scriptLocal"/imagedev)
-	! _mountChRoot_image_x64_prog "$chrootimagedev" && _stop 1
+	rm -f "$lock_quicktmp" > /dev/null 2>&1

 	return 0
 }

-_umountChRoot_directory_x64() {
-	_mustGetSudo
-
-	mkdir -p "$chrootDir"
-}
-
-_mountChRoot_image() {
-	_tryExecFull _hook_systemd_shutdown_action "_closeChRoot_emergency" "$sessionid"
-
-	# Include platform determination code for correct determination of partition and mounts.
-	_loopImage_imagefilename > /dev/null 2>&1
-
-	if [[ "$ubVirtPlatform" == "raspbian" ]]
-	then
-		_mountChRoot_image_raspbian
-		return "$?"
-	fi
-
-	if [[ "$ubVirtPlatform" == "x64"* ]]
+# DANGER: Only use with backends supporting full disk booting!
+# "$1" == imagedev (text)
+_umountFull_procedure() {
+	if [[ "$ubVirtDiskOverride" == "" ]]
 	then
-		_mountChRoot_image_x64
-		return "$?"
+		! _umountLoop "$1" && _stop 1
+	else
+		! _unmountLoop_losetup "$ubVirtDiskOverride" "$1" "$ubVirtDiskOverride" && _stop 1
 	fi
-
-	#Default x64 .
-	"$scriptAbsoluteLocation" _mountChRoot_image_x64
-	return "$?"
+	return 0
 }

-_umountChRoot_directory_platform() {
-	# Include platform determination code for correct determination of partition and mounts.
-	_loopImage_imagefilename > /dev/null 2>&1
-
-	if [[ "$ubVirtPlatform" == "raspbian" ]]
-	then
-		"$scriptAbsoluteLocation" _umountChRoot_directory_raspbian
-		return "$?"
-	fi
+_umountFull_sequence() {
+	_start

-	if [[ "$ubVirtPlatform" == "x64"* ]]
+	if ! _umountFull_procedure "$@"
 	then
-		"$scriptAbsoluteLocation" _umountChRoot_directory_x64
-		return "$?"
+		_stop 1
 	fi

-	#Default "vm.img" will be operated on as x64 image.
-	"$scriptAbsoluteLocation" _umountChRoot_directory_x64
-	return "$?"
-}
-
-_umountChRoot_directory() {
-	! _umountChRoot_directory_platform && return 1
-
-	_stopChRoot "$1"
-	_umountChRoot "$1"
-
-	# Full umount of chroot directory may be done by standard '_umountImage'.
-	#mountpoint "$1" > /dev/null 2>&1 && sudo -n umount "$1"
-	#"$scriptAbsoluteLocation" _checkForMounts "$1" && return 1
-
-	return 0
+	_stop 0
 }

-# ATTENTION: Override with "core.sh" or similar.
-# WARNING: Must return true to complete mount/umount procedure.
-_umountChRoot_image_prog() {
-	true
-
-	#[[ -d "$globalVirtFS"/../boot ]] && mountpoint "$globalVirtFS"/../boot >/dev/null 2>&1 && sudo -n umount "$globalVirtFS"/../boot >/dev/null 2>&1
+_umountFull() {
+	if "$scriptAbsoluteLocation" _umountFull_sequence "$@"
+	then
+		return 0
+	fi

-	#[[ -d "$globalVirtFS"/boot/efi ]] && mountpoint "$globalVirtFS"/boot/efi >/dev/null 2>&1 && sudo -n umount "$globalVirtFS"/boot/efi >/dev/null 2>&1
-	#[[ -d "$globalVirtFS"/boot ]] && mountpoint "$globalVirtFS"/boot >/dev/null 2>&1 && sudo -n umount "$globalVirtFS"/boot >/dev/null 2>&1
+	# Typically requires "_stop 1" .
+	return 1
 }

-_umountChRoot_image() {
+# "$1" == destinationDir (default: "$globalVirtFS")
+_umountImage() {
 	_mustGetSudo || return 1

-	# x64-efi (typical)
-	[[ -d "$globalVirtFS"/boot/efi ]] && mountpoint "$globalVirtFS"/boot/efi >/dev/null 2>&1 && sudo -n umount "$globalVirtFS"/boot/efi >/dev/null 2>&1
-	[[ -d "$globalVirtFS"/boot ]] && mountpoint "$globalVirtFS"/boot >/dev/null 2>&1 && sudo -n umount "$globalVirtFS"/boot >/dev/null 2>&1
-
-
-	! _umountChRoot_directory "$chrootDir" && return 1
-
-	! _umountChRoot_image_prog && return 1
-
-	# raspbian (typical)
-	[[ -d "$globalVirtFS"/../boot ]] && mountpoint "$globalVirtFS"/../boot >/dev/null 2>&1 && sudo -n umount "$globalVirtFS"/../boot >/dev/null 2>&1
+	local currentDestinationDir
+	currentDestinationDir="$1"
+	[[ "$currentDestinationDir" == "" ]] && currentDestinationDir="$globalVirtFS"

-	_umountImage "$chrootDir"
+	sudo -n umount "$currentDestinationDir" > /dev/null 2>&1

+	#Uniquely, it is desirable to allow unmounting to proceed a little further if the filesystem was not mounted to begin with. Enables manual intervention.

+	#Filesystem must be unmounted before proceeding.
+	_readyImage "$currentDestinationDir" && sleep 1 && sudo -n umount "$currentDestinationDir" > /dev/null 2>&1
+	_readyImage "$currentDestinationDir" && sleep 3 && sudo -n umount "$currentDestinationDir" > /dev/null 2>&1
+	_readyImage "$currentDestinationDir" && sleep 9 && sudo -n umount "$currentDestinationDir" > /dev/null 2>&1
+	_readyImage "$currentDestinationDir" && return 1

-	rm -f "$permaLog"/gsysd.log > /dev/null 2>&1
+	! _umountLoop && return 1

 	return 0
 }

-_waitChRoot_opening() {
-	_readyChRoot "$chrootDir" && return 0
+_waitLoop_opening() {
+	[[ -e "$scriptLocal"/imagedev ]] && return 0
+	sleep 0.1
+	[[ -e "$scriptLocal"/imagedev ]] && return 0
+	sleep 0.3
+	for iteration in `seq 1 45`;
+	do
+		[[ -e "$scriptLocal"/imagedev ]] && return 0
+		sleep 1
+	done
+
+	return 1
+}
+
+_waitImage_opening() {
+	_readyImage "$globalVirtFS" && return 0
 	sleep 1
-	_readyChRoot "$chrootDir" && return 0
+	_readyImage "$globalVirtFS" && return 0
 	sleep 3
-	_readyChRoot "$chrootDir" && return 0
+	_readyImage "$globalVirtFS" && return 0
 	sleep 9
-	_readyChRoot "$chrootDir" && return 0
+	_readyImage "$globalVirtFS" && return 0
 	sleep 27
-	_readyChRoot "$chrootDir" && return 0
+	_readyImage "$globalVirtFS" && return 0
 	sleep 81
-	_readyChRoot "$chrootDir" && return 0
+	_readyImage "$globalVirtFS" && return 0

 	return 1
 }

-_waitChRoot_closing() {
-	_readyChRoot "$chrootDir" || return 0
-	sleep 1
-	_readyChRoot "$chrootDir" || return 0
+_waitLoop_closing() {
+	! [[ -e "$scriptLocal"/imagedev ]] && return 0
+	sleep 0.1
+	! [[ -e "$scriptLocal"/imagedev ]] && return 0
+	sleep 0.3
+	for iteration in `seq 1 45`;
+	do
+		! [[ -e "$scriptLocal"/imagedev ]] && return 0
+		sleep 1
+	done
+
+	return 1
+}
+
+_waitImage_closing() {
+	_readyImage "$globalVirtFS" || return 0
+	sleep 1
+	_readyImage "$globalVirtFS" || return 0
 	sleep 3
-	_readyChRoot "$chrootDir" || return 0
+	_readyImage "$globalVirtFS" || return 0
 	sleep 9
-	_readyChRoot "$chrootDir" || return 0
+	_readyImage "$globalVirtFS" || return 0
 	sleep 27
-	_readyChRoot "$chrootDir" || return 0
+	_readyImage "$globalVirtFS" || return 0
 	sleep 81
-	_readyChRoot "$chrootDir" || return 0
+	_readyImage "$globalVirtFS" || return 0

 	return 1
 }

-_openChRoot() {
-	export specialLock="$lock_open_chroot"
-	_open _waitChRoot_opening _mountChRoot_image
-}
-
-_closeChRoot() {
-	_findInfrastructure_virtImage ${FUNCNAME[0]} "$@"
-	[[ "$ubVirtImageLocal" == "false" ]] && return
+_readyImage() {
+	local absolute1
+	absolute1=$(_getAbsoluteLocation "$1")

-	export specialLock="$lock_open_chroot"
-	if [[ "$1" == "--force" ]]
-	then
-		_close --force _waitChRoot_closing _umountChRoot_image
-		return
-	fi
+	mountpoint "$absolute1" > /dev/null 2>&1 || return 1

-	_close _waitChRoot_closing _umountChRoot_image
+	return 0
 }

-_haltAllChRoot() {
-	find "$scriptAbsoluteFolder"/v_*/fs -maxdepth 1 -type d -exec "$scriptAbsoluteLocation" _umountChRoot_directory '{}' \;
-	find "$scriptAbsoluteFolder"/v_*/tmp -maxdepth 1 -type d -exec sudo -n umount '{}' \;
-	find "$scriptAbsoluteFolder"/v_*/ -maxdepth 12 -type d | head -n 48 | tac | xargs rmdir
+_openImage() {
+	local returnStatus

-	"$scriptAbsoluteLocation" _closeChRoot --force
+	export specialLock="$lock_open_image"

-	#Closing file may remain if chroot was not open to begin with. Since haltAllChRoot is usually called for forced/emergency shutdown purposes, clearing the resultant lock file is usually safe.
-	rm -f "$lock_closing"
+	_open _waitImage_opening _mountImage
+	returnStatus="$?"
+
+	export specialLock=""
+
+	return "$returnStatus"
 }

-#Fast dismount of all ChRoot filesystems/instances and cleanup of lock files. Specifically intended to act on SIGTERM or during system(d) shutdown, when time and disk I/O may be limited.
-# TODO Use a tmpfs mount to track reboots (with appropriate BSD/Linux/Solaris checking) in the first place.
-#"$1" == sessionid (optional override for cleaning up stale systemd files)
-_closeChRoot_emergency() {
-	_checkSpecialLocks "$lock_open_chroot"
+_closeImage() {
+	local returnStatus

-	if [[ -e "$instancedVirtFS" ]]
+	export specialLock="$lock_open_image"
+
+	if [[ "$1" == "--force" ]]
 	then
-		_stopChRoot "$instancedVirtFS" >> "$logTmp"/usrchrt.log 2>&1
-		_umountChRoot_project >> "$logTmp"/usrchrt.log 2>&1
-		_umountChRoot_user_home >> "$logTmp"/usrchrt.log 2>&1
-		_umountChRoot_user >> "$logTmp"/usrchrt.log 2>&1
+		_close --force _waitImage_closing _umountImage
+		returnStatus="$?"

-		_rm_ubvrtusrChRoot
+		export specialLock=""

-		_stop_virt_instance >> "$logTmp"/usrchrt.log 2>&1
+		return "$returnStatus"
 	fi

-	#Not called by systemd, AND instanced directories still mounted, do not globally halt all. (optional)
-	#[[ "$1" == "" ]] && find "$scriptAbsoluteFolder"/v_* -maxdepth 1 -type d | _condition_lines_zero && return 0
-
-	#Not called by systemd, do not globally halt all.
-	[[ "$1" == "" ]] && return 0
-
-	! _readLocked "$lock_open" && find "$scriptAbsoluteFolder"/v_*/fs -maxdepth 1 -type d | _condition_lines_zero && return 0
-	_readLocked "$lock_closing" && return 1
-	_readLocked "$lock_opening" && return 1
-
-	_readLocked "$lock_emergency" && return 0
-	_createLocked "$lock_emergency"
-
-	_haltAllChRoot
-
-	#rm -f "$lock_emergency" || return 1
-	rm -f "$lock_emergency"
-	[[ -e "$lock_emergency" ]] && return 1
-
+	_close _waitImage_closing _umountImage
+	returnStatus="$?"

-	local hookSessionid
-	hookSessionid="$sessionid"
-	[[ "$1" != "" ]] && hookSessionid="$1"
-	_tryExecFull _unhook_systemd_shutdown "$hookSessionid"
+	export specialLock=""

+	return "$returnStatus"
 }

-#Debugging function.
-_removeChRoot() {
-	_haltAllChRoot
+_openLoop() {
+	local returnStatus

-	rm -f "$lock_closing"
-	rm -f "$lock_opening"
-	rm -f "$lock_instancing"
+	export specialLock="$lock_loop_image"

-	rm -f "$globalVirtDir"/_ubvrtusr
+	_open _waitLoop_opening _loopImage
+	returnStatus="$?"

+	export specialLock=""

+	return "$returnStatus"
 }

-_chroot() {
-
-	[[ ! -e "$chrootDir"/bin/bash ]] && return 1
-
-	_mustGetSudo
-
-	#cd "$chrootDir"
+_closeLoop() {
+	local returnStatus

-	local chrootExitStatus
+	export specialLock="$lock_loop_image"

-	sudo -n env -i HOME="/root" TERM="${TERM}" SHELL="/bin/bash" PATH="/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin" DISPLAY="$DISPLAY" XSOCK="$XSOCK" XAUTH="$XAUTH" localPWD="$localPWD" hostArch=$(uname -m) virtSharedUser="$virtGuestUser" USER="root" chrootName="chrt" devfast="$devfast" nonet="$nonet" GH_TOKEN="$GH_TOKEN" INPUT_GITHUB_TOKEN="$INPUT_GITHUB_TOKEN" TOKEN="$TOKEN" $(sudo -n bash -c "type -p chroot") "$chrootDir" "$@"
-
-
-	# WARNING: CAUTION: May be untested.
-	#export GH_TOKEN="$GH_TOKEN"
-	#export INPUT_GITHUB_TOKEN="$INPUT_GITHUB_TOKEN"
-	#export TOKEN="$TOKEN"
-	##env -i
-	#sudo -n -E --preserve-env=GH_TOKEN --preserve-env=INPUT_GITHUB_TOKEN --preserve-env=TOKEN env HOME="/root" TERM="${TERM}" SHELL="/bin/bash" PATH="/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin" DISPLAY="$DISPLAY" XSOCK="$XSOCK" XAUTH="$XAUTH" localPWD="$localPWD" hostArch=$(uname -m) virtSharedUser="$virtGuestUser" USER="root" chrootName="chrt" devfast="$devfast" nonet="$nonet" $(sudo -n bash -c "type -p chroot") "$chrootDir" "$@"
+	if [[ "$1" == "--force" ]]
+	then
+		_close --force _waitLoop_closing _umountLoop
+		returnStatus="$?"
+
+		export specialLock=""
+
+		return "$returnStatus"
+	fi

-	chrootExitStatus="$?"
+	_close _waitLoop_closing _umountLoop
+	returnStatus="$?"

-	return "$chrootExitStatus"
+	export specialLock=""

+	return "$returnStatus"
 }

-
-_mountChRoot_userAndHome() {
-
-	sudo -n mount -t tmpfs -o size=4G,uid="$HOST_USER_ID",gid="$HOST_GROUP_ID" tmpfs "$instancedVirtTmp"
-
-	#_bindMountManager "$globalVirtFS" "$instancedVirtFS" || return 1
-
-	#_bindMountManager "$instancedVirtTmp" "$instancedVirtHome" || return 1
-
-
-	#Remove directories that interfere with union mounting.
-	rmdir "$instancedProjectDir"
-	rmdir "$instancedVirtHome"
-	###rmdir "$instancedVirtHomeRef"
-	rmdir "$instancedVirtFS"/home
-	rmdir "$instancedVirtFS"/root > /dev/null 2>&1
-
-	# TODO Device Mapper snapshot ChRoot instancing alternative. Disadvantage of not allowing the root filesystem to be simultaneously mounted read-write.
-	# TODO Develop a function to automatically select whatever unionfs equivalent may be supported by the host.
-	#sudo -n /bin/mount -t unionfs -o dirs="$instancedVirtTmp":"$globalVirtFS"=ro unionfs "$instancedVirtFS"
-	sudo -n unionfs-fuse -o cow,allow_other,use_ino,suid,dev "$instancedVirtTmp"=RW:"$globalVirtFS"=RO "$instancedVirtFS"
-	#sudo -n unionfs -o dirs="$instancedVirtTmp":"$globalVirtFS"=ro "$instancedVirtFS"
-	sudo -n chown "$USER":"$USER" "$instancedVirtFS"
-
-	#unionfs-fuse -o cow,max_files=32768 -o allow_other,use_ino,suid,dev,nonempty /u/host/etc=RW:/u/group/etc=RO:/u/common/etc=RO /u/union/etc
+_testCreateFS() {
+	if _if_cygwin
+	then
+		echo 'warn: accepted: cygwin: missing: mount: mkfs'
+		return 0
+	fi

-	mkdir -p "$instancedProjectDir"
-	mkdir -p "$instancedVirtHome"
-	###mkdir -p "$instancedVirtHomeRef"
+	_mustGetSudo

-	return 0
+	_getDep mkfs
+	_getDep mkfs.ext4
 }

-_mountChRoot_project() {
-	#if [[ ! -e "$0" ]]
-	#then
-	#	return 1
-	#fi
-
-	if [[ "$sharedHostProjectDir" == "" ]]
+_testCreatePartition() {
+	if _if_cygwin
 	then
-		return 1
+		echo 'warn: accepted: cygwin: missing: mount: parted'
+		return 0
 	fi

-	if [[ "$sharedHostProjectDir" == "/" ]]
-	then
-		return 1
-	fi
+	_mustGetSudo

-	#Denylist.
-	[[ "$sharedHostProjectDir" == "/home" ]] && return 1
-	[[ "$sharedHostProjectDir" == "/home/" ]] && return 1
-	[[ "$sharedHostProjectDir" == "/home/$USER" ]] && return 1
-	[[ "$sharedHostProjectDir" == "/home/$USER/" ]] && return 1
-	[[ $(id -u) != 0 ]] && [[ "$sharedHostProjectDir" == "/$USER" ]] && return 1
-	[[ $(id -u) != 0 ]] && [[ "$sharedHostProjectDir" == "/$USER/" ]] && return 1
+	_getDep parted
+	#_getDep partprobe
+}
+
+_createRawImage_sequence() {
+	_start

-	[[ "$sharedHostProjectDir" == "/tmp" ]] && return 1
-	[[ "$sharedHostProjectDir" == "/tmp/" ]] && return 1
+	export vmImageFile="$scriptLocal"/vm.img

-	[[ $(id -u) != 0 ]] && [[ "$sharedHostProjectDir" == "$HOME" ]] && return 1
-	[[ $(id -u) != 0 ]] && [[ "$sharedHostProjectDir" == "$HOME/" ]] && return 1
+	[[ "$1" != "" ]] && export vmImageFile="$1"

-	#Allowlist.
-	local safeToMount=false
+	local createRawImageSize
+	createRawImageSize=7636
+	[[ "$vmSize" != "" ]] && createRawImageSize="$vmSize"

-	local safeScriptAbsoluteFolder="$_getScriptAbsoluteFolder"
+	[[ "$vmImageFile" == "" ]] && _stop 1
+	[[ -e "$vmImageFile" ]] && _stop 1

-	[[ "$sharedHostProjectDir" == "./"* ]] && [[ "$PWD" == "$safeScriptAbsoluteFolder"* ]] && safeToMount="true"
+	dd if=/dev/zero of="$vmImageFile" bs=1M count="$createRawImageSize" > /dev/null 2>&1

-	[[ "$sharedHostProjectDir" == "$safeScriptAbsoluteFolder"* ]] && safeToMount="true"
+	_stop
+}
+
+_createRawImage() {

-	[[ "$sharedHostProjectDir" == "/home/$USER"* ]] && safeToMount="true"
-	[[ "$sharedHostProjectDir" == "/root"* ]] && safeToMount="true"
+	"$scriptAbsoluteLocation" _createRawImage_sequence "$@"

-	[[ "$sharedHostProjectDir" == "/tmp/"* ]] && safeToMount="true"
+}
+
+_createPartition() {
+	_mustGetSudo

-	[[ "$safeToMount" == "false" ]] && return 1
+	sudo -n parted --script "$scriptLocal"/vm.img mklabel msdos
+	sudo -n partprobe > /dev/null 2>&1
+	sudo -n parted "$scriptLocal"/vm.img --script -- mkpart primary 0% 100%
+	sudo -n partprobe > /dev/null 2>&1
+}
+
+
+_createFS_sequence() {
+	_mustGetSudo

-	#Safeguards/
-	#[[ -d "$sharedHostProjectDir" ]] && find "$sharedHostProjectDir" | grep -i '\.git$' >/dev/null 2>&1 && return 1
+	_start

-	#Validate necessary tools were available for path building and checks.
-	_checkDep realpath
-	_checkDep readlink
-	_checkDep dirname
-	_checkDep basename
+	mkdir -p "$globalVirtFS"

-	sudo -n unionfs-fuse -o allow_other,use_ino,suid,dev "$sharedHostProjectDir"=RW "$instancedProjectDir"
-	sudo -n chown "$USER":"$USER" "$instancedProjectDir"
+	"$scriptAbsoluteLocation" _checkForMounts "$globalVirtFS" && _stop 1

-	#_bindMountManager "$sharedHostProjectDir" "$instancedProjectDir" || return 1
+	local imagedev
+	imagedev=$(cat "$scriptLocal"/imagedev)

-}
-
-_umountChRoot_project() {
+	local imagepart
+	#imagepart="$imagedev"p2
+	imagepart="$imagedev"p1

-	_wait_umount "$instancedProjectDir"
+	local loopdevfs
+	loopdevfs=$(sudo -n blkid -s TYPE -o value "$imagepart" | tr -dc 'a-zA-Z0-9')
+	[[ "$loopdevfs" == "ext4" ]] && _stop 1
+	sudo -n mkfs.ext4 "$imagepart" > /dev/null 2>&1 || _stop 1

+	_stop 0
 }

-_mountChRoot_userDirs() {
-	mkdir -p "$HOME"/Downloads
-	sudo -n mkdir -p "$instancedDownloadsDir"
-	sudo -n unionfs-fuse -o allow_other,use_ino,suid,dev "$HOME"/Downloads=RW "$instancedDownloadsDir"
-	sudo -n chown "$USER":"$USER" "$instancedDownloadsDir"
-
+_createFS_shell() {
+	"$scriptAbsoluteLocation" _loopImage_sequence || return 1
+	"$scriptAbsoluteLocation" _createFS_sequence || return 1
+	"$scriptAbsoluteLocation" _umountImage || return 1
+	return 0
 }

-_umountChRoot_userDirs() {
-	_wait_umount "$instancedDownloadsDir"
-	sudo -n rmdir "$instancedDownloadsDir"
+_createFS() {
+	local returnCode
+	_open true _createFS_shell
+	returnCode="$?"
+	_close true true

+	return "$returnCode"
 }

-#No production use. Already supported by bind mount of full "/tmp". Kept for reference only.
-_mountChRoot_X11() {
-	_bindMountManager "$XSOCK" "$instancedVirtFS"/"$XSOCK"
-	_bindMountManager "$XSOCK" "$instancedVirtFS"/"$XAUTH"
+
+
+
+
+_here_bootdisc_startup_xdg() {
+cat << 'CZXWXcRMTo8EmM8i4d'
+[Desktop Entry]
+Comment=
+Exec=sudo -n mount -t iso9660 -o ro,nofail LABEL=uk4uPhB663kVcygT0q /media/bootdisc > /dev/null ; sudo -n /media/bootdisc/rootnix.sh > /dev/null ; /media/bootdisc/cmd.sh > /dev/null
+GenericName=
+Icon=exec
+MimeType=
+Name=
+Path=
+StartupNotify=false
+Terminal=false
+TerminalOptions=
+Type=Application
+CZXWXcRMTo8EmM8i4d
 }

-#No production use. Already supported by bind mount of full "/tmp". Kept for reference only.
-_umountChRoot_X11() {
-	_wait_umount "$instancedVirtFS"/"$XSOCK"
-	_wait_umount "$instancedVirtFS"/"$XAUTH"
+_here_bootdisc_startup_systemd() {
+    cat << CZXWXcRMTo8EmM8i4d
+[Unit]
+After=xdg-desktop-autostart.target
+
+[Install]
+WantedBy=xdg-desktop-autostart.target
+
+[Service]
+Type=oneshot
+ExecStart="$1"/.config/startup.sh
+CZXWXcRMTo8EmM8i4d
 }

+_here_bootdisc_startup_script() {
+    cat << CZXWXcRMTo8EmM8i4d
+#!/usr/bin/env bash
+#export QT_QPA_PLATFORMTHEME= ; unset QT_QPA_PLATFORMTHEME ; export LANG="C"
+#export DESKTOP_SESSION=plasma
+#bash "$scriptAbsoluteLocation" _wsl_desktop-waitUp_wmctrl ; sleep 0.6
+export LANG="C"
+CZXWXcRMTo8EmM8i4d
+
+#dbus-run-session
+#_safeEcho_newline 'exec '"$@"' &'
+_safeEcho_newline 'sudo -n mount -t iso9660 -o ro,nofail LABEL=uk4uPhB663kVcygT0q /media/bootdisc > /dev/null ; sudo -n /media/bootdisc/rootnix.sh > /dev/null ; /media/bootdisc/cmd.sh > /dev/null'

-_umountChRoot_user() {
-
-	mountpoint "$instancedVirtFS" > /dev/null 2>&1 || return 1
-	#_umountChRoot "$instancedVirtFS"
-	_wait_umount "$instancedVirtFS"
-
+    cat << CZXWXcRMTo8EmM8i4d
+#disown -h \$!
+disown
+disown -a -h -r
+disown -a -r
+#rm -f "\$HOME"/.config/plasma-workspace/env/startup.sh
+#rm -f "\$HOME"/.config/startup.sh
+#sudo -n rm -f /etc/xdg/autostart/startup.desktop
+#rm -f "\$HOME"/.config/systemd/user/bootdiscStartup.service
+#bash "$scriptAbsoluteLocation" _wsl_desktop-waitDown_wmctrl
+#currentStopJobs=\$(jobs -p -r 2> /dev/null) ; [[ "\$displayStopJobs" != "" ]] && kill \$displayStopJobs > /dev/null 2>&1
+CZXWXcRMTo8EmM8i4d
 }

-_umountChRoot_user_home() {
-
-	_wait_umount "$instancedVirtHome" || return 1
-	mountpoint "$instancedVirtHome" > /dev/null 2>&1 && return 1
+_here_bootdisc_rootnix() {
+cat << 'CZXWXcRMTo8EmM8i4d'
+#!/usr/bin/env bash
+
+# https://www.howtogeek.com/803839/how-to-let-linux-scripts-detect-theyre-running-in-virtual-machines/
+# WARNING: Must be root!
+if [[ $(dmidecode -s system-product-name) == "VirtualBox" ]] && ! lsmod | grep vboxsf > /dev/null
+then
+	#! lsmod | grep vboxsf > /dev/null && /sbin/rcvboxadd cleanup
+	#/sbin/rcvboxadd quicksetup
+	/sbin/rcvboxadd setup
+fi
+
+if [[ "$0" != "/media/bootdisc/rootnix.sh" ]] && [[ -e "/media/bootdisc" ]]
+then
+	for iteration in `seq 1 25`;
+	do
+		! /bin/mountpoint /media/bootdisc > /dev/null 2>&1 && ! [[ -e "/media/bootdisc/rootnix.sh" ]] && sleep 6
+	done
+	sleep 0.1
+	/media/bootdisc/rootnix.sh "$@"
+	exit
+fi
+
+#Equivalent "fstab" entries for reference. Not used due to conflict for mountpoint, as well as lack of standard mounting options in vboxsf driver.
+#//10.0.2.4/qemu	/home/user/.pqm cifs	guest,_netdev,uid=user,user,nofail,exec		0 0
+#appFolder		/home/user/.pvb	vboxsf	uid=user,_netdev				0 0
+
+_mountGuestShareNIX() {
+	! /bin/mountpoint /home/user/project > /dev/null 2>&1 && /bin/mount -t vboxsf -o uid=user,_netdev appFolder /home/user/project 2>&1
+	! /bin/mountpoint /home/user/Downloads > /dev/null 2>&1 && /bin/mount -t vboxsf -o uid=user,_netdev Downloads /home/user/Downloads 2>&1

-	return 0
+	! /bin/mountpoint /home/user/project > /dev/null 2>&1 && /bin/mount -t cifs -o guest,_netdev,uid=user,user,nofail,exec '//10.0.2.4/qemu' /home/user/project > /dev/null 2>&1

 }

-_checkBaseDirRemote_chroot() {
-
-	[[ -e "$chrootDir"/"$1" ]] || return 1
-	return 0
+#http://stackoverflow.com/questions/687948/timeout-a-command-in-bash-without-unnecessary-delay
+_timeout() { ( set +b; sleep "$1" & "${@:2}" & wait -n; r=$?; kill -9 `jobs -p`; exit $r; ) }
+
+_uid() {
+	local uidLength
+	[[ -z "$1" ]] && uidLength=18 || uidLength="$1"

+	cat /dev/urandom | base64 | tr -dc 'a-zA-Z0-9' | head -c "$uidLength"
 }

+export sessionid=$(_uid)
+[[ -d /tmp ]] && export bootTmp=/tmp		#Typical BSD
+[[ -d /dev/shm ]] && export bootTmp=/dev/shm	#Typical Linux
+
+echo "rootnix" > "$bootTmp"/"$sessionid".rnx

+#/bin/mkdir -p /home/user/.pqm
+#/bin/mkdir -p /home/user/.pvb

-_rm_ubvrtusrChRoot() {
-
-	sudo -n rmdir "$sharedGuestProjectDir" > /dev/null 2>&1
-	sudo -n rmdir "$instancedVirtHome"/"$virtGuestUser"/project > /dev/null 2>&1
-	sudo -n rmdir "$instancedVirtHome"/"$virtGuestUser" > /dev/null 2>&1
-	sudo -n rmdir "$instancedVirtHome" > /dev/null 2>&1
-	###sudo -n rmdir "$instancedVirtHomeRef"/project > /dev/null 2>&1
-	###sudo -n rmdir "$instancedVirtHomeRef"/"$virtGuestUser"/project > /dev/null 2>&1
-	###sudo -n rmdir "$instancedVirtHomeRef"/"$virtGuestUser" > /dev/null 2>&1
-	###sudo -n rmdir "$instancedVirtHomeRef" > /dev/null 2>&1
-
-}
+/bin/mkdir -p /home/user/Downloads
+! /bin/mountpoint /home/user/Downloads && /bin/chown user:user /home/user/Downloads

+/bin/mkdir -p /home/user/project
+! /bin/mountpoint /home/user/project && /bin/chown user:user /home/user/project

+! /bin/mountpoint /home/user/project > /dev/null 2>&1 && sleep 0.1 && _mountGuestShareNIX
+! /bin/mountpoint /home/user/project > /dev/null 2>&1 && sleep 0.3 && _mountGuestShareNIX
+! /bin/mountpoint /home/user/project > /dev/null 2>&1 && sleep 1 && _mountGuestShareNIX
+! /bin/mountpoint /home/user/project > /dev/null 2>&1 && sleep 3 && _mountGuestShareNIX

-_ubvrtusrChRoot_report_failure() {
-
-	echo -n "ubvrtusr     ""$1"
-	echo -e -n '\t'
-	shift
-
-	echo -n "$1"
-	echo -e -n '\t'
-	shift
-
-	shift
-	echo "$@"
-
-	return 0
-
+for iteration in `seq 1 15`;
+do
+	! /bin/mountpoint /home/user/project > /dev/null 2>&1 && sleep 6 && _mountGuestShareNIX
+done
+
+! /bin/mountpoint /home/user/project > /dev/null 2>&1 && sleep 9 && _mountGuestShareNIX
+! /bin/mountpoint /home/user/project > /dev/null 2>&1 && sleep 18 && _mountGuestShareNIX
+! /bin/mountpoint /home/user/project > /dev/null 2>&1 && sleep 27 && _mountGuestShareNIX
+
+CZXWXcRMTo8EmM8i4d
 }

-_ubvrtusrChRoot_check() {
-	#Diagnostics.
-	echo '#####ubvrtusr     checks'
-
-	local internalFailure
-	internalFailure=false
-
-	###! [[ -e "$globalVirtFS"/"$virtGuestHomeRef" ]] && _ubvrtusrChRoot_report_failure "nohome" "$virtGuestHomeRef" '[[ -e "$virtGuestHomeRef" ]]' && internalFailure=true
-
-	! _chroot id -u "$virtGuestUser" > /dev/null 2>&1 && _ubvrtusrChRoot_report_failure "no guest user" "$virtGuestUser" '_chroot id -u "$virtGuestUser"' && internalFailure=true
-
-	! [[ $(_chroot id -u "$virtGuestUser") == "$HOST_USER_ID" ]] && _ubvrtusrChRoot_report_failure "bad uid" $(_chroot id -u "$virtGuestUser") '[[ $(_chroot id -u "$virtGuestUser") == "$HOST_USER_ID" ]]' && internalFailure=true
-
-	! [[ $(_chroot id -g "$virtGuestUser") == "$HOST_GROUP_ID" ]] && _ubvrtusrChRoot_report_failure "bad gid" $(_chroot id -g "$virtGuestUser") '[[ $(_chroot id -g "$virtGuestUser") == "$HOST_GROUP_ID" ]]' && internalFailure=true
-
-	echo '#####ubvrtusr     checks'
-
-	 [[ "$internalFailure" == "true" ]] && return 1
-	 return 0
+_here_bootdisc_startupbat() {
+cat << 'CZXWXcRMTo8EmM8i4d'
+REM CALL A:\uk4uPhB6.bat
+REM CALL B:\uk4uPhB6.bat
+CALL D:\uk4uPhB6.bat
+CALL E:\uk4uPhB6.bat
+CALL F:\uk4uPhB6.bat
+CALL G:\uk4uPhB6.bat
+CALL H:\uk4uPhB6.bat
+CALL Y:\shell.bat
+CZXWXcRMTo8EmM8i4d
 }

-_ubvrtusrChRoot() {
+_here_bootdisc_shellbat() {
+cat << 'CZXWXcRMTo8EmM8i4d'
+CALL Y:\loader.bat
+CALL Y:\application.bat
+CZXWXcRMTo8EmM8i4d
+}
+
+#No production use.
+_here_bootdisc_loaderZbat() {
+cat << 'CZXWXcRMTo8EmM8i4d'
+net use z: /delete
+
+:checkMount
+
+net use /USER:guest z: \\VBOXSVR\root ""
+
+ping -n 2 127.0.0.1 > nul
+IF NOT EXIST "Z:\" GOTO checkMount
+CZXWXcRMTo8EmM8i4d
+}
+
+_here_bootdisc_loaderXbat() {
+cat << 'CZXWXcRMTo8EmM8i4d'
+net use x: /delete
+
+:checkMount
+
+net use /USER:guest x: \\VBOXSVR\appFolder ""
+net use /USER:guest x: \\10.0.2.4\qemu ""
+
+ping -n 2 127.0.0.1 > nul
+IF NOT EXIST "X:\" GOTO checkMount
+CZXWXcRMTo8EmM8i4d
+}
+
+
+#Prints "$@" with quotes around every parameter.
+_echoArgsBootdisc_MSW() {

-	#If root, discontinue.
-	[[ $(id -u) == 0 ]] && return 0
+	#https://stackoverflow.com/questions/1668649/how-to-keep-quotes-in-bash-arguments

-	#If user correctly setup, discontinue. Check multiple times before recreating user.
-	local iterationCount
-	iterationCount=0
-	while [[ "$iterationCount" -lt "3" ]]
-	do
-		_ubvrtusrChRoot_check && return 0
+	local currentCommandStringPunctuated
+	local currentCommandStringParameter
+	for currentCommandStringParameter in "$@"; do

-		let iterationCount="$iterationCount"+1
-		sleep 0.3
+		# MSW interprets the expression \" and similar differently from UNIX.
+		#currentCommandStringParameter="${currentCommandStringParameter//\\/\\\\}"
+
+		currentCommandStringPunctuated="$currentCommandStringPunctuated \"${currentCommandStringParameter//\"/\\\"}\""
 	done
+	#_messagePlain_probe "$currentCommandStringPunctuated"

-	## Lock file. Not done with _waitFileCommands because there is nither an obvious means, nor an obviously catastrophically critical requirement, to independently check for completion of related useradd/mod/del operations.
-	_waitFile "$globalVirtDir"/_ubvrtusr || return 1
-	echo > "$globalVirtDir"/quicktmp
-	_moveconfirm "$globalVirtDir"/quicktmp "$globalVirtDir"/_ubvrtusr > /dev/null 2>&1 || return 1
-
-	_chroot userdel -r "$virtGuestUser"
-	_rm_ubvrtusrChRoot
-
-	_chroot groupadd -g "$HOST_GROUP_ID" -o "$virtGuestUser"
-	_chroot useradd --shell /bin/bash -u "$HOST_USER_ID" -g "$HOST_GROUP_ID" -o -c "" -m "$virtGuestUser" || return 1
-
-	_chroot usermod -a -G video "$virtGuestUser" > /dev/null 2>&1 || return 1
-
-	_chroot chown "$virtGuestUser":"$virtGuestUser" "$virtGuestHome" > /dev/null 2>&1
+	#echo -e -n '\E[0;34m '

-	sudo -n mkdir -p "$globalVirtFS""$virtGuestHome"
-	###sudo -n mkdir -p "$globalVirtFS""$virtGuestHomeRef"
-	###sudo -n cp -a "$globalVirtFS""$virtGuestHome"/. "$globalVirtFS""$virtGuestHomeRef"/
-	###echo sudo -n cp -a "$globalVirtFS""$virtGuestHome"/. "$globalVirtFS""$virtGuestHomeRef"/
-	###_chroot chown "$virtGuestUser":"$virtGuestUser" "$virtGuestHomeRef" > /dev/null 2>&1
+	_safeEcho "$currentCommandStringPunctuated"

-	#rm -f "$globalVirtDir"/_ubvrtusr > /dev/null 2>&1 || return 1
-	rm -f "$globalVirtDir"/_ubvrtusr > /dev/null 2>&1
-	[[ -e "$globalVirtDir"/_ubvrtusr ]] && return 1
+	#echo -e -n ' \E[0m'
+	echo

-	return 0
+	return
 }

-_userChRoot() {
-	_findInfrastructure_virtImage ${FUNCNAME[0]} "$@"
-	[[ "$ubVirtImageLocal" == "false" ]] && return
+#Prints "$@" with quotes around every parameter.
+_echoArgsBootdisc_UNIX() {

-	_start
-	_start_virt_all
-	export chrootDir="$globalVirtFS"
+	#https://stackoverflow.com/questions/1668649/how-to-keep-quotes-in-bash-arguments

-	_mustGetSudo || _stop 1
+	local currentCommandStringPunctuated
+	local currentCommandStringParameter
+	for currentCommandStringParameter in "$@"; do
+
+		# MSW interprets the expression \" and similar differently from UNIX.
+		currentCommandStringParameter="${currentCommandStringParameter//\\/\\\\}"
+
+		currentCommandStringPunctuated="$currentCommandStringPunctuated \"${currentCommandStringParameter//\"/\\\"}\""
+	done
+	#_messagePlain_probe "$currentCommandStringPunctuated"

+	#echo -e -n '\E[0;34m '

-	_checkDep mountpoint >> "$logTmp"/usrchrt.log 2>&1 || _stop 1
-	mountpoint "$instancedVirtDir" > /dev/null 2>&1 && _stop 1
-	mountpoint "$instancedVirtFS" > /dev/null 2>&1 && _stop 1
-	mountpoint "$instancedVirtTmp" > /dev/null 2>&1 && _stop 1
-	mountpoint "$instancedVirtHome" > /dev/null 2>&1 && _stop 1
+	_safeEcho "$currentCommandStringPunctuated"

-	"$scriptAbsoluteLocation" _openChRoot >> "$logTmp"/usrchrt.log 2>&1 || _stop 1
+	#echo -e -n ' \E[0m'
+	echo

-	_tryExecFull _hook_systemd_shutdown_action "_closeChRoot_emergency" "$sessionid"
+	return
+}
+
+
+_testVirtBootdisc() {
+	! _wantGetDep genisoimage && _wantGetDep mkisofs

+	if ! type mkisofs > /dev/null 2>&1 && ! type genisoimage > /dev/null 2>&1
+	then
+		echo 'need mkisofs or genisoimage'
+		_stop 1
+	fi
+}
+
+_prepareBootdisc() {
+	mkdir -p "$hostToGuestFiles" > /dev/null 2>&1 || return 1
+	mkdir -p "$hostToGuestDir" > /dev/null 2>&1 || return 1
+	return 0
+}
+
+_mkisofs() {
+	if type mkisofs > /dev/null 2>&1
+	then
+		mkisofs "$@"
+		return $?
+	fi

-	_ubvrtusrChRoot  >> "$logTmp"/usrchrt.log 2>&1 || _stop 1
+	if type genisoimage > /dev/null 2>&1
+	then
+		genisoimage "$@"
+		return $?
+	fi
+}
+
+_writeBootdisc() {
+	_mkisofs -V "$ubiquitousBashID" -volset "$ubiquitousBashID" -sysid "$ubiquitousBashID" -R -uid 0 -gid 0 -dir-mode 0555 -file-mode 0555 -new-dir-mode 0555 -J -hfs -o "$hostToGuestISO" "$hostToGuestFiles"
+}
+
+_setShareMSW_app() {
+	export sharedHostProjectDir="$sharedHostProjectDirDefault"
+	export sharedGuestProjectDir="$sharedGuestProjectDirDefault"

-	_mountChRoot_userAndHome >> "$logTmp"/usrchrt.log 2>&1 || _stop 1
-	###[[ $(id -u) != 0 ]] && cp -a "$instancedVirtHomeRef"/. "$instancedVirtHome"/ >> "$logTmp"/usrchrt.log 2>&1
-	export chrootDir="$instancedVirtFS"
+	export sharedGuestProjectDir="X:"
+}
+
+#No production use. Not recommended.
+_setShareMSW_root() {
+	export sharedHostProjectDir="$sharedHostProjectDirDefault"
+	export sharedGuestProjectDir="$sharedGuestProjectDirDefault"

+	export sharedHostProjectDir=/
+	export sharedGuestProjectDir="Z:"
+}
+
+_setShareMSW() {
+	[[ "$flagShareApp" ]] && _setShareMSW_app && return
+	[[ "$flagShareApp" ]] && _setShareMSW_root && return
+	return 1
+}
+
+#Consider using explorer.exe to use file associations within the guest. Overload with ops to force a more specific 'preCommand'.
+_preCommand_MSW() {
+	echo 'X:'
+	echo 'cd '"$localPWD"
+	echo -e -n 'start /MAX "" "explorer.exe" '
+}
+
+_createHTG_MSW() {
+	_setShareMSW

-	export checkBaseDirRemote=_checkBaseDirRemote_chroot
-	_virtUser "$@" >> "$logTmp"/usrchrt.log 2>&1
+	export checkBaseDirRemote=""
+	_virtUser "$@"
+	#"$sharedHostProjectDir"
+	#"${processedArgs[@]}"

-	#_mountChRoot_X11
+	_here_bootdisc_startupbat >> "$hostToGuestFiles"/rootmsw.bat

-	_mountChRoot_project >> "$logTmp"/usrchrt.log 2>&1 || _stop 1
-	_chroot chown "$virtGuestUser":"$virtGuestUser" "$sharedGuestProjectDir" >> "$logTmp"/usrchrt.log 2>&1
+	_preCommand_MSW >> "$hostToGuestFiles"/application.bat

-	#####
-	_mountChRoot_userDirs
+	# WARNING: Not fully tested with all plausible inputs. Beware possible misinterpretations of '$' and similar characters.
+	#_safeEcho_newline "${processedArgs[@]}" >> "$hostToGuestFiles"/application.bat
+	_echoArgsBootdisc_MSW "${processedArgs[@]}" >> "$hostToGuestFiles"/application.bat

+	echo ""  >> "$hostToGuestFiles"/application.bat

+	echo -e -n >> "$hostToGuestFiles"/loader.bat
+	[[ "$flagShareApp" == "true" ]] && _here_bootdisc_loaderXbat >> "$hostToGuestFiles"/loader.bat
+	[[ "$flagShareRoot" == "true" ]] && _here_bootdisc_loaderZbat >> "$hostToGuestFiles"/loader.bat

-	_chroot /bin/bash /usr/local/bin/ubiquitous_bash.sh _dropChRoot "${processedArgs[@]}"
-	local userChRootExitStatus="$?"
+	cat "$hostToGuestFiles"/loader.bat >> "$hostToGuestFiles"/uk4uPhB6.bat
+	cat "$hostToGuestFiles"/application.bat >> "$hostToGuestFiles"/uk4uPhB6.bat

-	_stopChRoot "$instancedVirtFS" >> "$logTmp"/usrchrt.log 2>&1
+	_here_bootdisc_shellbat >> "$hostToGuestFiles"/shell.bat

+	#https://www.cyberciti.biz/faq/howto-unix-linux-convert-dos-newlines-cr-lf-unix-text-format/
+	sed -i 's/$'"/`echo \\\r`/" "$hostToGuestFiles"/rootmsw.bat
+	sed -i 's/$'"/`echo \\\r`/" "$hostToGuestFiles"/application.bat
+	sed -i 's/$'"/`echo \\\r`/" "$hostToGuestFiles"/loader.bat
+	sed -i 's/$'"/`echo \\\r`/" "$hostToGuestFiles"/shell.bat
+	sed -i 's/$'"/`echo \\\r`/" "$hostToGuestFiles"/uk4uPhB6.bat
+}
+
+_setShareUNIX_app() {
+	export sharedHostProjectDir="$sharedHostProjectDirDefault"
+	export sharedGuestProjectDir="$sharedGuestProjectDirDefault"

+	export sharedGuestProjectDir="/home/user/project"
+}
+
+_setShareUNIX_root() {
+	export sharedHostProjectDir="$sharedHostProjectDirDefault"
+	export sharedGuestProjectDir="$sharedGuestProjectDirDefault"

+	export sharedGuestProjectDir="/home/user/project"
+	export sharedHostProjectDir=/
+}
+
+_setShareUNIX() {
+	[[ "$flagShareApp" ]] && _setShareUNIX_app && return
+	[[ "$flagShareApp" ]] && _setShareUNIX_root && return
+	return 1
+}
+
+_createHTG_UNIX() {
+	_setShareUNIX

-	_umountChRoot_userDirs
-	#####
+	export checkBaseDirRemote=""
+	_virtUser "$@"
+	#"$sharedHostProjectDir"
+	#"${processedArgs[@]}"

-	#_umountChRoot_X11
+	_here_bootdisc_startup_xdg >> "$hostToGuestFiles"/startup.desktop

-	_umountChRoot_project >> "$logTmp"/usrchrt.log 2>&1
-	_umountChRoot_user_home >> "$logTmp"/usrchrt.log 2>&1 || _stop 1
-	_umountChRoot_user >> "$logTmp"/usrchrt.log 2>&1 || _stop 1
+	_here_bootdisc_rootnix >> "$hostToGuestFiles"/rootnix.sh

-	_rm_ubvrtusrChRoot
+	echo '#!/usr/bin/env bash' >> "$hostToGuestFiles"/cmd.sh
+	echo "export localPWD=""$localPWD" >> "$hostToGuestFiles"/cmd.sh

-	"$scriptAbsoluteLocation" _checkForMounts "$instancedVirtFS" >> "$logTmp"/usrchrt.log 2>&1 && _stop 1
+	# WARNING: Not fully tested with all plausible inputs. Beware possible misinterpretations of '$' and similar characters.
+	#_safeEcho_newline "/media/bootdisc/ubiquitous_bash.sh _dropBootdisc ${processedArgs[@]}" >> "$hostToGuestFiles"/cmd.sh
+	echo -n "/media/bootdisc/ubiquitous_bash.sh _dropBootdisc " >> "$hostToGuestFiles"/cmd.sh
+	_echoArgsBootdisc_UNIX "${processedArgs[@]}" >> "$hostToGuestFiles"/cmd.sh

-	_stop_virt_instance >> "$logTmp"/usrchrt.log 2>&1
-	_stop "$userChRootExitStatus"
 }

-_removeUserChRoot_sequence() {
-	## Lock file. Not done with _waitFileCommands because there is nither an obvious means, nor an obviously catastrophically critical requirement, to independently check for completion of related useradd/mod/del operations.
-	_waitFile "$globalVirtDir"/_ubvrtusr || return 1
-	echo > "$globalVirtDir"/quicktmp
-	_moveconfirm "$globalVirtDir"/quicktmp "$globalVirtDir"/_ubvrtusr > /dev/null 2>&1 || return 1
+_commandBootdisc() {
+	_prepareBootdisc || return 1

+	export flagShareRoot="false"

-	_chroot userdel -r "$virtGuestUser" > /dev/null 2>&1
-	###[[ -d "$chrootDir""$virtGuestHomeRef" ]] && sudo -n "$scriptAbsoluteLocation" _safeRMR "$chrootDir""$virtGuestHomeRef"
+	#Rigiorously ensure flags will be set properly.
+	[[ "$flagShareRoot" != "true" ]] && export flagShareRoot="false"
+	[[ "$flagShareRoot" != "true" ]] && export flagShareApp="true"

-	_rm_ubvrtusrChRoot
+	#Include ubiquitous_bash itself.
+	cp "$scriptAbsoluteLocation" "$hostToGuestFiles"/
+	"$scriptBin"/.ubrgbin.sh _ubrgbin_cpA "$scriptBin" "$hostToGuestFiles"/_bin

-	#rm -f "$globalVirtDir"/_ubvrtusr > /dev/null 2>&1 || return 1
-	rm -f "$globalVirtDir"/_ubvrtusr > /dev/null 2>&1
-	[[ -e "$globalVirtDir"/_ubvrtusr ]] && return 1
+	#Process for MSW.
+	_createHTG_MSW "$@"

-	return 0
+	#Process for UNIX.
+	_createHTG_UNIX "$@"
+
+	#Ensure permissions are correctly set.
+	chmod 0755 "$hostToGuestFiles"/_bin/*
+	chmod 0755 "$hostToGuestFiles"/*.sh
+	chmod 0755 "$hostToGuestFiles"/*.desktop
+	chmod 0755 "$hostToGuestFiles"/*.bat
+	#chmod 0755 "$hostToGuestFiles"/*
+
+	_writeBootdisc || return 1
 }

-_removeUserChRoot() {
-	"$scriptAbsoluteLocation" _openChRoot || return 1
+_dropBootdisc() {
+	#Detect MSW/Cygwin architecture.
+		#Check for QEMU type shared directory, mount if present.
+		#Check for VBox type shared directory, mount if present.

-	_removeUserChRoot_sequence
+	#Detect UNIX architecture.
+	if ! uname -a | grep -i cygwin > /dev/null 2>&1
+	then
+		#Attempt to wait for QEMU or VBox type shared directory.
+		! mountpoint /home/user/project > /dev/null 2>&1 && sleep 0.3
+		! mountpoint /home/user/project > /dev/null 2>&1 && sleep 1
+		! mountpoint /home/user/project > /dev/null 2>&1 && sleep 3
+
+		for iteration in `seq 1 15`;
+		do
+			! /bin/mountpoint /home/user/project > /dev/null 2>&1 && sleep 6
+		done
+
+		! mountpoint /home/user/project > /dev/null 2>&1 && sleep 9
+		! mountpoint /home/user/project > /dev/null 2>&1 && sleep 18
+		! mountpoint /home/user/project > /dev/null 2>&1 && sleep 27
+		! mountpoint /home/user/project > /dev/null 2>&1 && sleep 36
+	fi
+	sleep 0.3

-	"$scriptAbsoluteLocation" _closeChRoot || return 1
-}
+	[[ -e "$HOME"/.config/plasma-workspace/env/profile.sh ]] && /bin/bash "$HOME"/.config/plasma-workspace/env/profile.sh

-_dropChRoot() {
-
-	# Change to localPWD or home.
 	cd "$localPWD"

-	"$scriptAbsoluteLocation" _gosuExecVirt cp -r /etc/skel/. "$virtGuestHomeDrop" > /dev/null 2>&1
-
-	"$scriptAbsoluteLocation" _gosuExecVirt "$scriptAbsoluteLocation" _setupUbiquitous_nonet > /dev/null 2>&1
-
-	# Drop to user ubvrtusr, using gosu.
-	_gosuExecVirt "$@"
+	"$@"
 }

-#No production use. Kept for reference only.
-###_prepareChRootUser() {
-
-	#_gosuExecVirt cp -r /etc/skel/. /home/
-
-	#cp -a /home/"$virtGuestUser".ref/. /home/"$virtGuestUser"/
-	#chown "$virtGuestUser":"$virtGuestUser" /home/"$virtGuestUser"
-
-	###true
-
-###}



-_vmsize-micro() {
-	# Part files have been as large as 1905MiB .
-	echo 7620
-}
-_vmsize() {
-	# 25.95GiB
-	#echo 26572

-	# Preferred before addition of any AI models. Smaller than 32GB USB flash drive.
-	# 27.95GiB
-	#echo 28620
+# TODO Launch "_fromImage", transfering "/home/user" to archive, then transfering this archive to "/etc/skel" .
+_importHomeUser() {
+	true
+}

-	# Preferred with 'augment' ~8b q4_k_m LLM model.
-	# 37.95GiB
-	#echo 38860
+_exportHomeUser() {
+	true
+}

-	# May accommodate a few additional AI models.
-	# 52.95GiB
-	#echo 54220
+# TODO To be used by "_userChRoot", binding "/home/user", as an alternative to copying "/etc/skel" .
+_bindHomeUser() {
+	true
+}

-	# Slightly smaller than expected 50GB BD-R DL .
-	# 46.1GiB
-	echo 47206
+_unbindHomeUser() {
+	true
 }

-# Similar to _createVMimage , but intended to create an image solely for online installer steps , a small image ingredient to follow up with subsequent offline build from other more de-facto standard ingredients.
-# ATTENTION: Override if necessary.
-# CAUTION: Must follow defaults of '_createVMimage', which in turn must follow defaults (eg. _set_ubDistBuild , 'core.sh' , 'ops.sh' , ubiquitous_bash , etc) .
-# CAUTION: Platforms other than the default 'x64-efi' must use entirely different function paths, different 'vm-arch.img' filenames, etc.
-# ATTENTION: If alternative architectures (eg. ARM) were desired, creating a bootable 'micro'/'ingredients' image would be a more logical first step than porting the legacy build system that does not differentiate between this small bootable ingredient and the offline larger full build .
-_createVMimage-micro() {
-	if ! "$scriptAbsoluteLocation" _createVMimage-micro_sequence "$@"
-	then
-		_stop 1
-	fi
-	return 0
+
+_test_transferimage() {
+	_mustGetSudo
+
+	_getDep rsync
 }
-_createVMimage-micro_sequence() {
-    #export ubVirtImageOverride="vm-ingredient.img"
-    export ubVirtImageOverride_alternate="$scriptLocal"/"vm-ingredient.img"
-	local ub_vmImage_micro="true"
-	_createVMimage "$@"
+
+_toImage() {
+	_findInfrastructure_virtImage ${FUNCNAME[0]} "$@"
+	[[ "$ubVirtImageLocal" == "false" ]] && return
+
+	#_openImage || return 1
+	_openChRoot || return 1
+
+	#rsync -avx -A -X "$1" "$globalVirtFS"/"$2"
+	rsync -avx "$1" "$globalVirtFS"/"$2"
 }
-_createVMimage-ingredient() {
-	_createVMimage-micro "$@"
+
+_toImageDir() {
+	mkdir -p "$globalVirtFS"/"$2"
+	_toImage "$1" "$2"
 }
-_createVMimage-micro-expand() {
-	local currentExitStatus
-	currentExitStatus="0"
-
-	_messageNormal '_custom-expand: dd'

-	local vmSize=$(_vmsize)
-	local vmSize_micro=$(_vmsize-micro)
-	local vmSize_boundary_expansion=$(bc <<< "$vmSize - $vmSize_micro - 1")
+_fromImage() {
+	#_openImage || return 1
+	_openChRoot || return 1
+
+	#rsync -avx -A -X "$globalVirtFS""$1" "$2"
+	rsync -avx "$globalVirtFS""$1" "$2"
+}

-	# ATTENTION: Expand ONLY the additional amount needed for custom additions . This is APPENDED .
-	! dd if=/dev/zero bs=1048576 count="$vmSize_boundary_expansion" >> "$scriptLocal"/vm.img && _messageFAIL
+_fromImageDir() {
+	mkdir -p "$2"
+	_fromImage "$1" "$2"
+}

-	# Alternatively, it may be possible, but STRONGLY DISCOURAGED, to pad the file to a size. This, however, assumes the upstream 'ubdist/OS', etc, has not unexpectedly grown larger, which is still a VERY BAD assumption.
-	# https://unix.stackexchange.com/questions/196715/how-to-pad-a-file-to-a-desired-size
-
-
-	_messageNormal '_custom-expand: growpart'
-	! _openLoop && _messagePlain_bad 'fail: openLoop' && _messageFAIL
+_imageToArc() {
+	[[ "$globalArcFS" == "" ]] && return 1
+	[[ "$globalArcFS" == "/" ]] && return 1

-	export ubVirtPlatform="x64-efi"
-	#_determine_rawFileRootPartition
+	mkdir -p "$globalArcFS" || return 1

-	export ubVirtImagePartition="p5"
+	_fromImageDir /home/user/. "$globalArcFS"/home/user
+	_fromImageDir /etc/skel/. "$globalArcFS"/etc/skel
+}
+
+_imageFromArc() {
+	[[ "$globalArcFS" == "" ]] && return 1
+	[[ "$globalArcFS" == "/" ]] && return 1

-	local current_imagedev=$(cat "$scriptLocal"/imagedev)
-	local current_rootpart=$(echo "$ubVirtImagePartition" | tr -dc '0-9')
+	mkdir -p "$globalArcFS" || return 1

-	! _messagePlain_probe_cmd sudo -n growpart "$current_imagedev" "$current_rootpart" && _messageFAIL
+	_toImageDir "$globalArcFS"/home/user/. /home/user
+	_toImageDir "$globalArcFS"/etc/skel/. /etc/skel
+}
+
+#Example. Translates permissions and copies ".arduino" directory.
+_buildFromImage() {
+	_mustGetSudo

-	unset ubVirtPlatform
-	unset ubVirtImagePartition
+	[[ "$globalBuildDir" == "" ]] && return 1
+	[[ "$globalBuildDir" == "/" ]] && return 1

-	! _closeLoop && _messagePlain_bad 'fail: closeLoop' && _messageFAIL
+	mkdir -p "$globalBuildDir" || return 1

-	_messageNormal '_custom-expand: btrfs resize'
-	! _openChRoot && _messagePlain_bad 'fail: openChRoot' && _messageFAIL
+	sudo -n "$scriptAbsoluteLocation" _fromImageDir /home/user/.arduino/. "$globalBuildDir"/.arduino
+	#sudo -n "$scriptAbsoluteLocation" _fromImageDir /etc/skel/.arduino/. "$globalBuildDir"/.arduino

+	_safePath "$globalBuildDir"/.arduino && sudo -n chown -R "$USER":"$GROUP" "$globalBuildDir"/.arduino
+}
+
+#Example. Translates permissions and copies ".arduino" directory.
+_buildToImage() {
+	_mustGetSudo

-	! _messagePlain_probe_cmd _chroot btrfs filesystem resize max / && _messageFAIL
+	[[ "$globalBuildDir" == "" ]] && return 1
+	[[ "$globalBuildDir" == "/" ]] && return 1

+	mkdir -p "$globalBuildDir" || return 1

-	! _closeChRoot && _messagePlain_bad 'fail: closeChRoot' && _messageFAIL
+	sudo -n "$scriptAbsoluteLocation" _toImageDir "$globalBuildDir"/.arduino/. /home/user/.arduino
+	sudo -n "$scriptAbsoluteLocation" _toImageDir "$globalBuildDir"/.arduino/. /etc/skel/.arduino

-	return 0
+	_chroot chown -R user:user /home/user/.arduino
+	_chroot chown -R root:root /etc/skel/.arduino
 }

-# Creates a raw VM image. Default Hybrid/UEFI partitioning and formatting.
-# ATTENTION: Override, if necessary.
-_createVMimage() {
-	_messageNormal '##### _createVMimage'
+
+_testChRoot() {
+	_mustGetSudo

-	mkdir -p "$scriptLocal"
+	_testGosu || _stop 1

-	#[[ "$ub_vmImage_micro" == "true" ]] && export ubVirtImageOverride="$scriptLocal"/vm-ingredient.img
+	_checkDep gosu-armel
+	_checkDep gosu-amd64
+	_checkDep gosu-i386

-	export vmImageFile="$scriptLocal"/vm.img
-	[[ "$ub_vmImage_micro" == "true" ]] && export vmImageFile="$scriptLocal"/vm-ingredient.img
-	[[ "$ubVirtImageOverride" != "" ]] && export vmImageFile="$ubVirtImageOverride"
+	_getDep id

-	[[ "$ubVirtImageOverride" == "" ]] && [[ -e "$vmImageFile" ]] && _messagePlain_good 'exists: '"$vmImageFile" && return 0
-	[[ "$ubVirtImageOverride" == "" ]] && [[ -e "$scriptLocal"/vm.img ]] && _messagePlain_good 'exists: '"$scriptLocal"/vm.img && return 0
-
-	[[ -e "$lock_open" ]]  && _messagePlain_bad 'bad: locked!' && _messageFAIL && _stop 1
-	[[ -e "$scriptLocal"/l_o ]]  && _messagePlain_bad 'bad: locked!' && _messageFAIL && _stop 1
-
-	[[ "$ubVirtImageOverride" == "" ]] && ! [[ $(df --block-size=1000000000 --output=avail "$scriptLocal" | tr -dc '0-9') -gt "25" ]] && _messageFAIL && _stop 1
+	_getDep mount
+	_getDep umount
+	_getDep mountpoint

+	_getDep unionfs-fuse

+}
+
+#Lists all chrooted processes. First parameter is chroot directory. Script might need to run as root.
+#Techniques originally released by other authors at http://forums.grsecurity.net/viewtopic.php?f=3&t=1632 .
+#"$1" == ChRoot Dir
+_listprocChRoot() {
+	local absolute1
+	absolute1=$(_getAbsoluteLocation "$1")
+	PROCS=""
+	local currentProcess
+	# CAUTION: Rarely necessary. Avoid relying on this if possible.
+	for currentProcess in `ps -o pid -A`; do
+		if [ "`sudo -n readlink /proc/$currentProcess/root`" = "$absolute1" ]; then
+			PROCS="$PROCS"" ""$currentProcess"
+		fi
+	done
+	echo "$PROCS"
+}
+
+_killprocChRoot() {
+	local chrootKillSignal
+	chrootKillSignal="$1"

-	local imagedev
+	local chrootKillDir
+	chrootKillDir="$2"

-	_open
+	chrootprocs=( $(_listprocChRoot "$2") )
+	[[ "${chrootprocs[0]}" == "" ]] && return 0
+	sudo -n kill -"$chrootKillSignal" "${chrootprocs[@]}" >/dev/null
+	sleep 0.1

-	export vmImageFile="$scriptLocal"/vm.img
-	[[ "$ub_vmImage_micro" == "true" ]] && export vmImageFile="$scriptLocal"/vm-ingredient.img
-	[[ "$ubVirtImageOverride" != "" ]] && export vmImageFile="$ubVirtImageOverride"
+	chrootprocs=( $(_listprocChRoot "$2") )
+	[[ "${chrootprocs[0]}" == "" ]] && return 0
+	sudo -n kill -"$chrootKillSignal" "${chrootprocs[@]}" >/dev/null
+	sleep 0.3

+	[[ "$EMERGENCYSHUTDOWN" == "true" ]] && return 1

-	if [[ "$ubVirtImageOverride" == "" ]]
-	then
-		[[ -e "$vmImageFile" ]] && _messagePlain_bad 'exists: '"$vmImageFile" && _messageFAIL && _stop 1
+	chrootprocs=( $(_listprocChRoot "$2") )
+	[[ "${chrootprocs[0]}" == "" ]] && return 0
+	sudo -n kill -"$chrootKillSignal" "${chrootprocs[@]}" >/dev/null
+	sleep 1

+	chrootprocs=( $(_listprocChRoot "$2") )
+	[[ "${chrootprocs[0]}" == "" ]] && return 0
+	sudo -n kill -"$chrootKillSignal" "${chrootprocs[@]}" >/dev/null
+	sleep 3

-		_messageNormal 'create: '"$vmImageFile"': file'
+	chrootprocs=( $(_listprocChRoot "$2") )
+	[[ "${chrootprocs[0]}" == "" ]] && return 0
+	sudo -n kill -"$chrootKillSignal" "${chrootprocs[@]}" >/dev/null
+	sleep 9

+	#chrootprocs=( $(_listprocChRoot "$2") )
+	#[[ "${chrootprocs[0]}" == "" ]] && return 0
+	#sudo -n kill -"$chrootKillSignal" "${chrootprocs[@]}" >/dev/null 2>&1
+	#sleep 18
+}

-		export vmSize=$(_vmsize)
-		[[ "$ub_vmImage_micro" == "true" ]] && export vmSize=$(_vmsize-micro)
-
-
-		export vmSize_boundary=$(bc <<< "$vmSize - 1")
-		_createRawImage "$vmImageFile"
-	else
-		_messageNormal 'create: '"$vmImageFile"': device'
-
-
-		export vmSize=$(bc <<< $(sudo -n lsblk -b --output SIZE -n -d "$vmImageFile")' / 1048576')
-		export vmSize=$(bc <<< "$vmSize - 1")
-		export vmSize_boundary=$(bc <<< "$vmSize - 1")
-	fi
-
-
-	_messageNormal 'partition: '"$vmImageFile"''
-	sudo -n parted --script "$vmImageFile" 'mklabel gpt'
-
-	# Unusual.
-	#   EFI, Image/Root.
-	# Former default, only preferable if disk is strictly spinning CAV and many more bits per second with beginning tracks.
-	#   Swap, EFI, Image/Root.
-	# Compromise. May have better compatibility, may reduce CLV (and zoned CAV) speed changes from slowest tracks at beginning of some optical discs.
-	#   EFI, Swap, Image/Root.
-	# Expect <8MiB usage of EFI parition FAT32 filesystem, ~28GiB usage of Image/Root partition ext4 filesystem.
-	# 512MiB EFI, 5120MiB Swap, remainder Image/Root
-	# https://www.compuhoy.com/what-is-difference-between-bios-and-efi/
-	#  'Does EFI partition have to be first?' 'UEFI does not impose a restriction on the number or location of System Partitions that can exist on a system. (Version 2.5, p. 540.) As a practical matter, putting the ESP first is advisable because this location is unlikely to be impacted by partition moving and resizing operations.'
-	# http://blog.arainho.me/grub/gpt/arch-linux/2016/01/14/grub-on-gpt-partition.html
-	#  'at the first 2GB of the disk with toggle bios_grub used for booting'
+#End user and diagnostic function, shuts down all processes in a chroot.
+_stopChRoot() {
+	_mustGetSudo

-	# CAUTION: *As DEFAULT*, must match other definitions (eg. _set_ubDistBuild , 'core.sh' , 'ops.sh' , ubiquitous_bash , etc) .
-	# NTFS, Recovery, partitions should not have set values in any other functions. Never used - documentation only.
-	# Swap, partition should only have set values in this and fstab functions. Never used elsewhere.
-	# x64-bios , raspbian , x64-efi
-	export ubVirtImage_doNotOverride="true"
-	export ubVirtPlatformOverride='x64-efi'
-	export ubVirtImageBIOS=p1
-	export ubVirtImageEFI=p2
-	export ubVirtImageNTFS=
-	export ubVirtImageRecovery=
-	export ubVirtImageSwap=p3
-	export ubVirtImageBoot=p4
-	export ubVirtImagePartition=p5
+	local absolute1
+	absolute1=$(_getAbsoluteLocation "$1")

+	echo "TERMinating all chrooted processes."

+	_killprocChRoot "TERM" "$absolute1"

+	echo "KILLing all chrooted processes."

-	# ATTENTION: NOTICE: Larger EFI partition may be more compatible. Larger Swap partition may be more useful for hibernation.
+	_killprocChRoot "KILL" "$absolute1"

-	# BIOS
-	sudo -n parted --script "$vmImageFile" 'mkpart primary ext2 1MiB 2MiB'
-	sudo -n parted --script "$vmImageFile" 'set 1 bios_grub on'
+	echo "Remaining chrooted processes."
+	_listprocChRoot "$absolute1"

+	echo '-----'

-	# EFI
-	##sudo -n parted --script "$vmImageFile" 'mkpart EFI fat32 '"2"'MiB '"514"'MiB'
-	#sudo -n parted --script "$vmImageFile" 'mkpart EFI fat32 '"2"'MiB '"74"'MiB'
-	sudo -n parted --script "$vmImageFile" 'mkpart EFI fat32 '"2"'MiB '"42"'MiB'
-	sudo -n parted --script "$vmImageFile" 'set 2 msftdata on'
-	sudo -n parted --script "$vmImageFile" 'set 2 boot on'
-	sudo -n parted --script "$vmImageFile" 'set 2 esp on'
+}
+
+
+# May override with 'ops.sh' or similar. Future development intended. Currently, creating an image of a physical device is strongly recommended instead.
+_detect_deviceAsChRootImage() {
+	false

+	# TODO: Determine if "$ubVirtImageOverride" or "$scriptLocal" points to a device file (typically under '/dev').
+	# TODO: Should call separate function _detect_deviceAsVirtImage .
+	# DANGER: Functions under 'mountimage.sh' must also respect this.
+}
+
+
+#"$1" == ChRoot Dir
+_mountChRoot() {
+	_mustGetSudo

-	# Swap
-	##sudo -n parted --script "$vmImageFile" 'mkpart primary '"514"'MiB '"5633"'MiB'
-	##sudo -n parted --script "$vmImageFile" 'mkpart primary '"514"'MiB '"3073"'MiB'
-	#sudo -n parted --script "$vmImageFile" 'mkpart primary '"74"'MiB '"98"'MiB'
-	sudo -n parted --script "$vmImageFile" 'mkpart primary '"42"'MiB '"44"'MiB'
+	[[ ! -e "$1" ]] && sleep 3
+	[[ ! -e "$1" ]] && return 1

+	local absolute1
+	absolute1=$(_getAbsoluteLocation "$1")

-	# Boot
-	#sudo -n parted --script "$vmImageFile" 'mkpart primary '"98"'MiB '"610"'MiB'
-	#sudo -n parted --script "$vmImageFile" 'mkpart primary '"44"'MiB '"384"'MiB'
-	#sudo -n parted --script "$vmImageFile" 'mkpart primary '"44"'MiB '"592"'MiB'
-	sudo -n parted --script "$vmImageFile" 'mkpart primary '"44"'MiB '"770"'MiB'
+	[[ "$absolute1" == "" ]] && return 1
+	[[ "$absolute1" == "/" ]] && return 1
+	[[ ! -e "$absolute1" ]] && return 1

+	_bindMountManager "/dev" "$absolute1"/dev

-	# Root
-	# WARNING: Adjust vmSize to match +1MiB .
-	# Try to keep this <23841MiB-256MiB-1MiB ( ie. <23584MiB ) (exactly 25000000000Bytes is 23841MiB ) . In practice, compression will obviate this issue, and the Live ISO may be more complete (ie. including 'accessories') for recovery purposes .
-	# https://www.mail-archive.com/kde-bugs-dist@kde.org/msg618604.html
-	#  '25025315816 bytes'   ...   'difference between the available space at the start and at the end is exactly 256M'
-	# http://fy.chalmers.se/~appro/linux/DVD+RW/Blu-ray/
-	#  '256MB'
-	# https://forum.blu-ray.com/showthread.php?t=76407
-	# https://forum.imgburn.com/topic/23120-overburn-or-truncate-for-blu-rays/
-	# Try to keep this <23GiB-1MiB . Prefer to fit two copies within 46GiB ( eg. 23296MiB == 22.75GiB ) .
-	# Try to keep this <28GiB-1MiB . Prefer to fit at least 18GiB (compressed rootfs tar, squashfs, etc) plus this 28GiB .
-	# Expect 25.75GiB may suffice ( ie. 22.75GiB+5GiB-2GiB ) (assuming 22.75GiB may have been sufficient by ~5GiB until another ~5GiB was added, and from there ~2GiB may have already been freed by other changes) .
-	# Expect 27.75GiB may suffice ( ie. 22.75GiB+5GiB-2GiB ) (assuming 22.75GiB may have been sufficient by ~5GiB until another ~5GiB was added) .
-
-	# Tested successfully.
-	# 22.75GiB-1MiB
-	#sudo -n parted --script "$vmImageFile" 'mkpart primary '"610"'MiB '"23295"'MiB'
-
-	# 22.95GiB-1MiB
-	##sudo -n parted --script "$vmImageFile" 'mkpart primary '"384"'MiB '"23499"'MiB'
-
-	# 23841MiB-256MiB-1MiB -2MiB
-	#sudo -n parted --script "$vmImageFile" 'mkpart primary '"384"'MiB '"23582"'MiB'
-
-	# 25.95GiB-1MiB
-	#sudo -n parted --script "$vmImageFile" 'mkpart primary '"384"'MiB '"26571"'MiB'
-
-	# Tested successfully.
-	# 26.25GiB-1MiB
-	#sudo -n parted --script "$vmImageFile" 'mkpart primary '"384"'MiB '"26879"'MiB'
+	#_bindMountManager "/proc" "$absolute1"/proc
+	sudo -n mkdir -p "$absolute1"/proc
+	sudo -n mount -t proc none "$absolute1"/proc

+	_bindMountManager "/sys" "$absolute1"/sys

+	_bindMountManager "/dev/pts" "$absolute1"/dev/pts

-	#sudo -n parted --script "$vmImageFile" 'mkpart primary '"384"'MiB '"$vmSize_boundary"'MiB'
-	sudo -n parted --script "$vmImageFile" 'mkpart primary '"770"'MiB '"$vmSize_boundary"'MiB'
+	_bindMountManager "/tmp" "$absolute1"/tmp

-	sudo -n parted --script "$vmImageFile" 'unit MiB print'
+	#Provide an shm filesystem at /dev/shm.
+	sudo -n mkdir -p "$absolute1"/dev/shm
+	sudo -n mount -t tmpfs -o size=4G tmpfs "$absolute1"/dev/shm

+	#Install ubiquitous_bash itself to chroot.
+	sudo -n mkdir -p "$absolute1"/usr/local/bin/
+	sudo -n mkdir -p "$absolute1"/usr/local/share/ubcore/bin/

-	_close
+	sudo -n cp "$scriptAbsoluteLocation" "$absolute1"/usr/local/bin/ubiquitous_bash.sh
+	sudo -n chmod 0755 "$absolute1"/usr/local/bin/ubiquitous_bash.sh
+	sudo -n chown root:root "$absolute1"/usr/local/bin/ubiquitous_bash.sh

+	if [[ -e "$scriptAbsoluteFolder"/lean.sh ]]
+	then
+		sudo -n cp "$scriptAbsoluteFolder"/lean.sh "$absolute1"/usr/local/bin/lean.sh
+		sudo -n chmod 0755 "$absolute1"/usr/local/bin/lean.sh
+		sudo -n chown root:root "$absolute1"/usr/local/bin/lean.sh
+	fi

-	# Format partitions .
-	_messageNormal 'format: '"$vmImageFile"''
-	#"$scriptAbsoluteLocation" _loopImage_sequence || _stop 1
-	! "$scriptAbsoluteLocation" _openLoop && _messagePlain_bad 'fail: _openLoop' && _messageFAIL
+	sudo -n cp "$scriptBin"/gosu-armel "$absolute1"/usr/local/share/ubcore/bin/gosu-armel
+	sudo -n cp "$scriptBin"/gosu-amd64 "$absolute1"/usr/local/share/ubcore/bin/gosu-amd64
+	sudo -n cp "$scriptBin"/gosu-i386 "$absolute1"/usr/local/share/ubcore/bin/gosu-i386
+	sudo -n chmod 0755 "$absolute1"/usr/local/share/ubcore/bin/*
+	sudo -n chown root:root "$absolute1"/usr/local/share/ubcore/bin/*

-	mkdir -p "$globalVirtFS"
-	"$scriptAbsoluteLocation" _checkForMounts "$globalVirtFS" && _messagePlain_bad 'bad: mounted: globalVirtFS' && _messageFAIL && _stop 1
-	#local imagedev
-	imagedev=$(cat "$scriptLocal"/imagedev)
+	#Workaround NetworkManager stealing /etc/resolv.conf with broken symlink.
+	if ! _chroot test -f /etc/resolv.conf
+	then
+		sudo -n mv "$absolute1"/etc/resolv.conf "$absolute1"/etc/resolv.conf.bak > /dev/null 2>&1
+		sudo -n rm -f "$absolute1"/etc/resolv.conf > /dev/null 2>&1
+	fi

-	local imagepart
-	local loopdevfs

-	# Compression from btrfs may free up ~8GB . Some performance degradation may result if files with many random writes (eg. COW VM images) are used with btrfs .
-	# https://www.phoronix.com/scan.php?page=article&item=btrfs-zstd-compress&num=4
-	# https://btrfs.wiki.kernel.org/index.php/Compression
-	# https://unix.stackexchange.com/questions/394973/why-would-i-want-to-disable-copy-on-write-while-creating-qemu-images
-	# https://gist.github.com/niflostancu/03810a8167edc533b1712551d4f90a14
+	if [[ -e "$absolute1"/etc/resolv.conf ]] && [[ ! -e "$absolute1"/etc/resolv.conf.host ]] && [[ -e /etc/resolv.conf ]]
+	then
+		sudo -n cp --no-clobber "$absolute1"/etc/resolv.conf "$absolute1"/etc/resolv.conf.guest.bak
+		sudo -n mv -n "$absolute1"/etc/resolv.conf "$absolute1"/etc/resolv.conf.guest
+
+		#if [[ ! -e "$absolute1"/etc/resolv.conf.host ]]
+		#then
+			sudo -n cp --no-clobber -L /etc/resolv.conf "$absolute1"/etc/resolv.conf.host
+			#sudo -n cat /etc/resolv.conf | sudo tee "$absolute1"/etc/resolv.conf.host > /dev/null 2>&1
+		#fi
+
+		sudo -n mv -f "$absolute1"/etc/resolv.conf.host "$absolute1"/etc/resolv.conf
+	fi

-	# WARNING: Compression/btrfs of boot partition may cause BIOS compatibility issues.
-	imagepart="$imagedev""$ubVirtImageBoot"
-	loopdevfs=$(sudo -n blkid -s TYPE -o value "$imagepart" | tr -dc 'a-zA-Z0-9')
-	[[ "$loopdevfs" == "ext4" ]] && _stop 1
-	sudo -n mkfs.ext2 -e remount-ro -E lazy_itable_init=0,lazy_journal_init=0 -m 0 "$imagepart" || _stop 1
-	#sudo -n mkfs.btrfs --checksum xxhash -M -d single "$imagepart" || _stop 1
+	if ! grep '8\.8\.8\.8' "$absolute1"/etc/resolv.conf > /dev/null 2>&1
+	then
+		echo 'nameserver 8.8.8.8' | sudo -n tee -a "$absolute1"/etc/resolv.conf > /dev/null 2>&1
+	fi

-	imagepart="$imagedev""$ubVirtImageEFI"
-	loopdevfs=$(sudo -n blkid -s TYPE -o value "$imagepart" | tr -dc 'a-zA-Z0-9')
-	[[ "$loopdevfs" == "ext4" ]] && _stop 1
-	sudo -n mkfs.vfat -F 32 -n EFI "$imagepart" || _stop 1
+	if ! grep '2001\:4860\:4860\:\:8888' "$absolute1"/etc/resolv.conf > /dev/null 2>&1
+	then
+		echo 'nameserver 2001:4860:4860::8888' | sudo -n tee -a "$absolute1"/etc/resolv.conf > /dev/null 2>&1
+	fi

-	imagepart="$imagedev""$ubVirtImagePartition"
-	loopdevfs=$(sudo -n blkid -s TYPE -o value "$imagepart" | tr -dc 'a-zA-Z0-9')
-	[[ "$loopdevfs" == "ext4" ]] && _stop 1
-	#sudo -n mkfs.ext4 -e remount-ro -E lazy_itable_init=0,lazy_journal_init=0 -m 0 "$imagepart" || _stop 1
-	sudo -n mkfs.btrfs --checksum xxhash -M -d single "$imagepart" || _stop 1

-	imagepart="$imagedev""$ubVirtImageSwap"
-	loopdevfs=$(sudo -n blkid -s TYPE -o value "$imagepart" | tr -dc 'a-zA-Z0-9')
-	[[ "$loopdevfs" == "ext4" ]] && _stop 1
-	sudo -n mkswap "$imagepart" || _stop 1
+	if ! grep 'deleteme_chrootHost_hostname' "$absolute1"/etc/resolv.conf > /dev/null 2>&1
+	then
+		echo '127.0.0.1 '"$HOSTNAME"' deleteme_chrootHost_hostname' | sudo -n tee -a "$absolute1"/etc/hosts > /dev/null 2>&1
+	fi
+
+
+	if _set_ingredients
+	then
+		sudo -n mkdir -p "$absolute1"/mnt/ingredients
+		_bindMountManager "$ub_INGREDIENTS" "$absolute1"/mnt/ingredients
+	fi

-	#"$scriptAbsoluteLocation" _umountImage || _stop 1
-	! "$scriptAbsoluteLocation" _closeLoop && _messagePlain_bad 'fail: _closeLoop' && _messageFAIL
 	return 0
 }
-# WARNING: No production use. No use as-is. Hybrid/UEFI is default.
-# WARNING: May necessitate 'update-grub' within 'qemu' or similar to remove incorrecly detected running kernel from menu.
-_convertVMimage_sequence() {
-	_messageNormal '_convertVMimage_sequence'
-
-	_messagePlain_nominal '_convertVMimage_sequence: start'
-	_start
-	mkdir -p "$safeTmp"/rootfs
-
-	local imagedev
+
+#"$1" == ChRoot Dir
+_umountChRoot() {
+	_mustGetSudo

+	[[ ! -e "$1" ]] && return 1

-	# ATTENTION: Override if necessary (ie. with 'ops.sh' from an existing image).
-	export ubVirtImage_doNotOverride="true"
-	export ubVirtPlatformOverride='x64-efi'
-	export ubVirtImageBIOS=p1
-	export ubVirtImageEFI=p2
-	export ubVirtImageNTFS=
-	export ubVirtImageRecovery=
-	export ubVirtImageSwap=p3
-	export ubVirtImageBoot=p4
-	export ubVirtImagePartition=p5
+	local absolute1
+	absolute1=$(_getAbsoluteLocation "$1")

+	#_set_ingredients &&
+	mountpoint "$absolute1"/mnt/ingredients > /dev/null 2>&1 && _wait_umount "$absolute1"/mnt/ingredients

-	_messagePlain_nominal '_convertVMimage_sequence: copy: out'
-	! "$scriptAbsoluteLocation" _openImage && _messagePlain_bad 'fail: _openImage' && _messageFAIL
-	imagedev=$(cat "$scriptLocal"/imagedev)
-	if [[ "$ubVirtImageBoot" != "" ]]
+	# && [[ -e "$absolute1"/etc/resolv.conf ]]
+	if [[ -e "$absolute1"/etc/resolv.conf.guest ]] && [[ ! -e "$absolute1"/etc/resolv.conf.host ]]
 	then
-		sudo -n mkdir -p "$globalVirtFS"/boot
-		sudo -n mount "$imagedev""$ubVirtImageBoot" "$globalVirtFS"/boot
+		sudo -n mv -f "$absolute1"/etc/resolv.conf.guest "$absolute1"/etc/resolv.conf
 	fi
-	if [[ "$ubVirtImageEFI" != "" ]]
+
+
+	if grep 'deleteme_chrootHost_hostname' "$absolute1"/etc/resolv.conf > /dev/null 2>&1
 	then
-		sudo -n mkdir -p "$globalVirtFS"/boot/efi
-		sudo -n mount "$imagedev""$ubVirtImageEFI" "$globalVirtFS"/boot/efi
+		sudo -n grep -v 'deleteme_chrootHost_hostname' "$absolute1"/etc/hosts | sudo -n tee "$absolute1"/etc/hosts.guest > /dev/null 2>&1
+		sudo -n mv -f "$absolute1"/etc/hosts.guest "$absolute1"/etc/hosts
 	fi

+	_wait_umount "$absolute1"/home/"$virtGuestUser"/project >/dev/null 2>&1
+	_wait_umount "$absolute1"/home/"$virtGuestUser" >/dev/null 2>&1
+	_wait_umount "$absolute1"/root/project >/dev/null 2>&1
+	_wait_umount "$absolute1"/root >/dev/null 2>&1

-	sudo -n rsync -ax "$globalVirtFS"/. "$safeTmp"/rootfs/.
-	[[ "$?" != "0" ]] && _messageFAIL
+	_wait_umount "$absolute1"/dev/shm
+	_wait_umount "$absolute1"/dev/pts

-	sudo -n rsync -ax "$globalVirtFS"/boot/. "$safeTmp"/rootfs/boot/.
-	[[ "$?" != "0" ]] && _messageFAIL
-	sudo -n rsync -ax "$globalVirtFS"/boot/efi/. "$safeTmp"/rootfs/boot/efi/.
-	[[ "$?" != "0" ]] && _messageFAIL

+	if [[ -e "$absolute1"/proc/sys/fs/binfmt_misc ]] && mountpoint "$absolute1"/proc/sys/fs/binfmt_misc > /dev/null 2>&1
+	then
+		_wait_umount "$absolute1"/proc/sys/fs/binfmt_misc
+	fi

-	sudo -n umount "$globalVirtFS"/boot/efi > /dev/null 2>&1
-	sudo -n umount "$globalVirtFS"/boot > /dev/null 2>&1
-	! "$scriptAbsoluteLocation" _closeImage && _messagePlain_bad 'fail: _closeImage' && _messageFAIL

+	sudo -n umount "$absolute1"/proc
+	_wait_umount "$absolute1"/sys

-	rm -f "$scriptLocal"/vm.img
-	_createVMimage
-	export ubVirtImage_doNotOverride="true"
+	_wait_umount "$absolute1"/tmp

+	_wait_umount "$absolute1"/dev

-	_messagePlain_nominal '_convertVMimage_sequence: copy: in'
-	! "$scriptAbsoluteLocation" _openImage && _messagePlain_bad 'fail: _openImage' && _messageFAIL
-	imagedev=$(cat "$scriptLocal"/imagedev)
-	if [[ "$ubVirtImageBoot" != "" ]]
-	then
-		sudo -n mkdir -p "$globalVirtFS"/boot
-		sudo -n mount "$imagedev""$ubVirtImageBoot" "$globalVirtFS"/boot
-	fi
-	if [[ "$ubVirtImageEFI" != "" ]]
+	if mountpoint "$absolute1"/proc > /dev/null 2>&1
 	then
-		sudo -n mkdir -p "$globalVirtFS"/boot/efi
-		sudo -n mount "$imagedev""$ubVirtImageEFI" "$globalVirtFS"/boot/efi
+		sleep 6
+		if mountpoint "$absolute1"/proc > /dev/null 2>&1
+		then
+			sudo -n umount "$absolute1"/proc
+			if mountpoint "$absolute1"/proc > /dev/null 2>&1
+			then
+				sleep 6
+				if mountpoint "$absolute1"/proc > /dev/null 2>&1
+				then
+					sudo -n umount "$absolute1"/proc
+
+					sleep 1
+					mountpoint "$absolute1"/proc > /dev/null 2>&1 && _wait_umount "$absolute1"/proc
+				fi
+			fi
+		fi
 	fi

+	# Full umount of chroot directory may be done by standard '_umountImage'.
+	#_wait_umount "$absolute1" >/dev/null 2>&1
+}
+
+_readyChRoot() {

-	sudo -n rsync -ax "$safeTmp"/rootfs/. "$globalVirtFS"/.
-	[[ "$?" != "0" ]] && _messageFAIL
-
-	sudo -n rsync -ax "$safeTmp"/rootfs/boot/. "$globalVirtFS"/boot/.
-	[[ "$?" != "0" ]] && _messageFAIL
-	sudo -n rsync -ax "$safeTmp"/rootfs/boot/efi/. "$globalVirtFS"/boot/efi/.
-	[[ "$?" != "0" ]] && _messageFAIL
+	local absolute1
+	absolute1=$(_getAbsoluteLocation "$1")

+	#mountpoint "$absolute1" > /dev/null 2>&1 || return 1

-	sudo -n umount "$globalVirtFS"/boot/efi > /dev/null 2>&1
-	sudo -n umount "$globalVirtFS"/boot > /dev/null 2>&1
-	! "$scriptAbsoluteLocation" _closeImage && _messagePlain_bad 'fail: _closeImage' && _messageFAIL
+	mountpoint "$absolute1"/dev > /dev/null 2>&1 || return 1
+	mountpoint "$absolute1"/proc > /dev/null 2>&1 || return 1
+	mountpoint "$absolute1"/sys > /dev/null 2>&1 || return 1

+	mountpoint "$absolute1"/dev/pts > /dev/null 2>&1 || return 1

+	mountpoint "$absolute1"/tmp > /dev/null 2>&1 || return 1

-	_createVMbootloader-bios
-	_createVMbootloader-efi
+	mountpoint "$absolute1"/dev/shm > /dev/null 2>&1 || return 1

+	return 0

-	_messagePlain_nominal '_convertVMimage_sequence: stop'
-	export safeToDeleteGit="true"
-	if ! _safePath "$safeTmp"/rootfs
-	then
-		_stop 1
-		exit 1
-		return 1
-	fi
-	#sudo -n rm -rf "$safeTmp"/rootfs
-	sudo -n chown -R "$USER":"$USER" "$safeTmp"/rootfs
-	sudo -n chmod -R 700 "$safeTmp"/rootfs
-	_safeRMR "$safeTmp"/rootfs
-	_stop
-}
-_convertVMimage() {
-	"$scriptAbsoluteLocation" _convertVMimage_sequence "$@"
-}
-
-
-# Creates a raw VM image. UEFI partitioning and formatting (expected possibility of eventual MSW dual-boot compatibility).
-_createVMimage-efi() {
-	false
 }

-
-# Creates a raw VM image. BIOS partitioning and formatting (legacy compatibility, possibly with some cloud providers).
-_createVMimage-bios() {
-	false
+# ATTENTION: Override with "core.sh" or similar.
+# WARNING: Must return true to complete mount/umount procedure.
+_mountChRoot_image_raspbian_prog() {
+	true
+
+	#local current_imagedev
+	#current_imagedev=$(cat "$scriptLocal"/imagedev)
+
+	#mkdir -p "$globalVirtFS"/../boot
+	#sudo -n mount "$current_imagedev"p1 "$globalVirtFS"/../boot
+
+	return 0
 }

-
-
-
-
-_createVMbootloader-bios() {
-	_messageNormal '##### _createVMbootloader-bios'
+_mountChRoot_image_raspbian() {
+	_mustGetSudo

-	! "$scriptAbsoluteLocation" _openChRoot && _messagePlain_bad 'fail: _openChRoot' && _messageFAIL
-	local imagedev
-	imagedev=$(cat "$scriptLocal"/imagedev)
+	_start

-	_createVMfstab
+	mkdir -p "$chrootDir"

+	"$scriptAbsoluteLocation" _checkForMounts "$chrootDir" && _stop 1

-	_messagePlain_nominal 'chroot: grub-install: bios'

-	# WARNING: Apparently, any use of BIOS bootloader either needs at least a 'BIOS boot partition' to share with EFI, or needs a dedicated '/boot' for 'btrfs' compression.
-	# https://bbs.archlinux.org/viewtopic.php?id=251059
-	#  'btrfs' 'zstd compression' 'properly installing the bootloader to a dedicated partitioning designed and maintained for that purpose'
-	# https://unix.stackexchange.com/questions/273329/can-i-install-grub2-on-a-flash-drive-to-boot-both-bios-and-uefi
-	#  'precondition for this to work is that you use GPT partitioning and that you have an BIOS boot partition (1 MiB is enough).'
-	# https://en.wikipedia.org/wiki/BIOS_boot_partition
-	#_chroot grub2-install --modules=part_msdos --target=i386-pc "$imagedev"
+	! _mountImage "$chrootDir" && _stop 1


-	_messagePlain_probe_cmd _chroot grub-install --modules=part_msdos --target=i386-pc "$imagedev"
-	_messagePlain_probe_cmd _chroot grub-install --force --modules=part_msdos --target=i386-pc "$imagedev""$ubVirtImageEFI"

+	_mountChRoot "$chrootDir"

-	_messagePlain_nominal 'chroot: update-grub'
-	_chroot update-grub
+	_readyChRoot "$chrootDir" || _stop 1

-	_messagePlain_nominal 'chroot: update-initramfs'
-	_chroot update-initramfs -u
+	sudo -n cp /usr/bin/qemu-arm-static "$chrootDir"/usr/bin/
+	sudo -n cp /usr/bin/qemu-armeb-static "$chrootDir"/usr/bin/
+
+	sudo -n cp --no-clobber "$chrootDir"/etc/ld.so.preload "$chrootDir"/etc/ld.so.preload.orig
+	echo | sudo -n tee "$chrootDir"/etc/ld.so.preload > /dev/null 2>&1


+	local chrootimagedev
+	chrootimagedev=$(cat "$scriptLocal"/imagedev)
+	! _mountChRoot_image_raspbian_prog "$chrootimagedev" && _stop 1


-	! "$scriptAbsoluteLocation" _closeChRoot && _messagePlain_bad 'fail: _closeChRoot' && _messageFAIL
 	return 0
 }

-_createVMbootloader-efi() {
-	_messageNormal '##### _createVMbootloader-efi'
+_umountChRoot_directory_raspbian() {

-	! "$scriptAbsoluteLocation" _openChRoot && _messagePlain_bad 'fail: _openChRoot' && _messageFAIL
-	local imagedev
-	imagedev=$(cat "$scriptLocal"/imagedev)
-
-	_createVMfstab
-
-
-	_messagePlain_nominal 'chroot: grub-install: efi'
-
-	# https://unix.stackexchange.com/questions/273329/can-i-install-grub2-on-a-flash-drive-to-boot-both-bios-and-uefi
-	#  'precondition for this to work is that you use GPT partitioning and that you have an BIOS boot partition (1 MiB is enough).'
-	# https://en.wikipedia.org/wiki/BIOS_boot_partition
-	# https://askubuntu.com/questions/705055/gpt-detected-please-create-a-bios-boot-partition
-	#  'must be located at the start of a GPT disk, and have a "bios_grub" flag' 'Size: 1MB.'
-	#_chroot grub2-install --modules=part_msdos --target=i386-pc "$imagedev"
+	_mustGetSudo

+	mkdir -p "$chrootDir"

-	_messagePlain_probe_cmd _chroot grub-install --boot-directory=/boot --root-directory=/ --modules=part_msdos --target=x86_64-efi --efi-directory=/boot/efi --bootloader-id=debian --recheck --no-nvram --removable "$imagedev"
-	_messagePlain_probe_cmd _chroot grub-install --boot-directory=/boot --root-directory=/ --modules=part_msdos --target=x86_64-efi --efi-directory=/boot/efi --bootloader-id=debian --recheck --no-nvram --removable "$imagedev""$ubVirtImageEFI"
+	sudo -n cp "$chrootDir"/etc/ld.so.preload.orig "$chrootDir"/etc/ld.so.preload

-	_messagePlain_probe_cmd _chroot grub-install --boot-directory=/boot --root-directory=/ --modules=part_msdos --target=x86_64-efi --efi-directory=/boot/efi --recheck "$imagedev"
+}
+
+_mountChRoot_image_x64_efi() {
+	[[ "$ubVirtPlatform" != "x64-efi" ]] && return 1
+	[[ "$ubVirtImageEFI" == "" ]] && return 1

-	#sudo -n mkdir -p "$globalVirtFS"/boot/efi/EFI/BOOT/
-	#sudo -n cp "$globalVirtFS"/boot/efi/EFI/debian/grubx64.efi "$globalVirtFS"/boot/efi/EFI/BOOT/bootx64.efi
+	local current_imagedev
+	current_imagedev=$(cat "$scriptLocal"/imagedev)

+	_determine_rawFileRootPartition "$current_imagedev" > /dev/null 2>&1

-	_messagePlain_nominal 'chroot: update-grub'
-	_chroot update-grub
+	local loopdevfs
+	loopdevfs=$(sudo -n blkid -s TYPE -o value "$current_imagedev""$ubVirtImageEFI" | tr -dc 'a-zA-Z0-9')

-	_messagePlain_nominal 'chroot: update-initramfs'
-	_chroot update-initramfs -u
+	! [[ "$loopdevfs" == "vfat" ]] && _stop 1


+	sudo -n mkdir -p "$globalVirtFS"/boot/efi

+	sudo -n mount "$current_imagedev""$ubVirtImageEFI" "$globalVirtFS"/boot/efi

-	! "$scriptAbsoluteLocation" _closeChRoot && _messagePlain_bad 'fail: _closeChRoot' && _messageFAIL
 	return 0
 }

-
-
-
-
-
-
-
-_createVMfstab() {
-	_messageNormal 'os: globalVirtFS: write: fs: _createVMfstab'
-
-
-	local imagedev
-	imagedev=$(cat "$scriptLocal"/imagedev)
-
-	[[ ! -e "$imagedev" ]] && _messageFAIL
-
-	sudo -n mkdir -p "$globalVirtFS"/media/bootdisc
-	sudo -n chmod 755 "$globalVirtFS"/media/bootdisc
-
-
-	# https://gist.github.com/varqox/42e213b6b2dde2b636ef#edit-fstab-file
-
-	#btrfs rescue zero-log /dev/sda5
-
-	local ubVirtImagePartition_UUID
-	ubVirtImagePartition_UUID=$(sudo -n blkid -s UUID -o value "$imagedev""$ubVirtImagePartition" | tr -dc 'a-zA-Z0-9\-')
-
-	#echo 'UUID='"$ubVirtImagePartition_UUID"' / ext4 errors=remount-ro 0 1' | sudo -n tee "$globalVirtFS"/etc/fstab
-	#echo 'UUID='"$ubVirtImagePartition_UUID"' / btrfs defaults,compress=zstd:1,notreelog 0 1' | sudo -n tee "$globalVirtFS"/etc/fstab
-	echo 'UUID='"$ubVirtImagePartition_UUID"' / btrfs defaults,compress=zstd:1,notreelog,discard=async 0 1' | sudo -n tee "$globalVirtFS"/etc/fstab
-
-
-	# initramfs-update, from chroot, may not enable hibernation/resume... may be device specific
-
-	if [[ "$ubVirtImageSwap" != "" ]]
-	then
-		local ubVirtImageSwap_UUID
-		ubVirtImageSwap_UUID=$(sudo -n blkid -s UUID -o value "$imagedev""$ubVirtImageSwap" | tr -dc 'a-zA-Z0-9\-')
-	fi
+# ATTENTION: Override with "core.sh" or similar.
+# WARNING: Must return true to complete mount/umount procedure.
+# By default attempts to mount EFI partition as specified by "$current_imagedev""$ubVirtImageEFI" .
+_mountChRoot_image_x64_prog() {
+	true

-	echo '#UUID='"$ubVirtImageSwap_UUID"' swap swap defaults 0 0' | sudo -n tee -a "$globalVirtFS"/etc/fstab
+	#export ubVirtPlatformOverride='x64-efi'
+	#export ubVirtImageBIOS=p1
+	#export ubVirtImageEFI=p2
+	#export ubVirtImageNTFS=
+	#export ubVirtImageRecovery=
+	#export ubVirtImageSwap=p3
+	#export ubVirtImageBoot=p4
+	#export ubVirtImagePartition=p5

+	local current_imagedev
+	current_imagedev=$(cat "$scriptLocal"/imagedev)

 	if [[ "$ubVirtImageBoot" != "" ]]
 	then
-		local ubVirtImageBoot_UUID
-		ubVirtImageBoot_UUID=$(sudo -n blkid -s UUID -o value "$imagedev""$ubVirtImageBoot" | tr -dc 'a-zA-Z0-9\-')
-	fi
-
-	echo 'UUID='"$ubVirtImageBoot_UUID"' /boot ext2 defaults 0 1' | sudo -n tee -a "$globalVirtFS"/etc/fstab
-
-
-	if [[ "$ubVirtImageEFI" != "" ]]
-	then
-		local ubVirtImageEFI_UUID
-		ubVirtImageEFI_UUID=$(sudo -n blkid -s UUID -o value "$imagedev""$ubVirtImageEFI" | tr -dc 'a-zA-Z0-9\-')
+		sudo -n mkdir -p "$globalVirtFS"/boot
+		if ! sudo -n mount "$current_imagedev""$ubVirtImageBoot" "$globalVirtFS"/boot
+		then
+			_stop 1
+		fi
 	fi

-	echo 'UUID='"$ubVirtImageEFI_UUID"' /boot/efi vfat umask=0077 0 1' | sudo -n tee -a "$globalVirtFS"/etc/fstab
-

-	if ! sudo -n cat "$globalVirtFS"/etc/fstab | grep 'uk4uPhB663kVcygT0q' | grep 'bootdisc' > /dev/null 2>&1
+	if [[ "$ubVirtPlatform" == "x64-efi" ]]
 	then
-		echo 'LABEL=uk4uPhB663kVcygT0q /media/bootdisc iso9660 ro,nofail 0 0' | sudo -n tee -a "$globalVirtFS"/etc/fstab
+		_mountChRoot_image_x64_efi "$@"
+		return
 	fi

-	# WARNING: May be untested.
-	echo '' | sudo -n tee -a "$globalVirtFS"/etc/fstab
-	echo '#none /var/spool/cups ramfs defaults,uid=0,gid=7,umask=007,dmask=007,fmask=117,size=800M 0 0' | sudo -n tee -a "$globalVirtFS"/etc/fstab
-	echo '#none /var/cache/cups ramfs defaults,uid=0,gid=7,umask=007,dmask=000,fmask=007,size=800M 0 0' | sudo -n tee -a "$globalVirtFS"/etc/fstab
-	echo '' | sudo -n tee -a "$globalVirtFS"/etc/fstab
-
 	return 0
 }

-
-
-
-
-
-
-
-_vm_convert_vdi() {
-	_messagePlain_nominal '_vm_convert_vdi: convert: vdi'
+# ATTENTION: Mounts image containing only root partiton.
+_mountChRoot_image_x64() {
+	_mustGetSudo

-	_override_bin_vbox
+	_start

-	# ATTENTION: Delete 'vm.vdi.uuid' to force generation of new uuid .
-	local current_UUID
-	current_UUID=$(head -n1 "$scriptLocal"/vm.vdi.uuid 2>/dev/null | tr -dc 'a-zA-Z0-9\-')
+	mkdir -p "$chrootDir"

-	if [[ $(echo "$current_UUID" | wc -c) != 37 ]]
-	then
-		current_UUID=$(_getUUID)
-		rm -f "$scriptLocal"/vm.vdi.uuid > /dev/null 2>&1
-		echo "$current_UUID" > "$scriptLocal"/vm.vdi.uuid
-	fi
+	"$scriptAbsoluteLocation" _checkForMounts "$chrootDir" && _stop 1


-	rm -f "$scriptLocal"/vm.vdi > /dev/null 2>&1
+	! _mountImage "$chrootDir" && _stop 1

-	! [[ -e "$scriptLocal"/vm.img ]] && _messagePlain_bad 'fail: missing: in file' && return 1
-	[[ -e "$scriptLocal"/vm.vdi ]] && _messagePlain_request 'request: rm '"$scriptLocal"/vm.vdi && return 1

-	_messagePlain_nominal '_img_to_vdi: convertdd'
-	if _userVBoxManage convertdd "$scriptLocal"/vm.img "$scriptLocal"/vm-c.vdi --format VDI
-	then
-		#_messagePlain_nominal '_img_to_vdi: closemedium'
-		#_userVBoxManage closemedium "$scriptLocal"/vm-c.vdi
-		_messagePlain_nominal '_img_to_vdi: mv vm-c.vdi vm.vdi'
-		_moveconfirm "$scriptLocal"/vm-c.vdi "$scriptLocal"/vm.vdi
-		_messagePlain_nominal '_img_to_vdi: setuuid'
-		VBoxManage internalcommands sethduuid "$scriptLocal"/vm.vdi "$current_UUID"
-		#_messagePlain_request 'request: rm '"$scriptLocal"/vm.img
-		_messagePlain_good 'End.'
-		return 0
-	else
-		_messageFAIL
-		_stop 1
-	fi
-}
-
-_vm_convert_vmdk() {
-	_messagePlain_nominal '_vm_convert_vmdk: convert: vmdk'

-	_override_bin_vbox
+	_mountChRoot "$chrootDir"

-	# ATTENTION: Delete 'vm.vmdk.uuid' to force generation of new uuid .
-	local current_UUID
-	current_UUID=$(head -n1 "$scriptLocal"/vm.vmdk.uuid 2>/dev/null | tr -dc 'a-zA-Z0-9\-')
+	_readyChRoot "$chrootDir" || _stop 1

-	if [[ $(echo "$current_UUID" | wc -c) != 37 ]]
-	then
-		current_UUID=$(_getUUID)
-		rm -f "$scriptLocal"/vm.vmdk.uuid > /dev/null 2>&1
-		echo "$current_UUID" > "$scriptLocal"/vm.vmdk.uuid
-	fi

+	local chrootimagedev
+	chrootimagedev=$(cat "$scriptLocal"/imagedev)
+	! _mountChRoot_image_x64_prog "$chrootimagedev" && _stop 1

-	rm -f "$scriptLocal"/vm.vmdk > /dev/null 2>&1
+	return 0
+}
+
+_umountChRoot_directory_x64() {
+	_mustGetSudo

-	! [[ -e "$scriptLocal"/vm.img ]] && _messagePlain_bad 'fail: missing: in file' && return 1
-	[[ -e "$scriptLocal"/vm.vmdk ]] && _messagePlain_request 'request: rm '"$scriptLocal"/vm.vmdk && return 1
+	mkdir -p "$chrootDir"
+}
+
+_mountChRoot_image() {
+	_tryExecFull _hook_systemd_shutdown_action "_closeChRoot_emergency" "$sessionid"

-	_messagePlain_nominal '_img_to_vmdk: convertdd'
+	# Include platform determination code for correct determination of partition and mounts.
+	_loopImage_imagefilename > /dev/null 2>&1

+	if [[ "$ubVirtPlatform" == "raspbian" ]]
+	then
+		_mountChRoot_image_raspbian
+		return "$?"
+	fi

-	# https://stackoverflow.com/questions/454899/how-to-convert-flat-raw-disk-image-to-vmdk-for-virtualbox-or-vmplayer
-	if _userVBoxManage convertdd "$scriptLocal"/vm.img "$scriptLocal"/vm-c.vmdk --format VMDK
-	#if qemu-img convert -O vmdk "$scriptLocal"/vm.img "$scriptLocal"/vm-c.vmdk
+	if [[ "$ubVirtPlatform" == "x64"* ]]
 	then
-		#_messagePlain_nominal '_img_to_vmdk: closemedium'
-		#_userVBoxManage closemedium "$scriptLocal"/vm-c.vmdk
-		_messagePlain_nominal '_img_to_vmdk: mv vm-c.vmdk vm.vmdk'
-		_moveconfirm "$scriptLocal"/vm-c.vmdk "$scriptLocal"/vm.vmdk
-		_messagePlain_nominal '_img_to_vmdk: setuuid'
-
-
-		#VBoxManage internalcommands sethduuid "$scriptLocal"/vm.vmdk "$current_UUID"
-		VBoxManage internalcommands sethduuid "$scriptLocal"/vm.vmdk "$current_UUID"
-
-
-		#_messagePlain_request 'request: rm '"$scriptLocal"/vm.img
-		_messagePlain_good 'End.'
-		return 0
-	else
-		_messageFAIL
-		_stop 1
+		_mountChRoot_image_x64
+		return "$?"
 	fi
+
+	#Default x64 .
+	"$scriptAbsoluteLocation" _mountChRoot_image_x64
+	return "$?"
 }

-
-_vm_convert_vhd() {
-	_messagePlain_nominal '_vm_convert_vhd: convert: vhd'
-
-	_override_bin_vbox
-
-	# ATTENTION: Delete 'vm.vhd.uuid' to force generation of new uuid .
-	local current_UUID
-	current_UUID=$(head -n1 "$scriptLocal"/vm.vhd.uuid 2>/dev/null | tr -dc 'a-zA-Z0-9\-')
+_umountChRoot_directory_platform() {
+	# Include platform determination code for correct determination of partition and mounts.
+	_loopImage_imagefilename > /dev/null 2>&1

-	if [[ $(echo "$current_UUID" | wc -c) != 37 ]]
+	if [[ "$ubVirtPlatform" == "raspbian" ]]
 	then
-		current_UUID=$(_getUUID)
-		rm -f "$scriptLocal"/vm.vhd.uuid > /dev/null 2>&1
-		echo "$current_UUID" > "$scriptLocal"/vm.vhd.uuid
+		"$scriptAbsoluteLocation" _umountChRoot_directory_raspbian
+		return "$?"
 	fi

-
-	rm -f "$scriptLocal"/vm.vhd > /dev/null 2>&1
-
-	! [[ -e "$scriptLocal"/vm.img ]] && _messagePlain_bad 'fail: missing: in file' && return 1
-	[[ -e "$scriptLocal"/vm.vhd ]] && _messagePlain_request 'request: rm '"$scriptLocal"/vm.vhd && return 1
-
-	_messagePlain_nominal '_img_to_vhd: convertdd'
-	if _userVBoxManage convertdd "$scriptLocal"/vm.img "$scriptLocal"/vm-c.vhd --format VHD
+	if [[ "$ubVirtPlatform" == "x64"* ]]
 	then
-		#_messagePlain_nominal '_img_to_vhd: closemedium'
-		#_userVBoxManage closemedium "$scriptLocal"/vm-c.vhd
-		_messagePlain_nominal '_img_to_vhd: mv vm-c.vhd vm.vhd'
-		_moveconfirm "$scriptLocal"/vm-c.vhd "$scriptLocal"/vm.vhd
-		_messagePlain_nominal '_img_to_vhd: setuuid'
-		VBoxManage internalcommands sethduuid "$scriptLocal"/vm.vhd "$current_UUID"
-		#_messagePlain_request 'request: rm '"$scriptLocal"/vm.img
-		_messagePlain_good 'End.'
-		return 0
-	else
-		_messageFAIL
-		_stop 1
+		"$scriptAbsoluteLocation" _umountChRoot_directory_x64
+		return "$?"
 	fi
-}
-
-
-
-
-
-
-
-
-_test_live_debianpackages() {
-	! dpkg-query -W grub-pc-bin > /dev/null 2>&1 && echo 'warn: missing: grub-pc-bin'
-	! dpkg-query -W grub-efi-amd64-bin > /dev/null 2>&1 && echo 'warn: missing: grub-efi-amd64-bin'

-	return 0
+	#Default "vm.img" will be operated on as x64 image.
+	"$scriptAbsoluteLocation" _umountChRoot_directory_x64
+	return "$?"
 }

-_test_live() {
-	_getDep debootstrap
-	#_getDep squashfs-tools
-	_getDep xorriso
-	#_getDep grub-pc-bin
-	#_getDep grub-efi-amd64-bin
-	_getDep mtools
+_umountChRoot_directory() {
+	! _umountChRoot_directory_platform && return 1

+	_stopChRoot "$1"
+	_umountChRoot "$1"

-	_getDep mksquashfs
-	_getDep grub-mkstandalone
+	# Full umount of chroot directory may be done by standard '_umountImage'.
+	#mountpoint "$1" > /dev/null 2>&1 && sudo -n umount "$1"
+	#"$scriptAbsoluteLocation" _checkForMounts "$1" && return 1

-	_getDep mkfs.vfat
+	return 0
+}
+
+# ATTENTION: Override with "core.sh" or similar.
+# WARNING: Must return true to complete mount/umount procedure.
+_umountChRoot_image_prog() {
+	true

-	_getDep mkswap
+	#[[ -d "$globalVirtFS"/../boot ]] && mountpoint "$globalVirtFS"/../boot >/dev/null 2>&1 && sudo -n umount "$globalVirtFS"/../boot >/dev/null 2>&1

+	#[[ -d "$globalVirtFS"/boot/efi ]] && mountpoint "$globalVirtFS"/boot/efi >/dev/null 2>&1 && sudo -n umount "$globalVirtFS"/boot/efi >/dev/null 2>&1
+	#[[ -d "$globalVirtFS"/boot ]] && mountpoint "$globalVirtFS"/boot >/dev/null 2>&1 && sudo -n umount "$globalVirtFS"/boot >/dev/null 2>&1
+}
+
+_umountChRoot_image() {
+	_mustGetSudo || return 1

-	_getDep mmd
-	_getDep mcopy
+	# x64-efi (typical)
+	[[ -d "$globalVirtFS"/boot/efi ]] && mountpoint "$globalVirtFS"/boot/efi >/dev/null 2>&1 && sudo -n umount "$globalVirtFS"/boot/efi >/dev/null 2>&1
+	[[ -d "$globalVirtFS"/boot ]] && mountpoint "$globalVirtFS"/boot >/dev/null 2>&1 && sudo -n umount "$globalVirtFS"/boot >/dev/null 2>&1


-	_getDep grub/i386-pc/cdboot.img
-	_getDep grub/i386-pc/boot_hybrid.img
+	! _umountChRoot_directory "$chrootDir" && return 1

+	! _umountChRoot_image_prog && return 1

-	[[ -e '/sbin/fdisk' ]] && _getDep fdisk
-	[[ -e '/sbin/sfdisk' ]] && _getDep sfdisk
+	# raspbian (typical)
+	[[ -d "$globalVirtFS"/../boot ]] && mountpoint "$globalVirtFS"/../boot >/dev/null 2>&1 && sudo -n umount "$globalVirtFS"/../boot >/dev/null 2>&1

+	_umountImage "$chrootDir"

-	# Currently only Debian is supported as a build host.
-	_test_live_debianpackages


-	#_getDep VBoxManage
-	_getDep qemu-img
+	rm -f "$permaLog"/gsysd.log > /dev/null 2>&1

 	return 0
 }

+_waitChRoot_opening() {
+	_readyChRoot "$chrootDir" && return 0
+	sleep 1
+	_readyChRoot "$chrootDir" && return 0
+	sleep 3
+	_readyChRoot "$chrootDir" && return 0
+	sleep 9
+	_readyChRoot "$chrootDir" && return 0
+	sleep 27
+	_readyChRoot "$chrootDir" && return 0
+	sleep 81
+	_readyChRoot "$chrootDir" && return 0
+
+	return 1
+}

+_waitChRoot_closing() {
+	_readyChRoot "$chrootDir" || return 0
+	sleep 1
+	_readyChRoot "$chrootDir" || return 0
+	sleep 3
+	_readyChRoot "$chrootDir" || return 0
+	sleep 9
+	_readyChRoot "$chrootDir" || return 0
+	sleep 27
+	_readyChRoot "$chrootDir" || return 0
+	sleep 81
+	_readyChRoot "$chrootDir" || return 0
+
+	return 1
+}

-
-_live_fdisk() {
-	if [[ -e '/sbin/fdisk' ]]
-	then
-		sudo -n /sbin/fdisk "$@"
-		return
-	fi
-	sudo -n fdisk "$@"
-	return
+_openChRoot() {
+	export specialLock="$lock_open_chroot"
+	_open _waitChRoot_opening _mountChRoot_image
 }

-_live_sfdisk() {
-	if [[ -e '/sbin/sfdisk' ]]
+_closeChRoot() {
+	_findInfrastructure_virtImage ${FUNCNAME[0]} "$@"
+	[[ "$ubVirtImageLocal" == "false" ]] && return
+
+	export specialLock="$lock_open_chroot"
+	if [[ "$1" == "--force" ]]
 	then
-		sudo -n /sbin/sfdisk "$@"
+		_close --force _waitChRoot_closing _umountChRoot_image
 		return
 	fi
-	sudo -n sfdisk "$@"
-	return
-}
-
-
-
-
-
-
-
-
-
-# https://manpages.debian.org/testing/live-boot-doc/persistence.conf.5.en.html
- # WARNING: 'persistence.conf' ... 'root of its file system' ... 'Any such labeled volume must have such a file, or it will be ignored.'
-_live_persistent_conf_here() {
-	cat <<'CZXWXcRMTo8EmM8i4d'
-/ union
-#/home union
-CZXWXcRMTo8EmM8i4d
+
+	_close _waitChRoot_closing _umountChRoot_image
 }

-_live_more_copy() {
-	_messagePlain_nominal '_live_more_copy'
+_haltAllChRoot() {
+	find "$scriptAbsoluteFolder"/v_*/fs -maxdepth 1 -type d -exec "$scriptAbsoluteLocation" _umountChRoot_directory '{}' \;
+	find "$scriptAbsoluteFolder"/v_*/tmp -maxdepth 1 -type d -exec sudo -n umount '{}' \;
+	find "$scriptAbsoluteFolder"/v_*/ -maxdepth 12 -type d | head -n 48 | tac | xargs rmdir

-	rm -f "$scriptLocal"/vm-live-more.iso
+	"$scriptAbsoluteLocation" _closeChRoot --force

-	cp "$scriptLocal"/vm-live.iso "$scriptLocal"/vm-live-more.iso
+	#Closing file may remain if chroot was not open to begin with. Since haltAllChRoot is usually called for forced/emergency shutdown purposes, clearing the resultant lock file is usually safe.
+	rm -f "$lock_closing"
 }

-_live_more_move() {
-	_messagePlain_nominal '_live_more_move'
+#Fast dismount of all ChRoot filesystems/instances and cleanup of lock files. Specifically intended to act on SIGTERM or during system(d) shutdown, when time and disk I/O may be limited.
+# TODO Use a tmpfs mount to track reboots (with appropriate BSD/Linux/Solaris checking) in the first place.
+#"$1" == sessionid (optional override for cleaning up stale systemd files)
+_closeChRoot_emergency() {
+	_checkSpecialLocks "$lock_open_chroot"

-	rm -f "$scriptLocal"/vm-live-more.iso
+	if [[ -e "$instancedVirtFS" ]]
+	then
+		_stopChRoot "$instancedVirtFS" >> "$logTmp"/usrchrt.log 2>&1
+		_umountChRoot_project >> "$logTmp"/usrchrt.log 2>&1
+		_umountChRoot_user_home >> "$logTmp"/usrchrt.log 2>&1
+		_umountChRoot_user >> "$logTmp"/usrchrt.log 2>&1
+
+		_rm_ubvrtusrChRoot
+
+		_stop_virt_instance >> "$logTmp"/usrchrt.log 2>&1
+	fi

-	mv "$scriptLocal"/vm-live.iso "$scriptLocal"/vm-live-more.iso
-}
-
-_live_more_procedure() {
-	_messageNormal 'init: _live_more_procedure'
+	#Not called by systemd, AND instanced directories still mounted, do not globally halt all. (optional)
+	#[[ "$1" == "" ]] && find "$scriptAbsoluteFolder"/v_* -maxdepth 1 -type d | _condition_lines_zero && return 0

-	#_start
+	#Not called by systemd, do not globally halt all.
+	[[ "$1" == "" ]] && return 0

+	! _readLocked "$lock_open" && find "$scriptAbsoluteFolder"/v_*/fs -maxdepth 1 -type d | _condition_lines_zero && return 0
+	_readLocked "$lock_closing" && return 1
+	_readLocked "$lock_opening" && return 1

-	[[ ! -e "$scriptLocal"/vm-live-more.iso ]] && _messageFAIL && _stop 1
+	_readLocked "$lock_emergency" && return 0
+	_createLocked "$lock_emergency"

+	_haltAllChRoot

+	#rm -f "$lock_emergency" || return 1
+	rm -f "$lock_emergency"
+	[[ -e "$lock_emergency" ]] && return 1


+	local hookSessionid
+	hookSessionid="$sessionid"
+	[[ "$1" != "" ]] && hookSessionid="$1"
+	_tryExecFull _unhook_systemd_shutdown "$hookSessionid"

+}
+
+#Debugging function.
+_removeChRoot() {
+	_haltAllChRoot

+	rm -f "$lock_closing"
+	rm -f "$lock_opening"
+	rm -f "$lock_instancing"

-	_messagePlain_nominal '_live_more_procedure: append'
+	rm -f "$globalVirtDir"/_ubvrtusr

-	# 32 * 1000 MB to GiB == 29.8023224 GiB
-	# 29.8 GB to MiB == 28419 MiB

-	# 1024 MiB to GiB == 1 GiB
-	# 1 GiB == 1073.74 MB
-	# 1024 MB + 64 MB == 1088 MB
+}
+
+_chroot() {

-	# 1088 * 12 + 32 == 13088 MB
+	[[ ! -e "$chrootDir"/bin/bash ]] && return 1

-	dd if=/dev/zero bs=1M count=13088 >> "$scriptLocal"/vm-live-more.iso
+	_mustGetSudo

+	#cd "$chrootDir"

+	local chrootExitStatus

-	_messagePlain_nominal '_live_more_procedure: partitions: add'
+	sudo -n env -i HOME="/root" TERM="${TERM}" SHELL="/bin/bash" PATH="/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin" DISPLAY="$DISPLAY" XSOCK="$XSOCK" XAUTH="$XAUTH" localPWD="$localPWD" hostArch=$(uname -m) virtSharedUser="$virtGuestUser" USER="root" chrootName="chrt" devfast="$devfast" nonet="$nonet" ub_dryRun="$ub_dryRun" GH_TOKEN="$GH_TOKEN" INPUT_GITHUB_TOKEN="$INPUT_GITHUB_TOKEN" TOKEN="$TOKEN" $(sudo -n bash -c "type -p chroot") "$chrootDir" "$@"
+
+
+	# WARNING: CAUTION: May be untested.
+	#export GH_TOKEN="$GH_TOKEN"
+	#export INPUT_GITHUB_TOKEN="$INPUT_GITHUB_TOKEN"
+	#export TOKEN="$TOKEN"
+	##env -i
+	#sudo -n -E --preserve-env=GH_TOKEN --preserve-env=INPUT_GITHUB_TOKEN --preserve-env=TOKEN env HOME="/root" TERM="${TERM}" SHELL="/bin/bash" PATH="/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin" DISPLAY="$DISPLAY" XSOCK="$XSOCK" XAUTH="$XAUTH" localPWD="$localPWD" hostArch=$(uname -m) virtSharedUser="$virtGuestUser" USER="root" chrootName="chrt" devfast="$devfast" nonet="$nonet" ub_dryRun="$ub_dryRun" $(sudo -n bash -c "type -p chroot") "$chrootDir" "$@"

-	#sudo -n parted --script "$scriptLocal"/vm-live-more.iso mklabel msdos
-	#sudo -n partprobe > /dev/null 2>&1
-	#sudo -n parted "$scriptLocal"/vm-live-more.iso --script -- mkpart primary 0% 100%
-	#sudo -n partprobe > /dev/null 2>&1
+	chrootExitStatus="$?"

-	# https://unix.stackexchange.com/questions/200582/scripteable-gpt-partitions-using-parted
+	return "$chrootExitStatus"

-	#sudo -n parted "$scriptLocal"/vm-live-more.iso --script -a optimal -- mkpart primary -12288MiB -8192MiB
-	#sudo -n parted "$scriptLocal"/vm-live-more.iso --script -a optimal -- mkpart primary -8192MiB -4096MiB
-	#sudo -n parted "$scriptLocal"/vm-live-more.iso --script -a optimal -- mkpart primary -4096MiB -0MiB
-	#sudo -n partprobe > /dev/null 2>&1
+}
+
+
+_mountChRoot_userAndHome() {

+	sudo -n mount -t tmpfs -o size=4G,uid="$HOST_USER_ID",gid="$HOST_GROUP_ID" tmpfs "$instancedVirtTmp"

+	#_bindMountManager "$globalVirtFS" "$instancedVirtFS" || return 1

-	# https://superuser.com/questions/332252/how-to-create-and-format-a-partition-using-a-bash-script
+	#_bindMountManager "$instancedVirtTmp" "$instancedVirtHome" || return 1

-	! _live_sfdisk -l "$scriptLocal"/vm-live-more.iso | grep 'Sector size (logical/physical): 512 bytes / 512 bytes' > /dev/null 2>&1 && _stop 1

-	rm -f "$safeTmp"/vm-live-more.iso.sfdisk
+	#Remove directories that interfere with union mounting.
+	rmdir "$instancedProjectDir"
+	rmdir "$instancedVirtHome"
+	###rmdir "$instancedVirtHomeRef"
+	rmdir "$instancedVirtFS"/home
+	rmdir "$instancedVirtFS"/root > /dev/null 2>&1

-	#_live_sfdisk -d "$scriptLocal"/vm-live-more.iso > "$safeTmp"/vm-live-more.iso.sfdisk
-	#echo 'size=8G, type=83' >> "$safeTmp"/vm-live-more.iso.sfdisk
+	# TODO Device Mapper snapshot ChRoot instancing alternative. Disadvantage of not allowing the root filesystem to be simultaneously mounted read-write.
+	# TODO Develop a function to automatically select whatever unionfs equivalent may be supported by the host.
+	#sudo -n /bin/mount -t unionfs -o dirs="$instancedVirtTmp":"$globalVirtFS"=ro unionfs "$instancedVirtFS"
+	sudo -n unionfs-fuse -o cow,allow_other,use_ino,suid,dev "$instancedVirtTmp"=RW:"$globalVirtFS"=RO "$instancedVirtFS"
+	#sudo -n unionfs -o dirs="$instancedVirtTmp":"$globalVirtFS"=ro "$instancedVirtFS"
+	sudo -n chown "$USER":"$USER" "$instancedVirtFS"

-	#echo 'size=4G, type=83' >> "$safeTmp"/vm-live-more.iso.sfdisk
-	#echo 'size=5G, type=5' >> "$safeTmp"/vm-live-more.iso.sfdisk
-	#echo 'size=4G, type=85' >> "$safeTmp"/vm-live-more.iso.sfdisk
+	#unionfs-fuse -o cow,max_files=32768 -o allow_other,use_ino,suid,dev,nonempty /u/host/etc=RW:/u/group/etc=RO:/u/common/etc=RO /u/union/etc

-	#echo 'size=1G, type=85' >> "$safeTmp"/vm-live-more.iso.sfdisk
+	mkdir -p "$instancedProjectDir"
+	mkdir -p "$instancedVirtHome"
+	###mkdir -p "$instancedVirtHomeRef"

+	return 0
+}
+
+_mountChRoot_project() {
+	#if [[ ! -e "$0" ]]
+	#then
+	#	return 1
+	#fi

-	echo 'size=2G, type=83' >> "$safeTmp"/vm-live-more.iso.sfdisk
-	echo 'type=5' >> "$safeTmp"/vm-live-more.iso.sfdisk
-	echo 'size=4G, type=82' >> "$safeTmp"/vm-live-more.iso.sfdisk
-	echo 'size=6G, type=83' >> "$safeTmp"/vm-live-more.iso.sfdisk
+	if [[ "$sharedHostProjectDir" == "" ]]
+	then
+		return 1
+	fi

+	if [[ "$sharedHostProjectDir" == "/" ]]
+	then
+		return 1
+	fi

-	# Tested , working .
-	#echo 'size=4G, type=82' >> "$safeTmp"/vm-live-more.iso.sfdisk
-	#echo 'size=6G, type=83' >> "$safeTmp"/vm-live-more.iso.sfdisk
+	#Denylist.
+	[[ "$sharedHostProjectDir" == "/home" ]] && return 1
+	[[ "$sharedHostProjectDir" == "/home/" ]] && return 1
+	[[ "$sharedHostProjectDir" == "/home/$USER" ]] && return 1
+	[[ "$sharedHostProjectDir" == "/home/$USER/" ]] && return 1
+	[[ $(id -u) != 0 ]] && [[ "$sharedHostProjectDir" == "/$USER" ]] && return 1
+	[[ $(id -u) != 0 ]] && [[ "$sharedHostProjectDir" == "/$USER/" ]] && return 1

+	[[ "$sharedHostProjectDir" == "/tmp" ]] && return 1
+	[[ "$sharedHostProjectDir" == "/tmp/" ]] && return 1

-	cat "$safeTmp"/vm-live-more.iso.sfdisk | _live_sfdisk --append "$scriptLocal"/vm-live-more.iso
+	[[ $(id -u) != 0 ]] && [[ "$sharedHostProjectDir" == "$HOME" ]] && return 1
+	[[ $(id -u) != 0 ]] && [[ "$sharedHostProjectDir" == "$HOME/" ]] && return 1

-	! _live_sfdisk -l "$scriptLocal"/vm-live-more.iso | grep 'Sector size (logical/physical): 512 bytes / 512 bytes' > /dev/null 2>&1 && _stop 1
+	#Allowlist.
+	local safeToMount=false

+	local safeScriptAbsoluteFolder="$_getScriptAbsoluteFolder"

+	[[ "$sharedHostProjectDir" == "./"* ]] && [[ "$PWD" == "$safeScriptAbsoluteFolder"* ]] && safeToMount="true"

+	[[ "$sharedHostProjectDir" == "$safeScriptAbsoluteFolder"* ]] && safeToMount="true"

+	[[ "$sharedHostProjectDir" == "/home/$USER"* ]] && safeToMount="true"
+	[[ "$sharedHostProjectDir" == "/root"* ]] && safeToMount="true"

+	[[ "$sharedHostProjectDir" == "/tmp/"* ]] && safeToMount="true"

+	[[ "$safeToMount" == "false" ]] && return 1

-	_messagePlain_nominal '_live_more_procedure: filesystems: format'
+	#Safeguards/
+	#[[ -d "$sharedHostProjectDir" ]] && find "$sharedHostProjectDir" | grep -i '\.git$' >/dev/null 2>&1 && return 1

+	#Validate necessary tools were available for path building and checks.
+	_checkDep realpath
+	_checkDep readlink
+	_checkDep dirname
+	_checkDep basename

+	sudo -n unionfs-fuse -o allow_other,use_ino,suid,dev "$sharedHostProjectDir"=RW "$instancedProjectDir"
+	sudo -n chown "$USER":"$USER" "$instancedProjectDir"

-	_messagePlain_nominal 'Attempt: _closeLoop'
-	! _closeLoop && _messageFAIL && _stop 1
+	#_bindMountManager "$sharedHostProjectDir" "$instancedProjectDir" || return 1

-	_messagePlain_nominal 'Attempt: _openLoop'
-	! [[ -e "$scriptLocal"/vm-live-more.iso ]] && _messageFAIL && _stop 1
-	export ubVirtImageOverride_alternate="$scriptLocal"/vm-live-more.iso
-	! _openLoop && _messageFAIL && _stop 1
+}
+
+_umountChRoot_project() {

-	local current_imagedev
-	current_imagedev=$(cat "$scriptLocal"/imagedev)
+	_wait_umount "$instancedProjectDir"

-	[[ "$current_imagedev" != '/dev/loop'* ]] && _messageFAIL && _stop 1
+}
+
+_mountChRoot_userDirs() {
+	mkdir -p "$HOME"/Downloads
+	sudo -n mkdir -p "$instancedDownloadsDir"
+	sudo -n unionfs-fuse -o allow_other,use_ino,suid,dev "$HOME"/Downloads=RW "$instancedDownloadsDir"
+	sudo -n chown "$USER":"$USER" "$instancedDownloadsDir"

+}
+
+_umountChRoot_userDirs() {
+	_wait_umount "$instancedDownloadsDir"
+	sudo -n rmdir "$instancedDownloadsDir"

-	! _live_sfdisk -l "$current_imagedev" | grep 'Sector size (logical/physical): 512 bytes / 512 bytes' > /dev/null 2>&1 && _messageFAIL && _stop 1
+}
+
+#No production use. Already supported by bind mount of full "/tmp". Kept for reference only.
+_mountChRoot_X11() {
+	_bindMountManager "$XSOCK" "$instancedVirtFS"/"$XSOCK"
+	_bindMountManager "$XSOCK" "$instancedVirtFS"/"$XAUTH"
+}
+
+#No production use. Already supported by bind mount of full "/tmp". Kept for reference only.
+_umountChRoot_X11() {
+	_wait_umount "$instancedVirtFS"/"$XSOCK"
+	_wait_umount "$instancedVirtFS"/"$XAUTH"
+}
+
+
+_umountChRoot_user() {

-	! _live_sfdisk -l "$current_imagedev" | grep "$current_imagedev"p3 | grep '4194304' > /dev/null 2>&1 && _messageFAIL && _stop 1
-	! _live_sfdisk -l "$current_imagedev" | grep "$current_imagedev"p5 | grep '8388608' > /dev/null 2>&1 && _messageFAIL && _stop 1
-	! _live_sfdisk -l "$current_imagedev" | grep "$current_imagedev"p6 | grep '12582912' > /dev/null 2>&1 && _messageFAIL && _stop 1
+	mountpoint "$instancedVirtFS" > /dev/null 2>&1 || return 1
+	#_umountChRoot "$instancedVirtFS"
+	_wait_umount "$instancedVirtFS"

-	! [[ -e "$current_imagedev"p6 ]] && _messageFAIL && _stop 1
+}
+
+_umountChRoot_user_home() {

+	_wait_umount "$instancedVirtHome" || return 1
+	mountpoint "$instancedVirtHome" > /dev/null 2>&1 && return 1

-	sudo -n mkfs.ext4 -L 'bulk' -U 'f1edb7fb-13b1-4c97-91d2-baf50e6d65d8' "$current_imagedev"p3
-	sudo -n mkswap -L 'hint' -U '469457fc-293f-46ec-92da-27b5d0c36b17' "$current_imagedev"p5
-	sudo -n mkfs.ext4 -L 'dent' -U 'd82e3d89-3156-4484-bde2-ccc534ca440b' "$current_imagedev"p6
+	return 0

+}
+
+_checkBaseDirRemote_chroot() {

+	[[ -e "$chrootDir"/"$1" ]] || return 1
+	return 0

-	# https://manpages.debian.org/testing/live-boot-doc/persistence.conf.5.en.html
-	 # WARNING: 'persistence.conf' ... 'root of its file system' ... 'Any such labeled volume must have such a file, or it will be ignored.'
-	mkdir -p "$safeTmp"/fsmount_temp/bulk
-	sudo -n mount "$current_imagedev"p3 "$safeTmp"/fsmount_temp/bulk
+}
+
+
+
+_rm_ubvrtusrChRoot() {

-	_live_persistent_conf_here | sudo tee "$safeTmp"/fsmount_temp/bulk/persistence.conf > /dev/null
+	sudo -n rmdir "$sharedGuestProjectDir" > /dev/null 2>&1
+	sudo -n rmdir "$instancedVirtHome"/"$virtGuestUser"/project > /dev/null 2>&1
+	sudo -n rmdir "$instancedVirtHome"/"$virtGuestUser" > /dev/null 2>&1
+	sudo -n rmdir "$instancedVirtHome" > /dev/null 2>&1
+	###sudo -n rmdir "$instancedVirtHomeRef"/project > /dev/null 2>&1
+	###sudo -n rmdir "$instancedVirtHomeRef"/"$virtGuestUser"/project > /dev/null 2>&1
+	###sudo -n rmdir "$instancedVirtHomeRef"/"$virtGuestUser" > /dev/null 2>&1
+	###sudo -n rmdir "$instancedVirtHomeRef" > /dev/null 2>&1

-	sudo -n mkdir -p "$safeTmp"/fsmount_temp/bulk/persist/bulk
-	_live_persistent_conf_here | sudo tee "$safeTmp"/fsmount_temp/bulk/persist/persistence.conf > /dev/null
-	_live_persistent_conf_here | sudo tee "$safeTmp"/fsmount_temp/bulk/persist/bulk/persistence.conf > /dev/null
+}
+
+
+
+_ubvrtusrChRoot_report_failure() {

+	echo -n "ubvrtusr     ""$1"
+	echo -e -n '\t'
+	shift

-	sudo -n umount "$safeTmp"/fsmount_temp/bulk
+	echo -n "$1"
+	echo -e -n '\t'
+	shift

+	shift
+	echo "$@"

-	#_live_sfdisk -l "$current_imagedev"
-	#ls -l "$current_imagedev"*
-	#sudo -n gparted "$current_imagedev" "$current_imagedev"p1 "$current_imagedev"p2 "$current_imagedev"p3 "$current_imagedev"p5 "$current_imagedev"p6
+	return 0

+}
+
+_ubvrtusrChRoot_check() {
+	#Diagnostics.
+	echo '#####ubvrtusr     checks'

-	_messagePlain_nominal 'Attempt: _closeLoop'
-	! _closeLoop && _messageFAIL && _stop 1
+	local internalFailure
+	internalFailure=false

-	export ubVirtImageOverride_alternate=
+	###! [[ -e "$globalVirtFS"/"$virtGuestHomeRef" ]] && _ubvrtusrChRoot_report_failure "nohome" "$virtGuestHomeRef" '[[ -e "$virtGuestHomeRef" ]]' && internalFailure=true

+	! _chroot id -u "$virtGuestUser" > /dev/null 2>&1 && _ubvrtusrChRoot_report_failure "no guest user" "$virtGuestUser" '_chroot id -u "$virtGuestUser"' && internalFailure=true

+	! [[ $(_chroot id -u "$virtGuestUser") == "$HOST_USER_ID" ]] && _ubvrtusrChRoot_report_failure "bad uid" $(_chroot id -u "$virtGuestUser") '[[ $(_chroot id -u "$virtGuestUser") == "$HOST_USER_ID" ]]' && internalFailure=true

+	! [[ $(_chroot id -g "$virtGuestUser") == "$HOST_GROUP_ID" ]] && _ubvrtusrChRoot_report_failure "bad gid" $(_chroot id -g "$virtGuestUser") '[[ $(_chroot id -g "$virtGuestUser") == "$HOST_GROUP_ID" ]]' && internalFailure=true

+	echo '#####ubvrtusr     checks'

+	 [[ "$internalFailure" == "true" ]] && return 1
+	 return 0
+}
+
+_ubvrtusrChRoot() {

+	#If root, discontinue.
+	[[ $(id -u) == 0 ]] && return 0

-	_messageNormal '_live_more_procedure: done'
+	#If user correctly setup, discontinue. Check multiple times before recreating user.
+	local iterationCount
+	iterationCount=0
+	while [[ "$iterationCount" -lt "3" ]]
+	do
+		_ubvrtusrChRoot_check && return 0
+
+		let iterationCount="$iterationCount"+1
+		sleep 0.3
+	done

-	#_stop 0
-}
-_live_more_sequence() {
-	_start
+	## Lock file. Not done with _waitFileCommands because there is nither an obvious means, nor an obviously catastrophically critical requirement, to independently check for completion of related useradd/mod/del operations.
+	_waitFile "$globalVirtDir"/_ubvrtusr || return 1
+	echo > "$globalVirtDir"/quicktmp
+	_moveconfirm "$globalVirtDir"/quicktmp "$globalVirtDir"/_ubvrtusr > /dev/null 2>&1 || return 1

-	_live_more_procedure "$@"
+	_chroot userdel -r "$virtGuestUser"
+	_rm_ubvrtusrChRoot

-	_stop 0
+	_chroot groupadd -g "$HOST_GROUP_ID" -o "$virtGuestUser"
+	_chroot useradd --shell /bin/bash -u "$HOST_USER_ID" -g "$HOST_GROUP_ID" -o -c "" -m "$virtGuestUser" || return 1
+
+	_chroot usermod -a -G video "$virtGuestUser" > /dev/null 2>&1 || return 1
+
+	_chroot chown "$virtGuestUser":"$virtGuestUser" "$virtGuestHome" > /dev/null 2>&1
+
+	sudo -n mkdir -p "$globalVirtFS""$virtGuestHome"
+	###sudo -n mkdir -p "$globalVirtFS""$virtGuestHomeRef"
+	###sudo -n cp -a "$globalVirtFS""$virtGuestHome"/. "$globalVirtFS""$virtGuestHomeRef"/
+	###echo sudo -n cp -a "$globalVirtFS""$virtGuestHome"/. "$globalVirtFS""$virtGuestHomeRef"/
+	###_chroot chown "$virtGuestUser":"$virtGuestUser" "$virtGuestHomeRef" > /dev/null 2>&1
+
+	#rm -f "$globalVirtDir"/_ubvrtusr > /dev/null 2>&1 || return 1
+	rm -f "$globalVirtDir"/_ubvrtusr > /dev/null 2>&1
+	[[ -e "$globalVirtDir"/_ubvrtusr ]] && return 1
+
+	return 0
 }

-
-_live_more_convert_vdi() {
-	_messagePlain_nominal '_live_more_convert_vdi: convert: vdi'
+_userChRoot() {
+	_findInfrastructure_virtImage ${FUNCNAME[0]} "$@"
+	[[ "$ubVirtImageLocal" == "false" ]] && return

+	_start
+	_start_virt_all
+	export chrootDir="$globalVirtFS"

-	# ATTENTION: Delete 'vm-live-more.vdi.uuid' to force generation of new uuid .
-	local current_UUID
-	current_UUID=$(head -n1 "$scriptLocal"/vm-live-more.vdi.uuid 2>/dev/null | tr -dc 'a-zA-Z0-9\-')
+	_mustGetSudo || _stop 1

-	if [[ $(echo "$current_UUID" | wc -c) != 37 ]]
-	then
-		current_UUID=$(_getUUID)
-		rm -f "$scriptLocal"/vm-live-more.vdi.uuid > /dev/null 2>&1
-		echo "$current_UUID" > "$scriptLocal"/vm-live-more.vdi.uuid
-	fi

+	_checkDep mountpoint >> "$logTmp"/usrchrt.log 2>&1 || _stop 1
+	mountpoint "$instancedVirtDir" > /dev/null 2>&1 && _stop 1
+	mountpoint "$instancedVirtFS" > /dev/null 2>&1 && _stop 1
+	mountpoint "$instancedVirtTmp" > /dev/null 2>&1 && _stop 1
+	mountpoint "$instancedVirtHome" > /dev/null 2>&1 && _stop 1

-	rm -f "$scriptLocal"/vm-live-more.vdi > /dev/null 2>&1
+	"$scriptAbsoluteLocation" _openChRoot >> "$logTmp"/usrchrt.log 2>&1 || _stop 1

-	! [[ -e "$scriptLocal"/vm-live-more.iso ]] && _messagePlain_bad 'fail: missing: in file' && return 1
-	[[ -e "$scriptLocal"/vm-live-more.vdi ]] && _messagePlain_request 'request: rm '"$scriptLocal"/vm-live-more.vdi && return 1
+	_tryExecFull _hook_systemd_shutdown_action "_closeChRoot_emergency" "$sessionid"

-	_messagePlain_nominal '_img_to_vdi: convertdd'
-	if _userVBoxManage convertdd "$scriptLocal"/vm-live-more.iso "$scriptLocal"/vm-live-more-c.vdi --format VDI
-	then
-		#_messagePlain_nominal '_img_to_vdi: closemedium'
-		#_userVBoxManage closemedium "$scriptLocal"/vm-live-more-c.vdi
-		_messagePlain_nominal '_img_to_vdi: mv vm-live-more-c.vdi vm.vdi'
-		_moveconfirm "$scriptLocal"/vm-live-more-c.vdi "$scriptLocal"/vm-live-more.vdi
-		_messagePlain_nominal '_img_to_vdi: setuuid'
-		VBoxManage internalcommands sethduuid "$scriptLocal"/vm-live-more.vdi "$current_UUID"
-		#_messagePlain_request 'request: rm '"$scriptLocal"/vm-live-more.iso
-		_messagePlain_good 'End.'
-		return 0
-	else
-		_messageFAIL
-		_stop 1
-	fi
+
+	_ubvrtusrChRoot  >> "$logTmp"/usrchrt.log 2>&1 || _stop 1
+
+	_mountChRoot_userAndHome >> "$logTmp"/usrchrt.log 2>&1 || _stop 1
+	###[[ $(id -u) != 0 ]] && cp -a "$instancedVirtHomeRef"/. "$instancedVirtHome"/ >> "$logTmp"/usrchrt.log 2>&1
+	export chrootDir="$instancedVirtFS"
+
+
+	export checkBaseDirRemote=_checkBaseDirRemote_chroot
+	_virtUser "$@" >> "$logTmp"/usrchrt.log 2>&1
+
+	#_mountChRoot_X11
+
+	_mountChRoot_project >> "$logTmp"/usrchrt.log 2>&1 || _stop 1
+	_chroot chown "$virtGuestUser":"$virtGuestUser" "$sharedGuestProjectDir" >> "$logTmp"/usrchrt.log 2>&1
+
+	#####
+	_mountChRoot_userDirs
+
+
+
+	_chroot /bin/bash /usr/local/bin/ubiquitous_bash.sh _dropChRoot "${processedArgs[@]}"
+	local userChRootExitStatus="$?"
+
+	_stopChRoot "$instancedVirtFS" >> "$logTmp"/usrchrt.log 2>&1
+
+
+
+
+	_umountChRoot_userDirs
+	#####
+
+	#_umountChRoot_X11
+
+	_umountChRoot_project >> "$logTmp"/usrchrt.log 2>&1
+	_umountChRoot_user_home >> "$logTmp"/usrchrt.log 2>&1 || _stop 1
+	_umountChRoot_user >> "$logTmp"/usrchrt.log 2>&1 || _stop 1
+
+	_rm_ubvrtusrChRoot
+
+	"$scriptAbsoluteLocation" _checkForMounts "$instancedVirtFS" >> "$logTmp"/usrchrt.log 2>&1 && _stop 1
+
+	_stop_virt_instance >> "$logTmp"/usrchrt.log 2>&1
+	_stop "$userChRootExitStatus"
 }

-_live_more_convert_vmdk() {
-	_messagePlain_nominal '_live_more_convert_vmdk: convert: vmdk'
+_removeUserChRoot_sequence() {
+	## Lock file. Not done with _waitFileCommands because there is nither an obvious means, nor an obviously catastrophically critical requirement, to independently check for completion of related useradd/mod/del operations.
+	_waitFile "$globalVirtDir"/_ubvrtusr || return 1
+	echo > "$globalVirtDir"/quicktmp
+	_moveconfirm "$globalVirtDir"/quicktmp "$globalVirtDir"/_ubvrtusr > /dev/null 2>&1 || return 1


-	# ATTENTION: Delete 'vm-live-more.vmdk.uuid' to force generation of new uuid .
-	local current_UUID
-	current_UUID=$(head -n1 "$scriptLocal"/vm-live-more.vmdk.uuid 2>/dev/null | tr -dc 'a-zA-Z0-9\-')
+	_chroot userdel -r "$virtGuestUser" > /dev/null 2>&1
+	###[[ -d "$chrootDir""$virtGuestHomeRef" ]] && sudo -n "$scriptAbsoluteLocation" _safeRMR "$chrootDir""$virtGuestHomeRef"

-	if [[ $(echo "$current_UUID" | wc -c) != 37 ]]
-	then
-		current_UUID=$(_getUUID)
-		rm -f "$scriptLocal"/vm-live-more.vmdk.uuid > /dev/null 2>&1
-		echo "$current_UUID" > "$scriptLocal"/vm-live-more.vmdk.uuid
-	fi
+	_rm_ubvrtusrChRoot

+	#rm -f "$globalVirtDir"/_ubvrtusr > /dev/null 2>&1 || return 1
+	rm -f "$globalVirtDir"/_ubvrtusr > /dev/null 2>&1
+	[[ -e "$globalVirtDir"/_ubvrtusr ]] && return 1

-	rm -f "$scriptLocal"/vm-live-more.vmdk > /dev/null 2>&1
+	return 0
+}
+
+_removeUserChRoot() {
+	"$scriptAbsoluteLocation" _openChRoot || return 1

-	! [[ -e "$scriptLocal"/vm-live-more.iso ]] && _messagePlain_bad 'fail: missing: in file' && return 1
-	[[ -e "$scriptLocal"/vm-live-more.vmdk ]] && _messagePlain_request 'request: rm '"$scriptLocal"/vm-live-more.vmdk && return 1
+	_removeUserChRoot_sequence

-	_messagePlain_nominal '_img_to_vmdk: convertdd'
+	"$scriptAbsoluteLocation" _closeChRoot || return 1
+}
+
+_dropChRoot() {

+	# Change to localPWD or home.
+	cd "$localPWD"

-	# https://stackoverflow.com/questions/454899/how-to-convert-flat-raw-disk-image-to-vmdk-for-virtualbox-or-vmplayer
-	if _userVBoxManage convertdd "$scriptLocal"/vm-live-more.iso "$scriptLocal"/vm-live-more-c.vmdk --format VMDK
-	#if qemu-img convert -O vmdk "$scriptLocal"/vm-live-more.iso "$scriptLocal"/vm-live-more-c.vmdk
-	then
-		#_messagePlain_nominal '_img_to_vmdk: closemedium'
-		#_userVBoxManage closemedium "$scriptLocal"/vm-live-more-c.vmdk
-		_messagePlain_nominal '_img_to_vmdk: mv vm-live-more-c.vmdk vm.vmdk'
-		_moveconfirm "$scriptLocal"/vm-live-more-c.vmdk "$scriptLocal"/vm-live-more.vmdk
-		_messagePlain_nominal '_img_to_vmdk: setuuid'
-
-
-		#VBoxManage internalcommands sethduuid "$scriptLocal"/vm-live-more.vmdk "$current_UUID"
-		VBoxManage internalcommands sethduuid "$scriptLocal"/vm-live-more.vmdk "$current_UUID"
-
-
-		#_messagePlain_request 'request: rm '"$scriptLocal"/vm-live-more.iso
-		_messagePlain_good 'End.'
-		return 0
-	else
-		_messageFAIL
-		_stop 1
-	fi
+	"$scriptAbsoluteLocation" _gosuExecVirt cp -r /etc/skel/. "$virtGuestHomeDrop" > /dev/null 2>&1
+
+	"$scriptAbsoluteLocation" _gosuExecVirt "$scriptAbsoluteLocation" _setupUbiquitous_nonet > /dev/null 2>&1
+
+	# Drop to user ubvrtusr, using gosu.
+	_gosuExecVirt "$@"
 }

+#No production use. Kept for reference only.
+###_prepareChRootUser() {
+
+	#_gosuExecVirt cp -r /etc/skel/. /home/
+
+	#cp -a /home/"$virtGuestUser".ref/. /home/"$virtGuestUser"/
+	#chown "$virtGuestUser":"$virtGuestUser" /home/"$virtGuestUser"
+
+	###true
+
+###}


+# WARNING: No production use!
+# If at all, used ONLY to by:
+#  ubDistBuild '_prog'/'core-custom.sh'
+#  ubDistBuild '_prog'/'core-upgrade.sh'
+#  ubDistBuild '_prog-ops'/'ops-custom.sh'
+# Such usage presumes '_create_ubDistBuild-install-ubDistBuild' has been used recently enough to copy 'ubiquitous_bash.sh' to '/home/user/ubDistBuild/' with a sufficiently recent copy of the relevant functions to run within the ChRoot .
+# CAUTION: DANGER: Do NOT use 'ubdistchroot' functions during build of ubdist/OS or any other dist/OS . These functions are ONLY intended for customization of a completely built dist/OS. Existence, atomic overwriting, etc, of prerequsite '/home/user/ubDistBuild/ubiquitous_bash.sh' is absolutely NOT feasible to guarantee until underlying dist/OS build has been completed. Such dist/OS build processes are be controlled by 'rotIns' (ie. rotten install script), and must NEVER rely on a copy of 'ubiquitous_bash.sh' from 'ubDistBuild' .

+# Better mechanisms of '_userChRoot' , '_dropChRoot' , etc, are NOT used here, due to both lesser requirements of the functions to run (ie. not graphical GUI apps accessing bind mount shared files, etc), and due to the greater emphasis on compatibility (ie. not depending on 'gosu', '_gosuExecVirt', etc).

-# Extra features for the exceptional situation of storing multiple hibernation states, as would be available through 'suspend/snapshot' features of VirtualBox, VMWare, etc, but for computers which do not have such features.
-# End users should not normally be expected to use 'live-more.iso' as a disk image for a personal workstation computer.
-# NOTICE: Such features may not be completely automatic.
-# Only iso filesystem will show to 'sudo gparted /dev/sda' . As usual, do NOT rely on '/dev/sda' (may become instead eg. '/dev/sdb').
-#sudo gparted /dev/sda1 /dev/sda2 /dev/sda3 /dev/sda4 /dev/sda5 ...
-#sudo swapon /dev/sda5
-#sudo mount /dev/sda6 /mnt/dent
-# Hibernate, Reboot/Ignore, ...
-#sudo dd if=/dev/sda5 of=/mnt/dent bs=1M status=progress
-#_bupStore ...
-_live_more() {
-	_live_more_copy "$@"
-	#_live_more_move "$@"
-	"$scriptAbsoluteLocation" _live_more_sequence "$@"
-}



+#_ubdistChRoot _compendium_git-custom-repo-org c/Corporation_ABBREVIATION GitHub_ORGANIZATION
+#_ubdistChRoot _compendium_git-custom-repo installations,infrastructure GitHub_ORGANIZATION,USER repositoryName

+_drop_ubdistChRoot() {
+    if [[ "$ub_dryRun" == "true" ]]
+    then
+        _stop
+        exit
+        return
+    fi

-_live_preload_here() {
-	cat << 'CZXWXcRMTo8EmM8i4d'
-#!/bin/sh
+    if ! cd
+    then
+        _messagePlain_bad 'bad: FAIL: cd'
+        _messageFAIL
+        _stop 1
+    fi
+    "$@"
+}

-PREREQ=""
+_ubdistChRoot() {
+    if [[ "$ub_dryRun" == "true" ]]
+    then
+        _stop
+        exit
+        return
+    fi

-prereqs()
-{
-    echo "$PREREQ"
+    _chroot sudo -n --preserve-env=GH_TOKEN --preserve-env=INPUT_GITHUB_TOKEN -u user /bin/bash /home/user/ubDistBuild/ubiquitous_bash.sh _drop_ubdistChRoot "$@"
 }

-case "$1" in
-prereqs)
-    prereqs
-    exit 0
-;;
-esac

-if type dd > /dev/null 2>&1 && type chroot > /dev/null 2>&1 && [ -e /root/bin/bash ] && [ -e /root/bin/sh ] && env -i HOME="/root" SHELL="/bin/bash" PATH="/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin" USER="root" chroot /root /bin/bash -c 'type dd' > /dev/null 2>&1
-then
-	progressFeed() {
-		env -i HOME="/root" SHELL="/bin/bash" PATH="/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin" USER="root" chroot /root dd of=/dev/null bs=1M status=progress
-	}
+_ubdistChRoot_backend_begin() {
+    ! _openChRoot && _messagePlain_bad 'bad: _openChRoot' && _messageFAIL
+    _backend() { _ubdistChRoot "$@" ; }
+    true
+}
+_ubdistChRoot_backend_end() {
+    unset -f _backend
+    ! _closeChRoot && _messagePlain_bad 'bad: _closeChRoot' && _messageFAIL
+    true
+}
+_ubdistChRoot_backend_sequence() {
+    _ubdistChRoot_backend_begin
+    "$@"
+    _ubdistChRoot_backend_end
+}
+_ubdistChRoot_backend() {
+    "$scriptAbsoluteLocation" _ubdistChRoot_backend_sequence "$@"
+}

-	echo "_____ preload: /root/home -not core -not .nix -not .gcloud"
-	find /root/home -not \( -path \/root/home/\*/core\* -prune \) -not \( -path \/root/home/\*/.nix\* -prune \) -not \( -path \/root/home/\*/.gcloud\* -prune \) -type f -exec dd if={} bs=16384 2>/dev/null \; | progressFeed
-	find /root/home/*/klipper -type f -exec dd if={} bs=16384 2>/dev/null \; | progressFeed
-	find /root/home/*/moonraker -type f -exec dd if={} bs=16384 2>/dev/null \; | progressFeed
-	find /root/home/*/moonraker-env -type f -exec dd if={} bs=16384 2>/dev/null \; | progressFeed
-	find /root/home/*/mainsail -type f -exec dd if={} bs=16384 2>/dev/null \; | progressFeed


-	echo "_____ preload: /root/usr/lib -maxdepth 9 -iname '*.so*'"
-	find /root/usr/lib -maxdepth 9 -type f -iname '*.so*' -exec dd if={} bs=16384 2>/dev/null \; | progressFeed

+_vmsize-micro() {
+	# Part files have been as large as 1905MiB .
+	echo 7620
+}
+_vmsize() {
+	# 25.95GiB
+	#echo 26572

-	echo "_____ preload: /root/home -not core -not .nix -not .gcloud"
-	find /root/home/*/.config -type f -exec dd if={} bs=16384 2>/dev/null \; | progressFeed
-	find /root/home/*/.kde -type f -exec dd if={} bs=16384 2>/dev/null \; | progressFeed
-	find /root/home/*/.ubcore -type f -exec dd if={} bs=16384 2>/dev/null \; | progressFeed
-	find /root/home -maxdepth 1 -type f -exec dd if={} bs=16384 2>/dev/null \; | progressFeed
+	# Preferred before addition of any AI models. Smaller than 32GB USB flash drive.
+	# 27.95GiB
+	#echo 28620

+	# Preferred with 'augment' ~8b q4_k_m LLM model.
+	# 37.95GiB
+	#echo 38860

-	echo "_____ preload: /root/root"
-	find /root/root -type f -exec dd if={} bs=16384 2>/dev/null \; | progressFeed
+	# May accommodate a few additional AI models.
+	# 52.95GiB
+	#echo 54220

-
-	# CAUTION: DUBIOUS .
-	echo "_____ preload: /VBoxGuestAdditions"
-	find /root/VBoxGuestAdditions -type f -exec dd if={} bs=16384 2>/dev/null \; | progressFeed
+	# Slightly smaller than expected 50GB BD-R DL .
+	# 46.1GiB
+	echo 47206
+}

-	# CAUTION: DUBIOUS .
-	echo "_____ preload: /opt"
-	find /root/opt -type f -exec dd if={} bs=16384 2>/dev/null \; | progressFeed
-
-	# CAUTION: DUBIOUS .
-	echo "_____ preload: /run"
-	find /root/run -type f -exec dd if={} bs=16384 2>/dev/null \; | progressFeed
-
-	# CAUTION: DUBIOUS .
-	echo "_____ preload: /srv"
-	find /root/srv -type f -exec dd if={} bs=16384 2>/dev/null \; | progressFeed
-
-
-	echo '_____ preload: /root/var'
-	find /root/var -type f -exec dd if={} bs=16384 2>/dev/null \; | progressFeed
-
-
-	echo '_____ preload: /root/usr/lib/modules'
-	find /root/usr/lib/modules -type f -exec dd if={} bs=16384 2>/dev/null \; | progressFeed
-
-	echo '_____ preload: /root/boot'
-	find /root/boot -type f -exec dd if={} bs=16384 2>/dev/null \; | progressFeed
-
-	echo '_____ preload: /root/usr/lib/systemd'
-	find /root/usr/lib/systemd -type f -exec dd if={} bs=16384 2>/dev/null \; | progressFeed
-
-	echo '_____ preload: /root/usr/bin'
-	find /root/usr/bin -type f -exec dd if={} bs=16384 2>/dev/null \; | progressFeed
-
-	echo '_____ preload: /root/bin'
-	find /root/bin -type f -exec dd if={} bs=16384 2>/dev/null \; | progressFeed
-
-	echo '_____ preload: /root/sbin'
-	find /root/sbin -type f -exec dd if={} bs=16384 2>/dev/null \; | progressFeed
-
-	echo '_____ preload: /root/etc'
-	find /root/etc -type f -exec dd if={} bs=16384 2>/dev/null \; | progressFeed
-# WARNING: May be untested.
-else
-	echo "_____ preload: /root/home -not core -not .nix -not .gcloud"
-	find /root/home -not \( -path \/root/home/\*/core\* -prune \) -not \( -path \/root/home/\*/.nix\* -prune \) -not \( -path \/root/home/\*/.gcloud\* -prune \) -type f -exec cat {} > /dev/null \;
-	find /root/home/*/klipper -type f -exec cat {} > /dev/null \;
-	find /root/home/*/moonraker -type f -exec cat {} > /dev/null \;
-	find /root/home/*/moonraker-env -type f -exec cat {} > /dev/null \;
-	find /root/home/*/mainsail -type f -exec cat {} > /dev/null \;
-
-
-	echo "_____ preload: /root/usr/lib -maxdepth 9 -iname '*.so*'"
-	find /root/usr/lib -maxdepth 9 -type f -iname '*.so*' -exec cat {} > /dev/null \;
-
-
-	echo "_____ preload: /root/home -not core -not .nix -not .gcloud"
-	find /root/home/*/.config -type f -exec cat {} > /dev/null \;
-	find /root/home/*/.kde -type f -exec cat {} > /dev/null \;
-	find /root/home/*/.ubcore -type f -exec cat {} > /dev/null \;
-	find /root/home -maxdepth 1 -type f -exec cat {} > /dev/null \;
-
-
-	echo "_____ preload: /root/root"
-	find /root/root -type f -exec cat {} > /dev/null \;
-
-
-
-	# CAUTION: DUBIOUS .
-	echo '_____ preload: /root/VBoxGuestAdditions'
-	find /root/VBoxGuestAdditions -type f -exec cat {} > /dev/null \;
-
-	# CAUTION: DUBIOUS .
-	echo '_____ preload: /root/opt'
-	find /root/opt -type f -exec cat {} > /dev/null \;
-
-	# CAUTION: DUBIOUS .
-	echo '_____ preload: /root/run'
-	find /root/run -type f -exec cat {} > /dev/null \;
-
-	# CAUTION: DUBIOUS .
-	echo '_____ preload: /root/srv'
-	find /root/srv -type f -exec cat {} > /dev/null \;
-
-
-	echo '_____ preload: /root/var'
-	find /root/var -type f -exec cat {} > /dev/null \;
-
-
-	echo '_____ preload: /root/usr/lib/modules'
-	find /root/usr/lib/modules -type f -exec cat {} > /dev/null \;
-
-	echo '_____ preload: /root/boot'
-	find /root/boot -type f -exec cat {} > /dev/null \;
-
-	echo '_____ preload: /root/usr/lib/systemd'
-	find /root/usr/lib/systemd -type f -exec cat {} > /dev/null \;
-
-	echo '_____ preload: /root/usr/bin'
-	find /root/usr/bin -type f -exec cat {} > /dev/null \;
-
-	echo '_____ preload: /root/bin'
-	find /root/bin -type f -exec cat {} > /dev/null \;
-
-	echo '_____ preload: /root/sbin'
-	find /root/sbin -type f -exec cat {} > /dev/null \;
-
-	echo '_____ preload: /root/etc'
-	find /root/etc -type f -exec cat {} > /dev/null \;
-fi
-
-CZXWXcRMTo8EmM8i4d
-}
-
-
-# https://master.dl.sourceforge.net/project/tboot/intel-txt-software-development-guide.pdf?viasf=1
-# 'Measured Launched Environment Developer-s Guide'
-# ...
-# https://wiki.gentoo.org/wiki/Trusted_Boot#TXT_Errors
-#  MAJOR - 'error will be preserved across a reboot (but not a hard poweroff).'
-#   'txt-parse_err'
-#  'Sometimes it'll hang. That usually means /boot/list.data doesn't reflect the current configuration - this will often happen after a configuration change.'
-# ...
-# https://fedoraproject.org/wiki/Tboot
-# 'last edited on 22 June 2012'
-#  As of 2023-09-23 .
-# 'module /2nd_gen_i5_i7_SINIT_51.BIN'
-# 'module /list.data'
-#  MAJOR - 'You may download all of the ACM modules into /boot and list them all as modules in your grub.conf. tboot will pick the right module for your platform.'
-# ...
-# https://sourceforge.net/p/tboot/mailman/tboot-devel/?page=1
-#  'when multiple SINITs is loaded, there is a chance that one (or more) of them will be overwritten by some TBOOT data structures that have hardcoded addresses'
-#   'Fri, 11 Mar 2022'
-#  'Being able to use e.g. the same Live CD on all pieces of hardware would be a huge win.'
-# ...
-# https://sourceforge.net/projects/tboot/files/
-#  'The location of SINIT Authenticated Code Module (ACM) files has been moved from this site to the following location: http://software.intel.com/en-us/articles/intel-trusted-execution-technology/'
-#  'The content, license, etc. of the ACMs has not changed.'
-#  'New ACMs and updates to existing ACMs will only be posted to the new site.'
-# ...
-# https://manpages.debian.org/testing/live-boot-doc/live-boot.7.en.html
-# https://github.com/bugra9/persistent
-# https://manpages.debian.org/testing/live-boot-doc/persistence.conf.5.en.html
-# https://www.freedesktop.org/software/systemd/man/systemd-gpt-auto-generator.html
-#  systemd.gpt_auto=false
-#  rd.systemd.gpt_auto=false
- # WARNING: 'persistence.conf' ... 'root of its file system' ... 'Any such labeled volume must have such a file, or it will be ignored.'
-# config debug=1 noeject persistence persistence-path=/persist persistence-label=bulk persistence-storage=directory
-_live_grub_here() {
-	cat <<'CZXWXcRMTo8EmM8i4d'
-
-insmod all_video
-
-search --set=root --file /ROOT_TEXT
-
-#set default="0"
-#set default="1"
-set default="2"
-set timeout=1
-
-menuentry "Live" {
-    #linux /vmlinuz boot=live config debug=1 noeject nopersistence selinux=0 mem=3712M resume=UUID=469457fc-293f-46ec-92da-27b5d0c36b17
-    #linux /vmlinuz boot=live config debug=1 noeject nopersistence selinux=0 mem=3712M resume=PARTUUID=469457fc-293f-46ec-92da-27b5d0c36b17
-    linux /vmlinuz boot=live config debug=1 noeject nopersistence selinux=0 mem=3712M resume=/dev/sda5
-    initrd /initrd
-
-    #linux /vmlinuz-lts boot=live config debug=1 noeject nopersistence selinux=0 mem=3712M resume=UUID=469457fc-293f-46ec-92da-27b5d0c36b17
-    #linux /vmlinuz-lts boot=live config debug=1 noeject nopersistence selinux=0 mem=3712M resume=PARTUUID=469457fc-293f-46ec-92da-27b5d0c36b17
-    linux /vmlinuz-lts boot=live config debug=1 noeject nopersistence selinux=0 mem=3712M resume=/dev/sda5
-    initrd /initrd-lts
+# Similar to _createVMimage , but intended to create an image solely for online installer steps , a small image ingredient to follow up with subsequent offline build from other more de-facto standard ingredients.
+# ATTENTION: Override if necessary.
+# CAUTION: Must follow defaults of '_createVMimage', which in turn must follow defaults (eg. _set_ubDistBuild , 'core.sh' , 'ops.sh' , ubiquitous_bash , etc) .
+# CAUTION: Platforms other than the default 'x64-efi' must use entirely different function paths, different 'vm-arch.img' filenames, etc.
+# ATTENTION: If alternative architectures (eg. ARM) were desired, creating a bootable 'micro'/'ingredients' image would be a more logical first step than porting the legacy build system that does not differentiate between this small bootable ingredient and the offline larger full build .
+_createVMimage-micro() {
+	if ! "$scriptAbsoluteLocation" _createVMimage-micro_sequence "$@"
+	then
+		_stop 1
+	fi
+	return 0
 }
-
-menuentry "Live - ( persistence )" {
-    linux /vmlinuz boot=live config debug=1 noeject persistence persistence-path=/persist persistence-label=bulk persistence-storage=directory selinux=0 mem=3712M resume=/dev/sda5
-    initrd /initrd
-
-    #linux /vmlinuz-lts boot=live config debug=1 noeject persistence persistence-path=/persist persistence-label=bulk persistence-storage=directory selinux=0 mem=3712M resume=/dev/sda5
-    #initrd /initrd-lts
+_createVMimage-micro_sequence() {
+    #export ubVirtImageOverride="vm-ingredient.img"
+    export ubVirtImageOverride_alternate="$scriptLocal"/"vm-ingredient.img"
+	local ub_vmImage_micro="true"
+	_createVMimage "$@"
 }
-
-menuentry "Live - ( hint: ignored: resume disabled ) ( mem: all )" {
-	linux /vmlinuz boot=live config debug=1 noeject nopersistence selinux=0
-    initrd /initrd
-
-	#linux /vmlinuz-lts boot=live config debug=1 noeject nopersistence selinux=0
-    #initrd /initrd-lts
+_createVMimage-ingredient() {
+	_createVMimage-micro "$@"
 }
-
-menuentry "Live - ( hint: ignored: resume disabled ) ( mem: all ) - tboot" {
-	##linux /vmlinuz boot=live config debug=1 noeject nopersistence selinux=0
-    ##initrd /initrd
+_createVMimage-micro-expand() {
+	local currentExitStatus
+	currentExitStatus="0"

-	#linux /vmlinuz-lts boot=live config debug=1 noeject nopersistence selinux=0
-    #initrd /initrd-lts
-
-    insmod multiboot2
-	multiboot2 /tboot.gz logging=serial,memory,vga
-	module2 /vmlinuz boot=live config debug=1 noeject nopersistence selinux=0
-	module2 /initrd
-	#module2 /vmlinuz-lts boot=live config debug=1 noeject nopersistence selinux=0
-	#module2 /initrd-lts
-	#module2 /SNB_IVB_SINIT_20190708_PW.bin
-	module2 /BDW_SINIT_20190708_1.3.2_PW.bin
-	#module2 /SKL_KBL_AML_SINIT_20211019_PRODUCTION_REL_NT_O1_1.10.0.bin
-	#module2 /CFL_SINIT_20221220_PRODUCTION_REL_NT_O1_1.10.1_signed.bin
-	#module2 /CML_S_SINIT_1_13_33_REL_NT_O1.PW_signed.bin
-	#module2 /CMLSTGP_SINIT_v1_14_46_20220819_REL_NT_O1.PW_signed.bin
-	#module2 /RKLS_SINIT_v1_14_46_20220819_REL_NT_O1.PW_signed.bin
-	#module2 /TGL_SINIT_v1_14_46_20220819_REL_NT_O1.PW_signed.bin
-	module2 /ADL_SINIT_v1_18_16_20230427_REL_NT_O1.PW_signed.bin
-
-	#module /list.data
-}
-
-CZXWXcRMTo8EmM8i4d
-}
-
-
-_write_revert_live() {
-	_messagePlain_nominal 'Attempt: _openChRoot'
-	! "$scriptAbsoluteLocation" _openChRoot && _messagePlain_bad 'fail: _openChRoot' && _messageFAIL
-
-	#_chroot systemctl enable nfs-blkmap
-	#_chroot systemctl enable nfs-idmapd
-	#_chroot systemctl enable nfs-mountd
-	#_chroot systemctl enable nfs-server
-	#_chroot systemctl enable nfsdcld
-
-	#_chroot systemctl enable ssh
-	#_chroot systemctl enable sshd
-
-	_chroot systemctl enable exim4
-
-
-	sudo -n rm -f "$globalVirtFS"/usr/share/initramfs-tools/scripts/init-bottom/preload_run
-
-	[[ -e "$globalVirtFS"/etc/systemd/system.conf.orig ]] && sudo -n mv -f "$globalVirtFS"/etc/systemd/system.conf.orig "$globalVirtFS"/etc/systemd/system.conf
-
+	_messageNormal '_custom-expand: dd'

-	_chroot update-initramfs -u -k all
+	local vmSize=$(_vmsize)
+	local vmSize_micro=$(_vmsize-micro)
+	local vmSize_boundary_expansion=$(bc <<< "$vmSize - $vmSize_micro - 1")

-	_messagePlain_nominal 'Attempt: _closeChRoot'
-	#sudo -n umount "$globalVirtFS"/boot/efi > /dev/null 2>&1
-	#sudo -n umount "$globalVirtFS"/boot > /dev/null 2>&1
-	! "$scriptAbsoluteLocation" _closeChRoot && _messagePlain_bad 'fail: _closeChRoot' && _messageFAIL
-}
+	# ATTENTION: Expand ONLY the additional amount needed for custom additions . This is APPENDED .
+	! dd if=/dev/zero bs=1048576 count="$vmSize_boundary_expansion" >> "$scriptLocal"/vm.img && _messageFAIL

-# https://willhaley.com/blog/custom-debian-live-environment-grub-only/
-# https://web.archive.org/web/*/https://willhaley.com/blog/custom-debian-live-environment-grub-only/*
-# https://itnext.io/how-to-create-a-custom-ubuntu-live-from-scratch-dd3b3f213f81
-# https://manpages.debian.org/jessie/initramfs-tools/initramfs-tools.8.en.html
-# http://www.opopop.net/booting_linux_from_a_loop_file_system/
-# https://forums.gentoo.org/viewtopic-t-931250-start-0.html
-# https://wiki.debian.org/InitramfsDebug
-# https://gist.github.com/avinash-oza/9791c4edd78a03540dc69d6fbf21bd9c
-_live_sequence_in() {
-	_messageNormal 'init: _live'
+	# Alternatively, it may be possible, but STRONGLY DISCOURAGED, to pad the file to a size. This, however, assumes the upstream 'ubdist/OS', etc, has not unexpectedly grown larger, which is still a VERY BAD assumption.
+	# https://unix.stackexchange.com/questions/196715/how-to-pad-a-file-to-a-desired-size

-	_mustGetSudo || return 0

+	_messageNormal '_custom-expand: growpart'
+	! _openLoop && _messagePlain_bad 'fail: openLoop' && _messageFAIL

+	export ubVirtPlatform="x64-efi"
+	#_determine_rawFileRootPartition

-	# WARNING: If the root filesystem has compressed, this would be absurd. Also not expected to affect iso image and such. Better to leave raw image compression to customization of the raw image.
-	#_messagePlain_nominal 'Attempt: _openChRoot'
-	#! _openChRoot && _messageFAIL && _stop 1
+	export ubVirtImagePartition="p5"

-	#_messagePlain_nominal 'Compression: zero blanking'
+	local current_imagedev=$(cat "$scriptLocal"/imagedev)
+	local current_rootpart=$(echo "$ubVirtImagePartition" | tr -dc '0-9')

-	#sudo -n dd if=/dev/zero of="$globalVirtFS"/zero.del bs=8M
-	#sudo -n rm -f "$globalVirtFS"/zero.del
+	! _messagePlain_probe_cmd sudo -n growpart "$current_imagedev" "$current_rootpart" && _messageFAIL

-	#_messagePlain_nominal 'Attempt: _closeChRoot'
-	#! _closeChRoot && _messageFAIL && _stop 1
+	unset ubVirtPlatform
+	unset ubVirtImagePartition

+	! _closeLoop && _messagePlain_bad 'fail: closeLoop' && _messageFAIL

+	_messageNormal '_custom-expand: btrfs resize'
+	! _openChRoot && _messagePlain_bad 'fail: openChRoot' && _messageFAIL


+	! _messagePlain_probe_cmd _chroot btrfs filesystem resize max / && _messageFAIL

-	_start

-	cd "$safeTmp"
-
-	_messagePlain_nominal 'Attempt: _openChRoot'
-	! "$scriptAbsoluteLocation" _openChRoot && _messagePlain_bad 'fail: _openChRoot' && _messageFAIL
-
-	##_chroot systemctl disable nfs-blkmap
-	##_chroot systemctl disable nfs-idmapd
-	##_chroot systemctl disable nfs-mountd
-	##_chroot systemctl disable nfs-server
-	##_chroot systemctl disable nfsdcld
-
-	##_chroot systemctl disable ssh
-	##_chroot systemctl disable sshd
-
-	#_chroot systemctl disable exim4
-
-
-	_live_preload_here | sudo -n tee "$globalVirtFS"/usr/share/initramfs-tools/scripts/init-bottom/preload_run > /dev/null
-	_chroot chown root:root /usr/share/initramfs-tools/scripts/init-bottom/preload_run
-	_chroot chmod 755 /usr/share/initramfs-tools/scripts/init-bottom/preload_run
-
-	# Apparent repeated success with 'DefaultTasksMax=12' . In one case, some services - SMART and NetworkManager - may have failed to start within timeouts. Some have certainly been close to timeout.
-	# Consider reducing below 12 iteratively.
-	# Alternatively, this may need to increase. Cron jobs may otherwise fail with such error message as 'fork retry resource temporarily unavailable' .
-	# Uncertain whether 'DefaultTasksMax' limits only the number of systemd services started simuntaneously, or also the number of threads total prior to interactive shell.
-	# CAUTION: Apparently sets 'ulimit' unfavorably against cron .
-	#  Hopefully, preload will be sufficient to prevent excessive disc seeking issues .
-	#sudo -n mv -n "$globalVirtFS"/etc/systemd/system.conf "$globalVirtFS"/etc/systemd/system.conf.orig
-	#echo '[Manager]
-#DefaultTasksMax=24' | sudo -n tee "$globalVirtFS"/etc/systemd/system.conf > /dev/null
-
+	! _closeChRoot && _messagePlain_bad 'fail: closeChRoot' && _messageFAIL
+
+	return 0
+}

-	_chroot update-initramfs -u -k all
+# Creates a raw VM image. Default Hybrid/UEFI partitioning and formatting.
+# ATTENTION: Override, if necessary.
+_createVMimage() {
+	_messageNormal '##### _createVMimage'
+
+	mkdir -p "$scriptLocal"
+
+	#[[ "$ub_vmImage_micro" == "true" ]] && export ubVirtImageOverride="$scriptLocal"/vm-ingredient.img
+
+	export vmImageFile="$scriptLocal"/vm.img
+	[[ "$ub_vmImage_micro" == "true" ]] && export vmImageFile="$scriptLocal"/vm-ingredient.img
+	[[ "$ubVirtImageOverride" != "" ]] && export vmImageFile="$ubVirtImageOverride"

+	[[ "$ubVirtImageOverride" == "" ]] && [[ -e "$vmImageFile" ]] && _messagePlain_good 'exists: '"$vmImageFile" && return 0
+	[[ "$ubVirtImageOverride" == "" ]] && [[ -e "$scriptLocal"/vm.img ]] && _messagePlain_good 'exists: '"$scriptLocal"/vm.img && return 0

+	[[ -e "$lock_open" ]]  && _messagePlain_bad 'bad: locked!' && _messageFAIL && _stop 1
+	[[ -e "$scriptLocal"/l_o ]]  && _messagePlain_bad 'bad: locked!' && _messageFAIL && _stop 1

+	[[ "$ubVirtImageOverride" == "" ]] && ! [[ $(df --block-size=1000000000 --output=avail "$scriptLocal" | tr -dc '0-9') -gt "25" ]] && _messageFAIL && _stop 1



-	_chroot apt-get -y clean
+	local imagedev

+	_open

+	export vmImageFile="$scriptLocal"/vm.img
+	[[ "$ub_vmImage_micro" == "true" ]] && export vmImageFile="$scriptLocal"/vm-ingredient.img
+	[[ "$ubVirtImageOverride" != "" ]] && export vmImageFile="$ubVirtImageOverride"


+	if [[ "$ubVirtImageOverride" == "" ]]
+	then
+		[[ -e "$vmImageFile" ]] && _messagePlain_bad 'exists: '"$vmImageFile" && _messageFAIL && _stop 1


-	# WARNING: Now also provides essential information about intel-acm .
-	# Solely to provide more information to convert 'vm-live.iso' back to 'vm.img' offline from only a Live BD-ROM disc .
-	mkdir -p "$safeTmp"/root002
-	#sudo -n cp -a "$globalVirtFS"/boot "$safeTmp"/root002/boot-copy
-	sudo -n rsync -a --progress --exclude "lost+found" "$globalVirtFS"/boot "$safeTmp"/root002/boot-copy
-	sudo -n cp -a "$globalVirtFS"/etc/fstab  "$safeTmp"/root002/fstab-copy
-
-
-
-	_messagePlain_nominal 'Attempt: _closeChRoot'
-	#sudo -n umount "$globalVirtFS"/boot/efi > /dev/null 2>&1
-	#sudo -n umount "$globalVirtFS"/boot > /dev/null 2>&1
-	! "$scriptAbsoluteLocation" _closeChRoot && _messagePlain_bad 'fail: _closeChRoot' && _messageFAIL
-
-
+		_messageNormal 'create: '"$vmImageFile"': file'
+

+		export vmSize=$(_vmsize)
+		[[ "$ub_vmImage_micro" == "true" ]] && export vmSize=$(_vmsize-micro)

+
+		export vmSize_boundary=$(bc <<< "$vmSize - 1")
+		_createRawImage "$vmImageFile"
+	else
+		_messageNormal 'create: '"$vmImageFile"': device'

-	export safeToDeleteGit="true"
-	[[ -e "$scriptLocal"/livefs ]] && _safeRMR "$scriptLocal"/livefs
-	[[ -e "$scriptLocal"/livefs ]] && _messageFAIL
+
+		export vmSize=$(bc <<< $(sudo -n lsblk -b --output SIZE -n -d "$vmImageFile")' / 1048576')
+		export vmSize=$(bc <<< "$vmSize - 1")
+		export vmSize_boundary=$(bc <<< "$vmSize - 1")
+	fi

-	mkdir -p "$scriptLocal"/livefs
-	[[ ! -e "$scriptLocal"/livefs ]] && _messageFAIL

+	_messageNormal 'partition: '"$vmImageFile"''
+	sudo -n parted --script "$vmImageFile" 'mklabel gpt'

-	_messagePlain_nominal 'Attempt: _openImage'
-	! _openImage && _messageFAIL && _stop 1
-	imagedev=$(cat "$scriptLocal"/imagedev)
-	if [[ "$ubVirtImageBoot" != "" ]]
-	then
-		sudo -n mkdir -p "$globalVirtFS"/boot
-		sudo -n mount "$imagedev""$ubVirtImageBoot" "$globalVirtFS"/boot
-	fi
-	if [[ "$ubVirtImageEFI" != "" ]]
-	then
-		sudo -n mkdir -p "$globalVirtFS"/boot/efi
-		sudo -n mount "$imagedev""$ubVirtImageEFI" "$globalVirtFS"/boot/efi
-	fi
+	# Unusual.
+	#   EFI, Image/Root.
+	# Former default, only preferable if disk is strictly spinning CAV and many more bits per second with beginning tracks.
+	#   Swap, EFI, Image/Root.
+	# Compromise. May have better compatibility, may reduce CLV (and zoned CAV) speed changes from slowest tracks at beginning of some optical discs.
+	#   EFI, Swap, Image/Root.
+	# Expect <8MiB usage of EFI parition FAT32 filesystem, ~28GiB usage of Image/Root partition ext4 filesystem.
+	# 512MiB EFI, 5120MiB Swap, remainder Image/Root
+	# https://www.compuhoy.com/what-is-difference-between-bios-and-efi/
+	#  'Does EFI partition have to be first?' 'UEFI does not impose a restriction on the number or location of System Partitions that can exist on a system. (Version 2.5, p. 540.) As a practical matter, putting the ESP first is advisable because this location is unlikely to be impacted by partition moving and resizing operations.'
+	# http://blog.arainho.me/grub/gpt/arch-linux/2016/01/14/grub-on-gpt-partition.html
+	#  'at the first 2GB of the disk with toggle bios_grub used for booting'

-	#/DEBIAN_CUSTOM
-	#/ROOT_TEXT
+	# CAUTION: *As DEFAULT*, must match other definitions (eg. _set_ubDistBuild , 'core.sh' , 'ops.sh' , ubiquitous_bash , etc) .
+	# NTFS, Recovery, partitions should not have set values in any other functions. Never used - documentation only.
+	# Swap, partition should only have set values in this and fstab functions. Never used elsewhere.
+	# x64-bios , raspbian , x64-efi
+	export ubVirtImage_doNotOverride="true"
+	export ubVirtPlatformOverride='x64-efi'
+	export ubVirtImageBIOS=p1
+	export ubVirtImageEFI=p2
+	export ubVirtImageNTFS=
+	export ubVirtImageRecovery=
+	export ubVirtImageSwap=p3
+	export ubVirtImageBoot=p4
+	export ubVirtImagePartition=p5


-	#LIVE_BOOT/chroot
-	#"$globalVirtFS"

-	#LIVE_BOOT/scratch
-	#"$scriptLocal"/livefs/partial

-	#LIVE_BOOT/image
-	#"$scriptLocal"/livefs/image
+	# ATTENTION: NOTICE: Larger EFI partition may be more compatible. Larger Swap partition may be more useful for hibernation.

+	# BIOS
+	sudo -n parted --script "$vmImageFile" 'mkpart primary ext2 1MiB 2MiB'
+	sudo -n parted --script "$vmImageFile" 'set 1 bios_grub on'

-	mkdir -p "$scriptLocal"/livefs/partial
-	mkdir -p "$scriptLocal"/livefs/image/live

-	# TODO: Consider LZO compression and such.
-	# TODO: May need to install live-boot , firmware-amd-graphics
-	#sudo -n mksquashfs "$globalVirtFS" "$scriptLocal"/livefs/image/live/filesystem.squashfs -no-xattrs -noI -noD -noF -noX -comp lzo -Xalgorithm lzo1x_1 -e boot -e etc/fstab
-	#sudo -n mksquashfs "$globalVirtFS" "$scriptLocal"/livefs/image/live/filesystem.squashfs -b  -no-xattrs -noI -noX -comp lzo -Xalgorithm lzo1x_1 -e boot -e etc/fstab
-
-
+	# EFI
+	##sudo -n parted --script "$vmImageFile" 'mkpart EFI fat32 '"2"'MiB '"514"'MiB'
+	#sudo -n parted --script "$vmImageFile" 'mkpart EFI fat32 '"2"'MiB '"74"'MiB'
+	sudo -n parted --script "$vmImageFile" 'mkpart EFI fat32 '"2"'MiB '"42"'MiB'
+	sudo -n parted --script "$vmImageFile" 'set 2 msftdata on'
+	sudo -n parted --script "$vmImageFile" 'set 2 boot on'
+	sudo -n parted --script "$vmImageFile" 'set 2 esp on'
+
+
+	# Swap
+	##sudo -n parted --script "$vmImageFile" 'mkpart primary '"514"'MiB '"5633"'MiB'
+	##sudo -n parted --script "$vmImageFile" 'mkpart primary '"514"'MiB '"3073"'MiB'
+	#sudo -n parted --script "$vmImageFile" 'mkpart primary '"74"'MiB '"98"'MiB'
+	sudo -n parted --script "$vmImageFile" 'mkpart primary '"42"'MiB '"44"'MiB'
+
+
+	# Boot
+	#sudo -n parted --script "$vmImageFile" 'mkpart primary '"98"'MiB '"610"'MiB'
+	#sudo -n parted --script "$vmImageFile" 'mkpart primary '"44"'MiB '"384"'MiB'
+	#sudo -n parted --script "$vmImageFile" 'mkpart primary '"44"'MiB '"592"'MiB'
+	sudo -n parted --script "$vmImageFile" 'mkpart primary '"44"'MiB '"770"'MiB'
+
+
+	# Root
+	# WARNING: Adjust vmSize to match +1MiB .
+	# Try to keep this <23841MiB-256MiB-1MiB ( ie. <23584MiB ) (exactly 25000000000Bytes is 23841MiB ) . In practice, compression will obviate this issue, and the Live ISO may be more complete (ie. including 'accessories') for recovery purposes .
+	# https://www.mail-archive.com/kde-bugs-dist@kde.org/msg618604.html
+	#  '25025315816 bytes'   ...   'difference between the available space at the start and at the end is exactly 256M'
+	# http://fy.chalmers.se/~appro/linux/DVD+RW/Blu-ray/
+	#  '256MB'
+	# https://forum.blu-ray.com/showthread.php?t=76407
+	# https://forum.imgburn.com/topic/23120-overburn-or-truncate-for-blu-rays/
+	# Try to keep this <23GiB-1MiB . Prefer to fit two copies within 46GiB ( eg. 23296MiB == 22.75GiB ) .
+	# Try to keep this <28GiB-1MiB . Prefer to fit at least 18GiB (compressed rootfs tar, squashfs, etc) plus this 28GiB .
+	# Expect 25.75GiB may suffice ( ie. 22.75GiB+5GiB-2GiB ) (assuming 22.75GiB may have been sufficient by ~5GiB until another ~5GiB was added, and from there ~2GiB may have already been freed by other changes) .
+	# Expect 27.75GiB may suffice ( ie. 22.75GiB+5GiB-2GiB ) (assuming 22.75GiB may have been sufficient by ~5GiB until another ~5GiB was added) .

+	# Tested successfully.
+	# 22.75GiB-1MiB
+	#sudo -n parted --script "$vmImageFile" 'mkpart primary '"610"'MiB '"23295"'MiB'

-	#mkdir -p "$safeTmp"/root001
-	#sudo -n cp -a "$globalVirtFS"/home  "$safeTmp"/root001/
+	# 22.95GiB-1MiB
+	##sudo -n parted --script "$vmImageFile" 'mkpart primary '"384"'MiB '"23499"'MiB'

-	#mkdir -p "$safeTmp"/recycle
-	#sudo -n mv -f "$safeTmp"/root001/home/user/* "$safeTmp"/recycle/
-	#sudo -n mv -f "$safeTmp"/recycle/core "$safeTmp"/root001/home/user/
-	#sudo -n chown -R "$USER":"$USER" "$safeTmp"/recycle
-	#_safeRMR "$safeTmp"/recycle
+	# 23841MiB-256MiB-1MiB -2MiB
+	#sudo -n parted --script "$vmImageFile" 'mkpart primary '"384"'MiB '"23582"'MiB'

-	#mkdir -p "$safeTmp"/recycle
-	#sudo -n mv -f "$safeTmp"/root001/home/* "$safeTmp"/recycle/
-	#sudo -n mv -f "$safeTmp"/recycle/user "$safeTmp"/root001/home/
-	#sudo -n chown -R "$USER":"$USER" "$safeTmp"/recycle
-	#_safeRMR "$safeTmp"/recycle
+	# 25.95GiB-1MiB
+	#sudo -n parted --script "$vmImageFile" 'mkpart primary '"384"'MiB '"26571"'MiB'

-	#_messagePlain_probe_cmd ls -ld "$safeTmp"/root001
-	#_messagePlain_probe_cmd ls -ld "$safeTmp"/root001/home
-	#_messagePlain_probe_cmd ls -ld "$safeTmp"/root001/home/user
-	#_messagePlain_probe_cmd ls -ld "$safeTmp"/root001/home/user/core
-	#_messagePlain_probe_cmd ls -l "$safeTmp"/root001/home/user/core/
-
-	#sudo -n mksquashfs "$safeTmp"/root001 "$scriptLocal"/livefs/image/live/filesystem.squashfs -b 65536 -no-xattrs -noI -noX -comp lzo -Xalgorithm lzo1x_1 -e boot -e etc/fstab
-	#sudo -n chown -R "$USER":"$USER" "$safeTmp"/root001
-	#_safeRMR "$safeTmp"/root001
-
-
-	# https://github.com/openwrt/openwrt/issues/9974
-	# http://neoscientists.org/~tmueller/binsort/
-	#sudo -n mksquashfs "$globalVirtFS" "$scriptLocal"/livefs/image/live/filesystem.squashfs -b 262144 -no-xattrs -noI -noX -comp lzo -Xalgorithm lzo1x_1 -e home/user/core -e boot -e etc/fstab
-
-
-
-	# Solely to provide more information to convert 'vm-live.iso' back to 'vm.img' offline from only a Live BD-ROM disc .
-	_messagePlain_nominal 'mksquashfs: root002: boot-copy , fstab-copy'
-	_messagePlain_probe_cmd df -h
-	if ! _messagePlain_probe_cmd sudo -n mksquashfs "$safeTmp"/root002 "$scriptLocal"/livefs/image/live/filesystem.squashfs -b 262144 -no-xattrs -noI -noX -comp lzo -Xalgorithm lzo1x_1 -e boot -e etc/fstab
+	# Tested successfully.
+	# 26.25GiB-1MiB
+	#sudo -n parted --script "$vmImageFile" 'mkpart primary '"384"'MiB '"26879"'MiB'
+
+
+
+	#sudo -n parted --script "$vmImageFile" 'mkpart primary '"384"'MiB '"$vmSize_boundary"'MiB'
+	sudo -n parted --script "$vmImageFile" 'mkpart primary '"770"'MiB '"$vmSize_boundary"'MiB'
+
+	sudo -n parted --script "$vmImageFile" 'unit MiB print'
+
+
+	_close
+
+
+	# Format partitions .
+	_messageNormal 'format: '"$vmImageFile"''
+	#"$scriptAbsoluteLocation" _loopImage_sequence || _stop 1
+	! "$scriptAbsoluteLocation" _openLoop && _messagePlain_bad 'fail: _openLoop' && _messageFAIL
+
+	mkdir -p "$globalVirtFS"
+	"$scriptAbsoluteLocation" _checkForMounts "$globalVirtFS" && _messagePlain_bad 'bad: mounted: globalVirtFS' && _messageFAIL && _stop 1
+	#local imagedev
+	imagedev=$(cat "$scriptLocal"/imagedev)
+
+	local imagepart
+	local loopdevfs
+
+	# Compression from btrfs may free up ~8GB . Some performance degradation may result if files with many random writes (eg. COW VM images) are used with btrfs .
+	# https://www.phoronix.com/scan.php?page=article&item=btrfs-zstd-compress&num=4
+	# https://btrfs.wiki.kernel.org/index.php/Compression
+	# https://unix.stackexchange.com/questions/394973/why-would-i-want-to-disable-copy-on-write-while-creating-qemu-images
+	# https://gist.github.com/niflostancu/03810a8167edc533b1712551d4f90a14
+
+	# WARNING: Compression/btrfs of boot partition may cause BIOS compatibility issues.
+	imagepart="$imagedev""$ubVirtImageBoot"
+	loopdevfs=$(sudo -n blkid -s TYPE -o value "$imagepart" | tr -dc 'a-zA-Z0-9')
+	[[ "$loopdevfs" == "ext4" ]] && _stop 1
+	sudo -n mkfs.ext2 -e remount-ro -E lazy_itable_init=0,lazy_journal_init=0 -m 0 "$imagepart" || _stop 1
+	#sudo -n mkfs.btrfs --checksum xxhash -M -d single "$imagepart" || _stop 1
+
+	imagepart="$imagedev""$ubVirtImageEFI"
+	loopdevfs=$(sudo -n blkid -s TYPE -o value "$imagepart" | tr -dc 'a-zA-Z0-9')
+	[[ "$loopdevfs" == "ext4" ]] && _stop 1
+	sudo -n mkfs.vfat -F 32 -n EFI "$imagepart" || _stop 1
+
+	imagepart="$imagedev""$ubVirtImagePartition"
+	loopdevfs=$(sudo -n blkid -s TYPE -o value "$imagepart" | tr -dc 'a-zA-Z0-9')
+	[[ "$loopdevfs" == "ext4" ]] && _stop 1
+	#sudo -n mkfs.ext4 -e remount-ro -E lazy_itable_init=0,lazy_journal_init=0 -m 0 "$imagepart" || _stop 1
+	sudo -n mkfs.btrfs --checksum xxhash -M -d single "$imagepart" || _stop 1
+
+	imagepart="$imagedev""$ubVirtImageSwap"
+	loopdevfs=$(sudo -n blkid -s TYPE -o value "$imagepart" | tr -dc 'a-zA-Z0-9')
+	[[ "$loopdevfs" == "ext4" ]] && _stop 1
+	sudo -n mkswap "$imagepart" || _stop 1
+
+	#"$scriptAbsoluteLocation" _umountImage || _stop 1
+	! "$scriptAbsoluteLocation" _closeLoop && _messagePlain_bad 'fail: _closeLoop' && _messageFAIL
+	return 0
+}
+# WARNING: No production use. No use as-is. Hybrid/UEFI is default.
+# WARNING: May necessitate 'update-grub' within 'qemu' or similar to remove incorrecly detected running kernel from menu.
+_convertVMimage_sequence() {
+	_messageNormal '_convertVMimage_sequence'
+
+	_messagePlain_nominal '_convertVMimage_sequence: start'
+	_start
+	mkdir -p "$safeTmp"/rootfs
+
+	local imagedev
+
+
+	# ATTENTION: Override if necessary (ie. with 'ops.sh' from an existing image).
+	export ubVirtImage_doNotOverride="true"
+	export ubVirtPlatformOverride='x64-efi'
+	export ubVirtImageBIOS=p1
+	export ubVirtImageEFI=p2
+	export ubVirtImageNTFS=
+	export ubVirtImageRecovery=
+	export ubVirtImageSwap=p3
+	export ubVirtImageBoot=p4
+	export ubVirtImagePartition=p5
+
+
+	_messagePlain_nominal '_convertVMimage_sequence: copy: out'
+	! "$scriptAbsoluteLocation" _openImage && _messagePlain_bad 'fail: _openImage' && _messageFAIL
+	imagedev=$(cat "$scriptLocal"/imagedev)
+	if [[ "$ubVirtImageBoot" != "" ]]
 	then
-		_messageFAIL
-		_stop 1
-		return 1
+		sudo -n mkdir -p "$globalVirtFS"/boot
+		sudo -n mount "$imagedev""$ubVirtImageBoot" "$globalVirtFS"/boot
 	fi
-	du -sh "$scriptLocal"/livefs/image/live/filesystem.squashfs
-	sudo -n chown -R "$USER":"$USER" "$safeTmp"/root002
-	export safeToDeleteGit="true"
-	_safeRMR "$safeTmp"/root002
-	if [[ -e "$safeTmp"/root002 ]]
+	if [[ "$ubVirtImageEFI" != "" ]]
 	then
-		_messageFAIL
-		_stop 1
-		return 1
+		sudo -n mkdir -p "$globalVirtFS"/boot/efi
+		sudo -n mount "$imagedev""$ubVirtImageEFI" "$globalVirtFS"/boot/efi
 	fi
-
-	mkdir -p "$safeTmp"/root001
-	sudo -n mkdir -p "$safeTmp"/root001/home
-	#sudo -n cp -a "$globalVirtFS"/home "$safeTmp"/root001/
-	sudo -n mount --bind "$globalVirtFS"/home "$safeTmp"/root001/home
-	_messagePlain_probe_cmd mountpoint "$safeTmp"/root001/home
-	_messagePlain_probe_cmd sudo -n ls -l "$safeTmp"/root001/home/user/core/
-	_messagePlain_probe_cmd sudo -n du -sh "$safeTmp"/root001/home
-	_messagePlain_nominal 'mksquashfs: root001: home'
-	_messagePlain_probe_cmd df -h
-	if ! _messagePlain_probe_cmd sudo -n mksquashfs "$safeTmp"/root001 "$scriptLocal"/livefs/image/live/filesystem.squashfs -b 262144 -no-xattrs -noI -noX -comp lzo -Xalgorithm lzo1x_1 -e boot -e etc/fstab
+
+
+	sudo -n rsync -ax "$globalVirtFS"/. "$safeTmp"/rootfs/.
+	[[ "$?" != "0" ]] && _messageFAIL
+
+	sudo -n rsync -ax "$globalVirtFS"/boot/. "$safeTmp"/rootfs/boot/.
+	[[ "$?" != "0" ]] && _messageFAIL
+	sudo -n rsync -ax "$globalVirtFS"/boot/efi/. "$safeTmp"/rootfs/boot/efi/.
+	[[ "$?" != "0" ]] && _messageFAIL
+
+
+	sudo -n umount "$globalVirtFS"/boot/efi > /dev/null 2>&1
+	sudo -n umount "$globalVirtFS"/boot > /dev/null 2>&1
+	! "$scriptAbsoluteLocation" _closeImage && _messagePlain_bad 'fail: _closeImage' && _messageFAIL
+
+
+	rm -f "$scriptLocal"/vm.img
+	_createVMimage
+	export ubVirtImage_doNotOverride="true"
+
+
+	_messagePlain_nominal '_convertVMimage_sequence: copy: in'
+	! "$scriptAbsoluteLocation" _openImage && _messagePlain_bad 'fail: _openImage' && _messageFAIL
+	imagedev=$(cat "$scriptLocal"/imagedev)
+	if [[ "$ubVirtImageBoot" != "" ]]
 	then
-		_messageFAIL
-		_stop 1
-		return 1
+		sudo -n mkdir -p "$globalVirtFS"/boot
+		sudo -n mount "$imagedev""$ubVirtImageBoot" "$globalVirtFS"/boot
 	fi
-	du -sh "$scriptLocal"/livefs/image/live/filesystem.squashfs
-	sudo -n umount "$safeTmp"/root001/home
-	if mountpoint "$safeTmp"/root001/home
+	if [[ "$ubVirtImageEFI" != "" ]]
 	then
-		_messageFAIL
-		_stop 1
-		return 1
+		sudo -n mkdir -p "$globalVirtFS"/boot/efi
+		sudo -n mount "$imagedev""$ubVirtImageEFI" "$globalVirtFS"/boot/efi
 	fi
-	sudo -n chown -R "$USER":"$USER" "$safeTmp"/root001
+
+
+	sudo -n rsync -ax "$safeTmp"/rootfs/. "$globalVirtFS"/.
+	[[ "$?" != "0" ]] && _messageFAIL
+
+	sudo -n rsync -ax "$safeTmp"/rootfs/boot/. "$globalVirtFS"/boot/.
+	[[ "$?" != "0" ]] && _messageFAIL
+	sudo -n rsync -ax "$safeTmp"/rootfs/boot/efi/. "$globalVirtFS"/boot/efi/.
+	[[ "$?" != "0" ]] && _messageFAIL
+
+
+	sudo -n umount "$globalVirtFS"/boot/efi > /dev/null 2>&1
+	sudo -n umount "$globalVirtFS"/boot > /dev/null 2>&1
+	! "$scriptAbsoluteLocation" _closeImage && _messagePlain_bad 'fail: _closeImage' && _messageFAIL
+
+
+
+	_createVMbootloader-bios
+	_createVMbootloader-efi
+
+
+	_messagePlain_nominal '_convertVMimage_sequence: stop'
 	export safeToDeleteGit="true"
-	_safeRMR "$safeTmp"/root001
-	if [[ -e "$safeTmp"/root001 ]]
-	then
-		_messageFAIL
-		_stop 1
-		return 1
-	fi
-
-	_messagePlain_nominal 'mksquashfs: globalVirtFS'
-	_messagePlain_probe_cmd df -h
-	if ! _messagePlain_probe_cmd sudo -n mksquashfs "$globalVirtFS" "$scriptLocal"/livefs/image/live/filesystem.squashfs -b 262144 -no-xattrs -noI -noX -comp lzo -Xalgorithm lzo1x_1 -e home -e boot -e etc/fstab
+	if ! _safePath "$safeTmp"/rootfs
 	then
-		_messageFAIL
 		_stop 1
+		exit 1
 		return 1
 	fi
-	du -sh "$scriptLocal"/livefs/image/live/filesystem.squashfs
-
+	#sudo -n rm -rf "$safeTmp"/rootfs
+	sudo -n chown -R "$USER":"$USER" "$safeTmp"/rootfs
+	sudo -n chmod -R 700 "$safeTmp"/rootfs
+	_safeRMR "$safeTmp"/rootfs
+	_stop
+}
+_convertVMimage() {
+	"$scriptAbsoluteLocation" _convertVMimage_sequence "$@"
+}


+# Creates a raw VM image. UEFI partitioning and formatting (expected possibility of eventual MSW dual-boot compatibility).
+_createVMimage-efi() {
+	false
+}


+# Creates a raw VM image. BIOS partitioning and formatting (legacy compatibility, possibly with some cloud providers).
+_createVMimage-bios() {
+	false
+}





+_createVMbootloader-bios() {
+	_messageNormal '##### _createVMbootloader-bios'

-	local currentFilesList
-
+	! "$scriptAbsoluteLocation" _openChRoot && _messagePlain_bad 'fail: _openChRoot' && _messageFAIL
+	local imagedev
+	imagedev=$(cat "$scriptLocal"/imagedev)

-	# ATTENTION: Configure, remove extra vmlinuz/initrd files, or accept possibility of matching an undesired kernel version.
-	#currentFilesList=( "$globalVirtFS"/boot/vmlinuz-* )
+	_createVMfstab

-	# Usually, +1 will be highest version mainline, +2 will be lts, +3 will be much older from distribution.
-	currentFilesList=$(ls -A -1 "$globalVirtFS"/boot/vmlinuz-* | sort -r -V | tail -n+1 | head -n1)
-	#currentFilesList=( $(ls -A -1 "$globalVirtFS"/boot/vmlinuz-* | sort -r -V | tail -n+1 | head -n2) )
-	#currentFilesList=$(ls -A -1 "$globalVirtFS"/boot/vmlinuz-* | sort -r -V | tail -n+2 | head -n1)
-	#currentFilesList=$(ls -A -1 "$globalVirtFS"/boot/vmlinuz-* | sort -r -V | tail -n+3 | head -n1)

-	cp "${currentFilesList[0]}" "$scriptLocal"/livefs/image/vmlinuz
-
-	currentFilesList=$(ls -A -1 "$globalVirtFS"/boot/vmlinuz-* | sort -r -V | tail -n+2 | head -n1)
-	cp "${currentFilesList[0]}" "$scriptLocal"/livefs/image/vmlinuz-lts
+	_messagePlain_nominal 'chroot: grub-install: bios'

+	# WARNING: Apparently, any use of BIOS bootloader either needs at least a 'BIOS boot partition' to share with EFI, or needs a dedicated '/boot' for 'btrfs' compression.
+	# https://bbs.archlinux.org/viewtopic.php?id=251059
+	#  'btrfs' 'zstd compression' 'properly installing the bootloader to a dedicated partitioning designed and maintained for that purpose'
+	# https://unix.stackexchange.com/questions/273329/can-i-install-grub2-on-a-flash-drive-to-boot-both-bios-and-uefi
+	#  'precondition for this to work is that you use GPT partitioning and that you have an BIOS boot partition (1 MiB is enough).'
+	# https://en.wikipedia.org/wiki/BIOS_boot_partition
+	#_chroot grub2-install --modules=part_msdos --target=i386-pc "$imagedev"

-	#currentFilesList=( "$globalVirtFS"/boot/initrd.img-* )

-	currentFilesList=$(ls -A -1 "$globalVirtFS"/boot/initrd.img-* | sort -r -V | tail -n+1 | head -n1)
-	#currentFilesList=( $(ls -A -1 "$globalVirtFS"/boot/initrd.img-* | sort -r -V | tail -n+1 | head -n2) )
-	#currentFilesList=$(ls -A -1 "$globalVirtFS"/boot/initrd.img-* | sort -r -V | tail -n+2 | head -n1)
-	#currentFilesList=$(ls -A -1 "$globalVirtFS"/boot/initrd.img-* | sort -r -V | tail -n+3 | head -n1)
+	_messagePlain_probe_cmd _chroot grub-install --modules=part_msdos --target=i386-pc "$imagedev"
+	_messagePlain_probe_cmd _chroot grub-install --force --modules=part_msdos --target=i386-pc "$imagedev""$ubVirtImageEFI"

-	cp "${currentFilesList[0]}" "$scriptLocal"/livefs/image/initrd
-
-	currentFilesList=$(ls -A -1 "$globalVirtFS"/boot/initrd.img-* | sort -r -V | tail -n+2 | head -n1)
-	cp "${currentFilesList[0]}" "$scriptLocal"/livefs/image/initrd-lts

-
+	_messagePlain_nominal 'chroot: update-grub'
+	_chroot update-grub

-	cp "$globalVirtFS"/boot/tboot* "$scriptLocal"/livefs/image/
-	cp "$globalVirtFS"/boot/*.bin "$scriptLocal"/livefs/image/
+	_messagePlain_nominal 'chroot: update-initramfs'
+	_chroot update-initramfs -u

-	_live_grub_here > "$scriptLocal"/livefs/partial/grub.cfg
-	touch "$scriptLocal"/livefs/image/ROOT_TEXT

-	_messagePlain_nominal 'Attempt: _closeImage'
-	sudo -n umount "$globalVirtFS"/boot/efi > /dev/null 2>&1
-	sudo -n umount "$globalVirtFS"/boot > /dev/null 2>&1
-	! _closeImage && _messageFAIL && _stop 1


+	! "$scriptAbsoluteLocation" _closeChRoot && _messagePlain_bad 'fail: _closeChRoot' && _messageFAIL
+	return 0
+}
+
+_createVMbootloader-efi() {
+	_messageNormal '##### _createVMbootloader-efi'

+	! "$scriptAbsoluteLocation" _openChRoot && _messagePlain_bad 'fail: _openChRoot' && _messageFAIL
+	local imagedev
+	imagedev=$(cat "$scriptLocal"/imagedev)

-	_write_revert_live
+	_createVMfstab


+	_messagePlain_nominal 'chroot: grub-install: efi'

-	grub-mkstandalone --format=x86_64-efi --output="$scriptLocal"/livefs/partial/bootx64.efi --locales="" --fonts="" "boot/grub/grub.cfg="$scriptLocal"/livefs/partial/grub.cfg"
+	# https://unix.stackexchange.com/questions/273329/can-i-install-grub2-on-a-flash-drive-to-boot-both-bios-and-uefi
+	#  'precondition for this to work is that you use GPT partitioning and that you have an BIOS boot partition (1 MiB is enough).'
+	# https://en.wikipedia.org/wiki/BIOS_boot_partition
+	# https://askubuntu.com/questions/705055/gpt-detected-please-create-a-bios-boot-partition
+	#  'must be located at the start of a GPT disk, and have a "bios_grub" flag' 'Size: 1MB.'
+	#_chroot grub2-install --modules=part_msdos --target=i386-pc "$imagedev"


-	cd "$scriptLocal"/livefs/partial
-	dd if=/dev/zero of="$scriptLocal"/livefs/partial/efiboot.img bs=1M count=10
-	"$(sudo -n bash -c 'type -p mkfs.vfat' || echo /sbin/mkfs.vfat)" "$scriptLocal"/livefs/partial/efiboot.img
-	mmd -i "$scriptLocal"/livefs/partial/efiboot.img efi efi/boot
-	mcopy -i "$scriptLocal"/livefs/partial/efiboot.img "$scriptLocal"/livefs/partial/bootx64.efi ::efi/boot/
-	cd "$scriptLocal"/livefs
+	_messagePlain_probe_cmd _chroot grub-install --boot-directory=/boot --root-directory=/ --modules=part_msdos --target=x86_64-efi --efi-directory=/boot/efi --bootloader-id=debian --recheck --no-nvram --removable "$imagedev"
+	_messagePlain_probe_cmd _chroot grub-install --boot-directory=/boot --root-directory=/ --modules=part_msdos --target=x86_64-efi --efi-directory=/boot/efi --bootloader-id=debian --recheck --no-nvram --removable "$imagedev""$ubVirtImageEFI"

+	_messagePlain_probe_cmd _chroot grub-install --boot-directory=/boot --root-directory=/ --modules=part_msdos --target=x86_64-efi --efi-directory=/boot/efi --recheck "$imagedev"

+	#sudo -n mkdir -p "$globalVirtFS"/boot/efi/EFI/BOOT/
+	#sudo -n cp "$globalVirtFS"/boot/efi/EFI/debian/grubx64.efi "$globalVirtFS"/boot/efi/EFI/BOOT/bootx64.efi

-	grub-mkstandalone --format=i386-pc --output="$scriptLocal"/livefs/partial/core.img --install-modules="linux normal iso9660 biosdisk memdisk search tar ls" --modules="linux normal iso9660 biosdisk search" --locales="" --fonts="" "boot/grub/grub.cfg="$scriptLocal"/livefs/partial/grub.cfg"

+	_messagePlain_nominal 'chroot: update-grub'
+	_chroot update-grub

-	cat /usr/lib/grub/i386-pc/cdboot.img "$scriptLocal"/livefs/partial/core.img > "$scriptLocal"/livefs/partial/bios.img
+	_messagePlain_nominal 'chroot: update-initramfs'
+	_chroot update-initramfs -u




+	! "$scriptAbsoluteLocation" _closeChRoot && _messagePlain_bad 'fail: _closeChRoot' && _messageFAIL
+	return 0
+}
+
+
+
+
+
+
+
+
+_createVMfstab() {
+	_messageNormal 'os: globalVirtFS: write: fs: _createVMfstab'


+	local imagedev
+	imagedev=$(cat "$scriptLocal"/imagedev)

-	_stop 0
-}
-_live_sequence_out() {
-	[[ ! -e "$scriptLocal"/livefs ]] && _messageFAIL
-	_start
+	[[ ! -e "$imagedev" ]] && _messageFAIL

+	sudo -n mkdir -p "$globalVirtFS"/media/bootdisc
+	sudo -n chmod 755 "$globalVirtFS"/media/bootdisc

-	xorriso -as mkisofs -iso-level 3 -full-iso9660-filenames -volid "ROOT_TEXT" -eltorito-boot boot/grub/bios.img -no-emul-boot -boot-load-size 4 -boot-info-table --eltorito-catalog boot/grub/boot.cat --grub2-boot-info --grub2-mbr /usr/lib/grub/i386-pc/boot_hybrid.img -eltorito-alt-boot -e EFI/efiboot.img -no-emul-boot -append_partition 2 0xef "$scriptLocal"/livefs/partial/efiboot.img -output "$safeTmp"/live.iso -graft-points "$scriptLocal"/livefs/image /boot/grub/bios.img="$scriptLocal"/livefs/partial/bios.img /EFI/efiboot.img="$scriptLocal"/livefs/partial/efiboot.img

+	# https://gist.github.com/varqox/42e213b6b2dde2b636ef#edit-fstab-file

-	mv "$safeTmp"/live.iso "$scriptLocal"/vm-live.iso
+	#btrfs rescue zero-log /dev/sda5

+	local ubVirtImagePartition_UUID
+	ubVirtImagePartition_UUID=$(sudo -n blkid -s UUID -o value "$imagedev""$ubVirtImagePartition" | tr -dc 'a-zA-Z0-9\-')

+	#echo 'UUID='"$ubVirtImagePartition_UUID"' / ext4 errors=remount-ro 0 1' | sudo -n tee "$globalVirtFS"/etc/fstab
+	#echo 'UUID='"$ubVirtImagePartition_UUID"' / btrfs defaults,compress=zstd:1,notreelog 0 1' | sudo -n tee "$globalVirtFS"/etc/fstab
+	echo 'UUID='"$ubVirtImagePartition_UUID"' / btrfs defaults,compress=zstd:1,notreelog,discard=async 0 1' | sudo -n tee "$globalVirtFS"/etc/fstab


-	_messageNormal '_live: done'
+	# initramfs-update, from chroot, may not enable hibernation/resume... may be device specific

-	_stop 0
-}
-_live() {
-	if ! "$scriptAbsoluteLocation" _live_sequence_in "$@"
+	if [[ "$ubVirtImageSwap" != "" ]]
 	then
-		_stop 1
+		local ubVirtImageSwap_UUID
+		ubVirtImageSwap_UUID=$(sudo -n blkid -s UUID -o value "$imagedev""$ubVirtImageSwap" | tr -dc 'a-zA-Z0-9\-')
 	fi

-	#rm -f "$scriptLocal"/vm.img
+	echo '#UUID='"$ubVirtImageSwap_UUID"' swap swap defaults 0 0' | sudo -n tee -a "$globalVirtFS"/etc/fstab

-	if ! "$scriptAbsoluteLocation" _live_sequence_out "$@"
+
+	if [[ "$ubVirtImageBoot" != "" ]]
 	then
-		_stop 1
+		local ubVirtImageBoot_UUID
+		ubVirtImageBoot_UUID=$(sudo -n blkid -s UUID -o value "$imagedev""$ubVirtImageBoot" | tr -dc 'a-zA-Z0-9\-')
 	fi

-	export safeToDeleteGit="true"
-	_safeRMR "$scriptLocal"/livefs
+	echo 'UUID='"$ubVirtImageBoot_UUID"' /boot ext2 defaults 0 1' | sudo -n tee -a "$globalVirtFS"/etc/fstab


-	#! _live_more && _stop 1
+	if [[ "$ubVirtImageEFI" != "" ]]
+	then
+		local ubVirtImageEFI_UUID
+		ubVirtImageEFI_UUID=$(sudo -n blkid -s UUID -o value "$imagedev""$ubVirtImageEFI" | tr -dc 'a-zA-Z0-9\-')
+	fi

-	#return 0
-}
-
-
-_override_VBox-live() {
-	#export ub_keepInstance='true'
-	export ub_override_vbox_livecd_more="$scriptLocal"/vm-live-more.vdi
-	#export ub_override_vbox_livecd_more="$scriptLocal"/vm-live-more.iso
-	#export ub_override_vbox_livecd="$scriptLocal"/vm-live.iso
-}
-
-
-_userVBoxLive() {
-	_override_VBox-live
+	echo 'UUID='"$ubVirtImageEFI_UUID"' /boot/efi vfat umask=0077 0 1' | sudo -n tee -a "$globalVirtFS"/etc/fstab

-	_userVBox "$@"
-}
-
-_editVBoxLive() {
-	_override_VBox-live

-	_editVBox "$@"
-}
-
-_persistentVBoxLive() {
-	_override_VBox-live
+	if ! sudo -n cat "$globalVirtFS"/etc/fstab | grep 'uk4uPhB663kVcygT0q' | grep 'bootdisc' > /dev/null 2>&1
+	then
+		echo 'LABEL=uk4uPhB663kVcygT0q /media/bootdisc iso9660 ro,nofail 0 0' | sudo -n tee -a "$globalVirtFS"/etc/fstab
+	fi

-	_persistentVBox "$@"
+	# WARNING: May be untested.
+	echo '' | sudo -n tee -a "$globalVirtFS"/etc/fstab
+	echo '#none /var/spool/cups ramfs defaults,uid=0,gid=7,umask=007,dmask=007,fmask=117,size=800M 0 0' | sudo -n tee -a "$globalVirtFS"/etc/fstab
+	echo '#none /var/cache/cups ramfs defaults,uid=0,gid=7,umask=007,dmask=000,fmask=007,size=800M 0 0' | sudo -n tee -a "$globalVirtFS"/etc/fstab
+	echo '' | sudo -n tee -a "$globalVirtFS"/etc/fstab
+
+	return 0
 }


-_override_qemu-live() {
-	#export ub_keepInstance='true'
-	export ub_override_qemu_livecd_more="$scriptLocal"/vm-live-more.iso
-	#export ub_override_qemu_livecd="$scriptLocal"/vm-live.iso
-}





-_userQemuLive() {
-	_override_qemu-live
-
-	_userQemu "$@"
-}

-_editQemuLive() {
-	_override_qemu-live
+_vm_convert_vdi() {
+	_messagePlain_nominal '_vm_convert_vdi: convert: vdi'

-	_editQemu "$@"
-}
-
-_persistentQemuLive() {
-	_override_qemu-live
+	_override_bin_vbox

-	_persistentQemu "$@"
-}
-
-
-
-
-#Ensures dependencies are met for raspi-on-raspi virtualization.
-_testQEMU_raspi-raspi() {
-	true
-}
-
-_testQEMU_hostArch_x64-raspi() {
-	local hostArch
-	hostArch=$(uname -m)
+	# ATTENTION: Delete 'vm.vdi.uuid' to force generation of new uuid .
+	local current_UUID
+	current_UUID=$(head -n1 "$scriptLocal"/vm.vdi.uuid 2>/dev/null | tr -dc 'a-zA-Z0-9\-')

-	if [[ "$hostArch" != "x86_64" ]]
+	if [[ $(echo "$current_UUID" | wc -c) != 37 ]]
 	then
-		return 1
+		current_UUID=$(_getUUID)
+		rm -f "$scriptLocal"/vm.vdi.uuid > /dev/null 2>&1
+		echo "$current_UUID" > "$scriptLocal"/vm.vdi.uuid
 	fi

-	return 0
-}
-
-_testQEMU_x64-raspi() {

-	_testQEMU_x64-x64
-	_getDep qemu-arm-static
-	_getDep qemu-armeb-static
+	rm -f "$scriptLocal"/vm.vdi > /dev/null 2>&1

-	_getDep qemu-system-arm
-	_getDep qemu-system-aarch64
+	! [[ -e "$scriptLocal"/vm.img ]] && _messagePlain_bad 'fail: missing: in file' && return 1
+	[[ -e "$scriptLocal"/vm.vdi ]] && _messagePlain_request 'request: rm '"$scriptLocal"/vm.vdi && return 1

+	_messagePlain_nominal '_img_to_vdi: convertdd'
+	if _userVBoxManage convertdd "$scriptLocal"/vm.img "$scriptLocal"/vm-c.vdi --format VDI
+	then
+		#_messagePlain_nominal '_img_to_vdi: closemedium'
+		#_userVBoxManage closemedium "$scriptLocal"/vm-c.vdi
+		_messagePlain_nominal '_img_to_vdi: mv vm-c.vdi vm.vdi'
+		_moveconfirm "$scriptLocal"/vm-c.vdi "$scriptLocal"/vm.vdi
+		_messagePlain_nominal '_img_to_vdi: setuuid'
+		VBoxManage internalcommands sethduuid "$scriptLocal"/vm.vdi "$current_UUID"
+		#_messagePlain_request 'request: rm '"$scriptLocal"/vm.img
+		_messagePlain_good 'End.'
+		return 0
+	else
+		_messageFAIL
+		_stop 1
+	fi
+}
+
+_vm_convert_vmdk() {
+	_messagePlain_nominal '_vm_convert_vmdk: convert: vmdk'

-	_mustGetSudo
+	_override_bin_vbox

-	! _testQEMU_hostArch_x64-raspi && echo "warn: not checking x64 translation" && return 0
+	# ATTENTION: Delete 'vm.vmdk.uuid' to force generation of new uuid .
+	local current_UUID
+	current_UUID=$(head -n1 "$scriptLocal"/vm.vmdk.uuid 2>/dev/null | tr -dc 'a-zA-Z0-9\-')

-	#\|Raspbian
-	if [[ -e /etc/issue ]] && cat /etc/issue | grep 'Debian\|Ubuntu' > /dev/null 2>&1
+	if [[ $(echo "$current_UUID" | wc -c) != 37 ]]
 	then
-		_getDep update-binfmts
+		current_UUID=$(_getUUID)
+		rm -f "$scriptLocal"/vm.vmdk.uuid > /dev/null 2>&1
+		echo "$current_UUID" > "$scriptLocal"/vm.vmdk.uuid
 	fi


-	sudo -n systemctl status binfmt-support 2>&1 | head -n 2 | grep -i 'chroot' > /dev/null && return 0
-	systemctl status binfmt-support 2>&1 | head -n 2 | grep -i 'chroot' > /dev/null && return 0
+	rm -f "$scriptLocal"/vm.vmdk > /dev/null 2>&1

-	sudo -n systemctl restart binfmt-support > /dev/null 2>&1
-
-	sudo -n service binfmt-support --full-restart > /dev/null 2>&1
-	service binfmt-support --full-restart > /dev/null 2>&1
+	! [[ -e "$scriptLocal"/vm.img ]] && _messagePlain_bad 'fail: missing: in file' && return 1
+	[[ -e "$scriptLocal"/vm.vmdk ]] && _messagePlain_request 'request: rm '"$scriptLocal"/vm.vmdk && return 1

-	if ! sudo -n cat /proc/sys/fs/binfmt_misc/* 2> /dev/null | grep qemu | grep 'arm$\|arm-static$\|arm-binfmt-P$\|arm-binfmt' > /dev/null 2>&1 && ! _if_cygwin
-	then
-		echo 'binfmts does not mention qemu-arm'
-		[[ "$INSTANCE_ID" == "" ]] && _stop 1
-	fi
+	_messagePlain_nominal '_img_to_vmdk: convertdd'

-	if ! sudo -n cat /proc/sys/fs/binfmt_misc/* 2> /dev/null | grep qemu | grep 'armeb$\|armeb-static$\|armeb-binfmt-P$\|armeb-binfmt' > /dev/null 2>&1 && ! _if_cygwin
+
+	# https://stackoverflow.com/questions/454899/how-to-convert-flat-raw-disk-image-to-vmdk-for-virtualbox-or-vmplayer
+	if _userVBoxManage convertdd "$scriptLocal"/vm.img "$scriptLocal"/vm-c.vmdk --format VMDK
+	#if qemu-img convert -O vmdk "$scriptLocal"/vm.img "$scriptLocal"/vm-c.vmdk
 	then
-		echo 'binfmts does not mention qemu-armeb'
-		[[ "$INSTANCE_ID" == "" ]] && _stop 1
+		#_messagePlain_nominal '_img_to_vmdk: closemedium'
+		#_userVBoxManage closemedium "$scriptLocal"/vm-c.vmdk
+		_messagePlain_nominal '_img_to_vmdk: mv vm-c.vmdk vm.vmdk'
+		_moveconfirm "$scriptLocal"/vm-c.vmdk "$scriptLocal"/vm.vmdk
+		_messagePlain_nominal '_img_to_vmdk: setuuid'
+
+
+		#VBoxManage internalcommands sethduuid "$scriptLocal"/vm.vmdk "$current_UUID"
+		VBoxManage internalcommands sethduuid "$scriptLocal"/vm.vmdk "$current_UUID"
+
+
+		#_messagePlain_request 'request: rm '"$scriptLocal"/vm.img
+		_messagePlain_good 'End.'
+		return 0
+	else
+		_messageFAIL
+		_stop 1
 	fi
-
-	return 0
 }


-
-_testQEMU_hostArch_x64_hardwarevt() {
-	#[[ -e /dev/kvm ]] && (grep -i svm /proc/cpuinfo > /dev/null 2>&1 || grep -i vmx /proc/cpuinfo > /dev/null 2>&1)
+_vm_convert_vhd() {
+	_messagePlain_nominal '_vm_convert_vhd: convert: vhd'

-	! [[ -e /dev/kvm ]] && return 1
+	_override_bin_vbox

-	grep -i svm /proc/cpuinfo > /dev/null 2>&1 && return 0
-	grep -i vmx /proc/cpuinfo > /dev/null 2>&1 && return 0
+	# ATTENTION: Delete 'vm.vhd.uuid' to force generation of new uuid .
+	local current_UUID
+	current_UUID=$(head -n1 "$scriptLocal"/vm.vhd.uuid 2>/dev/null | tr -dc 'a-zA-Z0-9\-')

-	return 1
-}
-
-_testQEMU_hostArch_x64_nested() {
-	grep '1' /sys/module/kvm_amd/parameters/nested > /dev/null 2>&1 && return 0
-	grep 'Y' /sys/module/kvm_amd/parameters/nested > /dev/null 2>&1 && return 0
-	grep '1' /sys/module/kvm_intel/parameters/nested > /dev/null 2>&1 && return 0
-	grep 'Y' /sys/module/kvm_intel/parameters/nested > /dev/null 2>&1 && return 0
+	if [[ $(echo "$current_UUID" | wc -c) != 37 ]]
+	then
+		current_UUID=$(_getUUID)
+		rm -f "$scriptLocal"/vm.vhd.uuid > /dev/null 2>&1
+		echo "$current_UUID" > "$scriptLocal"/vm.vhd.uuid
+	fi

-	return 1
-}
-
-_testQEMU_hostArch_x64-x64() {
-	local hostArch
-	hostArch=$(uname -m)

-	if [[ "$hostArch" != "x86_64" ]]
+	rm -f "$scriptLocal"/vm.vhd > /dev/null 2>&1
+
+	! [[ -e "$scriptLocal"/vm.img ]] && _messagePlain_bad 'fail: missing: in file' && return 1
+	[[ -e "$scriptLocal"/vm.vhd ]] && _messagePlain_request 'request: rm '"$scriptLocal"/vm.vhd && return 1
+
+	_messagePlain_nominal '_img_to_vhd: convertdd'
+	if _userVBoxManage convertdd "$scriptLocal"/vm.img "$scriptLocal"/vm-c.vhd --format VHD
 	then
-		return 1
+		#_messagePlain_nominal '_img_to_vhd: closemedium'
+		#_userVBoxManage closemedium "$scriptLocal"/vm-c.vhd
+		_messagePlain_nominal '_img_to_vhd: mv vm-c.vhd vm.vhd'
+		_moveconfirm "$scriptLocal"/vm-c.vhd "$scriptLocal"/vm.vhd
+		_messagePlain_nominal '_img_to_vhd: setuuid'
+		VBoxManage internalcommands sethduuid "$scriptLocal"/vm.vhd "$current_UUID"
+		#_messagePlain_request 'request: rm '"$scriptLocal"/vm.img
+		_messagePlain_good 'End.'
+		return 0
+	else
+		_messageFAIL
+		_stop 1
 	fi
+}
+
+
+
+
+
+
+
+
+_test_live_debianpackages() {
+	! dpkg-query -W grub-pc-bin > /dev/null 2>&1 && echo 'warn: missing: grub-pc-bin'
+	! dpkg-query -W grub-efi-amd64-bin > /dev/null 2>&1 && echo 'warn: missing: grub-efi-amd64-bin'

 	return 0
 }

-_testQEMU_x64-x64() {
-	_testQEMU_hostArch_x64-x64 || echo "warn: no native x64"
-	_testQEMU_hostArch_x64_hardwarevt || echo "warn: no x64 vt"
-	_testQEMU_hostArch_x64_nested || echo "warn: no nested x64"
+_test_live() {
+	_getDep debootstrap
+	#_getDep squashfs-tools
+	_getDep xorriso
+	#_getDep grub-pc-bin
+	#_getDep grub-efi-amd64-bin
+	_getDep mtools

-	_getDep qemu-system-x86_64
-	_getDep qemu-img

-	_getDep smbd
+	_getDep mksquashfs
+	_getDep grub-mkstandalone

-	_wantGetDep /usr/share/OVMF/OVMF_CODE.fd
-	_wantGetDep /usr/share/qemu/OVMF.fd
+	_getDep mkfs.vfat
+
+	_getDep mkswap
+
+
+	_getDep mmd
+	_getDep mcopy
+
+
+	_getDep grub/i386-pc/cdboot.img
+	_getDep grub/i386-pc/boot_hybrid.img
+
+
+	[[ -e '/sbin/fdisk' ]] && _getDep fdisk
+	[[ -e '/sbin/sfdisk' ]] && _getDep sfdisk
+
+
+	# Currently only Debian is supported as a build host.
+	_test_live_debianpackages
+
+
+	#_getDep VBoxManage
+	_getDep qemu-img
+
+	return 0
 }

-_qemu-system() {
-	qemu-system-x86_64 "$@"
+
+
+
+_live_fdisk() {
+	if [[ -e '/sbin/fdisk' ]]
+	then
+		sudo -n /sbin/fdisk "$@"
+		return
+	fi
+	sudo -n fdisk "$@"
+	return
 }

-#Overload this function, or the guestArch variable, to configure QEMU with specialized parameters.
-_qemu_system_x86_64() {
-	qemu-system-x86_64 "$@"
+_live_sfdisk() {
+	if [[ -e '/sbin/sfdisk' ]]
+	then
+		sudo -n /sbin/sfdisk "$@"
+		return
+	fi
+	sudo -n sfdisk "$@"
+	return
 }

-_qemu_system_arm() {
-	qemu-system-arm "$@"
+
+
+
+
+
+
+
+
+# https://manpages.debian.org/testing/live-boot-doc/persistence.conf.5.en.html
+ # WARNING: 'persistence.conf' ... 'root of its file system' ... 'Any such labeled volume must have such a file, or it will be ignored.'
+_live_persistent_conf_here() {
+	cat <<'CZXWXcRMTo8EmM8i4d'
+/ union
+#/home union
+CZXWXcRMTo8EmM8i4d
 }

-_qemu_system_aarch64() {
-	qemu-system-aarch64 "$@"
+_live_more_copy() {
+	_messagePlain_nominal '_live_more_copy'
+
+	rm -f "$scriptLocal"/vm-live-more.iso
+
+	cp "$scriptLocal"/vm-live.iso "$scriptLocal"/vm-live-more.iso
 }

-_integratedQemu_imagefilename() {
-	if [[ "$ubVirtDiskOverride" == "" ]]
-	then
-		local current_imagefilename
-		if ! current_imagefilename=$(_loopImage_imagefilename)
-		then
-			_messagePlain_bad 'fail: missing: vm*.img'
-			return 1
-		fi
-	else
-		current_imagefilename="$ubVirtDiskOverride"
-	fi
+_live_more_move() {
+	_messagePlain_nominal '_live_more_move'

-	echo "$current_imagefilename"
+	rm -f "$scriptLocal"/vm-live-more.iso

-	return 0
+	mv "$scriptLocal"/vm-live.iso "$scriptLocal"/vm-live-more.iso
 }

-# ATTENTION: Override with 'ops' or similar.
-_integratedQemu_x64_display() {
+_live_more_procedure() {
+	_messageNormal 'init: _live_more_procedure'

-	#qemuArgs+=(-device virtio-vga,virgl=on -display gtk,gl=on)
+	#_start

-	#return 0

+	[[ ! -e "$scriptLocal"/vm-live-more.iso ]] && _messageFAIL && _stop 1

-	true

-	#

-	# https://www.kraxel.org/blog/2019/09/display-devices-in-qemu/
-	[[ "$qemuOStype" == "" ]] && [[ "$vboxOStype" != "" ]] && qemuOStype="$vboxOStype"
-	if [[ "$ub_override_qemu_livecd" != '' ]] || [[ "$ub_override_qemu_livecd_more" != '' ]]
-	then
-		# DANGER: Beware not all "qemu" emulated "display" 'devices' seem to support 'hibernation' ('suspend to disk') !
-		# At least 'qxl-vga' is known to successfully resume .
-		# Assume 'livecd' is 'linux' .
-		#qemuArgs+=(-device qxl-vga -display gtk)
-		qemuArgs+=(-device qxl-vga)
-	elif [[ "$qemuOStype" == 'Debian_64' ]] || [[ "$qemuOStype" == 'Gentoo_64' ]]
-	then
-		# Not yet enabled (virtio-vga) by default for a few reasons.
-		# *) May need to specify 'gtk' or 'sdl' to enable OpenGL acceleration. If these backends are missing, qemu may fail.
-		# *) Some guest configurations (eg. LXDE and Linux 4.x instead of KDE/Plasma and Linux 5.x) may not continue updating guest display resize requests, ultimately causing guest to remain at low resolution (ie. 640x480) .
-		# *) Hardware graphics should only be necessary for a few specific applications (eg. FreeCAD, VR).
-		# *) Any use of 'virtio-vga' seems not to support 'linux' 'hibernation' ('suspend to disk') .
-		# https://github.com/mate-desktop/marco/issues/338
-		if [[ "$qemuNoGL" == 'true' ]]
-		then
-			qemuArgs+=(-device qxl-vga)
-			#qemuArgs+=(-device virtio-vga,virgl=on -display gtk,gl=off)
-		else
-			qemuArgs+=(-device qxl-vga)
-			#qemuArgs+=(-device virtio-vga,virgl=on -display gtk,gl=on)
-		fi
-	elif [[ "$qemuOStype" == 'Windows10_64' ]] || [[ "$qemuOStype" == 'Windows11_64' ]]
-	then
-		# WARNING: MSW11 may require 256MB VRAM. How this may be set by qemu is not obvious.
-		# https://blogs.oracle.com/virtualization/post/install-microsoft-windows-11-on-virtualbox
-		#qemuArgs+=(-device qxl)
-		qemuArgs+=(-device qxl-vga)
-	elif [[ "$qemuOStype" == 'WindowsXP' ]] || [[ "$qemuOStype" == 'legacy-obsolete' ]]
-	then
-		qemuArgs+=(-vga cirrus)
-	else
-		qemuArgs+=(-vga std)
-	fi
-}
-
-_integratedQemu_x64() {
-	_messagePlain_nominal 'init: _integratedQemu_x64'

-	[[ "$qemuOStype" == "" ]] && [[ "$vboxOStype" != "" ]] && qemuOStype="$vboxOStype"


-	local current_imagefilename
-	if ! current_imagefilename=$(_integratedQemu_imagefilename)
-	then
-		_stop 1
-	fi

+	_messagePlain_nominal '_live_more_procedure: append'

-	! mkdir -p "$instancedVirtDir" && _messagePlain_bad 'fail: mkdir -p instancedVirtDir= '"$instancedVirtDir" && _stop 1
+	# 32 * 1000 MB to GiB == 29.8023224 GiB
+	# 29.8 GB to MiB == 28419 MiB

-	! _commandBootdisc "$@" && _messagePlain_bad 'fail: _commandBootdisc' && _stop 1
+	# 1024 MiB to GiB == 1 GiB
+	# 1 GiB == 1073.74 MB
+	# 1024 MB + 64 MB == 1088 MB

-	#qemu-system-x86_64 -snapshot -machine accel=kvm -drive format=raw,file="$scriptLocal"/vm.img -drive file="$hostToGuestISO",media=cdrom -boot c -m 768
+	# 1088 * 12 + 32 == 13088 MB

-	#https://wiki.qemu.org/Documentation/9psetup#Mounting_the_shared_path
-	#qemu-system-x86_64 -snapshot -machine accel=kvm -drive format=raw,file="$scriptLocal"/vm.img -drive file="$hostToGuestISO",media=cdrom -boot c -m 768 -fsdev local,id=appFolder,path="$sharedHostProjectDir",security_model=mapped,writeout=writeout
+	dd if=/dev/zero bs=1M count=13088 >> "$scriptLocal"/vm-live-more.iso

-	#https://askubuntu.com/questions/614098/unable-to-get-execute-bit-on-samba-share-working-with-windows-7-client
-	#https://unix.stackexchange.com/questions/165554/shared-folder-between-qemu-windows-guest-and-linux-host
-	#https://linux.die.net/man/1/qemu-kvm

-	qemuArgs+=(-usb)

-	if _testQEMU_hostArch_x64_nested
-	then
-		_messagePlain_good 'supported: nested x64'
-
-		# WARNING: Nested virtualization support currently disabled by default. May impose frequent software updates or commonality between host/guest.
-		# Fail for Debian Buster/Stretch host/guest.
-		# Reasonably expected to fail with proprietary guest.
-		# https://bugzilla.redhat.com/show_bug.cgi?id=1565179
-
-		# ATTENTION: Overload "demandNestKVM" with "ops" or similar.
-		if [[ "$demandNestKVM" == 'true' ]] #|| ( ! [[ "$virtOStype" == 'MSW'* ]] && ! [[ "$virtOStype" == 'Windows'* ]] && ! [[ "$qemuOStype" == 'Windows'* ]] )
-		then
-			[[ "$demandNestKVM" == 'true' ]] && _messagePlain_warn 'force: nested x64'
-			_messagePlain_warn 'warn: set: nested x64'
-			qemuArgs+=(-cpu host)
-		else
-			_messagePlain_good 'unset: nested x64'
-		fi
-
-	else
-		_messagePlain_warn 'missing: nested x64'
-	fi
+	_messagePlain_nominal '_live_more_procedure: partitions: add'

-	local hostThreadCount=$(cat /proc/cpuinfo | grep MHz | wc -l | tr -dc '0-9')
-	if [[ "$hostThreadCount" -ge "4" ]] || [[ "$hostThreadCount" -ge "8" ]]
-	then
-		[[ "$hostThreadCount" -ge "4" ]] && [[ "$hostThreadCount" -lt "8" ]] && _messagePlain_probe 'cpu: >4' && qemuArgs+=(-smp 4)
-		[[ "$hostThreadCount" -ge "8" ]] && _messagePlain_probe 'cpu: >6' && qemuArgs+=(-smp 6)
-	else
-		# Single-threaded host with guest 'efi', 'Windows10_64', 'Windows11_64', are all not plausible. Minimum dual-CPU requirement of MSW11 as default.
-		# ATTENTION: For guests benefitting from single core performance only, force such non-default by exporting 'vboxCPUs' with 'ops' or similar.
-		if [[ "$ubVirtPlatform" == *'efi' ]] || [[ "$ubVirtPlatformOverride" == *'efi' ]] || [[ "$qemuOStype" == "Win"*"10"* ]] || [[ "$qemuOStype" == "Win"*"11"* ]]
-		then
-			qemuArgs+=(-smp 2)
-		fi
-	fi
+	#sudo -n parted --script "$scriptLocal"/vm-live-more.iso mklabel msdos
+	#sudo -n partprobe > /dev/null 2>&1
+	#sudo -n parted "$scriptLocal"/vm-live-more.iso --script -- mkpart primary 0% 100%
+	#sudo -n partprobe > /dev/null 2>&1

-	#https://superuser.com/questions/342719/how-to-boot-a-physical-windows-partition-with-qemu
-	#qemuUserArgs+=(-drive format=raw,file="$scriptLocal"/vm.img)
-	#qemuUserArgs+=(-drive format=raw,file="$current_imagefilename")
-	if [[ "$ub_override_qemu_livecd" != '' ]]
-	then
-		qemuUserArgs+=(-drive file="$ub_override_qemu_livecd",media=cdrom)
-	elif [[ "$ub_override_qemu_livecd_more" != '' ]]
-	then
-		qemuUserArgs+=(-drive format=raw,file="$ub_override_qemu_livecd_more")
-	else
-		qemuUserArgs+=(-drive format=raw,file="$current_imagefilename")
-	fi
+	# https://unix.stackexchange.com/questions/200582/scripteable-gpt-partitions-using-parted

-	qemuUserArgs+=(-drive file="$hostToGuestISO",media=cdrom -boot c)
+	#sudo -n parted "$scriptLocal"/vm-live-more.iso --script -a optimal -- mkpart primary -12288MiB -8192MiB
+	#sudo -n parted "$scriptLocal"/vm-live-more.iso --script -a optimal -- mkpart primary -8192MiB -4096MiB
+	#sudo -n parted "$scriptLocal"/vm-live-more.iso --script -a optimal -- mkpart primary -4096MiB -0MiB
+	#sudo -n partprobe > /dev/null 2>&1

-	[[ "$vmMemoryAllocation" == "" ]] && vmMemoryAllocation="$vmMemoryAllocationDefault"

-	# Must have at least 4096MB for 'livecd' , unless even larger memory allocation has been configured .
-	if [[ "$ub_override_qemu_livecd" != '' ]] || [[ "$ub_override_qemu_livecd_more" != '' ]]
-	then
-		if [[ "$vmMemoryAllocation" -lt 4096 ]]
-		then
-			vmMemoryAllocation=4096
-		fi
-	fi

-	#[[ "$ubVirtPlatform" == *'efi' ]] || [[ "$ubVirtPlatformOverride" == *'efi' ]]
-	if [[ "$vmMemoryAllocation" -lt 8704 ]] && ( [[ "$qemuOStype" == "Win"*"10"* ]] || [[ "$qemuOStype" == "Win"*"11"* ]] )
-	then
-		vmMemoryAllocation=8704
-	fi
+	# https://superuser.com/questions/332252/how-to-create-and-format-a-partition-using-a-bash-script

-	qemuUserArgs+=(-m "$vmMemoryAllocation")
+	! _live_sfdisk -l "$scriptLocal"/vm-live-more.iso | grep 'Sector size (logical/physical): 512 bytes / 512 bytes' > /dev/null 2>&1 && _stop 1

-	[[ "$qemuUserArgs_netRestrict" == "" ]] && qemuUserArgs_netRestrict="n"
+	rm -f "$safeTmp"/vm-live-more.iso.sfdisk

-	qemuUserArgs+=(-net nic,model=rtl8139 -net user,restrict="$qemuUserArgs_netRestrict",smb="$sharedHostProjectDir")
+	#_live_sfdisk -d "$scriptLocal"/vm-live-more.iso > "$safeTmp"/vm-live-more.iso.sfdisk
+	#echo 'size=8G, type=83' >> "$safeTmp"/vm-live-more.iso.sfdisk

-	#qemuArgs+=(-usbdevice tablet)
-	qemuArgs+=(-device usb-tablet)
+	#echo 'size=4G, type=83' >> "$safeTmp"/vm-live-more.iso.sfdisk
+	#echo 'size=5G, type=5' >> "$safeTmp"/vm-live-more.iso.sfdisk
+	#echo 'size=4G, type=85' >> "$safeTmp"/vm-live-more.iso.sfdisk

+	#echo 'size=1G, type=85' >> "$safeTmp"/vm-live-more.iso.sfdisk


-	_integratedQemu_x64_display
+	echo 'size=2G, type=83' >> "$safeTmp"/vm-live-more.iso.sfdisk
+	echo 'type=5' >> "$safeTmp"/vm-live-more.iso.sfdisk
+	echo 'size=4G, type=82' >> "$safeTmp"/vm-live-more.iso.sfdisk
+	echo 'size=6G, type=83' >> "$safeTmp"/vm-live-more.iso.sfdisk


+	# Tested , working .
+	#echo 'size=4G, type=82' >> "$safeTmp"/vm-live-more.iso.sfdisk
+	#echo 'size=6G, type=83' >> "$safeTmp"/vm-live-more.iso.sfdisk

-	[[ "$qemuArgs_audio" == "" ]] && qemuArgs+=(-device ich9-intel-hda -device hda-duplex)

-	# https://github.com/elisa-tech/meta-elisa/issues/23
-	# https://wiki.qemu.org/ChangeLog/6.0
-	# qemuArgs+=(-show-cursor)
-	local current_qemu_version_cursor
-	current_qemu_version_cursor=$(_qemu_system_x86_64 -version | grep version | sed 's/.*version\ //' | sed 's/\ .*//' | cut -f1 -d\. | tr -dc '0-9')
-	if [[ "$current_qemu_version_cursor" -lt "6" ]] && [[ "$current_qemu_version_cursor" != "" ]]
-	then
-		qemuArgs+=(-show-cursor)
-	fi
+	cat "$safeTmp"/vm-live-more.iso.sfdisk | _live_sfdisk --append "$scriptLocal"/vm-live-more.iso

-	if _testQEMU_hostArch_x64_hardwarevt
-	then
-		_messagePlain_good 'found: kvm'
-		qemuArgs+=(-machine accel=kvm)
-	else
-		_messagePlain_warn 'missing: kvm'
-	fi
+	! _live_sfdisk -l "$scriptLocal"/vm-live-more.iso | grep 'Sector size (logical/physical): 512 bytes / 512 bytes' > /dev/null 2>&1 && _stop 1


-	# https://blog.matejc.com/blogs/myblog/playing-on-qemu
-	# https://www.kraxel.org/repos/jenkins/edk2/
-	# https://www.kraxel.org/repos/
-	# https://unix.stackexchange.com/questions/52996/how-to-boot-efi-kernel-using-qemu-kvm
-	# https://blog.hartwork.org/posts/get-qemu-to-boot-efi/
-	# https://www.kraxel.org/repos/jenkins/edk2/
-	# https://www.kraxel.org/repos/jenkins/edk2/edk2.git-ovmf-x64-0-20200515.1447.g317d84abe3.noarch.rpm
-	if ( [[ "$ubVirtPlatform" == "x64-efi" ]] || [[ "$qemuOStype" == "Win"*"10"* ]] || [[ "$qemuOStype" == "Win"*"11"* ]] ) && [[ "$ub_override_qemu_livecd" == '' ]] && [[ "$ub_override_qemu_livecd_more" == '' ]]
-	then
-		if [[ -e "$HOME"/core/installations/ovmf/OVMF_CODE-pure-efi.fd ]] && [[ -e "$HOME"/core/installations/ovmf/OVMF_VARS-pure-efi.fd ]]
-		then
-			qemuArgs+=(-drive if=pflash,format=raw,readonly,file="$HOME"/core/installations/ovmf/OVMF_CODE-pure-efi.fd -drive if=pflash,format=raw,file="$HOME"/core/installations/ovmf/OVMF_VARS-pure-efi.fd)
-		elif [[ -e /usr/share/OVMF/OVMF_CODE.fd ]]
-		then
-			qemuArgs+=(-bios /usr/share/OVMF/OVMF_CODE.fd)
-		else
-			# Bootloader is not declared as other than legacy bios type.
-			# Do nothing by default. Loading an EFI bootloader with CSM module may cause unwanted delay.
-			true
-		fi
-	fi

-	qemuArgs+=("${qemuSpecialArgs[@]}" "${qemuUserArgs[@]}")

-	_messagePlain_probe _qemu_system_x86_64 "${qemuArgs[@]}"
-	_qemu_system_x86_64 "${qemuArgs[@]}"

-	_safeRMR "$instancedVirtDir" || _stop 1
-}
-
-# DANGER: Do NOT call without snapshot on RasPi images intended for real (ie. arm64, "RPI3") hardware! Untested!
-# WARNING: NOT recommended. Severely restricted performance and features.
-#https://azeria-labs.com/emulate-raspberry-pi-with-qemu/
-#https://www.raspberrypi.org/forums/viewtopic.php?t=195565
-#https://github.com/dhruvvyas90/qemu-rpi-kernel
-#qemu-system-arm -kernel ./kernel-raspi -cpu arm1176 -m 256 -M versatilepb -serial stdio -append "root=/dev/sda2 rootfstype=ext4 rw" -hda ./vm-raspbian.img -redir tcp:5022::22 -no-reboot
-#qemu-system-arm -kernel ./kernel-raspi -cpu arm1176 -m 256 -M versatilepb -dtb versatile-pb.dtb -no-reboot -append "root=/dev/sda2 panic=1 rootfstype=ext4 rw" -net nic -net user,hostfwd=tcp::5022-:22 -hda ./vm-raspbian.img
-#https://raspberrypi.stackexchange.com/questions/45936/has-anyone-managed-to-run-raspberry-pi-3-with-kvm-enabled
-#https://wiki.qemu.org/Documentation/Platforms/ARM
-#https://github.com/bztsrc/raspi3-tutorial
-#https://translatedcode.wordpress.com/2018/04/25/debian-on-qemus-raspberry-pi-3-model/
-_integratedQemu_raspi() {
-	_messagePlain_nominal 'init: _integratedQemu_raspi'


-	local current_imagefilename
-	if ! current_imagefilename=$(_integratedQemu_imagefilename)
-	then
-		_stop 1
-	fi
+	_messagePlain_nominal '_live_more_procedure: filesystems: format'


-	! mkdir -p "$instancedVirtDir" && _messagePlain_bad 'fail: mkdir -p instancedVirtDir= '"$instancedVirtDir" && _stop 1

-	! _commandBootdisc "$@" && _messagePlain_bad 'fail: _commandBootdisc' && _stop 1
+	_messagePlain_nominal 'Attempt: _closeLoop'
+	! _closeLoop && _messageFAIL && _stop 1

-	! [[ -e "$scriptLocal"/kernel-raspi ]] && _messagePlain_bad 'fail: missing: kernel-raspi' && _messagePlain_probe 'request: obtain kernel-raspi : https://github.com/dhruvvyas90/qemu-rpi-kernel'
-	! [[ -e "$scriptLocal"/kernel-raspi ]] && _messagePlain_bad 'fail: missing: versatile-pb.dtb' && _messagePlain_probe 'request: obtain versatile-pb.dtb : https://github.com/dhruvvyas90/qemu-rpi-kernel'
-	qemuUserArgs+=(-kernel "$scriptLocal"/kernel-raspi -cpu arm1176 -M versatilepb -dtb "$scriptLocal"/versatile-pb.dtb -append "root=/dev/sda2 panic=1 rootfstype=ext4 rw" -no-reboot)
-	#qemuUserArgs+=(-kernel "$scriptLocal"/kernel-raspi -M raspi3 -append "root=/dev/sda2 rootfstype=ext4 rw" -no-reboot)
-	#qemuUserArgs+=(-kernel "$scriptLocal"/kernel-raspi -M virt -bios /usr/share/qemu-efi/QEMU_EFI.fd -append "root=/dev/sda2 panic=1 rootfstype=ext4 rw" -no-reboot)
-	#qemuUserArgs+=(-kernel "$scriptLocal"/kernel-raspi -cpu arm1176 -M virt -bios /usr/share/qemu-efi/QEMU_EFI.fd -append "root=/dev/sda2 panic=1 rootfstype=ext4 rw" -no-reboot)
+	_messagePlain_nominal 'Attempt: _openLoop'
+	! [[ -e "$scriptLocal"/vm-live-more.iso ]] && _messageFAIL && _stop 1
+	export ubVirtImageOverride_alternate="$scriptLocal"/vm-live-more.iso
+	! _openLoop && _messageFAIL && _stop 1

-	#local hostThreadCount=$(cat /proc/cpuinfo | grep MHz | wc -l | tr -dc '0-9')
-	#[[ "$hostThreadCount" -ge "4" ]] && _messagePlain_probe 'cpu: >4' && qemuArgs+=(-smp 4)
+	local current_imagedev
+	current_imagedev=$(cat "$scriptLocal"/imagedev)

-	#https://superuser.com/questions/342719/how-to-boot-a-physical-windows-partition-with-qemu
-	#qemuUserArgs+=(-drive format=raw,file="$scriptLocal"/vm-raspbian.img)
-	qemuUserArgs+=(-drive format=raw,file="$current_imagefilename")
+	[[ "$current_imagedev" != '/dev/loop'* ]] && _messageFAIL && _stop 1


-	#qemuUserArgs+=(-drive if=none,id=uas-cdrom,media=cdrom,file="$hostToGuestISO" -device nec-usb-xhci,id=xhci -device usb-uas,id=uas,bus=xhci.0 -device scsi-cd,bus=uas.0,scsi-id=0,lun=5,drive=uas-cdrom)
+	! _live_sfdisk -l "$current_imagedev" | grep 'Sector size (logical/physical): 512 bytes / 512 bytes' > /dev/null 2>&1 && _messageFAIL && _stop 1

-	qemuUserArgs+=(-drive file="$hostToGuestISO",media=cdrom -boot c)
+	! _live_sfdisk -l "$current_imagedev" | grep "$current_imagedev"p3 | grep '4194304' > /dev/null 2>&1 && _messageFAIL && _stop 1
+	! _live_sfdisk -l "$current_imagedev" | grep "$current_imagedev"p5 | grep '8388608' > /dev/null 2>&1 && _messageFAIL && _stop 1
+	! _live_sfdisk -l "$current_imagedev" | grep "$current_imagedev"p6 | grep '12582912' > /dev/null 2>&1 && _messageFAIL && _stop 1

-	#[[ "$vmMemoryAllocation" == "" ]] && vmMemoryAllocation="$vmMemoryAllocationDefault"
-	#qemuUserArgs+=(-m "$vmMemoryAllocation")
-	qemuUserArgs+=(-m 256)
+	! [[ -e "$current_imagedev"p6 ]] && _messageFAIL && _stop 1

-	# ATTENTION: Overload with "ops" or similar.
-	[[ "$qemuUserArgs_netRestrict" == "" ]] && qemuUserArgs_netRestrict="n"
-	#[[ "$qemuUserArgs_net_guestSSH" == "" ]] && qemuUserArgs_net_guestSSH=",hostfwd=tcp::5022-:22"
-	[[ "$qemuUserArgs_net_guestSSH" == "" ]] && qemuUserArgs_net_guestSSH=""

-	#qemuUserArgs+=(-net nic,model=rtl8139 -net user,restrict="$qemuUserArgs_netRestrict",smb="$sharedHostProjectDir")
-	qemuUserArgs+=(-net nic -net user,restrict="$qemuUserArgs_netRestrict""$qemuUserArgs_net_guestSSH",smb="$sharedHostProjectDir")
+	sudo -n mkfs.ext4 -L 'bulk' -U 'f1edb7fb-13b1-4c97-91d2-baf50e6d65d8' "$current_imagedev"p3
+	sudo -n mkswap -L 'hint' -U '469457fc-293f-46ec-92da-27b5d0c36b17' "$current_imagedev"p5
+	sudo -n mkfs.ext4 -L 'dent' -U 'd82e3d89-3156-4484-bde2-ccc534ca440b' "$current_imagedev"p6

-	#qemuArgs+=(-usbdevice tablet)

-	#qemuArgs+=(-vga cirrus)

-	#[[ "$qemuArgs_audio" == "" ]] && qemuArgs+=(-device ich9-intel-hda -device hda-duplex)
+	# https://manpages.debian.org/testing/live-boot-doc/persistence.conf.5.en.html
+	 # WARNING: 'persistence.conf' ... 'root of its file system' ... 'Any such labeled volume must have such a file, or it will be ignored.'
+	mkdir -p "$safeTmp"/fsmount_temp/bulk
+	sudo -n mount "$current_imagedev"p3 "$safeTmp"/fsmount_temp/bulk

-	#qemuArgs+=(-show-cursor)
+	_live_persistent_conf_here | sudo tee "$safeTmp"/fsmount_temp/bulk/persistence.conf > /dev/null

-	qemuUserArgs+=(-serial stdio)
+	sudo -n mkdir -p "$safeTmp"/fsmount_temp/bulk/persist/bulk
+	_live_persistent_conf_here | sudo tee "$safeTmp"/fsmount_temp/bulk/persist/persistence.conf > /dev/null
+	_live_persistent_conf_here | sudo tee "$safeTmp"/fsmount_temp/bulk/persist/bulk/persistence.conf > /dev/null

-	qemuArgs+=("${qemuSpecialArgs[@]}" "${qemuUserArgs[@]}")

-	_messagePlain_probe _qemu_system_arm "${qemuArgs[@]}"
-	_qemu_system_arm "${qemuArgs[@]}"
-	#_messagePlain_probe _qemu_system_aarch64 "${qemuArgs[@]}"
-	#_qemu_system_aarch64 "${qemuArgs[@]}"
+	sudo -n umount "$safeTmp"/fsmount_temp/bulk

-	_safeRMR "$instancedVirtDir" || _stop 1
-}
-
-_integratedQemu() {
-	# Include platform determination code for correct determination of partition and mounts.
-	_loopImage_imagefilename > /dev/null 2>&1

-	if [[ "$ubVirtPlatform" == "x64-bios" ]]
-	then
-		_integratedQemu_x64 "$@"
-		return "$?"
-	fi
+	#_live_sfdisk -l "$current_imagedev"
+	#ls -l "$current_imagedev"*
+	#sudo -n gparted "$current_imagedev" "$current_imagedev"p1 "$current_imagedev"p2 "$current_imagedev"p3 "$current_imagedev"p5 "$current_imagedev"p6

-	if [[ "$ubVirtPlatform" == "x64-efi" ]]
-	then
-		_integratedQemu_x64 "$@"
-		return "$?"
-	fi
-
-	# TODO: 'efi' .
-	#https://unix.stackexchange.com/questions/52996/how-to-boot-efi-kernel-using-qemu-kvm

-	if [[ "$ubVirtPlatform" == "raspbian" ]]
-	then
-		_integratedQemu_raspi "$@"
-		return "$?"
-	fi
+	_messagePlain_nominal 'Attempt: _closeLoop'
+	! _closeLoop && _messageFAIL && _stop 1

-	#Default x64 .
-	if [[ "$ub_keepInstance" == 'true' ]]
-	then
-		_integratedQemu_x64 "$@"
-		return "$?"
-	fi
-	"$scriptAbsoluteLocation" _integratedQemu_x64 "$@"
-	return "$?"
-}
-
-#"${qemuSpecialArgs[@]}" == ["-snapshot "]
-_userQemu_sequence() {
-	unset qemuSpecialArgs
+	export ubVirtImageOverride_alternate=

-	qemuSpecialArgs+=("-snapshot")

-	export qemuSpecialArgs

-	_start

-	_integratedQemu "$@" || _stop 1

-	_stop
-}
-
-_userQemu() {
-	_findInfrastructure_virtImage ${FUNCNAME[0]} "$@"
-	[[ "$ubVirtImageLocal" == "false" ]] && return

-	if [[ "$ub_keepInstance" == 'true' ]]
-	then
-		_userQemu_sequence "$@"
-		return
-	fi
-	"$scriptAbsoluteLocation" _userQemu_sequence "$@"
-}
-
-_editQemu_sequence() {
-	unset qemuSpecialArgs

-	export qemuSpecialArgs
+	_messageNormal '_live_more_procedure: done'

+	#_stop 0
+}
+_live_more_sequence() {
 	_start

-	#_messageNormal "Checking lock."
-	#_readLocked "$scriptLocal"/_qemuEdit && _messageError 'lock: _qemuEdit' && _stop 1
-	#! _createLocked "$scriptLocal"/_qemuEdit  && _messageError 'lock: _qemuEdit' && _stop 1
-
-	_messageNormal "Checking lock and conflicts."
-	export specialLock="$lock_open_qemu"
-	! _open true true && _messageError 'FAIL' && _stop 1
-
-	_messageNormal "Launch: _integratedQemu."
-	! _integratedQemu "$@" && _messageError 'FAIL' && _stop 1
-
-	rm -f "$scriptLocal"/_qemuEdit > /dev/null 2>&1
-	export specialLock="$lock_open_qemu"
-	! _close true true && _messageError 'FAIL' && _stop 1
-
-	_stop
-}
-
-# DANGER: Do NOT call without snapshot on RasPi images intended for real (ie. arm64, "RPI3") hardware! Untested!
-_editQemu() {
-	_findInfrastructure_virtImage ${FUNCNAME[0]} "$@"
-	[[ "$ubVirtImageLocal" == "false" ]] && return
+	_live_more_procedure "$@"

-	if [[ "$ub_keepInstance" == 'true' ]]
-	then
-		_editQemu_sequence "$@"
-		return
-	fi
-	"$scriptAbsoluteLocation" _editQemu_sequence "$@"
+	_stop 0
 }

-_persistentQemu() {
-	_editQemu "$@"
-}

-_testVBox() {
-	if ( [[ -e /etc/issue ]] && cat /etc/issue | grep 'Debian' > /dev/null 2>&1 ) || ( [[ -e /etc/issue ]] && cat /etc/issue | grep 'Ubuntu' > /dev/null 2>&1 )
-	then
-		if ! dpkg -l | grep linux-headers-$(uname -r) > /dev/null 2>&1
-		then
-			sudo -n apt-get install -y linux-headers-$(uname -r)
-		fi
-	fi
-
-	_getDep VirtualBox
-	_getDep VBoxSDL
-	_getDep VBoxManage
-	_getDep VBoxHeadless
-
-	#sudo -n checkDep dkms
-
-	! _noFireJail virtualbox && _stop 1
+_live_more_convert_vdi() {
+	_messagePlain_nominal '_live_more_convert_vdi: convert: vdi'

-	return 0
-}
-
-
-_checkVBox_raw() {
-	#Use existing VDI image if available.
-	[[ -e "$scriptLocal"/vm.vdi ]] && _messagePlain_bad 'conflict: vm.vdi' && return 1

-	# WARNING: Only 'vm.img' is supported as a raw image file name for vbox virtualization backend.
-	[[ ! -e "$scriptLocal"/vm.img ]] && _messagePlain_bad 'missing: vm.img' && return 1
+	# ATTENTION: Delete 'vm-live-more.vdi.uuid' to force generation of new uuid .
+	local current_UUID
+	current_UUID=$(head -n1 "$scriptLocal"/vm-live-more.vdi.uuid 2>/dev/null | tr -dc 'a-zA-Z0-9\-')

-	return 0
-}
-
-# WARNING
-# Per VirtualBox developers, "This is a development tool and shall only be used to analyse problems. It is completely unsupported and will change in incompatible ways without warning."
-# If that happens, this function will be revised quickly, possibly to the point of generating the VMDK file itself with a here document instead of VirtualBox commands. See "_diag/data/vmdkRawExample".
-_create_vbox_raw() {
-	if ! VBoxManage internalcommands createrawvmdk -filename "$vboxRaw" -rawdisk "$1" > "$vboxRaw".log
+	if [[ $(echo "$current_UUID" | wc -c) != 37 ]]
 	then
-		_messagePlain_bad 'fail: 'VBoxManage internalcommands createrawvmdk -filename "$vboxRaw" -rawdisk "$1" '>' "$vboxRaw".log
+		current_UUID=$(_getUUID)
+		rm -f "$scriptLocal"/vm-live-more.vdi.uuid > /dev/null 2>&1
+		echo "$current_UUID" > "$scriptLocal"/vm-live-more.vdi.uuid
 	fi
-	return 0
-}
-
-_mountVBox_raw_sequence() {
-	_messagePlain_nominal 'start: _mountVBox_raw_sequence'
-	_start
-
-	_checkVBox_raw || _stop 1
-
-	! _wantSudo && _messagePlain_bad 'bad: sudo' && return 1
-
-	_prepare_instance_vbox

-	rm -f "$vboxRaw" > /dev/null 2>&1

+	rm -f "$scriptLocal"/vm-live-more.vdi > /dev/null 2>&1

+	! [[ -e "$scriptLocal"/vm-live-more.iso ]] && _messagePlain_bad 'fail: missing: in file' && return 1
+	[[ -e "$scriptLocal"/vm-live-more.vdi ]] && _messagePlain_request 'request: rm '"$scriptLocal"/vm-live-more.vdi && return 1

-	if _tryExecFull _hook_systemd_shutdown_action "_closeVBoxRaw" "$sessionid"
+	_messagePlain_nominal '_img_to_vdi: convertdd'
+	if _userVBoxManage convertdd "$scriptLocal"/vm-live-more.iso "$scriptLocal"/vm-live-more-c.vdi --format VDI
 	then
-		_messagePlain_good 'pass: _hook_systemd_shutdown_action'
+		#_messagePlain_nominal '_img_to_vdi: closemedium'
+		#_userVBoxManage closemedium "$scriptLocal"/vm-live-more-c.vdi
+		_messagePlain_nominal '_img_to_vdi: mv vm-live-more-c.vdi vm.vdi'
+		_moveconfirm "$scriptLocal"/vm-live-more-c.vdi "$scriptLocal"/vm-live-more.vdi
+		_messagePlain_nominal '_img_to_vdi: setuuid'
+		VBoxManage internalcommands sethduuid "$scriptLocal"/vm-live-more.vdi "$current_UUID"
+		#_messagePlain_request 'request: rm '"$scriptLocal"/vm-live-more.iso
+		_messagePlain_good 'End.'
+		return 0
 	else
-		_messagePlain_bad 'fail: _hook_systemd_shutdown_action'
+		_messageFAIL
+		_stop 1
 	fi
+}
+
+_live_more_convert_vmdk() {
+	_messagePlain_nominal '_live_more_convert_vmdk: convert: vmdk'


+	# ATTENTION: Delete 'vm-live-more.vmdk.uuid' to force generation of new uuid .
+	local current_UUID
+	current_UUID=$(head -n1 "$scriptLocal"/vm-live-more.vmdk.uuid 2>/dev/null | tr -dc 'a-zA-Z0-9\-')

+	if [[ $(echo "$current_UUID" | wc -c) != 37 ]]
+	then
+		current_UUID=$(_getUUID)
+		rm -f "$scriptLocal"/vm-live-more.vmdk.uuid > /dev/null 2>&1
+		echo "$current_UUID" > "$scriptLocal"/vm-live-more.vmdk.uuid
+	fi

-	local current_imagefilename
-	current_imagefilename=$(_loopImage_imagefilename)
-
-	_messagePlain_nominal 'Creating loopback.'
-
-	# Echo error message.
-	[[ -e "$scriptLocal"/vboxloop ]] && _messagePlain_bad 'fail: copy vboxloop' && _stop 1
-
-	! _loopFull "$scriptLocal"/vboxloop && _messagePlain_bad 'fail: losetup' && _stop 1

+	rm -f "$scriptLocal"/vm-live-more.vmdk > /dev/null 2>&1

+	! [[ -e "$scriptLocal"/vm-live-more.iso ]] && _messagePlain_bad 'fail: missing: in file' && return 1
+	[[ -e "$scriptLocal"/vm-live-more.vmdk ]] && _messagePlain_request 'request: rm '"$scriptLocal"/vm-live-more.vmdk && return 1

-	local vboximagedev
-	vboximagedev=$(cat "$scriptLocal"/vboxloop)
+	_messagePlain_nominal '_img_to_vmdk: convertdd'


-	if _detect_deviceAsVirtImage "$current_imagefilename"
+	# https://stackoverflow.com/questions/454899/how-to-convert-flat-raw-disk-image-to-vmdk-for-virtualbox-or-vmplayer
+	if _userVBoxManage convertdd "$scriptLocal"/vm-live-more.iso "$scriptLocal"/vm-live-more-c.vmdk --format VMDK
+	#if qemu-img convert -O vmdk "$scriptLocal"/vm-live-more.iso "$scriptLocal"/vm-live-more-c.vmdk
 	then
-		_messagePlain_warn 'warn: chown: ignoring device'
+		#_messagePlain_nominal '_img_to_vmdk: closemedium'
+		#_userVBoxManage closemedium "$scriptLocal"/vm-live-more-c.vmdk
+		_messagePlain_nominal '_img_to_vmdk: mv vm-live-more-c.vmdk vm.vmdk'
+		_moveconfirm "$scriptLocal"/vm-live-more-c.vmdk "$scriptLocal"/vm-live-more.vmdk
+		_messagePlain_nominal '_img_to_vmdk: setuuid'
+
+
+		#VBoxManage internalcommands sethduuid "$scriptLocal"/vm-live-more.vmdk "$current_UUID"
+		VBoxManage internalcommands sethduuid "$scriptLocal"/vm-live-more.vmdk "$current_UUID"
+
+
+		#_messagePlain_request 'request: rm '"$scriptLocal"/vm-live-more.iso
+		_messagePlain_good 'End.'
+		return 0
 	else
-		! sudo -n chown "$USER" "$vboximagedev" && _messagePlain_bad 'chown vboximagedev= '"$vboximagedev" && _stop 1
+		_messageFAIL
+		_stop 1
 	fi
-
-
-	_messagePlain_nominal 'Creating VBoxRaw.'
-	_create_vbox_raw "$vboximagedev"
-
-
-
-	_messagePlain_nominal 'stop: _mountVBox_raw_sequence'
-	#_safeRMR "$instancedVirtDir" || _stop 1
-	_rm_instance_vbox || _stop 1
-	_stop 0
 }

-_mountVBox_raw() {
-	"$scriptAbsoluteLocation" _mountVBox_raw_sequence
-	return "$?"
-}

-_waitVBox_opening() {
-	! [[ -e "$vboxRaw" ]] && return 1
-	! [[ -e "$scriptLocal"/vboxloop ]] && return 1
-
-	local vboximagedev=$(cat "$safeTmp"/vboxloop)
-	! [[ -e "$vboximagedev" ]] && return 1
-}

-_umountVBox_raw() {
-	! _umountFull "$scriptLocal"/vboxloop && _stop 1
-
-	rm -f "$scriptLocal"/vboxloop > /dev/null 2>&1
-	rm -f "$vboxRaw" > /dev/null 2>&1
-	rm -f "$vboxRaw".log > /dev/null 2>&1
-
-	return 0
-}

-_waitVBox_closing() {
-	true
-}

-_openVBoxRaw() {
-	export specialLock="$lock_open_vbox"
-
-	_checkVBox_raw || _stop 1
-
-	_messagePlain_nominal 'launch: _open _waitVBox_opening _mountVBox_raw'
-
-	local openVBoxRaw_exitStatus
-	_open _waitVBox_opening _mountVBox_raw
-	openVBoxRaw_exitStatus="$?"
-
-	export specialLock=""
-
-	return "$openVBoxRaw_exitStatus"
+# Extra features for the exceptional situation of storing multiple hibernation states, as would be available through 'suspend/snapshot' features of VirtualBox, VMWare, etc, but for computers which do not have such features.
+# End users should not normally be expected to use 'live-more.iso' as a disk image for a personal workstation computer.
+# NOTICE: Such features may not be completely automatic.
+# Only iso filesystem will show to 'sudo gparted /dev/sda' . As usual, do NOT rely on '/dev/sda' (may become instead eg. '/dev/sdb').
+#sudo gparted /dev/sda1 /dev/sda2 /dev/sda3 /dev/sda4 /dev/sda5 ...
+#sudo swapon /dev/sda5
+#sudo mount /dev/sda6 /mnt/dent
+# Hibernate, Reboot/Ignore, ...
+#sudo dd if=/dev/sda5 of=/mnt/dent bs=1M status=progress
+#_bupStore ...
+_live_more() {
+	_live_more_copy "$@"
+	#_live_more_move "$@"
+	"$scriptAbsoluteLocation" _live_more_sequence "$@"
 }

-_closeVBoxRaw() {
-	_findInfrastructure_virtImage ${FUNCNAME[0]} "$@"
-	[[ "$ubVirtImageLocal" == "false" ]] && return
-
-	export specialLock="$lock_open_vbox"
-
-	if [[ "$1" == "--force" ]]
-	then
-		_close --force _waitVBox_closing _umountVBox_raw
-		[[ "$1" != "" ]] && _tryExecFull _unhook_systemd_shutdown "$1"
-		export specialLock=""
-		return 0
-	fi
-
-	_close _waitVBox_closing _umountVBox_raw
-	[[ "$1" != "" ]] && _tryExecFull _unhook_systemd_shutdown "$1"
-	export specialLock=""
-	return 0
-}

-##VBox Boxing
-_wait_lab_vbox() {
-	_prepare_lab_vbox || return 1
-
-	VBoxXPCOMIPCD_PID=$(cat "$VBoxXPCOMIPCD_PIDfile" 2> /dev/null)
-	#echo -e '\E[1;32;46mWaiting for VBoxXPCOMIPCD to finish... \E[0m'
-	while kill -0 "$VBoxXPCOMIPCD_PID" > /dev/null 2>&1
-	do
-		sleep 0.2
-	done
-}

-#Not routine.
-_remove_lab_vbox() {
-	_prepare_lab_vbox || return 1
-
-	_wait_lab_vbox
-
-	#echo -e '\E[1;32;46mRemoving IPC folder and vBoxHome directory symlink from filesystem.\E[0m'
-
-	rm -f /tmp/\.vbox-"$VBOX_IPC_SOCKETID"-ipc/ipcd > /dev/null 2>&1
-	rm -f /tmp/\.vbox-"$VBOX_IPC_SOCKETID"-ipc/lock > /dev/null 2>&1
-	rmdir /tmp/\.vbox-"$VBOX_IPC_SOCKETID"-ipc > /dev/null 2>&1
-
-	rm -f "$VBOX_USER_HOME_short" > /dev/null 2>&1
-}


-_launch_lab_vbox_sequence() {
-	_start
-
-	_prepare_lab_vbox || return 1
-
-	#Directly opening raw images in the VBoxLab environment is not recommended, due to changing VMDK disk identifiers.
-	#Better practice may be to instead programmatically construct the raw image virtual machines before opening VBoxLab environment.
-	#_openVBoxRaw
-
-	_VirtualBox_env_VBOX_USER_HOME_short "$@"
-
-	_wait_lab_vbox
-
-	_stop
-}
+_live_preload_here() {
+	cat << 'CZXWXcRMTo8EmM8i4d'
+#!/bin/sh

-_launch_lab_vbox() {
-	"$scriptAbsoluteLocation" _launch_lab_vbox_sequence "$@"
-}
+PREREQ=""

-_labVBox() {
-	_launch_lab_vbox "$@"
+prereqs()
+{
+    echo "$PREREQ"
 }

-_launch_lab_vbox_manage_sequence() {
-	_start
-
-	_prepare_lab_vbox || return 1
-
-	#Directly opening raw images in the VBoxLab environment is not recommended, due to changing VMDK disk identifiers.
-	#Better practice may be to instead programmatically construct the raw image virtual machines before opening VBoxLab environment.
-	#_openVBoxRaw
-
-	_VBoxManage_env_VBOX_USER_HOME_short "$@"
-
-	_wait_lab_vbox
-
-	_stop
-}
+case "$1" in
+prereqs)
+    prereqs
+    exit 0
+;;
+esac

-_launch_lab_vbox_manage() {
-	"$scriptAbsoluteLocation" _launch_lab_vbox_manage_sequence "$@"
-}
+if type dd > /dev/null 2>&1 && type chroot > /dev/null 2>&1 && [ -e /root/bin/bash ] && [ -e /root/bin/sh ] && env -i HOME="/root" SHELL="/bin/bash" PATH="/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin" USER="root" chroot /root /bin/bash -c 'type dd' > /dev/null 2>&1
+then
+	progressFeed() {
+		env -i HOME="/root" SHELL="/bin/bash" PATH="/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin" USER="root" chroot /root dd of=/dev/null bs=1M status=progress
+	}

-_labVBoxManage() {
-	_launch_lab_vbox_manage "$@"
-}
+	echo "_____ preload: /root/home -not core -not .nix -not .gcloud"
+	find /root/home -not \( -path \/root/home/\*/core\* -prune \) -not \( -path \/root/home/\*/.nix\* -prune \) -not \( -path \/root/home/\*/.gcloud\* -prune \) -type f -exec dd if={} bs=16384 2>/dev/null \; | progressFeed
+	find /root/home/*/klipper -type f -exec dd if={} bs=16384 2>/dev/null \; | progressFeed
+	find /root/home/*/moonraker -type f -exec dd if={} bs=16384 2>/dev/null \; | progressFeed
+	find /root/home/*/moonraker-env -type f -exec dd if={} bs=16384 2>/dev/null \; | progressFeed
+	find /root/home/*/mainsail -type f -exec dd if={} bs=16384 2>/dev/null \; | progressFeed


-_vboxlabSSH() {
-	ssh -q -F "$scriptLocal"/vblssh -i "$scriptLocal"/id_rsa "$1"
-}
+	echo "_____ preload: /root/usr/lib -maxdepth 9 -iname '*.so*'"
+	find /root/usr/lib -maxdepth 9 -type f -iname '*.so*' -exec dd if={} bs=16384 2>/dev/null \; | progressFeed

-_labVBox_migrate() {
-	_messageNormal 'init: _labVBox_migrate'
-
-	! _prepare_lab_vbox && _messagePlain_bad 'fail: _prepare_lab_vbox' && return 1
-
-	export ub_new_VBOXID=$(_uid)
-
-	find . \( -iname '*.xml' -o -iname '*.xml*' -o -iname '*.xbel' -o -iname '*.conf' -o -iname '*.vbox' -o -iname '*.vbox*' -o -iname '*.id' \) -exec sed -i 's/'$VBOXID'/'"$ub_new_VBOXID"'/g' '{}' \;
-
-	_messagePlain_good 'complete: _labVBox_migrate'
-}

+	echo "_____ preload: /root/home -not core -not .nix -not .gcloud"
+	find /root/home/*/.config -type f -exec dd if={} bs=16384 2>/dev/null \; | progressFeed
+	find /root/home/*/.kde -type f -exec dd if={} bs=16384 2>/dev/null \; | progressFeed
+	find /root/home/*/.ubcore -type f -exec dd if={} bs=16384 2>/dev/null \; | progressFeed
+	find /root/home -maxdepth 1 -type f -exec dd if={} bs=16384 2>/dev/null \; | progressFeed


-_prepare_instance_vbox() {
-	_prepare_vbox "$instancedVirtDir"
-}
+	echo "_____ preload: /root/root"
+	find /root/root -type f -exec dd if={} bs=16384 2>/dev/null \; | progressFeed

-_wait_instance_vbox() {
-	_prepare_instance_vbox || return 1

-	VBoxXPCOMIPCD_PID=$(cat "$VBoxXPCOMIPCD_PIDfile" 2> /dev/null)
-	#echo -e '\E[1;32;46mWaiting for VBoxXPCOMIPCD to finish... \E[0m'
-	while kill -0 "$VBoxXPCOMIPCD_PID" > /dev/null 2>&1
-	do
-		sleep 0.2
-	done
-}
+	# CAUTION: DUBIOUS .
+	echo "_____ preload: /VBoxGuestAdditions"
+	find /root/VBoxGuestAdditions -type f -exec dd if={} bs=16384 2>/dev/null \; | progressFeed

-_rm_instance_vbox() {
-	_prepare_instance_vbox || return 1
-
-	#Usually unnecessary, possibly destructive, may delete VM images.
-	#VBoxManage unregistervm "$sessionid" --delete > /dev/null 2>&1
-
-	_safeRMR "$instancedVirtDir" || return 1
-
-	rm -f /tmp/\.vbox-"$VBOX_IPC_SOCKETID"-ipc/ipcd > /dev/null 2>&1
-	rm -f /tmp/\.vbox-"$VBOX_IPC_SOCKETID"-ipc/lock > /dev/null 2>&1
-	rmdir /tmp/\.vbox-"$VBOX_IPC_SOCKETID"-ipc > /dev/null 2>&1
-
-	rm -f "$VBOX_USER_HOME_short" > /dev/null 2>&1
+	# CAUTION: DUBIOUS .
+	echo "_____ preload: /opt"
+	find /root/opt -type f -exec dd if={} bs=16384 2>/dev/null \; | progressFeed

-	#_closeVBoxRaw || return 1
+	# CAUTION: DUBIOUS .
+	echo "_____ preload: /run"
+	find /root/run -type f -exec dd if={} bs=16384 2>/dev/null \; | progressFeed

-	return 0
-}
+	# CAUTION: DUBIOUS .
+	echo "_____ preload: /srv"
+	find /root/srv -type f -exec dd if={} bs=16384 2>/dev/null \; | progressFeed

-#Not routine.
-_remove_instance_vbox() {
-	_prepare_instance_vbox || return 1
-}

-#https://www.virtualbox.org/ticket/18257
-_workaround_VirtualBoxVM() {
-	if type VirtualBoxVM > /dev/null 2>&1
-	then
-		VirtualBoxVM "$@"
-		return
-	fi
-	if ! type VirtualBoxVM > /dev/null 2>&1 && type /usr/lib/virtualbox/VirtualBoxVM > /dev/null 2>&1
-	then
-		/usr/lib/virtualbox/VirtualBoxVM "$@"
-		return
-	fi
-	if ! type VirtualBoxVM > /dev/null 2>&1 && type /usr/local/lib/virtualbox/VirtualBoxVM > /dev/null 2>&1
-	then
-		/usr/local/lib/virtualbox/VirtualBoxVM "$@"
-		return
-	fi
-	if ! type VirtualBoxVM > /dev/null 2>&1
-	then
-		VirtualBox "$@"
-		return
-	fi
-}
+	echo '_____ preload: /root/var'
+	find /root/var -type f -exec dd if={} bs=16384 2>/dev/null \; | progressFeed

-_vboxGUI() {
-	_workaround_VirtualBoxVM "$@"
-
-	#VirtualBoxVM "$@"
-	#VirtualBox "$@"
-	#VBoxSDL "$@"
-}

+	echo '_____ preload: /root/usr/lib/modules'
+	find /root/usr/lib/modules -type f -exec dd if={} bs=16384 2>/dev/null \; | progressFeed

-_set_instance_vbox_type() {
-	#[[ "$vboxOStype" == "" ]] && export vboxOStype=Debian_64
-	#[[ "$vboxOStype" == "" ]] && export vboxOStype=Gentoo_64
-	#[[ "$vboxOStype" == "" ]] && export vboxOStype=Windows2003
-	#[[ "$vboxOStype" == "" ]] && export vboxOStype=WindowsXP
-	#[[ "$vboxOStype" == "" ]] && export vboxOStype=Windows10_64
-	#[[ "$vboxOStype" == "" ]] && export vboxOStype=Windows11_64
-
-	#[[ "$vboxOStype" == "Windows11_64" ]] && vboxOStype="Windows10_64"
-
-	if [[ "$ubVirtPlatformOverride" == "" ]]
-	then
-		[[ "$vboxOStype" == "Win"*"10"* ]] && export ubVirtPlatformOverride="x64-efi"
-		[[ "$vboxOStype" == "Win"*"11"* ]] && export ubVirtPlatformOverride="x64-efi"
-	fi
-
-
-	[[ "$vboxOStype" == "" ]] && _readLocked "$lock_open" && export vboxOStype=Debian_64
-	[[ "$vboxOStype" == "" ]] && export vboxOStype=WindowsXP
-
-	_messagePlain_probe 'vboxOStype= '"$vboxOStype"
-
-	if VBoxManage createvm --name "$sessionid" --ostype "$vboxOStype" --register --basefolder "$VBOX_USER_HOME_short"
-	then
-		_messagePlain_probe VBoxManage createvm --name "$sessionid" --ostype "$vboxOStype" --register --basefolder "$VBOX_USER_HOME_short"
-		return 0
-	fi
-	_messagePlain_bad 'fail: 'VBoxManage createvm --name "$sessionid" --ostype "$vboxOStype" --register --basefolder "$VBOX_USER_HOME_short"
-	return 1
+	echo '_____ preload: /root/boot'
+	find /root/boot -type f -exec dd if={} bs=16384 2>/dev/null \; | progressFeed
+
+	echo '_____ preload: /root/usr/lib/systemd'
+	find /root/usr/lib/systemd -type f -exec dd if={} bs=16384 2>/dev/null \; | progressFeed
+
+	echo '_____ preload: /root/usr/bin'
+	find /root/usr/bin -type f -exec dd if={} bs=16384 2>/dev/null \; | progressFeed
+
+	echo '_____ preload: /root/bin'
+	find /root/bin -type f -exec dd if={} bs=16384 2>/dev/null \; | progressFeed
+
+	echo '_____ preload: /root/sbin'
+	find /root/sbin -type f -exec dd if={} bs=16384 2>/dev/null \; | progressFeed
+
+	echo '_____ preload: /root/etc'
+	find /root/etc -type f -exec dd if={} bs=16384 2>/dev/null \; | progressFeed
+# WARNING: May be untested.
+else
+	echo "_____ preload: /root/home -not core -not .nix -not .gcloud"
+	find /root/home -not \( -path \/root/home/\*/core\* -prune \) -not \( -path \/root/home/\*/.nix\* -prune \) -not \( -path \/root/home/\*/.gcloud\* -prune \) -type f -exec cat {} > /dev/null \;
+	find /root/home/*/klipper -type f -exec cat {} > /dev/null \;
+	find /root/home/*/moonraker -type f -exec cat {} > /dev/null \;
+	find /root/home/*/moonraker-env -type f -exec cat {} > /dev/null \;
+	find /root/home/*/mainsail -type f -exec cat {} > /dev/null \;
+
+
+	echo "_____ preload: /root/usr/lib -maxdepth 9 -iname '*.so*'"
+	find /root/usr/lib -maxdepth 9 -type f -iname '*.so*' -exec cat {} > /dev/null \;
+
+
+	echo "_____ preload: /root/home -not core -not .nix -not .gcloud"
+	find /root/home/*/.config -type f -exec cat {} > /dev/null \;
+	find /root/home/*/.kde -type f -exec cat {} > /dev/null \;
+	find /root/home/*/.ubcore -type f -exec cat {} > /dev/null \;
+	find /root/home -maxdepth 1 -type f -exec cat {} > /dev/null \;
+
+
+	echo "_____ preload: /root/root"
+	find /root/root -type f -exec cat {} > /dev/null \;
+
+
+
+	# CAUTION: DUBIOUS .
+	echo '_____ preload: /root/VBoxGuestAdditions'
+	find /root/VBoxGuestAdditions -type f -exec cat {} > /dev/null \;
+
+	# CAUTION: DUBIOUS .
+	echo '_____ preload: /root/opt'
+	find /root/opt -type f -exec cat {} > /dev/null \;
+
+	# CAUTION: DUBIOUS .
+	echo '_____ preload: /root/run'
+	find /root/run -type f -exec cat {} > /dev/null \;
+
+	# CAUTION: DUBIOUS .
+	echo '_____ preload: /root/srv'
+	find /root/srv -type f -exec cat {} > /dev/null \;
+
+
+	echo '_____ preload: /root/var'
+	find /root/var -type f -exec cat {} > /dev/null \;
+
+
+	echo '_____ preload: /root/usr/lib/modules'
+	find /root/usr/lib/modules -type f -exec cat {} > /dev/null \;
+
+	echo '_____ preload: /root/boot'
+	find /root/boot -type f -exec cat {} > /dev/null \;
+
+	echo '_____ preload: /root/usr/lib/systemd'
+	find /root/usr/lib/systemd -type f -exec cat {} > /dev/null \;
+
+	echo '_____ preload: /root/usr/bin'
+	find /root/usr/bin -type f -exec cat {} > /dev/null \;
+
+	echo '_____ preload: /root/bin'
+	find /root/bin -type f -exec cat {} > /dev/null \;
+
+	echo '_____ preload: /root/sbin'
+	find /root/sbin -type f -exec cat {} > /dev/null \;
+
+	echo '_____ preload: /root/etc'
+	find /root/etc -type f -exec cat {} > /dev/null \;
+fi
+
+CZXWXcRMTo8EmM8i4d
 }

-_set_instance_vbox_cores_more() {
-	[[ "$1" -ge "$vboxCPUs" ]] && _messagePlain_probe 'cpu: >'"$1" && export vboxCPUs="$1"
+
+# https://master.dl.sourceforge.net/project/tboot/intel-txt-software-development-guide.pdf?viasf=1
+# 'Measured Launched Environment Developer-s Guide'
+# ...
+# https://wiki.gentoo.org/wiki/Trusted_Boot#TXT_Errors
+#  MAJOR - 'error will be preserved across a reboot (but not a hard poweroff).'
+#   'txt-parse_err'
+#  'Sometimes it'll hang. That usually means /boot/list.data doesn't reflect the current configuration - this will often happen after a configuration change.'
+# ...
+# https://fedoraproject.org/wiki/Tboot
+# 'last edited on 22 June 2012'
+#  As of 2023-09-23 .
+# 'module /2nd_gen_i5_i7_SINIT_51.BIN'
+# 'module /list.data'
+#  MAJOR - 'You may download all of the ACM modules into /boot and list them all as modules in your grub.conf. tboot will pick the right module for your platform.'
+# ...
+# https://sourceforge.net/p/tboot/mailman/tboot-devel/?page=1
+#  'when multiple SINITs is loaded, there is a chance that one (or more) of them will be overwritten by some TBOOT data structures that have hardcoded addresses'
+#   'Fri, 11 Mar 2022'
+#  'Being able to use e.g. the same Live CD on all pieces of hardware would be a huge win.'
+# ...
+# https://sourceforge.net/projects/tboot/files/
+#  'The location of SINIT Authenticated Code Module (ACM) files has been moved from this site to the following location: http://software.intel.com/en-us/articles/intel-trusted-execution-technology/'
+#  'The content, license, etc. of the ACMs has not changed.'
+#  'New ACMs and updates to existing ACMs will only be posted to the new site.'
+# ...
+# https://manpages.debian.org/testing/live-boot-doc/live-boot.7.en.html
+# https://github.com/bugra9/persistent
+# https://manpages.debian.org/testing/live-boot-doc/persistence.conf.5.en.html
+# https://www.freedesktop.org/software/systemd/man/systemd-gpt-auto-generator.html
+#  systemd.gpt_auto=false
+#  rd.systemd.gpt_auto=false
+ # WARNING: 'persistence.conf' ... 'root of its file system' ... 'Any such labeled volume must have such a file, or it will be ignored.'
+# config debug=1 noeject persistence persistence-path=/persist persistence-label=bulk persistence-storage=directory
+_live_grub_here() {
+	cat <<'CZXWXcRMTo8EmM8i4d'
+
+insmod all_video
+
+search --set=root --file /ROOT_TEXT
+
+#set default="0"
+#set default="1"
+set default="2"
+set timeout=1
+
+menuentry "Live" {
+    #linux /vmlinuz boot=live config debug=1 noeject nopersistence selinux=0 mem=3712M resume=UUID=469457fc-293f-46ec-92da-27b5d0c36b17
+    #linux /vmlinuz boot=live config debug=1 noeject nopersistence selinux=0 mem=3712M resume=PARTUUID=469457fc-293f-46ec-92da-27b5d0c36b17
+    linux /vmlinuz boot=live config debug=1 noeject nopersistence selinux=0 mem=3712M resume=/dev/sda5
+    initrd /initrd
+
+    #linux /vmlinuz-lts boot=live config debug=1 noeject nopersistence selinux=0 mem=3712M resume=UUID=469457fc-293f-46ec-92da-27b5d0c36b17
+    #linux /vmlinuz-lts boot=live config debug=1 noeject nopersistence selinux=0 mem=3712M resume=PARTUUID=469457fc-293f-46ec-92da-27b5d0c36b17
+    linux /vmlinuz-lts boot=live config debug=1 noeject nopersistence selinux=0 mem=3712M resume=/dev/sda5
+    initrd /initrd-lts
 }

-# ATTENTION: Override, function, or, variables, with "ops" or similar.
-# WARNING: Do not cause use of more than half the number of physical cores (not threads) unless specifically required.
-_set_instance_vbox_cores() {
-	# DANGER: Do not set "vboxCPUs" unless specifically required.
-	# Intended only where specifically necessary to force a specific number of threads (eg. "1").
-	# FAIL if "hostThreadCount" < "vboxCPUs" .
-	# FAIL or DEGRADE if "hostCoreCount" < "vboxCPUs" .
-	# POSSIBLE DEGRADE if nesting AND "vboxCPUs" != "" .
-	[[ "$vboxCPUs" != "" ]] && _messagePlain_warn 'warn: configured: force: vboxCPUs= '"$vboxCPUs" && return 0
+menuentry "Live - ( persistence )" {
+    linux /vmlinuz boot=live config debug=1 noeject persistence persistence-path=/persist persistence-label=bulk persistence-storage=directory selinux=0 mem=3712M resume=/dev/sda5
+    initrd /initrd
+
+    #linux /vmlinuz-lts boot=live config debug=1 noeject persistence persistence-path=/persist persistence-label=bulk persistence-storage=directory selinux=0 mem=3712M resume=/dev/sda5
+    #initrd /initrd-lts
+}
+
+menuentry "Live - ( hint: ignored: resume disabled ) ( mem: all )" {
+	linux /vmlinuz boot=live config debug=1 noeject nopersistence selinux=0
+    initrd /initrd

-	export vboxCPUs=1
+	#linux /vmlinuz-lts boot=live config debug=1 noeject nopersistence selinux=0
+    #initrd /initrd-lts
+}
+
+menuentry "Live - ( hint: ignored: resume disabled ) ( mem: all ) - tboot" {
+	##linux /vmlinuz boot=live config debug=1 noeject nopersistence selinux=0
+    ##initrd /initrd

-	# Single-threaded host with guest 'efi', 'Windows10_64', 'Windows11_64', are all not plausible. Minimum dual-CPU requirement of MSW11 as default.
-	# ATTENTION: For guests benefitting from single core performance only, force such non-default by exporting 'vboxCPUs' with 'ops' or similar.
-	if [[ "$ubVirtPlatform" == *'efi' ]] || [[ "$ubVirtPlatformOverride" == *'efi' ]] || [[ "$vboxOStype" == "Win"*"10"* ]] || [[ "$vboxOStype" == "Win"*"11"* ]]
-	then
-		export vboxCPUs=2
-	fi
+	#linux /vmlinuz-lts boot=live config debug=1 noeject nopersistence selinux=0
+    #initrd /initrd-lts
+
+    insmod multiboot2
+	multiboot2 /tboot.gz logging=serial,memory,vga
+	module2 /vmlinuz boot=live config debug=1 noeject nopersistence selinux=0
+	module2 /initrd
+	#module2 /vmlinuz-lts boot=live config debug=1 noeject nopersistence selinux=0
+	#module2 /initrd-lts
+	#module2 /SNB_IVB_SINIT_20190708_PW.bin
+	module2 /BDW_SINIT_20190708_1.3.2_PW.bin
+	#module2 /SKL_KBL_AML_SINIT_20211019_PRODUCTION_REL_NT_O1_1.10.0.bin
+	#module2 /CFL_SINIT_20221220_PRODUCTION_REL_NT_O1_1.10.1_signed.bin
+	#module2 /CML_S_SINIT_1_13_33_REL_NT_O1.PW_signed.bin
+	#module2 /CMLSTGP_SINIT_v1_14_46_20220819_REL_NT_O1.PW_signed.bin
+	#module2 /RKLS_SINIT_v1_14_46_20220819_REL_NT_O1.PW_signed.bin
+	#module2 /TGL_SINIT_v1_14_46_20220819_REL_NT_O1.PW_signed.bin
+	module2 /ADL_SINIT_v1_18_16_20230427_REL_NT_O1.PW_signed.bin
+
+	#module /list.data
+}
+
+CZXWXcRMTo8EmM8i4d
+}
+
+
+_write_revert_live() {
+	_messagePlain_nominal 'Attempt: _openChRoot'
+	! "$scriptAbsoluteLocation" _openChRoot && _messagePlain_bad 'fail: _openChRoot' && _messageFAIL
+
+	#_chroot systemctl enable nfs-blkmap
+	#_chroot systemctl enable nfs-idmapd
+	#_chroot systemctl enable nfs-mountd
+	#_chroot systemctl enable nfs-server
+	#_chroot systemctl enable nfsdcld
+
+	#_chroot systemctl enable ssh
+	#_chroot systemctl enable sshd
+
+	_chroot systemctl enable exim4
+
+
+	sudo -n rm -f "$globalVirtFS"/usr/share/initramfs-tools/scripts/init-bottom/preload_run
+
+	[[ -e "$globalVirtFS"/etc/systemd/system.conf.orig ]] && sudo -n mv -f "$globalVirtFS"/etc/systemd/system.conf.orig "$globalVirtFS"/etc/systemd/system.conf
+
+
+	_chroot update-initramfs -u -k all
+
+	_messagePlain_nominal 'Attempt: _closeChRoot'
+	#sudo -n umount "$globalVirtFS"/boot/efi > /dev/null 2>&1
+	#sudo -n umount "$globalVirtFS"/boot > /dev/null 2>&1
+	! "$scriptAbsoluteLocation" _closeChRoot && _messagePlain_bad 'fail: _closeChRoot' && _messageFAIL
+}
+
+# https://willhaley.com/blog/custom-debian-live-environment-grub-only/
+# https://web.archive.org/web/*/https://willhaley.com/blog/custom-debian-live-environment-grub-only/*
+# https://itnext.io/how-to-create-a-custom-ubuntu-live-from-scratch-dd3b3f213f81
+# https://manpages.debian.org/jessie/initramfs-tools/initramfs-tools.8.en.html
+# http://www.opopop.net/booting_linux_from_a_loop_file_system/
+# https://forums.gentoo.org/viewtopic-t-931250-start-0.html
+# https://wiki.debian.org/InitramfsDebug
+# https://gist.github.com/avinash-oza/9791c4edd78a03540dc69d6fbf21bd9c
+_live_sequence_in() {
+	_messageNormal 'init: _live'

-	local hostCoreCount
-	local hostThreadCount
-	local hostThreadAllowance
+	_mustGetSudo || return 0


-	# Physical Cores.
-	local hostCoreCount=$(grep ^cpu\\scores /proc/cpuinfo | head -n 1 | tr -dc '0-9')

-	# Logical Threads.
-	local hostThreadCount=$(cat /proc/cpuinfo | grep MHz | wc -l | tr -dc '0-9')
+	# WARNING: If the root filesystem has compressed, this would be absurd. Also not expected to affect iso image and such. Better to leave raw image compression to customization of the raw image.
+	#_messagePlain_nominal 'Attempt: _openChRoot'
+	#! _openChRoot && _messageFAIL && _stop 1

-	# Typical stability margin reservation.
-	let hostThreadAllowance="$hostCoreCount"-2
+	#_messagePlain_nominal 'Compression: zero blanking'

-	_messagePlain_probe_var hostCoreCount
-	_messagePlain_probe_var hostThreadCount
+	#sudo -n dd if=/dev/zero of="$globalVirtFS"/zero.del bs=8M
+	#sudo -n rm -f "$globalVirtFS"/zero.del

-	# Catch core/thread detection failure.
-	if [[ "$hostCoreCount" -lt "1" ]] || [[ "$hostCoreCount" == "" ]] || [[ "$hostThreadCount" -lt "1" ]] || [[ "$hostThreadCount" == "" ]]
-	then
-		_messagePlain_bad 'fail: hostCoreCount, hostThreadCount'
-		_messagePlain_warn 'missing: smp: force: vboxCPUs= '1
-
-		# Default, allow single threaded operation if core/thread count was indeterminite.
-		return 0
-	fi
+	#_messagePlain_nominal 'Attempt: _closeChRoot'
+	#! _closeChRoot && _messageFAIL && _stop 1

-	# Logical Threads > Physical Cores ('SMT', 'Hyper-Threading', etc)
-	if [[ "$hostThreadCount" -gt "$hostCoreCount" ]]
-	then
-		# Logical Threads Present
-		_messagePlain_good 'detect: logical threads'
-
-		[[ "$hostCoreCount" -lt "6" ]] && _set_instance_vbox_cores_more "$hostCoreCount"
-
-		# DANGER: Do not set "vboxCPUsAllowManyThreads" if processor capabilities (eg. Intel Atom) will be uncertain and/or host/guest latencies may be important.
-		# Not recommended for Intel i7-2640M (as found in Lenovo X220) or older hosts.
-		# Nevertheless, power efficiency (eg Intel Atom) may be a good reason to specifically enable this.
-		# https://unix.stackexchange.com/questions/325932/virtualbox-is-it-a-bad-idea-to-assign-more-virtual-cpu-cores-than-number-of-phy
-		# https://en.wikipedia.org/wiki/Hyper-threading
-		if [[ "$vboxCPUsAllowManyThreads" == 'true' ]]
-		then
-			_messagePlain_warn 'warn: configured: vboxCPUsAllowManyThreads'
-
-			[[ "$hostCoreCount" -lt "4" ]] && _set_instance_vbox_cores_more "$hostThreadCount"
-
-			let hostThreadAllowance="$hostThreadCount"-2
-			_set_instance_vbox_cores_more "$hostThreadAllowance"
-		fi
-
-		# WARNING: Do not set "vboxCPUsAllowManyCores" unless it is acceptable for guest to consume (at least nearly) 100% CPU cores/threads/time/resources.
-		if [[ "$vboxCPUsAllowManyCores" == 'true' ]]
-		then
-			_messagePlain_probe 'configured: vboxCPUsAllowManyCores'
-
-			let hostThreadAllowance="$hostCoreCount"-2
-			_set_instance_vbox_cores_more "$hostThreadAllowance"
-		fi
-
-		[[ "$hostCoreCount" -ge "32" ]] && _set_instance_vbox_cores_more 20
-
-		[[ "$hostCoreCount" -lt "32" ]] && [[ "$hostCoreCount" -ge "24" ]] && _set_instance_vbox_cores_more 14
-		[[ "$hostCoreCount" -lt "24" ]] && [[ "$hostCoreCount" -ge "16" ]] && _set_instance_vbox_cores_more 10
-		[[ "$hostCoreCount" -lt "16" ]] && [[ "$hostCoreCount" -ge "12" ]] && _set_instance_vbox_cores_more 8
-		[[ "$hostCoreCount" -lt "12" ]] && [[ "$hostCoreCount" -ge "10" ]] && _set_instance_vbox_cores_more 8
-		[[ "$hostCoreCount" -lt "10" ]] && [[ "$hostCoreCount" -ge "8" ]] && _set_instance_vbox_cores_more 6
-		[[ "$hostCoreCount" -lt "8" ]] && [[ "$hostCoreCount" -ge "6" ]] && _set_instance_vbox_cores_more 4
-
-
-	else
-		# Logical Threads Absent
-		_messagePlain_bad 'missing: logical threads'
-
-		[[ "$hostCoreCount" -lt "4" ]] && _set_instance_vbox_cores_more "$hostCoreCount"
-
-		# WARNING: Do not set "vboxCPUsAllowManyCores" unless it is acceptable for guest to consume (at least nearly) 100% CPU cores/threads/time/resources.
-		if [[ "$vboxCPUsAllowManyCores" == 'true' ]]
-		then
-			let hostThreadAllowance="$hostCoreCount"-2
-			_set_instance_vbox_cores_more "$hostThreadAllowance"
-		fi
-
-		[[ "$hostCoreCount" -ge "32" ]] && _set_instance_vbox_cores_more 16
-
-		[[ "$hostCoreCount" -lt "32" ]] && [[ "$hostCoreCount" -ge "24" ]] && _set_instance_vbox_cores_more 12
-		[[ "$hostCoreCount" -lt "24" ]] && [[ "$hostCoreCount" -ge "16" ]] && _set_instance_vbox_cores_more 8
-		[[ "$hostCoreCount" -lt "16" ]] && [[ "$hostCoreCount" -ge "10" ]] && _set_instance_vbox_cores_more 6
-		[[ "$hostCoreCount" -lt "10" ]] && [[ "$hostCoreCount" -ge "8" ]] && _set_instance_vbox_cores_more 4
-		[[ "$hostCoreCount" -lt "8" ]] && [[ "$hostCoreCount" -ge "4" ]] && _set_instance_vbox_cores_more 4
-	fi

-	# ATTENTION: Do not set "vboxCPUsMax" unless specifically required.
-	if [[ "$vboxCPUsMax" != "" ]]
-	then
-		_messagePlain_warn 'warn: configured: vboxCPUsMax= '"$vboxCPUsMax"
-		[[ "$vboxCPUs" -ge "$vboxCPUsMax" ]] && export vboxCPUs="$vboxCPUsMax"
-	fi

-	_messagePlain_probe_var vboxCPUs
-	return 0
-}
+
+
+	_start
+
+	cd "$safeTmp"

-_set_instance_vbox_features() {
-	#VBoxManage modifyvm "$sessionid" --boot1 disk --biosbootmenu disabled --bioslogofadein off --bioslogofadeout off --bioslogodisplaytime 5 --vram 256 --memory 1512 --nic1 nat --nictype1 "82543GC" --clipboard bidirectional --accelerate3d off --accelerate2dvideo off --vrde off --audio pulse --usb on --cpus 1 --ioapic off --acpi on --pae off --chipset piix3
+	_messagePlain_nominal 'Attempt: _openChRoot'
+	! "$scriptAbsoluteLocation" _openChRoot && _messagePlain_bad 'fail: _openChRoot' && _messageFAIL
+
+	##_chroot systemctl disable nfs-blkmap
+	##_chroot systemctl disable nfs-idmapd
+	##_chroot systemctl disable nfs-mountd
+	##_chroot systemctl disable nfs-server
+	##_chroot systemctl disable nfsdcld
+
+	##_chroot systemctl disable ssh
+	##_chroot systemctl disable sshd
+
+	#_chroot systemctl disable exim4
+
+
+	_live_preload_here | sudo -n tee "$globalVirtFS"/usr/share/initramfs-tools/scripts/init-bottom/preload_run > /dev/null
+	_chroot chown root:root /usr/share/initramfs-tools/scripts/init-bottom/preload_run
+	_chroot chmod 755 /usr/share/initramfs-tools/scripts/init-bottom/preload_run
+
+	# Apparent repeated success with 'DefaultTasksMax=12' . In one case, some services - SMART and NetworkManager - may have failed to start within timeouts. Some have certainly been close to timeout.
+	# Consider reducing below 12 iteratively.
+	# Alternatively, this may need to increase. Cron jobs may otherwise fail with such error message as 'fork retry resource temporarily unavailable' .
+	# Uncertain whether 'DefaultTasksMax' limits only the number of systemd services started simuntaneously, or also the number of threads total prior to interactive shell.
+	# CAUTION: Apparently sets 'ulimit' unfavorably against cron .
+	#  Hopefully, preload will be sufficient to prevent excessive disc seeking issues .
+	#sudo -n mv -n "$globalVirtFS"/etc/systemd/system.conf "$globalVirtFS"/etc/systemd/system.conf.orig
+	#echo '[Manager]
+#DefaultTasksMax=24' | sudo -n tee "$globalVirtFS"/etc/systemd/system.conf > /dev/null
+
+
+	_chroot update-initramfs -u -k all

-	! _set_instance_vbox_cores && return 1

-	# WARNING: Do not set "$vmMemoryAllocation" to a high number unless specifically required.
-	[[ "$vmMemoryAllocation" == "" ]] && vmMemoryAllocation="$vmMemoryAllocationDefault"

-	# Must have at least 4096MB for 'livecd' , unless even larger memory allocation has been configured .
-	if [[ "$ub_override_vbox_livecd" != '' ]] || [[ "$ub_override_vbox_livecd_more" != '' ]]
-	then
-		if [[ "$vmMemoryAllocation" -lt 4096 ]]
-		then
-			vmMemoryAllocation=4096
-		fi
-	fi

-	#[[ "$ubVirtPlatform" == *'efi' ]] || [[ "$ubVirtPlatformOverride" == *'efi' ]]
-	if [[ "$vmMemoryAllocation" -lt 8704 ]] && ( [[ "$vboxOStype" == "Win"*"10"* ]] || [[ "$vboxOStype" == "Win"*"11"* ]] )
-	then
-		vmMemoryAllocation=8704
-	fi

-	_messagePlain_probe 'vmMemoryAllocation= '"$vmMemoryAllocation"

-	[[ "$vboxNic" == "" ]] && export vboxNic="nat"
-	_messagePlain_probe 'vboxNic= '"$vboxNic"
+	_chroot apt-get -y clean


-	local vboxChipset
-	vboxChipset="ich9"
-	#[[ "$vboxOStype" == *"Win"*"XP"* ]] && vboxChipset="piix3"
-	_messagePlain_probe 'vboxChipset= '"$vboxChipset"

-	local vboxNictype
-	vboxNictype="82543GC"
-	[[ "$vboxOStype" == *"Win"*"7"* ]] && vboxNictype="82540EM"
-	[[ "$vboxOStype" == *"Win"*"10"* ]] && vboxNictype="82540EM"
-	[[ "$vboxOStype" == *"Win"*"11"* ]] && vboxNictype="82540EM"
-	_messagePlain_probe 'vboxNictype= '"$vboxNictype"

-	local vboxAudioController
-	vboxAudioController="ac97"
-	[[ "$vboxOStype" == *"Win"*"7"* ]] && vboxAudioController="hda"
-	[[ "$vboxOStype" == *"Win"*"10"* ]] && vboxAudioController="hda"
-	[[ "$vboxOStype" == *"Win"*"11"* ]] && vboxAudioController="hda"
-	_messagePlain_probe 'vboxAudioController= '"$vboxAudioController"

-	_messagePlain_nominal "Setting VBox VM features."

-	if ! _messagePlain_probe_cmd VBoxManage modifyvm "$sessionid" --biosbootmenu disabled --bioslogofadein off --bioslogofadeout off --bioslogodisplaytime 1 --vram 256 --memory "$vmMemoryAllocation" --nic1 "$vboxNic" --nictype1 "$vboxNictype" --accelerate3d off --accelerate2dvideo off --vrde off --audio null --audioin off --audioout on --usb on --cpus "$vboxCPUs" --ioapic on --acpi on --pae on --chipset "$vboxChipset" --audiocontroller="$vboxAudioController"
-	then
-		_messagePlain_bad 'fail: VBoxManage'
-		return 1
-	fi
+	# WARNING: Now also provides essential information about intel-acm .
+	# Solely to provide more information to convert 'vm-live.iso' back to 'vm.img' offline from only a Live BD-ROM disc .
+	mkdir -p "$safeTmp"/root002
+	#sudo -n cp -a "$globalVirtFS"/boot "$safeTmp"/root002/boot-copy
+	sudo -n rsync -a --progress --exclude "lost+found" "$globalVirtFS"/boot "$safeTmp"/root002/boot-copy
+	sudo -n cp -a "$globalVirtFS"/etc/fstab  "$safeTmp"/root002/fstab-copy
+
+
+
+	_messagePlain_nominal 'Attempt: _closeChRoot'
+	#sudo -n umount "$globalVirtFS"/boot/efi > /dev/null 2>&1
+	#sudo -n umount "$globalVirtFS"/boot > /dev/null 2>&1
+	! "$scriptAbsoluteLocation" _closeChRoot && _messagePlain_bad 'fail: _closeChRoot' && _messageFAIL
+
+
+
+
+
+	export safeToDeleteGit="true"
+	[[ -e "$scriptLocal"/livefs ]] && _safeRMR "$scriptLocal"/livefs
+	[[ -e "$scriptLocal"/livefs ]] && _messageFAIL

-	#_messagePlain_probe_cmd VBoxManage controlvm "$sessionid" clipboard bidirectional
+	mkdir -p "$scriptLocal"/livefs
+	[[ ! -e "$scriptLocal"/livefs ]] && _messageFAIL

-	# Linux hosts may benefit from 'vboxsvga' instead of 'vmsvga'.
-	#https://wiki.gentoo.org/wiki/VirtualBox
-	#Testing shows this may not be the case, and 3D acceleration reportedly requires vmsvga.
-	if ! _if_cygwin && ( [[ "$vboxOStype" == *"Debian"* ]] || [[ "$vboxOStype" == *"Gentoo"* ]] )
+
+	_messagePlain_nominal 'Attempt: _openImage'
+	! _openImage && _messageFAIL && _stop 1
+	imagedev=$(cat "$scriptLocal"/imagedev)
+	if [[ "$ubVirtImageBoot" != "" ]]
 	then
-		# ATTENTION: Nested virtualization through VMWare Workstation host, seems incompatable with 'accelerate3d on', result may be black screen with cursor.
-		# ATTENTION: WARNING: VirtualBox 'accelerate3d' may be disabled by default, if not already, if more incompatibilities are found. Explicitly declare with 'ops.sh' if 'accelerate3d' is actually necessary.
-		# Assuming x64 hosts served by VBox will have at least 'Intel HD Graphics 3000' (as found on X220 laptop/tablet) equivalent. Lesser hardware not recommended.
-		#if [[ "$vboxCPUs" -ge "2" ]] && ! lspci | grep -i vmware && ! lspci | grep -i virtualbox && ! cat /proc/cpuinfo | grep -i model | grep -i qemu && ! sudo -n lspci | grep -i vmware && ! sudo -n lspci | grep -i virtualbox
-		#then
-			#if ! _messagePlain_probe_cmd VBoxManage modifyvm "$sessionid" --graphicscontroller vmsvga --accelerate3d on --accelerate2dvideo off
-			#then
-				#_messagePlain_warn 'warn: fail: VBoxManage: --graphicscontroller vmsvga --accelerate3d on --accelerate2dvideo off'
-			#fi
-		#else
-			#vmsvga
-			#vboxsvga
-			if ! _messagePlain_probe_cmd VBoxManage modifyvm "$sessionid" --graphicscontroller vmsvga --accelerate3d off --accelerate2dvideo off
-			then
-				_messagePlain_warn 'warn: fail: VBoxManage: --graphicscontroller vmsvga --accelerate3d off --accelerate2dvideo off'
-			fi
-		#fi
+		sudo -n mkdir -p "$globalVirtFS"/boot
+		sudo -n mount "$imagedev""$ubVirtImageBoot" "$globalVirtFS"/boot
 	fi
-
-	# Assuming x64 hosts served by VBox will have at least 'Intel HD Graphics 3000' (as found on X220 laptop/tablet) equivalent. Lesser hardware not recommended.
-	#if ! _if_cygwin && ( ( [[ "$vboxOStype" == *"Win"*"10"* ]] || [[ "$vboxOStype" == *"Win"*"11"* ]] ) && [[ "$vboxCPUs" -ge "2" ]] && ! lspci | grep -i vmware && ! lspci | grep -i virtualbox && ! cat /proc/cpuinfo | grep -i model | grep -i qemu && ! sudo -n lspci | grep -i vmware && ! sudo -n lspci | grep -i virtualbox )
-	#then
-		#_messagePlain_probe VBoxManage modifyvm "$sessionid" --graphicscontroller vboxsvga --accelerate3d on --accelerate2dvideo on
-		#if ! VBoxManage modifyvm "$sessionid" --graphicscontroller vboxsvga --accelerate3d on --accelerate2dvideo on
-		#then
-			#_messagePlain_warn 'warn: fail: VBoxManage: --graphicscontroller vboxsvga --accelerate3d on --accelerate2dvideo on'
-		#fi
-	#fi
-
-	# MSW Host with Hyper-V seems to specifically require both graphics acceleration and HyperV paravirtualization interface .
-	# ATTENTION: HyperV should be enabled by default by 'ubDistBuild' installer and similar installers .
-	# CAUTION: Any automatic provision for an alternative should detect if HyperV is NOT installed, and fail to the assumption that HyperV is installed.
-	# https://superuser.com/questions/1026651/how-to-find-out-whether-hyper-v-is-currently-enabled-running
-	#  Strongly discouraged - apparently requries admin privileges and powershell .
-	#&& ! lspci | grep -i vmware && ! lspci | grep -i virtualbox && ! cat /proc/cpuinfo | grep -i model | grep -i qemu && ! sudo -n lspci | grep -i vmware && ! sudo -n lspci | grep -i virtualbox )
-	if _if_cygwin
+	if [[ "$ubVirtImageEFI" != "" ]]
 	then
-		if ! _messagePlain_probe_cmd VBoxManage modifyvm "$sessionid" --graphicscontroller vmsvga --accelerate3d on --accelerate2dvideo off
-		then
-			_messagePlain_warn 'warn: fail: VBoxManage: Acceleration from MSW Host'
-		fi
-		if ! _messagePlain_probe_cmd VBoxManage modifyvm "$sessionid" --paravirt-provider=hyperv
-		then
-			_messagePlain_warn 'warn: fail: VBoxManage: Acceleration from MSW Host'
-		fi
+		sudo -n mkdir -p "$globalVirtFS"/boot/efi
+		sudo -n mount "$imagedev""$ubVirtImageEFI" "$globalVirtFS"/boot/efi
 	fi

-	return 0
+	#/DEBIAN_CUSTOM
+	#/ROOT_TEXT

-}
-
-_set_instance_vbox_features_app() {
-	true

-	#if [[ "$vboxOStype" == *"Win"*"XP"* ]]
-	#then
-	#	export vboxChipset="piix3"
-	#	! VBoxManage modifyvm "$sessionid" --chipset "$vboxChipset" && return 1
-	#fi
+	#LIVE_BOOT/chroot
+	#"$globalVirtFS"

-	#! VBoxManage modifyvm "$sessionid" --usbxhci on && return 1
-}
-
-_set_instance_vbox_features_app_post() {
-	true
+	#LIVE_BOOT/scratch
+	#"$scriptLocal"/livefs/partial

-	# WARNING: Change to 'SATA Controller' if appropriate.
-	#if ! _messagePlain_probe_cmd VBoxManage storageattach "$sessionid" --storagectl "IDE Controller" --port 2 --device 0 --type hdd --medium "$scriptLocal"/vm_bulk.vdi --mtype "immutable"
-	#then
-	#	_messagePlain_warn 'fail: vm_bulk.vdi'
-	#fi
-}
+	#LIVE_BOOT/image
+	#"$scriptLocal"/livefs/image
+
+
+	mkdir -p "$scriptLocal"/livefs/partial
+	mkdir -p "$scriptLocal"/livefs/image/live
+
+	# TODO: Consider LZO compression and such.
+	# TODO: May need to install live-boot , firmware-amd-graphics
+	#sudo -n mksquashfs "$globalVirtFS" "$scriptLocal"/livefs/image/live/filesystem.squashfs -no-xattrs -noI -noD -noF -noX -comp lzo -Xalgorithm lzo1x_1 -e boot -e etc/fstab
+	#sudo -n mksquashfs "$globalVirtFS" "$scriptLocal"/livefs/image/live/filesystem.squashfs -b  -no-xattrs -noI -noX -comp lzo -Xalgorithm lzo1x_1 -e boot -e etc/fstab

-_set_instance_vbox_share() {
-	#VBoxManage sharedfolder add "$sessionid" --name "root" --hostpath "/"
-	if [[ "$sharedHostProjectDir" != "" ]]
+
+
+
+	#mkdir -p "$safeTmp"/root001
+	#sudo -n cp -a "$globalVirtFS"/home  "$safeTmp"/root001/
+
+	#mkdir -p "$safeTmp"/recycle
+	#sudo -n mv -f "$safeTmp"/root001/home/user/* "$safeTmp"/recycle/
+	#sudo -n mv -f "$safeTmp"/recycle/core "$safeTmp"/root001/home/user/
+	#sudo -n chown -R "$USER":"$USER" "$safeTmp"/recycle
+	#_safeRMR "$safeTmp"/recycle
+
+	#mkdir -p "$safeTmp"/recycle
+	#sudo -n mv -f "$safeTmp"/root001/home/* "$safeTmp"/recycle/
+	#sudo -n mv -f "$safeTmp"/recycle/user "$safeTmp"/root001/home/
+	#sudo -n chown -R "$USER":"$USER" "$safeTmp"/recycle
+	#_safeRMR "$safeTmp"/recycle
+
+	#_messagePlain_probe_cmd ls -ld "$safeTmp"/root001
+	#_messagePlain_probe_cmd ls -ld "$safeTmp"/root001/home
+	#_messagePlain_probe_cmd ls -ld "$safeTmp"/root001/home/user
+	#_messagePlain_probe_cmd ls -ld "$safeTmp"/root001/home/user/core
+	#_messagePlain_probe_cmd ls -l "$safeTmp"/root001/home/user/core/
+
+	#sudo -n mksquashfs "$safeTmp"/root001 "$scriptLocal"/livefs/image/live/filesystem.squashfs -b 65536 -no-xattrs -noI -noX -comp lzo -Xalgorithm lzo1x_1 -e boot -e etc/fstab
+	#sudo -n chown -R "$USER":"$USER" "$safeTmp"/root001
+	#_safeRMR "$safeTmp"/root001
+
+
+	# https://github.com/openwrt/openwrt/issues/9974
+	# http://neoscientists.org/~tmueller/binsort/
+	#sudo -n mksquashfs "$globalVirtFS" "$scriptLocal"/livefs/image/live/filesystem.squashfs -b 262144 -no-xattrs -noI -noX -comp lzo -Xalgorithm lzo1x_1 -e home/user/core -e boot -e etc/fstab
+
+
+
+	# Solely to provide more information to convert 'vm-live.iso' back to 'vm.img' offline from only a Live BD-ROM disc .
+	_messagePlain_nominal 'mksquashfs: root002: boot-copy , fstab-copy'
+	_messagePlain_probe_cmd df -h
+	if ! _messagePlain_probe_cmd sudo -n mksquashfs "$safeTmp"/root002 "$scriptLocal"/livefs/image/live/filesystem.squashfs -b 262144 -no-xattrs -noI -noX -comp lzo -Xalgorithm lzo1x_1 -e boot -e etc/fstab
 	then
-		_messagePlain_probe VBoxManage sharedfolder add "$sessionid" --name "appFolder" --hostpath "$sharedHostProjectDir"
-
-		! VBoxManage sharedfolder add "$sessionid" --name "appFolder" --hostpath "$sharedHostProjectDir" && _messagePlain_warn 'fail: mount sharedHostProjectDir= '"$sharedHostProjectDir"
+		_messageFAIL
+		_stop 1
+		return 1
 	fi
-
-	if [[ -e "$HOME"/Downloads ]]
+	du -sh "$scriptLocal"/livefs/image/live/filesystem.squashfs
+	sudo -n chown -R "$USER":"$USER" "$safeTmp"/root002
+	export safeToDeleteGit="true"
+	_safeRMR "$safeTmp"/root002
+	if [[ -e "$safeTmp"/root002 ]]
 	then
-		_messagePlain_probe VBoxManage sharedfolder add "$sessionid" --name "Downloads" --hostpath "$HOME"/Downloads
-
-		! VBoxManage sharedfolder add "$sessionid" --name "Downloads" --hostpath "$HOME"/Downloads && _messagePlain_warn 'fail: mount (shared) Downloads= '"$HOME"/Downloads
+		_messageFAIL
+		_stop 1
+		return 1
 	fi
-}

-_set_instance_vbox_command() {
-	_messagePlain_nominal 'Creating BootDisc.'
-	! _commandBootdisc "$@" && _messagePlain_bad 'fail: _commandBootdisc' && return 1
-	return 0
-}
+	mkdir -p "$safeTmp"/root001
+	sudo -n mkdir -p "$safeTmp"/root001/home
+	#sudo -n cp -a "$globalVirtFS"/home "$safeTmp"/root001/
+	sudo -n mount --bind "$globalVirtFS"/home "$safeTmp"/root001/home
+	_messagePlain_probe_cmd mountpoint "$safeTmp"/root001/home
+	_messagePlain_probe_cmd sudo -n ls -l "$safeTmp"/root001/home/user/core/
+	_messagePlain_probe_cmd sudo -n du -sh "$safeTmp"/root001/home
+	_messagePlain_nominal 'mksquashfs: root001: home'
+	_messagePlain_probe_cmd df -h
+	if ! _messagePlain_probe_cmd sudo -n mksquashfs "$safeTmp"/root001 "$scriptLocal"/livefs/image/live/filesystem.squashfs -b 262144 -no-xattrs -noI -noX -comp lzo -Xalgorithm lzo1x_1 -e boot -e etc/fstab
+	then
+		_messageFAIL
+		_stop 1
+		return 1
+	fi
+	du -sh "$scriptLocal"/livefs/image/live/filesystem.squashfs
+	sudo -n umount "$safeTmp"/root001/home
+	if mountpoint "$safeTmp"/root001/home
+	then
+		_messageFAIL
+		_stop 1
+		return 1
+	fi
+	sudo -n chown -R "$USER":"$USER" "$safeTmp"/root001
+	export safeToDeleteGit="true"
+	_safeRMR "$safeTmp"/root001
+	if [[ -e "$safeTmp"/root001 ]]
+	then
+		_messageFAIL
+		_stop 1
+		return 1
+	fi
+
+	_messagePlain_nominal 'mksquashfs: globalVirtFS'
+	_messagePlain_probe_cmd df -h
+	if ! _messagePlain_probe_cmd sudo -n mksquashfs "$globalVirtFS" "$scriptLocal"/livefs/image/live/filesystem.squashfs -b 262144 -no-xattrs -noI -noX -comp lzo -Xalgorithm lzo1x_1 -e home -e boot -e etc/fstab
+	then
+		_messageFAIL
+		_stop 1
+		return 1
+	fi
+	du -sh "$scriptLocal"/livefs/image/live/filesystem.squashfs
+
+
+
+
+
+
+
+
+

-_create_instance_vbox_storageattach_ide() {
-	_messagePlain_nominal 'Attaching local filesystems.'
-	! VBoxManage storagectl "$sessionid" --name "IDE Controller" --add ide --controller PIIX4 && _messagePlain_bad 'fail: VBoxManage... attach ide controller'

-	#export vboxDiskMtype="normal"
-	#[[ "$vboxDiskMtype" == "" ]] && export vboxDiskMtype="multiattach"
-	[[ "$vboxDiskMtype" == "" ]] && export vboxDiskMtype="immutable"
-	_messagePlain_probe 'vboxDiskMtype= '"$vboxDiskMtype"
+	local currentFilesList


+	# ATTENTION: Configure, remove extra vmlinuz/initrd files, or accept possibility of matching an undesired kernel version.
+	#currentFilesList=( "$globalVirtFS"/boot/vmlinuz-* )

-	if [[ "$ub_override_vbox_livecd" != '' ]]
-	then
-		_messagePlain_probe VBoxManage storageattach "$sessionid" --storagectl "IDE Controller" --port 0 --device 0 --type dvddrive --medium "$ub_override_vbox_livecd"
-		! VBoxManage storageattach "$sessionid" --storagectl "IDE Controller" --port 0 --device 0 --type dvddrive --medium "$ub_override_vbox_livecd" && _messagePlain_bad 'fail: VBoxManage... attach vboxInstanceDiskImage= '"$ub_override_vbox_livecd"
-	elif [[ "$ub_override_vbox_livecd_more" != '' ]]
-	then
-		_messagePlain_probe VBoxManage storageattach "$sessionid" --storagectl "IDE Controller" --port 0 --device 0 --type hdd --medium "$ub_override_vbox_livecd_more" --mtype "$vboxDiskMtype"
-		! VBoxManage storageattach "$sessionid" --storagectl "IDE Controller" --port 0 --device 0 --type hdd --medium "$ub_override_vbox_livecd_more" --mtype "$vboxDiskMtype" && _messagePlain_bad 'fail: VBoxManage... attach vboxInstanceDiskImage= '"$ub_override_vbox_livecd_more"
-	else
-		_messagePlain_probe VBoxManage storageattach "$sessionid" --storagectl "IDE Controller" --port 0 --device 0 --type hdd --medium "$vboxInstanceDiskImage" --mtype "$vboxDiskMtype"
-		! VBoxManage storageattach "$sessionid" --storagectl "IDE Controller" --port 0 --device 0 --type hdd --medium "$vboxInstanceDiskImage" --mtype "$vboxDiskMtype" && _messagePlain_bad 'fail: VBoxManage... attach vboxInstanceDiskImage= '"$vboxInstanceDiskImage"
-	fi
+	# Usually, +1 will be highest version mainline, +2 will be lts, +3 will be much older from distribution.
+	currentFilesList=$(ls -A -1 "$globalVirtFS"/boot/vmlinuz-* | sort -r -V | tail -n+1 | head -n1)
+	#currentFilesList=( $(ls -A -1 "$globalVirtFS"/boot/vmlinuz-* | sort -r -V | tail -n+1 | head -n2) )
+	#currentFilesList=$(ls -A -1 "$globalVirtFS"/boot/vmlinuz-* | sort -r -V | tail -n+2 | head -n1)
+	#currentFilesList=$(ls -A -1 "$globalVirtFS"/boot/vmlinuz-* | sort -r -V | tail -n+3 | head -n1)

+	cp "${currentFilesList[0]}" "$scriptLocal"/livefs/image/vmlinuz
+
+	currentFilesList=$(ls -A -1 "$globalVirtFS"/boot/vmlinuz-* | sort -r -V | tail -n+2 | head -n1)
+	cp "${currentFilesList[0]}" "$scriptLocal"/livefs/image/vmlinuz-lts


-	[[ -e "$hostToGuestISO" ]] && ! VBoxManage storageattach "$sessionid" --storagectl "IDE Controller" --port 1 --device 0 --type dvddrive --medium "$hostToGuestISO" && _messagePlain_bad 'fail: VBoxManage... attach hostToGuestISO= '"$hostToGuestISO"
+	#currentFilesList=( "$globalVirtFS"/boot/initrd.img-* )

-	# Due to some EFI systems occasionally needing a Live bootloader image (ie. super grub2), it may be best to ensure disk is always booted preferentially if possible.
-	VBoxManage modifyvm "$sessionid" --boot1 disk
-	VBoxManage modifyvm "$sessionid" --boot2 floppy
-	VBoxManage modifyvm "$sessionid" --boot3 dvd
-	VBoxManage modifyvm "$sessionid" --boot4 none
+	currentFilesList=$(ls -A -1 "$globalVirtFS"/boot/initrd.img-* | sort -r -V | tail -n+1 | head -n1)
+	#currentFilesList=( $(ls -A -1 "$globalVirtFS"/boot/initrd.img-* | sort -r -V | tail -n+1 | head -n2) )
+	#currentFilesList=$(ls -A -1 "$globalVirtFS"/boot/initrd.img-* | sort -r -V | tail -n+2 | head -n1)
+	#currentFilesList=$(ls -A -1 "$globalVirtFS"/boot/initrd.img-* | sort -r -V | tail -n+3 | head -n1)

-	return 0
-}
+	cp "${currentFilesList[0]}" "$scriptLocal"/livefs/image/initrd

-_create_instance_vbox_storageattach_sata() {
-	_messagePlain_nominal 'Attaching local filesystems.'
-	! VBoxManage storagectl "$sessionid" --name "SATA Controller" --add sata --controller IntelAHCI --portcount 5 --hostiocache on && _messagePlain_bad 'fail: VBoxManage... attach sata controller'
+	currentFilesList=$(ls -A -1 "$globalVirtFS"/boot/initrd.img-* | sort -r -V | tail -n+2 | head -n1)
+	cp "${currentFilesList[0]}" "$scriptLocal"/livefs/image/initrd-lts

-	#export vboxDiskMtype="normal"
-	#[[ "$vboxDiskMtype" == "" ]] && export vboxDiskMtype="multiattach"
-	[[ "$vboxDiskMtype" == "" ]] && export vboxDiskMtype="immutable"
-	_messagePlain_probe 'vboxDiskMtype= '"$vboxDiskMtype"
+

+	cp "$globalVirtFS"/boot/tboot* "$scriptLocal"/livefs/image/
+	cp "$globalVirtFS"/boot/*.bin "$scriptLocal"/livefs/image/

+	_live_grub_here > "$scriptLocal"/livefs/partial/grub.cfg
+	touch "$scriptLocal"/livefs/image/ROOT_TEXT

+	_messagePlain_nominal 'Attempt: _closeImage'
+	sudo -n umount "$globalVirtFS"/boot/efi > /dev/null 2>&1
+	sudo -n umount "$globalVirtFS"/boot > /dev/null 2>&1
+	! _closeImage && _messageFAIL && _stop 1

-	if [[ "$ub_override_vbox_livecd" != '' ]]
-	then
-		_messagePlain_probe VBoxManage storageattach "$sessionid" --storagectl "SATA Controller" --port 0 --device 0 --type dvddrive --medium "$ub_override_vbox_livecd"
-		! VBoxManage storageattach "$sessionid" --storagectl "SATA Controller" --port 0 --device 0 --type dvddrive --medium "$ub_override_vbox_livecd" && _messagePlain_bad 'fail: VBoxManage... attach vboxInstanceDiskImage= '"$ub_override_vbox_livecd"
-	elif [[ "$ub_override_vbox_livecd_more" != '' ]]
-	then
-		_messagePlain_probe VBoxManage storageattach "$sessionid" --storagectl "SATA Controller" --port 0 --device 0 --type hdd --medium "$ub_override_vbox_livecd_more" --mtype "$vboxDiskMtype"
-		! VBoxManage storageattach "$sessionid" --storagectl "SATA Controller" --port 0 --device 0 --type hdd --medium "$ub_override_vbox_livecd_more" --mtype "$vboxDiskMtype" && _messagePlain_bad 'fail: VBoxManage... attach vboxInstanceDiskImage= '"$ub_override_vbox_livecd_more"
-	else
-		_messagePlain_probe VBoxManage storageattach "$sessionid" --storagectl "SATA Controller" --port 0 --device 0 --type hdd --medium "$vboxInstanceDiskImage" --mtype "$vboxDiskMtype"
-		! VBoxManage storageattach "$sessionid" --storagectl "SATA Controller" --port 0 --device 0 --type hdd --medium "$vboxInstanceDiskImage" --mtype "$vboxDiskMtype" && _messagePlain_bad 'fail: VBoxManage... attach vboxInstanceDiskImage= '"$vboxInstanceDiskImage"
-	fi



+	_write_revert_live

-	[[ -e "$hostToGuestISO" ]] && ! VBoxManage storageattach "$sessionid" --storagectl "SATA Controller" --port 1 --device 0 --type dvddrive --medium "$hostToGuestISO" && _messagePlain_bad 'fail: VBoxManage... attach hostToGuestISO= '"$hostToGuestISO"

-	# Due to some EFI systems occasionally needing a Live bootloader image (ie. super grub2), it may be best to ensure disk is always booted preferentially if possible.
-	VBoxManage modifyvm "$sessionid" --boot1 disk
-	VBoxManage modifyvm "$sessionid" --boot2 floppy
-	VBoxManage modifyvm "$sessionid" --boot3 dvd
-	VBoxManage modifyvm "$sessionid" --boot4 none

-	return 0
-}
-
-_create_instance_vbox_storageattach() {
-	# IDE Controller found to have some problems with at least Gentoo_64 EFI guests.
-	# WARNING: Do NOT change without consideration for legacy VMs. Although, legacy software seems on the way out anyway now.
-	#[[ "$vboxOStype" != *"Debian"* ]] && [[ "$vboxOStype" != *"Win"*"10"* ]] && [[ "$vboxOStype" != *"Win"* ]]
-	if [[ "$ubVirtPlatform" == *'efi' ]] || [[ "$ubVirtPlatformOverride" == *'efi' ]] || ( [[ "$vboxOStype" != "" ]] && [[ "$vboxOStype" != *"Win"*"XP"* ]] )
-	then
-		_create_instance_vbox_storageattach_sata
-		return
-	fi
+	grub-mkstandalone --format=x86_64-efi --output="$scriptLocal"/livefs/partial/bootx64.efi --locales="" --fonts="" "boot/grub/grub.cfg="$scriptLocal"/livefs/partial/grub.cfg"

-	# Legacy default.
-	_create_instance_vbox_storageattach_ide
-	return
-}
-
-_create_instance_vbox() {

-	#Use existing VDI image if available.
-	if ! [[ -e "$scriptLocal"/vm.vdi ]] && [[ "$ub_override_vbox_livecd" == '' ]] && [[ "$ub_override_vbox_livecd_more" == '' ]]
-	then
-		# IMG file may be a device file. See 'virtualization/image/mountimage.sh' .
-		_messagePlain_nominal 'Missing VDI. Attempting to open IMG.'
-		! _openVBoxRaw && _messageError 'FAIL' && return 1
-	fi
+	cd "$scriptLocal"/livefs/partial
+	dd if=/dev/zero of="$scriptLocal"/livefs/partial/efiboot.img bs=1M count=10
+	"$(sudo -n bash -c 'type -p mkfs.vfat' || echo /sbin/mkfs.vfat)" "$scriptLocal"/livefs/partial/efiboot.img
+	mmd -i "$scriptLocal"/livefs/partial/efiboot.img efi efi/boot
+	mcopy -i "$scriptLocal"/livefs/partial/efiboot.img "$scriptLocal"/livefs/partial/bootx64.efi ::efi/boot/
+	cd "$scriptLocal"/livefs

-	_messagePlain_nominal 'Checking VDI or IMG availability.'
-	if [[ "$ub_override_vbox_livecd" == '' ]] && [[ "$ub_override_vbox_livecd_more" == '' ]]
-	then
-		export vboxInstanceDiskImage="$scriptLocal"/vm.vdi
-		_readLocked "$lock_open" && vboxInstanceDiskImage="$vboxRaw"
-		! [[ -e "$vboxInstanceDiskImage" ]] && _messagePlain_bad 'missing: vboxInstanceDiskImage= '"$vboxInstanceDiskImage" && return 1
-	elif [[ "$ub_override_vbox_livecd" != '' ]] || [[ "$ub_override_vbox_livecd_more" != '' ]]
-	then
-		[[ "$ub_override_vbox_livecd" != '' ]] && ! [[ -e "$ub_override_vbox_livecd" ]] && _messagePlain_bad 'missing: ub_override_vbox_livecd= '"$ub_override_vbox_livecd" && return 1
-		[[ "$ub_override_vbox_livecd_more" != '' ]] && ! [[ -e "$ub_override_vbox_livecd_more" ]] && _messagePlain_bad 'missing: ub_override_vbox_livecd_more= '"$ub_override_vbox_livecd_more" && return 1
-	fi

-	_messagePlain_nominal 'Determining OS type.'
-	_set_instance_vbox_type

-	! _set_instance_vbox_features && _messageError 'FAIL' && return 1
+	grub-mkstandalone --format=i386-pc --output="$scriptLocal"/livefs/partial/core.img --install-modules="linux normal iso9660 biosdisk memdisk search tar ls" --modules="linux normal iso9660 biosdisk search" --locales="" --fonts="" "boot/grub/grub.cfg="$scriptLocal"/livefs/partial/grub.cfg"


-	if [[ "$ubVirtPlatform" == *'efi' ]] || [[ "$ubVirtPlatformOverride" == *'efi' ]]
-	then
-		VBoxManage modifyvm "$sessionid" --firmware efi64
-	else
-		# Default.
-		VBoxManage modifyvm "$sessionid" --firmware bios
-	fi
+	cat /usr/lib/grub/i386-pc/cdboot.img "$scriptLocal"/livefs/partial/core.img > "$scriptLocal"/livefs/partial/bios.img

-	! _set_instance_vbox_features_app && _messageError 'FAIL: unknown app failure' && return 1

-	_set_instance_vbox_command "$@"

-	_messagePlain_nominal 'Mounting shared filesystems.'
-	_set_instance_vbox_share

-	_create_instance_vbox_storageattach



-	#VBoxManage showhdinfo "$scriptLocal"/vm.vdi
-
-	#Suppress annoying warnings.
-	! VBoxManage setextradata global GUI/SuppressMessages "remindAboutAutoCapture,remindAboutMouseIntegration,remindAboutMouseIntegrationOn,showRuntimeError.warning.HostAudioNotResponding,remindAboutGoingSeamless,remindAboutInputCapture,remindAboutGoingFullscreen,remindAboutMouseIntegrationOff,confirmGoingSeamless,confirmInputCapture,remindAboutPausedVMInput,confirmVMReset,confirmGoingFullscreen,remindAboutWrongColorDepth" && _messagePlain_warn 'fail: VBoxManage... suppress messages'
+	_stop 0
+}
+_live_sequence_out() {
+	[[ ! -e "$scriptLocal"/livefs ]] && _messageFAIL
+	_start

-	! VBoxManage setextradata global GUI/SuppressMessages "Update" && _messagePlain_warn 'fail: VBoxManage... suppress messages... Update'

+	xorriso -as mkisofs -iso-level 3 -full-iso9660-filenames -volid "ROOT_TEXT" -eltorito-boot boot/grub/bios.img -no-emul-boot -boot-load-size 4 -boot-info-table --eltorito-catalog boot/grub/boot.cat --grub2-boot-info --grub2-mbr /usr/lib/grub/i386-pc/boot_hybrid.img -eltorito-alt-boot -e EFI/efiboot.img -no-emul-boot -append_partition 2 0xef "$scriptLocal"/livefs/partial/efiboot.img -output "$safeTmp"/live.iso -graft-points "$scriptLocal"/livefs/image /boot/grub/bios.img="$scriptLocal"/livefs/partial/bios.img /EFI/efiboot.img="$scriptLocal"/livefs/partial/efiboot.img

-	# WARNING: Some of these annoying warnings have apparently not been disabled effectively, possibly due to 'real' "$HOME" directory configuration, or specific versions of VirtualBox .

-	# From source code.
-	# remindAboutAutoCapture,remindAboutMouseIntegrationOn,remindAboutMouseIntegrationOn
+	mv "$safeTmp"/live.iso "$scriptLocal"/vm-live.iso

-	# https://askubuntu.com/questions/763107/how-do-i-permanently-disable-notifications-about-auto-capture-keyboard-and-mouse
-	# confirmInputCapture,remindAboutAutoCapture,remindAboutMouseIntegrationOff,remindAboutMouseIntegrationOn,remindAboutWrongColorDepth



-	_set_instance_vbox_features_app_post
+	_messageNormal '_live: done'

-	return 0
+	_stop 0
 }
-
-#Create and launch temporary VM around persistent disk image.
-_user_instance_vbox_sequence() {
-	_messageNormal '_user_instance_vbox_sequence: start'
-	_start
-
-	_prepare_instance_vbox || _stop 1
+_live() {
+	if ! "$scriptAbsoluteLocation" _live_sequence_in "$@"
+	then
+		_stop 1
+	fi

-	_messageNormal '_user_instance_vbox_sequence: Checking lock vBox_vdi= '"$vBox_vdi"
-	_readLocked "$vBox_vdi" && _messagePlain_bad 'lock: vBox_vdi= '"$vBox_vdi" && _stop 1
+	#rm -f "$scriptLocal"/vm.img

-	_messageNormal '_user_instance_vbox_sequence: Creating instance. '"$sessionid"
-	if ! _create_instance_vbox "$@"
+	if ! "$scriptAbsoluteLocation" _live_sequence_out "$@"
 	then
 		_stop 1
 	fi

-	_messageNormal '_user_instance_vbox_sequence: Launch: _vboxGUI '"$sessionid"
-	 _vboxGUI --startvm "$sessionid"
+	export safeToDeleteGit="true"
+	_safeRMR "$scriptLocal"/livefs

-	_messageNormal '_user_instance_vbox_sequence: Removing instance. '"$sessionid"
-	_rm_instance_vbox

-	_messageNormal '_user_instance_vbox_sequence: stop'
-	_stop
+	#! _live_more && _stop 1
+
+	#return 0
 }

-# Keep instance should only be set by end-user functions which require overriding of internal functions.
-_user_instance_vbox() {
-	if [[ "$ub_keepInstance" == 'true' ]]
-	then
-		_user_instance_vbox_sequence "$@"
-		return
-	fi
-	"$scriptAbsoluteLocation" _user_instance_vbox_sequence "$@"
-	return
+
+_override_VBox-live() {
+	#export ub_keepInstance='true'
+	export ub_override_vbox_livecd_more="$scriptLocal"/vm-live-more.vdi
+	#export ub_override_vbox_livecd_more="$scriptLocal"/vm-live-more.iso
+	#export ub_override_vbox_livecd="$scriptLocal"/vm-live.iso
 }

-_userVBox() {
-	_findInfrastructure_virtImage ${FUNCNAME[0]} "$@"
-	[[ "$ubVirtImageLocal" == "false" ]] && return
+
+_userVBoxLive() {
+	_override_VBox-live

-	_messageNormal 'Begin: '"$@"
-	_user_instance_vbox "$@"
-	_messageNormal 'End: '"$@"
+	_userVBox "$@"
 }

-_edit_instance_vbox_sequence() {
-	_start
-
-	_prepare_instance_vbox || return 1
-
-	#VBoxManage modifymedium "$scriptLocal"/vm.vdi --type normal
-
-	export vboxDiskMtype="normal"
-	if ! _create_instance_vbox "$@"
-	then
-		return 1
-	fi
-
-	_readLocked "$vBox_vdi" && return 1
-
-	_createLocked "$vBox_vdi" || return 1
-
-	_VirtualBox_env_VBOX_USER_HOME_short
-
-	_wait_instance_vbox
-
-	#VBoxManage modifymedium "$scriptLocal"/vm.vdi --type multiattach
-
-	rm -f "$vBox_vdi" > /dev/null 2>&1
-
-	_rm_instance_vbox
+_editVBoxLive() {
+	_override_VBox-live

-	_stop
+	_editVBox "$@"
 }

-_edit_instance_vbox() {
-	if [[ "$ub_keepInstance" == 'true' ]]
-	then
-		_edit_instance_vbox_sequence "$@"
-		return
-	fi
-	"$scriptAbsoluteLocation" _edit_instance_vbox_sequence "$@"
-	return
+_persistentVBoxLive() {
+	_override_VBox-live
+
+	_persistentVBox "$@"
 }

-_editVBox() {
-	_findInfrastructure_virtImage ${FUNCNAME[0]} "$@"
-	[[ "$ubVirtImageLocal" == "false" ]] && return
-
-	_messageNormal 'Begin: '"$@"
-	_edit_instance_vbox "$@"
-	_messageNormal 'End: '"$@"
+
+_override_qemu-live() {
+	#export ub_keepInstance='true'
+	export ub_override_qemu_livecd_more="$scriptLocal"/vm-live-more.iso
+	#export ub_override_qemu_livecd="$scriptLocal"/vm-live.iso
 }




-_persistent_instance_vbox_sequence() {
-	_messageNormal '_persistent_instance_vbox_sequence: start'
-	_start
-
-	_prepare_instance_vbox || _stop 1
-
-	_messageNormal '_persistent_instance_vbox_sequence: Checking lock vBox_vdi= '"$vBox_vdi"
-	_readLocked "$vBox_vdi" && _messagePlain_bad 'lock: vBox_vdi= '"$vBox_vdi" && _stop 1
-
-	export vboxDiskMtype="normal"
-	_messageNormal '_persistent_instance_vbox_sequence: Creating instance. '"$sessionid"
-	if ! _create_instance_vbox "$@"
-	then
-		_stop 1
-	fi
-
-	_messageNormal '_persistent_instance_vbox_sequence: Launch: _vboxGUI '"$sessionid"
-	 _vboxGUI --startvm "$sessionid"
-
-	_messageNormal '_persistent_instance_vbox_sequence: Removing instance. '"$sessionid"
-	_rm_instance_vbox
+
+_userQemuLive() {
+	_override_qemu-live

-	_messageNormal '_persistent_instance_vbox_sequence: stop'
-	_stop
+	_userQemu "$@"
 }

-_persistent_instance_vbox() {
-	if [[ "$ub_keepInstance" == 'true' ]]
-	then
-		_persistent_instance_vbox_sequence "$@"
-		return
-	fi
-	"$scriptAbsoluteLocation" _persistent_instance_vbox_sequence "$@"
-	return
+_editQemuLive() {
+	_override_qemu-live
+
+	_editQemu "$@"
 }

-_persistentVBox() {
-	_findInfrastructure_virtImage ${FUNCNAME[0]} "$@"
-	[[ "$ubVirtImageLocal" == "false" ]] && return
+_persistentQemuLive() {
+	_override_qemu-live

-	_messageNormal 'Begin: '"$@"
-	_persistent_instance_vbox "$@"
-	_messageNormal 'End: '"$@"
+	_persistentQemu "$@"
 }




-_launch_user_vbox_manage_sequence() {
-	_start
+#Ensures dependencies are met for raspi-on-raspi virtualization.
+_testQEMU_raspi-raspi() {
+	true
+}
+
+_testQEMU_hostArch_x64-raspi() {
+	local hostArch
+	hostArch=$(uname -m)

-	_prepare_instance_vbox || _stop 1
+	if [[ "$hostArch" != "x86_64" ]]
+	then
+		return 1
+	fi

-	_readLocked "$vBox_vdi" && return 1
+	return 0
+}
+
+_testQEMU_x64-raspi() {

-	_createLocked "$vBox_vdi" || return 1
+	_testQEMU_x64-x64
+	_getDep qemu-arm-static
+	_getDep qemu-armeb-static

-	_VBoxManage_env_VBOX_USER_HOME_short "$@"
+	_getDep qemu-system-arm
+	_getDep qemu-system-aarch64

-	_wait_instance_vbox

-	rm -f "$vBox_vdi" > /dev/null 2>&1
+	_mustGetSudo

-	_rm_instance_vbox
+	! _testQEMU_hostArch_x64-raspi && echo "warn: not checking x64 translation" && return 0

-	_stop
-}
-
-_launch_user_vbox_manage() {
-	"$scriptAbsoluteLocation" _launch_user_vbox_manage_sequence "$@"
-}
-
-_userVBoxManage() {
-	_launch_user_vbox_manage "$@"
-}
-
-
-
-_here_dosbox_base_conf() {
-
-cat << 'CZXWXcRMTo8EmM8i4d'
-# This is the configurationfile for DOSBox 0.74. (Please use the latest version of DOSBox)
-# Lines starting with a # are commentlines and are ignored by DOSBox.
-# They are used to (briefly) document the effect of each option.
-
-[sdl]
-#       fullscreen: Start dosbox directly in fullscreen. (Press ALT-Enter to go back)
-#       fulldouble: Use double buffering in fullscreen. It can reduce screen flickering, but it can also result in a slow DOSBox.
-#   fullresolution: What resolution to use for fullscreen: original or fixed size (e.g. 1024x768).
-#                     Using your monitor's native resolution with aspect=true might give the best results.
-#                     If you end up with small window on a large screen, try an output different from surface.
-# windowresolution: Scale the window to this size IF the output device supports hardware scaling.
-#                     (output=surface does not!)
-#           output: What video system to use for output.
-#                   Possible values: surface, overlay, opengl, openglnb.
-#         autolock: Mouse will automatically lock, if you click on the screen. (Press CTRL-F10 to unlock)
-#      sensitivity: Mouse sensitivity.
-#      waitonerror: Wait before closing the console if dosbox has an error.
-#         priority: Priority levels for dosbox. Second entry behind the comma is for when dosbox is not focused/minimized.
-#                     pause is only valid for the second entry.
-#                   Possible values: lowest, lower, normal, higher, highest, pause.
-#       mapperfile: File used to load/save the key/event mappings from. Resetmapper only works with the defaul value.
-#     usescancodes: Avoid usage of symkeys, might not work on all operating systems.
-
-fullscreen=false
-fulldouble=false
-fullresolution=original
-windowresolution=original
-output=surface
-autolock=true
-sensitivity=100
-waitonerror=true
-priority=higher,normal
-mapperfile=mapper-0.74.map
-usescancodes=true
-
-[dosbox]
-# language: Select another language file.
-#  machine: The type of machine tries to emulate.
-#           Possible values: hercules, cga, tandy, pcjr, ega, vgaonly, svga_s3, svga_et3000, svga_et4000, svga_paradise, vesa_nolfb, vesa_oldvbe.
-# captures: Directory where things like wave, midi, screenshot get captured.
-#  memsize: Amount of memory DOSBox has in megabytes.
-#             This value is best left at its default to avoid problems with some games,
-#             though few games might require a higher value.
-#             There is generally no speed advantage when raising this value.
-
-language=
-machine=svga_s3
-captures=capture
-memsize=16
-
-[render]
-# frameskip: How many frames DOSBox skips before drawing one.
-#    aspect: Do aspect correction, if your output method doesn't support scaling this can slow things down!.
-#    scaler: Scaler used to enlarge/enhance low resolution modes.
-#              If 'forced' is appended, then the scaler will be used even if the result might not be desired.
-#            Possible values: none, normal2x, normal3x, advmame2x, advmame3x, advinterp2x, advinterp3x, hq2x, hq3x, 2xsai, super2xsai, supereagle, tv2x, tv3x, rgb2x, rgb3x, scan2x, scan3x.
-
-frameskip=0
-aspect=false
-scaler=normal2x
-
-[cpu]
-#      core: CPU Core used in emulation. auto will switch to dynamic if available and appropriate.
-#            Possible values: auto, dynamic, normal, simple.
-#   cputype: CPU Type used in emulation. auto is the fastest choice.
-#            Possible values: auto, 386, 386_slow, 486_slow, pentium_slow, 386_prefetch.
-#    cycles: Amount of instructions DOSBox tries to emulate each millisecond.
-#            Setting this value too high results in sound dropouts and lags.
-#            Cycles can be set in 3 ways:
-#              'auto'          tries to guess what a game needs.
-#                              It usually works, but can fail for certain games.
-#              'fixed #number' will set a fixed amount of cycles. This is what you usually need if 'auto' fails.
-#                              (Example: fixed 4000).
-#              'max'           will allocate as much cycles as your computer is able to handle.
-#
-#            Possible values: auto, fixed, max.
-#   cycleup: Amount of cycles to decrease/increase with keycombo.(CTRL-F11/CTRL-F12)
-# cycledown: Setting it lower than 100 will be a percentage.
-
-core=auto
-cputype=auto
-cycles=auto
-cycleup=10
-cycledown=20
-
-[mixer]
-#   nosound: Enable silent mode, sound is still emulated though.
-#      rate: Mixer sample rate, setting any device's rate higher than this will probably lower their sound quality.
-#            Possible values: 44100, 48000, 32000, 22050, 16000, 11025, 8000, 49716.
-# blocksize: Mixer block size, larger blocks might help sound stuttering but sound will also be more lagged.
-#            Possible values: 1024, 2048, 4096, 8192, 512, 256.
-# prebuffer: How many milliseconds of data to keep on top of the blocksize.
-
-nosound=false
-rate=44100
-blocksize=1024
-prebuffer=20
-
-[midi]
-#     mpu401: Type of MPU-401 to emulate.
-#             Possible values: intelligent, uart, none.
-# mididevice: Device that will receive the MIDI data from MPU-401.
-#             Possible values: default, win32, alsa, oss, coreaudio, coremidi, none.
-# midiconfig: Special configuration options for the device driver. This is usually the id of the device you want to use.
-#               See the README/Manual for more details.
-
-mpu401=intelligent
-mididevice=default
-midiconfig=
-
-[sblaster]
-#  sbtype: Type of Soundblaster to emulate. gb is Gameblaster.
-#          Possible values: sb1, sb2, sbpro1, sbpro2, sb16, gb, none.
-#  sbbase: The IO address of the soundblaster.
-#          Possible values: 220, 240, 260, 280, 2a0, 2c0, 2e0, 300.
-#     irq: The IRQ number of the soundblaster.
-#          Possible values: 7, 5, 3, 9, 10, 11, 12.
-#     dma: The DMA number of the soundblaster.
-#          Possible values: 1, 5, 0, 3, 6, 7.
-#    hdma: The High DMA number of the soundblaster.
-#          Possible values: 1, 5, 0, 3, 6, 7.
-# sbmixer: Allow the soundblaster mixer to modify the DOSBox mixer.
-# oplmode: Type of OPL emulation. On 'auto' the mode is determined by sblaster type. All OPL modes are Adlib-compatible, except for 'cms'.
-#          Possible values: auto, cms, opl2, dualopl2, opl3, none.
-#  oplemu: Provider for the OPL emulation. compat might provide better quality (see oplrate as well).
-#          Possible values: default, compat, fast.
-# oplrate: Sample rate of OPL music emulation. Use 49716 for highest quality (set the mixer rate accordingly).
-#          Possible values: 44100, 49716, 48000, 32000, 22050, 16000, 11025, 8000.
-
-sbtype=sb16
-sbbase=220
-irq=7
-dma=1
-hdma=5
-sbmixer=true
-oplmode=auto
-oplemu=default
-oplrate=44100
-
-[gus]
-#      gus: Enable the Gravis Ultrasound emulation.
-#  gusrate: Sample rate of Ultrasound emulation.
-#           Possible values: 44100, 48000, 32000, 22050, 16000, 11025, 8000, 49716.
-#  gusbase: The IO base address of the Gravis Ultrasound.
-#           Possible values: 240, 220, 260, 280, 2a0, 2c0, 2e0, 300.
-#   gusirq: The IRQ number of the Gravis Ultrasound.
-#           Possible values: 5, 3, 7, 9, 10, 11, 12.
-#   gusdma: The DMA channel of the Gravis Ultrasound.
-#           Possible values: 3, 0, 1, 5, 6, 7.
-# ultradir: Path to Ultrasound directory. In this directory
-#           there should be a MIDI directory that contains
-#           the patch files for GUS playback. Patch sets used
-#           with Timidity should work fine.
-
-gus=false
-gusrate=44100
-gusbase=240
-gusirq=5
-gusdma=3
-ultradir=C:\ULTRASND
-
-[speaker]
-# pcspeaker: Enable PC-Speaker emulation.
-#    pcrate: Sample rate of the PC-Speaker sound generation.
-#            Possible values: 44100, 48000, 32000, 22050, 16000, 11025, 8000, 49716.
-#     tandy: Enable Tandy Sound System emulation. For 'auto', emulation is present only if machine is set to 'tandy'.
-#            Possible values: auto, on, off.
-# tandyrate: Sample rate of the Tandy 3-Voice generation.
-#            Possible values: 44100, 48000, 32000, 22050, 16000, 11025, 8000, 49716.
-#    disney: Enable Disney Sound Source emulation. (Covox Voice Master and Speech Thing compatible).
-
-pcspeaker=true
-pcrate=44100
-tandy=auto
-tandyrate=44100
-disney=true
-
-[joystick]
-# joysticktype: Type of joystick to emulate: auto (default), none,
-#               2axis (supports two joysticks),
-#               4axis (supports one joystick, first joystick used),
-#               4axis_2 (supports one joystick, second joystick used),
-#               fcs (Thrustmaster), ch (CH Flightstick).
-#               none disables joystick emulation.
-#               auto chooses emulation depending on real joystick(s).
-#               (Remember to reset dosbox's mapperfile if you saved it earlier)
-#               Possible values: auto, 2axis, 4axis, 4axis_2, fcs, ch, none.
-#        timed: enable timed intervals for axis. Experiment with this option, if your joystick drifts (away).
-#     autofire: continuously fires as long as you keep the button pressed.
-#       swap34: swap the 3rd and the 4th axis. can be useful for certain joysticks.
-#   buttonwrap: enable button wrapping at the number of emulated buttons.
+	#\|Raspbian
+	if [[ -e /etc/issue ]] && cat /etc/issue | grep 'Debian\|Ubuntu' > /dev/null 2>&1
+	then
+		_getDep update-binfmts
+	fi
+
+
+	sudo -n systemctl status binfmt-support 2>&1 | head -n 2 | grep -i 'chroot' > /dev/null && return 0
+	systemctl status binfmt-support 2>&1 | head -n 2 | grep -i 'chroot' > /dev/null && return 0
+
+	sudo -n systemctl restart binfmt-support > /dev/null 2>&1

-joysticktype=auto
-timed=true
-autofire=false
-swap34=false
-buttonwrap=false
+	sudo -n service binfmt-support --full-restart > /dev/null 2>&1
+	service binfmt-support --full-restart > /dev/null 2>&1
+
+	if ! sudo -n cat /proc/sys/fs/binfmt_misc/* 2> /dev/null | grep qemu | grep 'arm$\|arm-static$\|arm-binfmt-P$\|arm-binfmt' > /dev/null 2>&1 && ! _if_cygwin
+	then
+		echo 'binfmts does not mention qemu-arm'
+		[[ "$INSTANCE_ID" == "" ]] && _stop 1
+	fi
+
+	if ! sudo -n cat /proc/sys/fs/binfmt_misc/* 2> /dev/null | grep qemu | grep 'armeb$\|armeb-static$\|armeb-binfmt-P$\|armeb-binfmt' > /dev/null 2>&1 && ! _if_cygwin
+	then
+		echo 'binfmts does not mention qemu-armeb'
+		[[ "$INSTANCE_ID" == "" ]] && _stop 1
+	fi
+
+	return 0
+}

-[serial]
-# serial1: set type of device connected to com port.
-#          Can be disabled, dummy, modem, nullmodem, directserial.
-#          Additional parameters must be in the same line in the form of
-#          parameter:value. Parameter for all types is irq (optional).
-#          for directserial: realport (required), rxdelay (optional).
-#                           (realport:COM1 realport:ttyS0).
-#          for modem: listenport (optional).
-#          for nullmodem: server, rxdelay, txdelay, telnet, usedtr,
-#                         transparent, port, inhsocket (all optional).
-#          Example: serial1=modem listenport:5000
-#          Possible values: dummy, disabled, modem, nullmodem, directserial.
-# serial2: see serial1
-#          Possible values: dummy, disabled, modem, nullmodem, directserial.
-# serial3: see serial1
-#          Possible values: dummy, disabled, modem, nullmodem, directserial.
-# serial4: see serial1
-#          Possible values: dummy, disabled, modem, nullmodem, directserial.

-serial1=dummy
-serial2=dummy
-serial3=disabled
-serial4=disabled

-[dos]
-#            xms: Enable XMS support.
-#            ems: Enable EMS support.
-#            umb: Enable UMB support.
-# keyboardlayout: Language code of the keyboard layout (or none).
+_testQEMU_hostArch_x64_hardwarevt() {
+	#[[ -e /dev/kvm ]] && (grep -i svm /proc/cpuinfo > /dev/null 2>&1 || grep -i vmx /proc/cpuinfo > /dev/null 2>&1)
+
+	! [[ -e /dev/kvm ]] && return 1
+
+	grep -i svm /proc/cpuinfo > /dev/null 2>&1 && return 0
+	grep -i vmx /proc/cpuinfo > /dev/null 2>&1 && return 0
+
+	return 1
+}

-xms=true
-ems=true
-umb=true
-keyboardlayout=auto
+_testQEMU_hostArch_x64_nested() {
+	grep '1' /sys/module/kvm_amd/parameters/nested > /dev/null 2>&1 && return 0
+	grep 'Y' /sys/module/kvm_amd/parameters/nested > /dev/null 2>&1 && return 0
+	grep '1' /sys/module/kvm_intel/parameters/nested > /dev/null 2>&1 && return 0
+	grep 'Y' /sys/module/kvm_intel/parameters/nested > /dev/null 2>&1 && return 0
+
+	return 1
+}

-[ipx]
-# ipx: Enable ipx over UDP/IP emulation.
+_testQEMU_hostArch_x64-x64() {
+	local hostArch
+	hostArch=$(uname -m)
+
+	if [[ "$hostArch" != "x86_64" ]]
+	then
+		return 1
+	fi
+
+	return 0
+}

-ipx=false
+_testQEMU_x64-x64() {
+	_testQEMU_hostArch_x64-x64 || echo "warn: no native x64"
+	_testQEMU_hostArch_x64_hardwarevt || echo "warn: no x64 vt"
+	_testQEMU_hostArch_x64_nested || echo "warn: no nested x64"
+
+	_getDep qemu-system-x86_64
+	_getDep qemu-img
+
+	_getDep smbd
+
+	_wantGetDep /usr/share/OVMF/OVMF_CODE.fd
+	_wantGetDep /usr/share/qemu/OVMF.fd
+}

-[autoexec]
-# Lines in this section will be run at startup.
-# You can put your MOUNT lines here.
+_qemu-system() {
+	qemu-system-x86_64 "$@"
+}

-CZXWXcRMTo8EmM8i4d
+#Overload this function, or the guestArch variable, to configure QEMU with specialized parameters.
+_qemu_system_x86_64() {
+	qemu-system-x86_64 "$@"
+}

+_qemu_system_arm() {
+	qemu-system-arm "$@"
 }

-_test_dosbox() {
-	_getDep dosbox
-
-	! _noFireJail dosbox && _stop 1
+_qemu_system_aarch64() {
+	qemu-system-aarch64 "$@"
 }

-_prepare_dosbox() {
-	mkdir -p "$scriptLocal"/_dosbox
-
-	mkdir -p "$instancedVirtDir"
-	mkdir -p "$instancedVirtFS"
-	mkdir -p "$instancedVirtTmp"
+_integratedQemu_imagefilename() {
+	if [[ "$ubVirtDiskOverride" == "" ]]
+	then
+		local current_imagefilename
+		if ! current_imagefilename=$(_loopImage_imagefilename)
+		then
+			_messagePlain_bad 'fail: missing: vm*.img'
+			return 1
+		fi
+	else
+		current_imagefilename="$ubVirtDiskOverride"
+	fi

-	_here_dosbox_base_conf > "$instancedVirtDir"/dosbox.conf
+	echo "$current_imagefilename"

+	return 0
 }

-_dosbox_sequence() {
-	_start
-
-	_prepare_dosbox
-
-	echo -e -n 'mount c ' >> "$instancedVirtDir"/dosbox.conf
-	echo "$scriptLocal"/_dosbox >> "$instancedVirtDir"/dosbox.conf
-	echo 'c:' >> "$instancedVirtDir"/dosbox.conf
+# ATTENTION: Override with 'ops' or similar.
+_integratedQemu_x64_display() {

-	export sharedGuestProjectDir='X:'
-	_virtUser "$@"
+	#qemuArgs+=(-device virtio-vga,virgl=on -display gtk,gl=on)

-	if [[ "$sharedHostProjectDir" != "" ]]
-	then
-		echo -e -n 'mount x ' >> "$instancedVirtDir"/dosbox.conf
-		echo "$sharedHostProjectDir" >> "$instancedVirtDir"/dosbox.conf
-		echo 'x:' >> "$instancedVirtDir"/dosbox.conf
-	fi
+	#return 0

-	#Alternatively, "-c" could be used with dosbox, but this seems not to work well with multiple parameters.
-	#Note "DOS" will not like paths not conforming to 8.3 .
-	_safeEcho_newline "${processedArgs[@]}" >> "$instancedVirtDir"/dosbox.conf

-	dosbox -conf "$instancedVirtDir"/dosbox.conf
+	true

-	_safeRMR "$instancedVirtDir" || _stop 1
+	#

-	_stop
-}
-
-_dosbox() {
-	"$scriptAbsoluteLocation" _dosbox_sequence "$@"
+	# https://www.kraxel.org/blog/2019/09/display-devices-in-qemu/
+	[[ "$qemuOStype" == "" ]] && [[ "$vboxOStype" != "" ]] && qemuOStype="$vboxOStype"
+	if [[ "$ub_override_qemu_livecd" != '' ]] || [[ "$ub_override_qemu_livecd_more" != '' ]]
+	then
+		# DANGER: Beware not all "qemu" emulated "display" 'devices' seem to support 'hibernation' ('suspend to disk') !
+		# At least 'qxl-vga' is known to successfully resume .
+		# Assume 'livecd' is 'linux' .
+		#qemuArgs+=(-device qxl-vga -display gtk)
+		qemuArgs+=(-device qxl-vga)
+	elif [[ "$qemuOStype" == 'Debian_64' ]] || [[ "$qemuOStype" == 'Gentoo_64' ]]
+	then
+		# Not yet enabled (virtio-vga) by default for a few reasons.
+		# *) May need to specify 'gtk' or 'sdl' to enable OpenGL acceleration. If these backends are missing, qemu may fail.
+		# *) Some guest configurations (eg. LXDE and Linux 4.x instead of KDE/Plasma and Linux 5.x) may not continue updating guest display resize requests, ultimately causing guest to remain at low resolution (ie. 640x480) .
+		# *) Hardware graphics should only be necessary for a few specific applications (eg. FreeCAD, VR).
+		# *) Any use of 'virtio-vga' seems not to support 'linux' 'hibernation' ('suspend to disk') .
+		# https://github.com/mate-desktop/marco/issues/338
+		if [[ "$qemuNoGL" == 'true' ]]
+		then
+			qemuArgs+=(-device qxl-vga)
+			#qemuArgs+=(-device virtio-vga,virgl=on -display gtk,gl=off)
+		else
+			qemuArgs+=(-device qxl-vga)
+			#qemuArgs+=(-device virtio-vga,virgl=on -display gtk,gl=on)
+		fi
+	elif [[ "$qemuOStype" == 'Windows10_64' ]] || [[ "$qemuOStype" == 'Windows11_64' ]]
+	then
+		# WARNING: MSW11 may require 256MB VRAM. How this may be set by qemu is not obvious.
+		# https://blogs.oracle.com/virtualization/post/install-microsoft-windows-11-on-virtualbox
+		#qemuArgs+=(-device qxl)
+		qemuArgs+=(-device qxl-vga)
+	elif [[ "$qemuOStype" == 'WindowsXP' ]] || [[ "$qemuOStype" == 'legacy-obsolete' ]]
+	then
+		qemuArgs+=(-vga cirrus)
+	else
+		qemuArgs+=(-vga std)
+	fi
 }

-_testWINE() {
-	_getDep wine
+_integratedQemu_x64() {
+	_messagePlain_nominal 'init: _integratedQemu_x64'

-	if wine 2>&1 | grep 'wine32 is missing' > /dev/null 2>&1
+	[[ "$qemuOStype" == "" ]] && [[ "$vboxOStype" != "" ]] && qemuOStype="$vboxOStype"
+
+
+	local current_imagefilename
+	if ! current_imagefilename=$(_integratedQemu_imagefilename)
 	then
-		echo 'wine32 may be missing'
 		_stop 1
 	fi

-	! _noFireJail wine && _stop 1
-}
-
-_setBottleDir() {
-	export wineExeDir
-	export wineBottle
-	export WINEPREFIX

-	export sharedHostProjectDir
-	export sharedGuestProjectDir
-	export processedArgs
+	! mkdir -p "$instancedVirtDir" && _messagePlain_bad 'fail: mkdir -p instancedVirtDir= '"$instancedVirtDir" && _stop 1

-	local wineAppDir
-	local oldWineAppDir
+	! _commandBootdisc "$@" && _messagePlain_bad 'fail: _commandBootdisc' && _stop 1

-	#wineExeDir=$(_searchBaseDir "$@" "$PWD")
-	wineExeDir="$PWD"
+	#qemu-system-x86_64 -snapshot -machine accel=kvm -drive format=raw,file="$scriptLocal"/vm.img -drive file="$hostToGuestISO",media=cdrom -boot c -m 768

-	[[ -e "$1" ]] && [[ "$1" == *".exe" ]] && wineExeDir=$(_getAbsoluteFolder "$1")
+	#https://wiki.qemu.org/Documentation/9psetup#Mounting_the_shared_path
+	#qemu-system-x86_64 -snapshot -machine accel=kvm -drive format=raw,file="$scriptLocal"/vm.img -drive file="$hostToGuestISO",media=cdrom -boot c -m 768 -fsdev local,id=appFolder,path="$sharedHostProjectDir",security_model=mapped,writeout=writeout
+
+	#https://askubuntu.com/questions/614098/unable-to-get-execute-bit-on-samba-share-working-with-windows-7-client
+	#https://unix.stackexchange.com/questions/165554/shared-folder-between-qemu-windows-guest-and-linux-host
+	#https://linux.die.net/man/1/qemu-kvm

+	qemuArgs+=(-usb)

-	if uname -m | grep 64 > /dev/null 2>&1
+	if _testQEMU_hostArch_x64_nested
 	then
-		wineAppDir=${wineExeDir/\/_wbottle*}
-		wineBottle="$wineAppDir"/_wbottle
-
-		#Optional support for older naming convention.
-		#oldWineAppDir=${wineExeDir/\/wineBottle*}
-		#[[ -e "$oldWineAppDir"/wineBottle ]] && wineBottle="$oldWineAppDir"/wineBottle
+		_messagePlain_good 'supported: nested x64'

-		[[ "$wineBottleHere" != "true" ]] && wineBottle="$scriptLocal"/_wbottle
-	else
-		wineAppDir=${wineExeDir/\/_wine32*}
-		wineBottle="$wineAppDir"/_wine32
+		# WARNING: Nested virtualization support currently disabled by default. May impose frequent software updates or commonality between host/guest.
+		# Fail for Debian Buster/Stretch host/guest.
+		# Reasonably expected to fail with proprietary guest.
+		# https://bugzilla.redhat.com/show_bug.cgi?id=1565179

-		[[ "$wineBottleHere" != "true" ]] && wineBottle="$scriptLocal"/_wine32
+		# ATTENTION: Overload "demandNestKVM" with "ops" or similar.
+		if [[ "$demandNestKVM" == 'true' ]] #|| ( ! [[ "$virtOStype" == 'MSW'* ]] && ! [[ "$virtOStype" == 'Windows'* ]] && ! [[ "$qemuOStype" == 'Windows'* ]] )
+		then
+			[[ "$demandNestKVM" == 'true' ]] && _messagePlain_warn 'force: nested x64'
+			_messagePlain_warn 'warn: set: nested x64'
+			qemuArgs+=(-cpu host)
+		else
+			_messagePlain_good 'unset: nested x64'
+		fi

-		export WINEARCH
-		WINEARCH=win32
+	else
+		_messagePlain_warn 'missing: nested x64'
 	fi

-	mkdir -p "$wineBottle"
+	local hostThreadCount=$(cat /proc/cpuinfo | grep MHz | wc -l | tr -dc '0-9')
+	if [[ "$hostThreadCount" -ge "4" ]] || [[ "$hostThreadCount" -ge "8" ]]
+	then
+		[[ "$hostThreadCount" -ge "4" ]] && [[ "$hostThreadCount" -lt "8" ]] && _messagePlain_probe 'cpu: >4' && qemuArgs+=(-smp 4)
+		[[ "$hostThreadCount" -ge "8" ]] && _messagePlain_probe 'cpu: >6' && qemuArgs+=(-smp 6)
+	else
+		# Single-threaded host with guest 'efi', 'Windows10_64', 'Windows11_64', are all not plausible. Minimum dual-CPU requirement of MSW11 as default.
+		# ATTENTION: For guests benefitting from single core performance only, force such non-default by exporting 'vboxCPUs' with 'ops' or similar.
+		if [[ "$ubVirtPlatform" == *'efi' ]] || [[ "$ubVirtPlatformOverride" == *'efi' ]] || [[ "$qemuOStype" == "Win"*"10"* ]] || [[ "$qemuOStype" == "Win"*"11"* ]]
+		then
+			qemuArgs+=(-smp 2)
+		fi
+	fi

-	export WINEPREFIX="$wineBottle"/
+	#https://superuser.com/questions/342719/how-to-boot-a-physical-windows-partition-with-qemu
+	#qemuUserArgs+=(-drive format=raw,file="$scriptLocal"/vm.img)
+	#qemuUserArgs+=(-drive format=raw,file="$current_imagefilename")
+	if [[ "$ub_override_qemu_livecd" != '' ]]
+	then
+		qemuUserArgs+=(-drive file="$ub_override_qemu_livecd",media=cdrom)
+	elif [[ "$ub_override_qemu_livecd_more" != '' ]]
+	then
+		qemuUserArgs+=(-drive format=raw,file="$ub_override_qemu_livecd_more")
+	else
+		qemuUserArgs+=(-drive format=raw,file="$current_imagefilename")
+	fi

-	sharedHostProjectDir=/
-	sharedGuestProjectDir='Z:'
+	qemuUserArgs+=(-drive file="$hostToGuestISO",media=cdrom -boot c)

-	_virtUser "$@"
+	[[ "$vmMemoryAllocation" == "" ]] && vmMemoryAllocation="$vmMemoryAllocationDefault"

-}
-
-_setBottleHere() {
-	export wineBottleHere
-	wineBottleHere="true"
-}
-
-_winecfghere() {
-	_setBottleHere
-	_setBottleDir "$@"
+	# Must have at least 4096MB for 'livecd' , unless even larger memory allocation has been configured .
+	if [[ "$ub_override_qemu_livecd" != '' ]] || [[ "$ub_override_qemu_livecd_more" != '' ]]
+	then
+		if [[ "$vmMemoryAllocation" -lt 4096 ]]
+		then
+			vmMemoryAllocation=4096
+		fi
+	fi

-	winecfg
-}
-
-_winehere() {
-	_setBottleHere
-	_setBottleDir "$@"
+	#[[ "$ubVirtPlatform" == *'efi' ]] || [[ "$ubVirtPlatformOverride" == *'efi' ]]
+	if [[ "$vmMemoryAllocation" -lt 8704 ]] && ( [[ "$qemuOStype" == "Win"*"10"* ]] || [[ "$qemuOStype" == "Win"*"11"* ]] )
+	then
+		vmMemoryAllocation=8704
+	fi

-	wine "${processedArgs[@]}"
-}
-
-_winecfg() {
-	_setBottleDir "$@"
+	qemuUserArgs+=(-m "$vmMemoryAllocation")

-	winecfg
-}
-
-_wine() {
-	_setBottleDir "$@"
+	[[ "$qemuUserArgs_netRestrict" == "" ]] && qemuUserArgs_netRestrict="n"

-	wine "${processedArgs[@]}"
-}
-
-_here_dockerfile_entrypoint() {
-	cat << 'CZXWXcRMTo8EmM8i4d'
-ENTRYPOINT ["/usr/local/bin/ubiquitous_bash.sh", "_drop_docker"]
-CZXWXcRMTo8EmM8i4d
-}
-
-_here_dockerfile_special() {
-	cat << 'CZXWXcRMTo8EmM8i4d'
-RUN mkdir -p /usr/bin
-RUN mkdir -p /usr/local/bin
-RUN mkdir -p /usr/share
-RUN mkdir -p /usr/local/share
-
-RUN mkdir -p /usr/local/share/ubcore/bin
-
-COPY ubiquitous_bash.sh /usr/local/bin/ubiquitous_bash.sh
-
-COPY ubbin /usr/local/share/ubcore/bin
-
-COPY gosu-armel /usr/local/bin/gosu-armel
-COPY gosu-amd64 /usr/local/bin/gosu-amd64
-COPY gosu-i386 /usr/local/bin/gosu-i386
-
-RUN mkdir -p /etc/skel/Downloads
-
-RUN mkdir -p /opt/exec
-CZXWXcRMTo8EmM8i4d
-
-_here_dockerfile_entrypoint
-}
-
-_here_dockerfile_lite_scratch() {
-	cat << 'CZXWXcRMTo8EmM8i4d'
-FROM scratch
-COPY hello /
-CMD ["/hello"]
-CZXWXcRMTo8EmM8i4d
-}
-
-#No production use. Dockerfiles now stored in "_lib". Kept for reference only.
-_here_dockerfile_lite_debianjessie() {
-	cat << 'CZXWXcRMTo8EmM8i4d'
-FROM ubvrt/debian:jessie
-CZXWXcRMTo8EmM8i4d
-}
-
-#No production use. Dockerfiles now stored in "_lib". Kept for reference only.
-_here_dockerfile_debianjessie() {
-	cat << 'CZXWXcRMTo8EmM8i4d'
-FROM ubvrt/debian:jessie
-
-RUN apt-get update && apt-get -y --no-install-recommends install \
-ca-certificates \
-curl \
-x11-apps \
-libgl1-mesa-glx libgl1-mesa-dri mesa-utils \
-wget \
-gnupg2 \
-file \
-build-essential \
-fuse \
-hicolor-icon-theme
-
-RUN apt-get -y install \
-default-jre
-CZXWXcRMTo8EmM8i4d
-}
-
-_here_dockerfile() {
-	[[ -e "$scriptLocal"/Dockerfile ]] && cat "$scriptLocal"/Dockerfile && _here_dockerfile_special && return 0
+	qemuUserArgs+=(-net nic,model=rtl8139 -net user,restrict="$qemuUserArgs_netRestrict",smb="$sharedHostProjectDir")

-	#Reads out Dockerfile from _lib. Not recommended. Supported primarily for sake of example.
-	[[ "$dockerBaseObjectName" == "ubvrt/debian:jessie" ]] && [[ -e "$scriptAbsoluteFolder"/_lib/docker/debian/ubvrt/Dockerfile ]] && cat "$scriptAbsoluteFolder"/_lib/docker/debian/ubvrt/Dockerfile && _here_dockerfile_special && return 0
+	#qemuArgs+=(-usbdevice tablet)
+	qemuArgs+=(-device usb-tablet)

-	#[[ "$dockerBaseObjectName" == "ubvrt/debian:jessie" ]] && _here_dockerfile_debianjessie "$@" && _here_dockerfile_debianjessie && return 0

-	[[ "$dockerBaseObjectName" == "scratch:latest" ]] && _here_dockerfile_lite_scratch "$@" && return 0

-	return 1
-}
-
-# WARNING Stability of this function's API is important for compatibility with existing docker images.
-_drop_docker() {
-	# Add local user
-	# Either use the LOCAL_USER_ID if passed in at runtime or
-	# fallback
+	_integratedQemu_x64_display

-	USER_ID=${LOCAL_USER_ID:-9001}

-	if [[ "$LOCAL_USER_ID" == "" ]] || [[ "$LOCAL_USER_ID" == "0" ]]
+
+	[[ "$qemuArgs_audio" == "" ]] && qemuArgs+=(-device ich9-intel-hda -device hda-duplex)
+
+	# https://github.com/elisa-tech/meta-elisa/issues/23
+	# https://wiki.qemu.org/ChangeLog/6.0
+	# qemuArgs+=(-show-cursor)
+	local current_qemu_version_cursor
+	current_qemu_version_cursor=$(_qemu_system_x86_64 -version | grep version | sed 's/.*version\ //' | sed 's/\ .*//' | cut -f1 -d\. | tr -dc '0-9')
+	if [[ "$current_qemu_version_cursor" -lt "6" ]] && [[ "$current_qemu_version_cursor" != "" ]]
 	then
-		#Root access by default, typically used to make permanent changes to a container for commitment to image.
-		if [[ "$1" == "" ]]
+		qemuArgs+=(-show-cursor)
+	fi
+
+	if _testQEMU_hostArch_x64_hardwarevt
+	then
+		_messagePlain_good 'found: kvm'
+		qemuArgs+=(-machine accel=kvm)
+	else
+		_messagePlain_warn 'missing: kvm'
+	fi
+
+
+	# https://blog.matejc.com/blogs/myblog/playing-on-qemu
+	# https://www.kraxel.org/repos/jenkins/edk2/
+	# https://www.kraxel.org/repos/
+	# https://unix.stackexchange.com/questions/52996/how-to-boot-efi-kernel-using-qemu-kvm
+	# https://blog.hartwork.org/posts/get-qemu-to-boot-efi/
+	# https://www.kraxel.org/repos/jenkins/edk2/
+	# https://www.kraxel.org/repos/jenkins/edk2/edk2.git-ovmf-x64-0-20200515.1447.g317d84abe3.noarch.rpm
+	if ( [[ "$ubVirtPlatform" == "x64-efi" ]] || [[ "$qemuOStype" == "Win"*"10"* ]] || [[ "$qemuOStype" == "Win"*"11"* ]] ) && [[ "$ub_override_qemu_livecd" == '' ]] && [[ "$ub_override_qemu_livecd_more" == '' ]]
+	then
+		if [[ -e "$HOME"/core/installations/ovmf/OVMF_CODE-pure-efi.fd ]] && [[ -e "$HOME"/core/installations/ovmf/OVMF_VARS-pure-efi.fd ]]
 		then
-			/bin/bash "$@"
-			exit
+			qemuArgs+=(-drive if=pflash,format=raw,readonly,file="$HOME"/core/installations/ovmf/OVMF_CODE-pure-efi.fd -drive if=pflash,format=raw,file="$HOME"/core/installations/ovmf/OVMF_VARS-pure-efi.fd)
+		elif [[ -e /usr/share/OVMF/OVMF_CODE.fd ]]
+		then
+			qemuArgs+=(-bios /usr/share/OVMF/OVMF_CODE.fd)
+		else
+			# Bootloader is not declared as other than legacy bios type.
+			# Do nothing by default. Loading an EFI bootloader with CSM module may cause unwanted delay.
+			true
 		fi
-
-		"$@"
-		exit
 	fi

-	#echo "Starting with UID : $USER_ID"
-	useradd --shell /bin/bash -u $USER_ID -o -c "" -m "$virtSharedUser" >/dev/null 2>&1
-	usermod -a -G video "$virtSharedUser"
-	export HOME=/home/"$virtSharedUser"
+	qemuArgs+=("${qemuSpecialArgs[@]}" "${qemuUserArgs[@]}")

-	chown "$virtSharedUser":"$virtSharedUser" "$HOME"
+	_messagePlain_probe _qemu_system_x86_64 "${qemuArgs[@]}"
+	_qemu_system_x86_64 "${qemuArgs[@]}"

-	#cp -r /etc/skel/. "$HOME"
+	_safeRMR "$instancedVirtDir" || _stop 1
+}
+
+# DANGER: Do NOT call without snapshot on RasPi images intended for real (ie. arm64, "RPI3") hardware! Untested!
+# WARNING: NOT recommended. Severely restricted performance and features.
+#https://azeria-labs.com/emulate-raspberry-pi-with-qemu/
+#https://www.raspberrypi.org/forums/viewtopic.php?t=195565
+#https://github.com/dhruvvyas90/qemu-rpi-kernel
+#qemu-system-arm -kernel ./kernel-raspi -cpu arm1176 -m 256 -M versatilepb -serial stdio -append "root=/dev/sda2 rootfstype=ext4 rw" -hda ./vm-raspbian.img -redir tcp:5022::22 -no-reboot
+#qemu-system-arm -kernel ./kernel-raspi -cpu arm1176 -m 256 -M versatilepb -dtb versatile-pb.dtb -no-reboot -append "root=/dev/sda2 panic=1 rootfstype=ext4 rw" -net nic -net user,hostfwd=tcp::5022-:22 -hda ./vm-raspbian.img
+#https://raspberrypi.stackexchange.com/questions/45936/has-anyone-managed-to-run-raspberry-pi-3-with-kvm-enabled
+#https://wiki.qemu.org/Documentation/Platforms/ARM
+#https://github.com/bztsrc/raspi3-tutorial
+#https://translatedcode.wordpress.com/2018/04/25/debian-on-qemus-raspberry-pi-3-model/
+_integratedQemu_raspi() {
+	_messagePlain_nominal 'init: _integratedQemu_raspi'

-	# Change to localPWD or home.
-	cd "$localPWD"

-	# Drop to user ubvrtusr or remain root, using gosu.
+	local current_imagefilename
+	if ! current_imagefilename=$(_integratedQemu_imagefilename)
+	then
+		_stop 1
+	fi

-	##Example alternative code for future reference.
-	#export INPUTRC='~/.inputrc'
-	#export profileScriptLocation=/usr/local/bin/entrypoint.sh
-	#export profileScriptFolder=/usr/local/bin/

-	#bash -c ". ./etc/profile > /dev/null 2>&1 ; set -o allexport ; . ~/.bash_profile > /dev/null 2>&1 ; . ~/.bashrc > /dev/null 2>&1 ; . ./ubiquitous_bash.sh _importShortcuts > /dev/null 2>&1 ; set +o allexport ; bash --noprofile --norc -i ; . ~/.bash_logout > /dev/null 2>&1"
+	! mkdir -p "$instancedVirtDir" && _messagePlain_bad 'fail: mkdir -p instancedVirtDir= '"$instancedVirtDir" && _stop 1

-	#bash --init-file <(echo ". ~/.bashrc ; . ./ubiquitous_bash.sh _importShortcuts")
+	! _commandBootdisc "$@" && _messagePlain_bad 'fail: _commandBootdisc' && _stop 1

-	#_gosuExecVirt bash --init-file <(echo ". ~/.bashrc ; . /usr/local/bin/entrypoint.sh _importShortcuts" "$@")
+	! [[ -e "$scriptLocal"/kernel-raspi ]] && _messagePlain_bad 'fail: missing: kernel-raspi' && _messagePlain_probe 'request: obtain kernel-raspi : https://github.com/dhruvvyas90/qemu-rpi-kernel'
+	! [[ -e "$scriptLocal"/kernel-raspi ]] && _messagePlain_bad 'fail: missing: versatile-pb.dtb' && _messagePlain_probe 'request: obtain versatile-pb.dtb : https://github.com/dhruvvyas90/qemu-rpi-kernel'
+	qemuUserArgs+=(-kernel "$scriptLocal"/kernel-raspi -cpu arm1176 -M versatilepb -dtb "$scriptLocal"/versatile-pb.dtb -append "root=/dev/sda2 panic=1 rootfstype=ext4 rw" -no-reboot)
+	#qemuUserArgs+=(-kernel "$scriptLocal"/kernel-raspi -M raspi3 -append "root=/dev/sda2 rootfstype=ext4 rw" -no-reboot)
+	#qemuUserArgs+=(-kernel "$scriptLocal"/kernel-raspi -M virt -bios /usr/share/qemu-efi/QEMU_EFI.fd -append "root=/dev/sda2 panic=1 rootfstype=ext4 rw" -no-reboot)
+	#qemuUserArgs+=(-kernel "$scriptLocal"/kernel-raspi -cpu arm1176 -M virt -bios /usr/share/qemu-efi/QEMU_EFI.fd -append "root=/dev/sda2 panic=1 rootfstype=ext4 rw" -no-reboot)

-	##Setup and launch.
-	"$scriptAbsoluteLocation" _gosuExecVirt cp -r /etc/skel/. "$virtGuestHomeDrop"
+	#local hostThreadCount=$(cat /proc/cpuinfo | grep MHz | wc -l | tr -dc '0-9')
+	#[[ "$hostThreadCount" -ge "4" ]] && _messagePlain_probe 'cpu: >4' && qemuArgs+=(-smp 4)

-	"$scriptAbsoluteLocation" _gosuExecVirt "$scriptAbsoluteLocation" _setupUbiquitous_nonet
+	#https://superuser.com/questions/342719/how-to-boot-a-physical-windows-partition-with-qemu
+	#qemuUserArgs+=(-drive format=raw,file="$scriptLocal"/vm-raspbian.img)
+	qemuUserArgs+=(-drive format=raw,file="$current_imagefilename")

-	# Drop to user ubvrtusr, using gosu.
-	_gosuExecVirt "$@"

+	#qemuUserArgs+=(-drive if=none,id=uas-cdrom,media=cdrom,file="$hostToGuestISO" -device nec-usb-xhci,id=xhci -device usb-uas,id=uas,bus=xhci.0 -device scsi-cd,bus=uas.0,scsi-id=0,lun=5,drive=uas-cdrom)
+
+	qemuUserArgs+=(-drive file="$hostToGuestISO",media=cdrom -boot c)
+
+	#[[ "$vmMemoryAllocation" == "" ]] && vmMemoryAllocation="$vmMemoryAllocationDefault"
+	#qemuUserArgs+=(-m "$vmMemoryAllocation")
+	qemuUserArgs+=(-m 256)
+
+	# ATTENTION: Overload with "ops" or similar.
+	[[ "$qemuUserArgs_netRestrict" == "" ]] && qemuUserArgs_netRestrict="n"
+	#[[ "$qemuUserArgs_net_guestSSH" == "" ]] && qemuUserArgs_net_guestSSH=",hostfwd=tcp::5022-:22"
+	[[ "$qemuUserArgs_net_guestSSH" == "" ]] && qemuUserArgs_net_guestSSH=""
+
+	#qemuUserArgs+=(-net nic,model=rtl8139 -net user,restrict="$qemuUserArgs_netRestrict",smb="$sharedHostProjectDir")
+	qemuUserArgs+=(-net nic -net user,restrict="$qemuUserArgs_netRestrict""$qemuUserArgs_net_guestSSH",smb="$sharedHostProjectDir")
+
+	#qemuArgs+=(-usbdevice tablet)
+
+	#qemuArgs+=(-vga cirrus)
+
+	#[[ "$qemuArgs_audio" == "" ]] && qemuArgs+=(-device ich9-intel-hda -device hda-duplex)
+
+	#qemuArgs+=(-show-cursor)
+
+	qemuUserArgs+=(-serial stdio)
+
+	qemuArgs+=("${qemuSpecialArgs[@]}" "${qemuUserArgs[@]}")
+
+	_messagePlain_probe _qemu_system_arm "${qemuArgs[@]}"
+	_qemu_system_arm "${qemuArgs[@]}"
+	#_messagePlain_probe _qemu_system_aarch64 "${qemuArgs[@]}"
+	#_qemu_system_aarch64 "${qemuArgs[@]}"
+
+	_safeRMR "$instancedVirtDir" || _stop 1
 }

-#Runs command directly if member of "docker" group, or through sudo if not.
-#Docker inevitably requires effective root.
-_permitDocker() {
-	if groups | grep docker > /dev/null 2>&1
+_integratedQemu() {
+	# Include platform determination code for correct determination of partition and mounts.
+	_loopImage_imagefilename > /dev/null 2>&1
+
+	if [[ "$ubVirtPlatform" == "x64-bios" ]]
 	then
-		"$@"
+		_integratedQemu_x64 "$@"
 		return "$?"
 	fi

-	if _wantSudo > /dev/null 2>&1
+	if [[ "$ubVirtPlatform" == "x64-efi" ]]
 	then
-		sudo -n "$@"
+		_integratedQemu_x64 "$@"
 		return "$?"
 	fi

-	return 1
+	# TODO: 'efi' .
+	#https://unix.stackexchange.com/questions/52996/how-to-boot-efi-kernel-using-qemu-kvm
+
+	if [[ "$ubVirtPlatform" == "raspbian" ]]
+	then
+		_integratedQemu_raspi "$@"
+		return "$?"
+	fi
+
+	#Default x64 .
+	if [[ "$ub_keepInstance" == 'true' ]]
+	then
+		_integratedQemu_x64 "$@"
+		return "$?"
+	fi
+	"$scriptAbsoluteLocation" _integratedQemu_x64 "$@"
+	return "$?"
 }

-_test_docker() {
-	_testGosu || _stop 1
+#"${qemuSpecialArgs[@]}" == ["-snapshot "]
+_userQemu_sequence() {
+	unset qemuSpecialArgs

-	_checkDep gosu-armel
-	_checkDep gosu-amd64
-	_checkDep gosu-i386
+	qemuSpecialArgs+=("-snapshot")

+	export qemuSpecialArgs

-	if ! _if_cygwin
-	then
-
-		#https://docs.docker.com/engine/installation/linux/docker-ce/debian/#install-using-the-repository
-		#https://wiki.archlinux.org/index.php/Docker#Installation
-		#sudo -n usermod -a -G docker "$USER"
-
-		_getDep /sbin/losetup
-		if ! [[ -e "/dev/loop-control" ]] || ! [[ -e "/sbin/losetup" ]]
-		then
-			echo 'may be missing loopback interface'
-			_stop 1
-		fi
-
-		_getDep docker
-		_getDep docker-compose
-
-		local dockerPermission
-		dockerPermission=$(_permitDocker echo true 2> /dev/null)
-		if [[ "$dockerPermission" != "true" ]]
-		then
-			echo 'no permissions to run docker'
-			_stop 1
-		fi
-
-
-		#if ! _permitDocker docker run hello-world 2>&1 | grep 'Hello from Docker' > /dev/null 2>&1
-		#then
-		#	echo 'failed docker hello world'
-		#	_stop 1
-		#fi
-
-	fi
+	_start

+	_integratedQemu "$@" || _stop 1

+	_stop
+}
+
+_userQemu() {
+	_findInfrastructure_virtImage ${FUNCNAME[0]} "$@"
+	[[ "$ubVirtImageLocal" == "false" ]] && return

-	if ! _discoverResource moby/contrib/mkimage.sh > /dev/null 2>&1 && ! _discoverResource docker/contrib/mkimage.sh
-	#if true
+	if [[ "$ub_keepInstance" == 'true' ]]
 	then
-		echo
-		echo 'base images cannot be created without mkimage'
-		#_stop 1
+		_userQemu_sequence "$@"
+		return
 	fi
+	"$scriptAbsoluteLocation" _userQemu_sequence "$@"
+}
+
+_editQemu_sequence() {
+	unset qemuSpecialArgs

-	if ! [[ -e "$scriptBin"/hello ]]
-	then
-		echo
-		echo 'some base images cannot be created without hello'
-	fi
+	export qemuSpecialArgs

+	_start

+	#_messageNormal "Checking lock."
+	#_readLocked "$scriptLocal"/_qemuEdit && _messageError 'lock: _qemuEdit' && _stop 1
+	#! _createLocked "$scriptLocal"/_qemuEdit  && _messageError 'lock: _qemuEdit' && _stop 1

-	if _if_cygwin
-	then
-		return 0
-	fi
+	_messageNormal "Checking lock and conflicts."
+	export specialLock="$lock_open_qemu"
+	! _open true true && _messageError 'FAIL' && _stop 1

-	sudo -n systemctl status docker 2>&1 | head -n 2 | grep -i 'chroot' > /dev/null && return 0
-	systemctl status docker 2>&1 | head -n 2 | grep -i 'chroot' > /dev/null && return 0
+	_messageNormal "Launch: _integratedQemu."
+	! _integratedQemu "$@" && _messageError 'FAIL' && _stop 1

-	_permitDocker docker import "$scriptBin"/"dockerHello".tar "ubdockerhello" --change 'CMD ["/hello"]' > /dev/null 2>&1
-	if ! _permitDocker docker run "ubdockerhello" 2>&1 | grep 'hello world' > /dev/null 2>&1
+	rm -f "$scriptLocal"/_qemuEdit > /dev/null 2>&1
+	export specialLock="$lock_open_qemu"
+	! _close true true && _messageError 'FAIL' && _stop 1
+
+	_stop
+}
+
+# DANGER: Do NOT call without snapshot on RasPi images intended for real (ie. arm64, "RPI3") hardware! Untested!
+_editQemu() {
+	_findInfrastructure_virtImage ${FUNCNAME[0]} "$@"
+	[[ "$ubVirtImageLocal" == "false" ]] && return
+
+	if [[ "$ub_keepInstance" == 'true' ]]
 	then
-		echo 'failed ubdockerhello'
-		echo 'request: may require iptables legacy'
-		echo 'sudo -n update-alternatives --set iptables /usr/sbin/iptables-legacy'
-		echo 'sudo -n update-alternatives --set ip6tables /usr/sbin/ip6tables-legacy'
-		_stop 1
+		_editQemu_sequence "$@"
+		return
+	fi
+	"$scriptAbsoluteLocation" _editQemu_sequence "$@"
+}
+
+_persistentQemu() {
+	_editQemu "$@"
+}
+
+_testVBox() {
+	if ( [[ -e /etc/issue ]] && cat /etc/issue | grep 'Debian' > /dev/null 2>&1 ) || ( [[ -e /etc/issue ]] && cat /etc/issue | grep 'Ubuntu' > /dev/null 2>&1 )
+	then
+		if ! dpkg -l | grep linux-headers-$(uname -r) > /dev/null 2>&1
+		then
+			sudo -n apt-get install -y linux-headers-$(uname -r)
+		fi
 	fi

+	_getDep VirtualBox
+	_getDep VBoxSDL
+	_getDep VBoxManage
+	_getDep VBoxHeadless
+
+	#sudo -n checkDep dkms
+
+	! _noFireJail virtualbox && _stop 1
+
+	return 0
 }


-_checkBaseDirRemote_docker() {
-	#-e LOCAL_USER_ID=`id -u $USER`
-	if ! _permitDocker docker run -it --name "$dockerContainerObjectNameInstanced"_cr --rm "$dockerImageObjectName" /bin/bash -c '[[ -e "'"$1"'" ]] && ! [[ -d "'"$1"'" ]] && [[ "'"$1"'" != "." ]] && [[ "'"$1"'" != ".." ]] && [[ "'"$1"'" != "./" ]] && [[ "'"$1"'" != "../" ]]'
+_checkVBox_raw() {
+	#Use existing VDI image if available.
+	[[ -e "$scriptLocal"/vm.vdi ]] && _messagePlain_bad 'conflict: vm.vdi' && return 1
+
+	# WARNING: Only 'vm.img' is supported as a raw image file name for vbox virtualization backend.
+	[[ ! -e "$scriptLocal"/vm.img ]] && _messagePlain_bad 'missing: vm.img' && return 1
+
+	return 0
+}
+
+# WARNING
+# Per VirtualBox developers, "This is a development tool and shall only be used to analyse problems. It is completely unsupported and will change in incompatible ways without warning."
+# If that happens, this function will be revised quickly, possibly to the point of generating the VMDK file itself with a here document instead of VirtualBox commands. See "_diag/data/vmdkRawExample".
+_create_vbox_raw() {
+	if ! VBoxManage internalcommands createrawvmdk -filename "$vboxRaw" -rawdisk "$1" > "$vboxRaw".log
 	then
-		return 1
+		_messagePlain_bad 'fail: 'VBoxManage internalcommands createrawvmdk -filename "$vboxRaw" -rawdisk "$1" '>' "$vboxRaw".log
 	fi
 	return 0
 }

-_userDocker_sequence() {
+_mountVBox_raw_sequence() {
+	_messagePlain_nominal 'start: _mountVBox_raw_sequence'
 	_start
-	_prepare_docker
-	local userDockerExitStatus

-	export checkBaseDirRemote=_checkBaseDirRemote_docker
-	_virtUser "$@" >> "$logTmp"/usrdock.log 2>&1
+	_checkVBox_raw || _stop 1

-	#"$sharedHostProjectDir"
-	#"${processedArgs[@]}"
+	! _wantSudo && _messagePlain_bad 'bad: sudo' && return 1

-	local dockerRunArgs
+	_prepare_instance_vbox

-	#Translation only.
-	local LOCAL_USER_ID=$(id -u)
-	dockerRunArgs+=(-e virtSharedUser="$virtGuestUser" -e localPWD="$localPWD" -e LOCAL_USER_ID="$LOCAL_USER_ID")
+	rm -f "$vboxRaw" > /dev/null 2>&1

-	#Directory sharing.
-	dockerRunArgs+=(-v "$HOME"/Downloads:"$virtGuestHome"/Downloads:rw -v "$sharedHostProjectDir":"$sharedGuestProjectDir":rw)

-	#Display
-	dockerRunArgs+=(-e DISPLAY=$DISPLAY -e "XAUTHORITY=${XAUTH}")
-	dockerRunArgs+=(-v $XSOCK:$XSOCK:rw -v $XAUTH:$XAUTH:rw)
-	#dockerRunArgs+=(-v /tmp:/tmp:rw)

-	#FUSE (AppImage)
-	dockerRunArgs+=(--cap-add SYS_ADMIN --device /dev/fuse --security-opt apparmor:unconfined)
-
-	#OpenGL, Intel HD Graphics.
-	dockerRunArgs+=(--device=/dev/dri:/dev/dri)
+	if _tryExecFull _hook_systemd_shutdown_action "_closeVBoxRaw" "$sessionid"
+	then
+		_messagePlain_good 'pass: _hook_systemd_shutdown_action'
+	else
+		_messagePlain_bad 'fail: _hook_systemd_shutdown_action'
+	fi

-	_permitDocker docker run -it --name "$dockerContainerObjectNameInstanced" --rm "${dockerRunArgs[@]}" "$dockerImageObjectName" "${processedArgs[@]}"


-	userDockerExitStatus="$?"

-	rm -f "$logTmp"/usrdock.log > /dev/null 2>&1
-	_stop "$userDockerExitStatus"
-}
-
-_userDocker() {
-	_findInfrastructure_virtImage ${FUNCNAME[0]} "$@"
-	[[ "$ubVirtImageLocal" == "false" ]] && return
+	local current_imagefilename
+	current_imagefilename=$(_loopImage_imagefilename)

-	local dockerImageNeeded
-	"$scriptAbsoluteLocation" _create_docker_image_needed_sequence > /dev/null 2>&1
-	dockerImageNeeded="$?"
-	[[ "$dockerImageNeeded" == "0" ]] && return 1
-	[[ "$dockerImageNeeded" == "1" ]] && return 1
+	_messagePlain_nominal 'Creating loopback.'

-	"$scriptAbsoluteLocation" _userDocker_sequence "$@"
-	return "$?"
-}
-
-
-
-_write_wslconfig() {
-    ! _if_cygwin && _messagePlain_bad 'fail: Cygwin/MSW only' && return 1
-    if _if_cygwin
-    then
-        _here_wsl_config "$1" > "$USERPROFILE"/.wslconfig
-        return
-    fi
+	# Echo error message.
+	[[ -e "$scriptLocal"/vboxloop ]] && _messagePlain_bad 'fail: copy vboxloop' && _stop 1
+
+	! _loopFull "$scriptLocal"/vboxloop && _messagePlain_bad 'fail: losetup' && _stop 1
+
+
+
+	local vboximagedev
+	vboximagedev=$(cat "$scriptLocal"/vboxloop)
+
+
+	if _detect_deviceAsVirtImage "$current_imagefilename"
+	then
+		_messagePlain_warn 'warn: chown: ignoring device'
+	else
+		! sudo -n chown "$USER" "$vboximagedev" && _messagePlain_bad 'chown vboximagedev= '"$vboximagedev" && _stop 1
+	fi
+
+
+	_messagePlain_nominal 'Creating VBoxRaw.'
+	_create_vbox_raw "$vboximagedev"
+
+
+
+	_messagePlain_nominal 'stop: _mountVBox_raw_sequence'
+	#_safeRMR "$instancedVirtDir" || _stop 1
+	_rm_instance_vbox || _stop 1
+	_stop 0
 }

-
-
-
-
-# End user function .
-_setup_wsl2_procedure() {
-    ! _if_cygwin && _messagePlain_bad 'fail: Cygwin/MSW only' && return 1
-
-    _messageNormal 'init: _setup_wsl2'
-
-    _messagePlain_nominal 'setup: write: _write_msw_WSLENV'
-    _write_msw_WSLENV
-
-    _messagePlain_nominal 'setup: write: _write_msw_wslconfig'
-    _write_wslconfig "ub_ignore_kernel_wsl"
-
-    _messagePlain_nominal 'setup: wsl2'
-
-    # https://www.omgubuntu.co.uk/how-to-install-wsl2-on-windows-10
-
-    _messagePlain_probe dism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart
-    dism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart
-
-    _messagePlain_probe dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart
-    dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart
-
-    _messagePlain_probe wsl --set-default-version 2
-    wsl --set-default-version 2
-
-    _messagePlain_probe wsl --update
-    wsl --update
-
-    _messagePlain_probe wsl --install --no-launch
-    wsl --install --no-launch
-
-    echo 'WSL errors and usage information above may or may not be disregarded.'
-
-    _messagePlain_probe wsl --update
-    wsl --update
-
-    _messagePlain_probe wsl --set-default-version 2
-    wsl --set-default-version 2
-
-    _messagePlain_probe wsl --update
-    wsl --update
-
-    sleep 45
-    wsl --update
-
-    sleep 5
-    wsl --update
-
-    sleep 5
-    wsl --set-default-version 2
-
-    sleep 5
-    wsl --update
-
-    sleep 5
-    wsl --set-default-version 2
-}
-_setup_wsl2() {
-    "$scriptAbsoluteLocation" _setup_wsl2_procedure "$@"
-}
-_setup_wsl() {
-    _setup_wsl2 "$@"
+_mountVBox_raw() {
+	"$scriptAbsoluteLocation" _mountVBox_raw_sequence
+	return "$?"
 }

-
-
-
-
-
-
-
-
-_here_wsl_config() {
-    cat << 'CZXWXcRMTo8EmM8i4d'
-[wsl2]
-memory=999GB
-CZXWXcRMTo8EmM8i4d
-
-    if [[ -e /cygdrive/c/core/infrastructure/ubdist-kernel/ubdist-kernel ]] && [[ "$1" != "ub_ignore_kernel_wsl" ]]
-    then
-        echo 'kernel=C:\\core\\infrastructure\\ubdist-kernel\\ubdist-kernel'
-    fi
-
-    echo
+_waitVBox_opening() {
+	! [[ -e "$vboxRaw" ]] && return 1
+	! [[ -e "$scriptLocal"/vboxloop ]] && return 1
+
+	local vboximagedev=$(cat "$safeTmp"/vboxloop)
+	! [[ -e "$vboximagedev" ]] && return 1
 }

-
-_here_wsl_conf() {
-    cat << 'CZXWXcRMTo8EmM8i4d'
-
-[boot]
-systemd = true
-command = /bin/bash -c 'systemctl stop sddm ; rm -f /root/_rootGrab.sh ; usermod -a -G kvm user ; chown -v root:kvm /dev/kvm ; chmod 660 /dev/kvm ; ( rm /home/user/___quick/mount.sh ; rmdir /home/user/___quick ; ( [[ ! -e /home/user/___quick ]] && ln -s /mnt/c/q /home/user/___quick ) ; rm -f /home/user/___quick/q )'
-
-[user]
-default = user
-
-[wsl2]
-nestedVirtualization=true
-
-[automount]
-options = "metadata"
-
-CZXWXcRMTo8EmM8i4d
+_umountVBox_raw() {
+	! _umountFull "$scriptLocal"/vboxloop && _stop 1
+
+	rm -f "$scriptLocal"/vboxloop > /dev/null 2>&1
+	rm -f "$vboxRaw" > /dev/null 2>&1
+	rm -f "$vboxRaw".log > /dev/null 2>&1
+
+	return 0
 }

-
-
-
-
-
-
-
-
-_here_wsl_qt5ct_conf() {
-    cat << 'CZXWXcRMTo8EmM8i4d'
-
-[Appearance]
-color_scheme_path=/usr/share/qt5ct/colors/airy.conf
-custom_palette=false
-icon_theme=breeze-dark
-standard_dialogs=default
-style=Breeze
-
-[Interface]
-activate_item_on_single_click=1
-buttonbox_layout=0
-cursor_flash_time=1000
-dialog_buttons_have_icons=1
-double_click_interval=400
-gui_effects=@Invalid()
-keyboard_scheme=2
-menus_have_icons=true
-show_shortcuts_in_context_menus=true
-stylesheets=@Invalid()
-toolbutton_style=4
-underline_shortcut=1
-wheel_scroll_lines=3
-
-[Troubleshooting]
-force_raster_widgets=1
-ignored_applications=@Invalid()
-
-CZXWXcRMTo8EmM8i4d
+_waitVBox_closing() {
+	true
 }

-_write_wsl_qt5ct_conf() {
-    if [[ "$HOME" == "/root" ]] || [[ $(id -u) == 0 ]]
-    then
-        return 1
-    fi
-
-    local currentHome
-    currentHome="$HOME"
-    [[ "$currentHome" == "/root" ]] && currentHome="/home/user"
-    [[ "$1" != "" ]] && currentHome="$1"
-
-    [[ -e "$currentHome"/.config/qt5ct/qt5ct.conf ]] && return 0
-
-    mkdir -p "$currentHome"/.config/qt5ct
-    mkdir -p "$currentHome"/.config/qt5ct/colors
-    mkdir -p "$currentHome"/.config/qt5ct/qss
-
-    _here_wsl_qt5ct_conf > "$currentHome"/.config/qt5ct/qt5ct.conf
-
-    [[ -e "$currentHome"/.config/qt5ct/qt5ct.conf ]] && return 0
-
-    return 1
+_openVBoxRaw() {
+	export specialLock="$lock_open_vbox"
+
+	_checkVBox_raw || _stop 1
+
+	_messagePlain_nominal 'launch: _open _waitVBox_opening _mountVBox_raw'
+
+	local openVBoxRaw_exitStatus
+	_open _waitVBox_opening _mountVBox_raw
+	openVBoxRaw_exitStatus="$?"
+
+	export specialLock=""
+
+	return "$openVBoxRaw_exitStatus"
 }

+_closeVBoxRaw() {
+	_findInfrastructure_virtImage ${FUNCNAME[0]} "$@"
+	[[ "$ubVirtImageLocal" == "false" ]] && return
+
+	export specialLock="$lock_open_vbox"
+
+	if [[ "$1" == "--force" ]]
+	then
+		_close --force _waitVBox_closing _umountVBox_raw
+		[[ "$1" != "" ]] && _tryExecFull _unhook_systemd_shutdown "$1"
+		export specialLock=""
+		return 0
+	fi
+
+	_close _waitVBox_closing _umountVBox_raw
+	[[ "$1" != "" ]] && _tryExecFull _unhook_systemd_shutdown "$1"
+	export specialLock=""
+	return 0
+}

-
-# WARNING: Experimental. Installer use only. May cause issues with applications running natively from the MSW side. Fortunately, it seems QT_QPA_PLATFORMTHEME is ignored if qt5ct is not present, as expected in the case of 'native' QT MSW applications.
-_write_msw_qt5ct() {
-    setx QT_QPA_PLATFORMTHEME qt5ct /m
+##VBox Boxing
+_wait_lab_vbox() {
+	_prepare_lab_vbox || return 1
+
+	VBoxXPCOMIPCD_PID=$(cat "$VBoxXPCOMIPCD_PIDfile" 2> /dev/null)
+	#echo -e '\E[1;32;46mWaiting for VBoxXPCOMIPCD to finish... \E[0m'
+	while kill -0 "$VBoxXPCOMIPCD_PID" > /dev/null 2>&1
+	do
+		sleep 0.2
+	done
 }

-# https://www.ibm.com/docs/en/sva/7.0.0?topic=SSPREK_7.0.0/com.ibm.isam.doc_80/ameb_audit_guide/concept/con_lang_var_win.htm
-# Seems 'LANG=C' would also be a normal setting for MSW .
-# nix-shell --run "locale -a" -p bash
-#  C   C.utf8   POSIX
-_write_msw_LANG() {
-    setx LANG C /m
+#Not routine.
+_remove_lab_vbox() {
+	_prepare_lab_vbox || return 1
+
+	_wait_lab_vbox
+
+	#echo -e '\E[1;32;46mRemoving IPC folder and vBoxHome directory symlink from filesystem.\E[0m'
+
+	rm -f /tmp/\.vbox-"$VBOX_IPC_SOCKETID"-ipc/ipcd > /dev/null 2>&1
+	rm -f /tmp/\.vbox-"$VBOX_IPC_SOCKETID"-ipc/lock > /dev/null 2>&1
+	rmdir /tmp/\.vbox-"$VBOX_IPC_SOCKETID"-ipc > /dev/null 2>&1
+
+	rm -f "$VBOX_USER_HOME_short" > /dev/null 2>&1
 }


-# KDE Plasma, FreeCAD, etc, may not be usable without usable OpenGL .
-# https://github.com/microsoft/wslg/wiki/GPU-selection-in-WSLg
-_write_msw_discreteGPU() {
-    #glxinfo -B | grep -i intel > /dev/null 2>&1 && setx MESA_D3D12_DEFAULT_ADAPTER_NAME NVIDIA /m
-
-    "$(cygpath -S)"/wbem/wmic.exe path win32_VideoController get name | grep -i 'intel' > /dev/null 2>&1 && "$(cygpath -S)"/wbem/wmic.exe path win32_VideoController get name | grep -i 'nvidia' > /dev/null 2>&1 && setx MESA_D3D12_DEFAULT_ADAPTER_NAME NVIDIA /m
+_launch_lab_vbox_sequence() {
+	_start
+
+	_prepare_lab_vbox || return 1
+
+	#Directly opening raw images in the VBoxLab environment is not recommended, due to changing VMDK disk identifiers.
+	#Better practice may be to instead programmatically construct the raw image virtual machines before opening VBoxLab environment.
+	#_openVBoxRaw
+
+	_VirtualBox_env_VBOX_USER_HOME_short "$@"
+
+	_wait_lab_vbox
+
+	_stop
 }

+_launch_lab_vbox() {
+	"$scriptAbsoluteLocation" _launch_lab_vbox_sequence "$@"
+}

-_write_msw_WSLENV() {
-    _messagePlain_request 'request: If the value of system variable WSLENV is important to you, the previous value is noted here.'
-    _messagePlain_probe_var WSLENV
-
-    _write_msw_qt5ct
-    #setx WSLENV QT_QPA_PLATFORMTHEME /m
-
-    _write_msw_LANG
-    #setx WSLENV LANG /m
+_labVBox() {
+	_launch_lab_vbox "$@"
+}

-    _write_msw_discreteGPU
-    #setx MESA_D3D12_DEFAULT_ADAPTER_NAME NVIDIA /m
+_launch_lab_vbox_manage_sequence() {
+	_start
+
+	_prepare_lab_vbox || return 1
+
+	#Directly opening raw images in the VBoxLab environment is not recommended, due to changing VMDK disk identifiers.
+	#Better practice may be to instead programmatically construct the raw image virtual machines before opening VBoxLab environment.
+	#_openVBoxRaw
+
+	_VBoxManage_env_VBOX_USER_HOME_short "$@"
+
+	_wait_lab_vbox
+
+	_stop
+}

-    #setx WSLENV LANG:QT_QPA_PLATFORMTHEME:MESA_D3D12_DEFAULT_ADAPTER_NAME /m
+_launch_lab_vbox_manage() {
+	"$scriptAbsoluteLocation" _launch_lab_vbox_manage_sequence "$@"
+}

-    setx WSLENV LANG:QT_QPA_PLATFORMTHEME:MESA_D3D12_DEFAULT_ADAPTER_NAME:GH_TOKEN /m
+_labVBoxManage() {
+	_launch_lab_vbox_manage "$@"
 }


+_vboxlabSSH() {
+	ssh -q -F "$scriptLocal"/vblssh -i "$scriptLocal"/id_rsa "$1"
+}

+_labVBox_migrate() {
+	_messageNormal 'init: _labVBox_migrate'
+
+	! _prepare_lab_vbox && _messagePlain_bad 'fail: _prepare_lab_vbox' && return 1
+
+	export ub_new_VBOXID=$(_uid)
+
+	find . \( -iname '*.xml' -o -iname '*.xml*' -o -iname '*.xbel' -o -iname '*.conf' -o -iname '*.vbox' -o -iname '*.vbox*' -o -iname '*.id' \) -exec sed -i 's/'$VBOXID'/'"$ub_new_VBOXID"'/g' '{}' \;
+
+	_messagePlain_good 'complete: _labVBox_migrate'
+}



-_wsl_desktop-waitUp_wmctrl() {
-    while [[ $(wmctrl -d 2>/dev/null | wc -l) -lt 1 ]]
-    do
-        sleep 0.2
-    done
-}
-_wsl_desktop-waitDown_wmctrl() {
-    while [[ $(wmctrl -d 2>/dev/null | wc -l) -gt 1 ]]
-    do
-        sleep 0.4
-    done
+_prepare_instance_vbox() {
+	_prepare_vbox "$instancedVirtDir"
 }
-_here_wsl_desktop_startup_script() {
-    cat << CZXWXcRMTo8EmM8i4d
-#!/usr/bin/env bash
-export DBUS_SESSION_BUS_ADDRESS="$DBUS_SESSION_BUS_ADDRESS"
-export DBUS_SESSION_BUS_PID="$DBUS_SESSION_BUS_PID"
-export DBUS_SESSION_BUS_WINDOWID="$DBUS_SESSION_BUS_WINDOWID"
-export QT_QPA_PLATFORMTHEME= ; unset QT_QPA_PLATFORMTHEME ; export LANG="C"
-export DESKTOP_SESSION=plasma
-#bash "$scriptAbsoluteLocation" _wsl_desktop-waitUp_wmctrl ; sleep 0.6
-export LANG="C"
-CZXWXcRMTo8EmM8i4d

-#dbus-run-session
-_safeEcho_newline 'exec '"$@"' &'
-
-    cat << CZXWXcRMTo8EmM8i4d
-#disown -h \$!
-disown
-disown -a -h -r
-disown -a -r
-rm -f "\$HOME"/.config/plasma-workspace/env/tmp_wsl_desktop.sh
-rm -f "\$HOME"/.config/tmp_wsl_desktop.sh
-sudo -n rm -f /etc/xdg/autostart/tmp_wsl_desktop.desktop
-rm -f "\$HOME"/.config/systemd/user/tmp_wsl_desktop.service
-#bash "$scriptAbsoluteLocation" _wsl_desktop-waitDown_wmctrl
-#currentStopJobs=\$(jobs -p -r 2> /dev/null) ; [[ "\$displayStopJobs" != "" ]] && kill \$displayStopJobs > /dev/null 2>&1
-CZXWXcRMTo8EmM8i4d
-}
-_wsl_desktop_startup_plasmaWorkspaceEnv_write() {
-    mkdir -p "$HOME"/.config/plasma-workspace/env/
-    _here_wsl_desktop_startup_script "$@" > "$HOME"/.config/plasma-workspace/env/tmp_wsl_desktop.sh
-    chmod u+x "$HOME"/.config/plasma-workspace/env/tmp_wsl_desktop.sh
-}
-_here_wsl_desktop_startup_xdg() {
-    cat << CZXWXcRMTo8EmM8i4d
-[Desktop Entry]
-Comment=
-Exec="$HOME"/.config/tmp_wsl_desktop.sh > /dev/null
-GenericName=
-Icon=exec
-MimeType=
-Name=
-Path=
-StartupNotify=false
-Terminal=false
-TerminalOptions=
-Type=Application
-CZXWXcRMTo8EmM8i4d
+_wait_instance_vbox() {
+	_prepare_instance_vbox || return 1
+
+	VBoxXPCOMIPCD_PID=$(cat "$VBoxXPCOMIPCD_PIDfile" 2> /dev/null)
+	#echo -e '\E[1;32;46mWaiting for VBoxXPCOMIPCD to finish... \E[0m'
+	while kill -0 "$VBoxXPCOMIPCD_PID" > /dev/null 2>&1
+	do
+		sleep 0.2
+	done
 }
-_wsl_desktop_startup_xdg_write() {
-    mkdir -p "$HOME"/.config/
-    _here_wsl_desktop_startup_script "$@" > "$HOME"/.config/tmp_wsl_desktop.sh
-    chmod u+x "$HOME"/.config/tmp_wsl_desktop.sh

-    _here_wsl_desktop_startup_xdg | sudo -n tee /etc/xdg/autostart/tmp_wsl_desktop.desktop > /dev/null
+_rm_instance_vbox() {
+	_prepare_instance_vbox || return 1
+
+	#Usually unnecessary, possibly destructive, may delete VM images.
+	#VBoxManage unregistervm "$sessionid" --delete > /dev/null 2>&1
+
+	_safeRMR "$instancedVirtDir" || return 1
+
+	rm -f /tmp/\.vbox-"$VBOX_IPC_SOCKETID"-ipc/ipcd > /dev/null 2>&1
+	rm -f /tmp/\.vbox-"$VBOX_IPC_SOCKETID"-ipc/lock > /dev/null 2>&1
+	rmdir /tmp/\.vbox-"$VBOX_IPC_SOCKETID"-ipc > /dev/null 2>&1
+
+	rm -f "$VBOX_USER_HOME_short" > /dev/null 2>&1
+
+	#_closeVBoxRaw || return 1
+
+	return 0
 }
-# https://bbs.archlinux.org/viewtopic.php?id=279740
-_here_wsl_desktop_startup_systemd() {
-    cat << CZXWXcRMTo8EmM8i4d
-[Unit]
-After=xdg-desktop-autostart.target

-[Install]
-WantedBy=xdg-desktop-autostart.target
+#Not routine.
+_remove_instance_vbox() {
+	_prepare_instance_vbox || return 1
+}

-[Service]
-Type=oneshot
-ExecStart="$HOME"/.config/tmp_wsl_desktop.sh
-CZXWXcRMTo8EmM8i4d
+#https://www.virtualbox.org/ticket/18257
+_workaround_VirtualBoxVM() {
+	if type VirtualBoxVM > /dev/null 2>&1
+	then
+		VirtualBoxVM "$@"
+		return
+	fi
+	if ! type VirtualBoxVM > /dev/null 2>&1 && type /usr/lib/virtualbox/VirtualBoxVM > /dev/null 2>&1
+	then
+		/usr/lib/virtualbox/VirtualBoxVM "$@"
+		return
+	fi
+	if ! type VirtualBoxVM > /dev/null 2>&1 && type /usr/local/lib/virtualbox/VirtualBoxVM > /dev/null 2>&1
+	then
+		/usr/local/lib/virtualbox/VirtualBoxVM "$@"
+		return
+	fi
+	if ! type VirtualBoxVM > /dev/null 2>&1
+	then
+		VirtualBox "$@"
+		return
+	fi
 }
-_wsl_desktop_startup_systemd_write() {
-    mkdir -p "$HOME"/.config/
-    _here_wsl_desktop_startup_script "$@" > "$HOME"/.config/tmp_wsl_desktop.sh
-    chmod u+x "$HOME"/.config/tmp_wsl_desktop.sh
-
-    mkdir -p "$HOME"/.config/systemd/user/
-    _here_wsl_desktop_startup_systemd | sudo -n tee "$HOME"/.config/systemd/user/tmp_wsl_desktop.service > /dev/null

-    systemctl --user stop tmp_wsl_desktop
-    systemctl --user daemon-reload
-    systemctl --user enable tmp_wsl_desktop
-    systemctl --user enable tmp_wsl_desktop.service
+_vboxGUI() {
+	_workaround_VirtualBoxVM "$@"
+
+	#VirtualBoxVM "$@"
+	#VirtualBox "$@"
+	#VBoxSDL "$@"
 }
-_wsl_desktop() {
-    local functionEntryPWD
-    functionEntryPWD="$PWD"

-    (
-        _messageNormal "init: _wsl_desktop"

-        # KDE Plasma may not be usable without usable OpenGL .
-        # https://github.com/microsoft/wslg/wiki/GPU-selection-in-WSLg
-        _set_discreteGPU-forWSL
-
-        if [[ "$PWD" == "/mnt/"?"/WINDOWS/system32" ]] || [[ "$PWD" == "/mnt/"?"/Windows/system32" ]] || [[ "$PWD" == "/mnt/"?"/windows/system32" ]]
-        then
-            _messagePlain_probe 'reject: /mnt/'?'/WINDOWS/system32'
-            _messagePlain_probe_cmd cd
-        fi
-
-        export QT_QPA_PLATFORMTHEME=
-        unset QT_QPA_PLATFORMTHEME
-        #_set_qt5ct
-
-
-        # nix-shell --run "locale -a" -p bash
-        #  C   C.utf8   POSIX
-        export LANG="C"
-
-
-        # https://stackoverflow.com/questions/12153552/how-high-do-x11-display-numbers-go
-        # https://en.wikipedia.org/wiki/List_of_TCP_and_UDP_port_numbers
-        _messagePlain_nominal 'Searching for unused X11 display.'
-        local xephyrDisplay
-        local xephyrDisplayValid
-        xephyrDisplayValid="false"
-
-        if [[ "$2" == *"panel.sh" ]] || [[ "$2" == *"panel"*".sh" ]] || [[ "$2" == *"panel"*".bat" ]]
-        then
-            for (( xephyrDisplay = 53 ; xephyrDisplay <= 79 ; xephyrDisplay++ ))
-            do
-                ! [[ -e /tmp/.X"$xephyrDisplay"-lock ]] && ! [[ -e /tmp/.X11-unix/X"$xephyrDisplay" ]] && xephyrDisplayValid="true" && _messagePlain_good 'found: unused X11 display= '"$xephyrDisplay" && break
-            done
-        else
-            # RESERVED - 53-79 (or greater) for PanelBoard
-            for (( xephyrDisplay = 13 ; xephyrDisplay <= 52 ; xephyrDisplay++ ))
-            do
-                ! [[ -e /tmp/.X"$xephyrDisplay"-lock ]] && ! [[ -e /tmp/.X11-unix/X"$xephyrDisplay" ]] && xephyrDisplayValid="true" && _messagePlain_good 'found: unused X11 display= '"$xephyrDisplay" && break
-            done
-        fi
-
-        _messagePlain_nominal 'Xephyr.'
-        local xephyrResolution
-        xephyrResolution="1600x1200"
-        [[ "$1" == *"x"* ]] && xephyrResolution="$1"
-        shift
-        if type -p dbus-launch > /dev/null 2>&1 && type -p dbus-run-session > /dev/null 2>&1 && type -p startplasma-x11 > /dev/null 2>&1
-        then
-            export -f _wsl_desktop-waitUp_wmctrl
-            export -f _wsl_desktop-waitDown_wmctrl
-            export -f _set_qt5ct
-
-            #if [[ "$descriptiveSelf" != ""]]
-            #then
-                #export currentPlasmaSession="$HOME"/.ubtmp/plasmaSession-"$descriptiveSelf"
-            #else
-                #export currentPlasmaSession="$HOME"/.ubtmp/plasmaSession-"$sessionid"
-            #fi
-
-            #_set_qt5ct
-            #"$@"
-
-            (
-                _timeout 0.3 xmessage -timeout 1 "splash-ldesk: init: Xephyr"
-                Xephyr -screen "$xephyrResolution" :"$xephyrDisplay" &#disown -h $!
-                disown
-                disown -a -h -r
-                disown -a -r
-                (
-
-                    export DISPLAY=:"$xephyrDisplay"
-                    export QT_QPA_PLATFORMTHEME=
-                    unset QT_QPA_PLATFORMTHEME
-                    export LANG="C"
-
-                    export DESKTOP_SESSION=plasma
-
-                    _timeout 0.3 xmessage -timeout 1 "splash-ldesk: init: dbus-launch"
-                    export $(dbus-launch)
-
-                    _timeout 0.3 xmessage -timeout 1 "splash-ldesk: init: xclipsync"
-                    "$HOME"/core/installations/xclipsync/xclipsync &
-                    disown
-                    disown -a -h -r
-                    disown -a -r
-
-                    # https://blog.davidedmundson.co.uk/blog/plasma-and-the-systemd-startup/
-                    # https://bbs.archlinux.org/viewtopic.php?id=279740
-                    # https://www.reddit.com/r/archlinux/comments/ves6mh/kde_autostart_mostly_no_longer_working/
-                    ##kwriteconfig5 --file startkderc --group General --key systemdBoot false
-                    ##kwriteconfig5 --file startkderc --group General --key systemdBoot true
-                    #_wsl_desktop_startup_plasmaWorkspaceEnv_write "$@"
-                    _wsl_desktop_startup_xdg_write "$@"
-                    #_wsl_desktop_startup_systemd_write "$@"
-
-                    ##dbus-run-session
-                    _timeout 0.3 xmessage -timeout 1 "splash-ldesk: init: startplasma-x11"
-                    exec startplasma-x11 > /dev/null 2>&1 &
-
-
-                    #sleep 0.1
-                    #_wsl_desktop-waitUp_wmctrl
-                    ##sleep 3
-
-                    #exec "$@" > /dev/null 2>&1 &
-
-                    echo '---------------------------------------------'
-                    wait
-                    echo '+++++++++++++++++++++++++++++++++++++++++++++'
-
-                    export LANG="C"
-
-                    #_wsl_desktop-waitDown_wmctrl ; currentStopJobs=$(jobs -p -r 2> /dev/null) ; [[ "$displayStopJobs" != "" ]] && kill $displayStopJobs > /dev/null 2>&1
-
-                )
-
-                wait
-            )
-            #_wsl_desktop-waitDown_wmctrl ; currentStopJobs=$(jobs -p -r 2> /dev/null) ; [[ "$displayStopJobs" != "" ]] && kill $displayStopJobs > /dev/null 2>&1
-            return 0
-            cd "$functionEntryPWD"
-        fi
-        _messagePlain_bad 'bad: missing: GUI'
-        _messageFAIL
-        _stop 1
-        return 1
-    )
-
-    cd "$functionEntryPWD"
-}
-ldesk() {
-    _wsl_desktop "$@"
-}
-
-
-
-
-
-
-
-
-_test_wsl2_internal() {
-    _if_cygwin && return 0
-
-    if ! _if_cygwin
-    then
-        _getDep 'xclip'
-
-        _getDep 'tclsh'
-        _getDep 'wish'
-
-        _getDep Xephyr
-
-        _wantGetDep dbus-run-session
-        _wantGetDep startplasma-x11
-
-        return
-    fi
-    return 1
-}
-#####Shortcuts
-
-# https://unix.stackexchange.com/questions/434409/make-a-bash-ps1-that-counts-streak-of-correct-commands
-_visualPrompt_promptCommand() {
-	[[ "$PS1_lineNumber" == "" ]] && PS1_lineNumber='0'
-	#echo "$PS1_lineNumber"
-	let PS1_lineNumber="$PS1_lineNumber"+1
-	#export PS1_lineNumber
-
-	PS1_lineNumberText="$PS1_lineNumber"
-	if [[ "$PS1_lineNumber" == '1' ]]
+_set_instance_vbox_type() {
+	#[[ "$vboxOStype" == "" ]] && export vboxOStype=Debian_64
+	#[[ "$vboxOStype" == "" ]] && export vboxOStype=Gentoo_64
+	#[[ "$vboxOStype" == "" ]] && export vboxOStype=Windows2003
+	#[[ "$vboxOStype" == "" ]] && export vboxOStype=WindowsXP
+	#[[ "$vboxOStype" == "" ]] && export vboxOStype=Windows10_64
+	#[[ "$vboxOStype" == "" ]] && export vboxOStype=Windows11_64
+
+	#[[ "$vboxOStype" == "Windows11_64" ]] && vboxOStype="Windows10_64"
+
+	if [[ "$ubVirtPlatformOverride" == "" ]]
 	then
-		# https://unix.stackexchange.com/questions/266921/is-it-possible-to-use-ansi-color-escape-codes-in-bash-here-documents
-		PS1_lineNumberText=$(echo -e -n '\E[1;36m'1)
-		#PS1_lineNumberText=$(echo -e -n '\E[1;36m'1)
-		#PS1_lineNumberText=$(echo -e -n '\[\033[01;36m\]'1)
-		#PS1_lineNumberText=$(echo -e -n '\033[01;36m'1)
+		[[ "$vboxOStype" == "Win"*"10"* ]] && export ubVirtPlatformOverride="x64-efi"
+		[[ "$vboxOStype" == "Win"*"11"* ]] && export ubVirtPlatformOverride="x64-efi"
 	fi
-}
-
-_visualPrompt() {
-	local currentHostname
-	currentHostname="$HOSTNAME"
-
-	[[ -e /etc/hostname ]] && export currentHostname=$(cat /etc/hostname)


-	export currentChroot=
-	[[ "$chrootName" != "" ]] && export currentChroot="$chrootName"
+	[[ "$vboxOStype" == "" ]] && _readLocked "$lock_open" && export vboxOStype=Debian_64
+	[[ "$vboxOStype" == "" ]] && export vboxOStype=WindowsXP

+	_messagePlain_probe 'vboxOStype= '"$vboxOStype"

-	#+%H:%M:%S\ %Y-%m-%d\ Q%q
-	#+%H:%M:%S\ %b\ %d,\ %y
+	if VBoxManage createvm --name "$sessionid" --ostype "$vboxOStype" --register --basefolder "$VBOX_USER_HOME_short"
+	then
+		_messagePlain_probe VBoxManage createvm --name "$sessionid" --ostype "$vboxOStype" --register --basefolder "$VBOX_USER_HOME_short"
+		return 0
+	fi
+	_messagePlain_bad 'fail: 'VBoxManage createvm --name "$sessionid" --ostype "$vboxOStype" --register --basefolder "$VBOX_USER_HOME_short"
+	return 1
+}

-	#Long.
-	#export PS1='\[\033[01;40m\]\[\033[01;36m\]+\[\033[01;34m\]-|\[\033[01;31m\]${?}:${debian_chroot:+($debian_chroot)}\[\033[01;33m\]\u\[\033[01;32m\]@\h\[\033[01;36m\]\[\033[01;34m\])-\[\033[01;36m\]--\[\033[01;34m\]-(\[\033[01;35m\]$(date +%H:%M:%S\ .%d)\[\033[01;34m\])-\[\033[01;36m\]-|\[\033[00m\]\n\[\033[01;40m\]\[\033[01;36m\]+\[\033[01;34m\]-|\[\033[37m\][\w]\[\033[00m\]\n\[\033[01;36m\]+\[\033[01;34m\]-|\#) \[\033[36m\]>\[\033[00m\] '
+_set_instance_vbox_cores_more() {
+	[[ "$1" -ge "$vboxCPUs" ]] && _messagePlain_probe 'cpu: >'"$1" && export vboxCPUs="$1"
+}

-	#Short.
-	#export PS1='\[\033[01;40m\]\[\033[01;36m\]+\[\033[01;34m\]|\[\033[01;31m\]${?}:${debian_chroot:+($debian_chroot)}\[\033[01;33m\]\u\[\033[01;32m\]@\h\[\033[01;36m\]\[\033[01;34m\])-\[\033[01;36m\]-\[\033[01;34m\]-(\[\033[01;35m\]$(date +%H:%M:%S\ .%d)\[\033[01;34m\])\[\033[01;36m\]|\[\033[00m\]\n\[\033[01;40m\]\[\033[01;36m\]+\[\033[01;34m\]|\[\033[37m\][\w]\[\033[00m\]\n\[\033[01;36m\]+\[\033[01;34m\]|\#) \[\033[36m\]>\[\033[00m\] '
-
-	#Truncated, 40 columns.
-	#export PS1='\[\033[01;40m\]\[\033[01;36m\]\[\033[01;34m\]|\[\033[01;31m\]${?}:${debian_chroot:+($debian_chroot)}\[\033[01;33m\]\u\[\033[01;32m\]@\h\[\033[01;36m\]\[\033[01;34m\])\[\033[01;36m\]\[\033[01;34m\]-(\[\033[01;35m\]$(date +%H:%M:%S\.%d)\[\033[01;34m\])\[\033[01;36m\]|\[\033[00m\]\n\[\033[01;40m\]\[\033[01;36m\]\[\033[01;34m\]|\[\033[37m\][\w]\[\033[00m\]\n\[\033[01;36m\]\[\033[01;34m\]|\#) \[\033[36m\]>\[\033[00m\] '
-
-
-	# https://unix.stackexchange.com/questions/434409/make-a-bash-ps1-that-counts-streak-of-correct-commands
-
-	#export PROMPT_COMMAND=$(declare -f _visualPrompt_promptCommand)' ; _visualPrompt_promptCommand'
-	#export PROMPT_COMMAND='_visualPrompt_promptCommand () { [[ "$PS1_lineNumber" == "" ]] && PS1_lineNumber="0"; let PS1_lineNumber="$PS1_lineNumber"+1; PS1_lineNumberText="$PS1_lineNumber"; if [[ "$PS1_lineNumber" == "1" ]]; then PS1_lineNumberText=$(echo -e -n "'"\E[1;36m"'"1"'"\E[0m"'"); fi } ; _visualPrompt_promptCommand'
-
-	export -f _visualPrompt_promptCommand
-	export PROMPT_COMMAND=_visualPrompt_promptCommand
+# ATTENTION: Override, function, or, variables, with "ops" or similar.
+# WARNING: Do not cause use of more than half the number of physical cores (not threads) unless specifically required.
+_set_instance_vbox_cores() {
+	# DANGER: Do not set "vboxCPUs" unless specifically required.
+	# Intended only where specifically necessary to force a specific number of threads (eg. "1").
+	# FAIL if "hostThreadCount" < "vboxCPUs" .
+	# FAIL or DEGRADE if "hostCoreCount" < "vboxCPUs" .
+	# POSSIBLE DEGRADE if nesting AND "vboxCPUs" != "" .
+	[[ "$vboxCPUs" != "" ]] && _messagePlain_warn 'warn: configured: force: vboxCPUs= '"$vboxCPUs" && return 0

-	#export PS1='\[\033[01;40m\]\[\033[01;36m\]\[\033[01;34m\]|\[\033[01;31m\]${?}:${debian_chroot:+($debian_chroot)}\[\033[01;33m\]\u\[\033[01;32m\]@\h\[\033[01;36m\]\[\033[01;34m\])\[\033[01;36m\]\[\033[01;34m\]-(\[\033[01;35m\]$(date +%H:%M:%S\.%d)\[\033[01;34m\])\[\033[01;36m\]|\[\033[00m\]\n\[\033[01;40m\]\[\033[01;36m\]\[\033[01;34m\]|\[\033[37m\][\w]\[\033[00m\]\n\[\033[01;36m\]\[\033[01;34m\]|$PS1_lineNumberText\[\033[01;34m\]) \[\033[36m\]>\[\033[00m\] '
+	export vboxCPUs=1

+	# Single-threaded host with guest 'efi', 'Windows10_64', 'Windows11_64', are all not plausible. Minimum dual-CPU requirement of MSW11 as default.
+	# ATTENTION: For guests benefitting from single core performance only, force such non-default by exporting 'vboxCPUs' with 'ops' or similar.
+	if [[ "$ubVirtPlatform" == *'efi' ]] || [[ "$ubVirtPlatformOverride" == *'efi' ]] || [[ "$vboxOStype" == "Win"*"10"* ]] || [[ "$vboxOStype" == "Win"*"11"* ]]
+	then
+		export vboxCPUs=2
+	fi

-	#export PS1='\[\033[01;40m\]\[\033[01;36m\]\[\033[01;34m\]|\[\033[01;31m\]${?}:${debian_chroot:+($debian_chroot)}\[\033[01;33m\]\u\[\033[01;32m\]@\h\[\033[01;36m\]\[\033[01;34m\])\[\033[01;36m\]\[\033[01;34m\]-'"$prompt_cloudNetName"'(\[\033[01;35m\]$(date +%H:%M:%S\.%d)\[\033[01;34m\])\[\033[01;36m\]|\[\033[00m\]\n\[\033[01;40m\]\[\033[01;36m\]\[\033[01;34m\]|\[\033[37m\][\w]\[\033[00m\]\n\[\033[01;36m\]\[\033[01;34m\]|$PS1_lineNumberText\[\033[01;34m\]) \[\033[36m\]'""'>\[\033[00m\] '
+	local hostCoreCount
+	local hostThreadCount
+	local hostThreadAllowance


-	if [[ "$SHELL" == *"/nix/store/"*"/bin/bash"* ]]
-	then
-		export prompt_nixShell="nixShell"
-	else
-		export prompt_nixShell=""
-	fi
+	# Physical Cores.
+	local hostCoreCount=$(grep ^cpu\\scores /proc/cpuinfo | head -n 1 | tr -dc '0-9')

-	#export PS1='\[\033[01;40m\]\[\033[01;36m\]\[\033[01;34m\]|\[\033[01;31m\]${?}:${debian_chroot:+($debian_chroot)}\[\033[01;33m\]\u\[\033[01;32m\]@\h\[\033[01;36m\]\[\033[01;34m\])\[\033[01;36m\]\[\033[01;34m\]-'"$prompt_cloudNetName"'(\[\033[01;35m\]$(date +%H:%M:%S\.%d)\[\033[01;34m\])\[\033[01;36m\]|\[\033[00m\]'"$prompt_nixShell"'\n\[\033[01;40m\]\[\033[01;36m\]\[\033[01;34m\]|\[\033[37m\][\w]\[\033[00m\]\n\[\033[01;36m\]\[\033[01;34m\]|$([[ "$PS1_lineNumber" == "1" ]] && echo -e -n '"'"'\[\033[01;36m\]'"'"'$PS1_lineNumber || echo -e -n $PS1_lineNumber)\[\033[01;34m\]) \[\033[36m\]'""'>\[\033[00m\] '
+	# Logical Threads.
+	local hostThreadCount=$(cat /proc/cpuinfo | grep MHz | wc -l | tr -dc '0-9')

+	# Typical stability margin reservation.
+	let hostThreadAllowance="$hostCoreCount"-2

+	_messagePlain_probe_var hostCoreCount
+	_messagePlain_probe_var hostThreadCount

-	if _if_cygwin
-	then
-		export PS1='\[\033[01;40m\]\[\033[01;36m\]\[\033[01;34m\]|\[\033[01;31m\]${?}:${currentChroot:+($currentChroot)}\[\033[01;33m\]\u\[\033[01;32m\]@'"$currentHostname"'\[\033[01;36m\]\[\033[01;34m\])\[\033[01;36m\]\[\033[01;34m\]-'"$prompt_cloudNetName"'(\[\033[01;35m\]$(date +%H:%M:%S\.%d)\[\033[01;34m\])\[\033[01;36m\]|\[\033[00m\]'"$prompt_nixShell"'\n\[\033[01;40m\]\[\033[01;36m\]\[\033[01;34m\]\[\033[37m\]\w\[\033[00m\]\n\[\033[01;36m\]\[\033[01;34m\]|$([[ "$PS1_lineNumber" == "1" ]] && echo -e -n '"'"'\[\033[01;36m\]'"'"'$PS1_lineNumber || echo -e -n $PS1_lineNumber)\[\033[01;34m\]) \[\033[36m\]'""'>\[\033[00m\] '
-	elif ( uname -a | grep -i 'microsoft' > /dev/null 2>&1 || uname -a | grep -i 'WSL2' > /dev/null 2>&1 )
+	# Catch core/thread detection failure.
+	if [[ "$hostCoreCount" -lt "1" ]] || [[ "$hostCoreCount" == "" ]] || [[ "$hostThreadCount" -lt "1" ]] || [[ "$hostThreadCount" == "" ]]
 	then
-		export PS1='\[\033[01;40m\]\[\033[01;36m\]\[\033[01;34m\]|\[\033[01;31m\]${?}:${currentChroot:+($currentChroot)}\[\033[01;33m\]\u\[\033[01;32m\]@'"$currentHostname"-wsl2'\[\033[01;36m\]\[\033[01;34m\])\[\033[01;36m\]\[\033[01;34m\]-'"$prompt_cloudNetName"'(\[\033[01;35m\]$(date +%H:%M:%S\.%d)\[\033[01;34m\])\[\033[01;36m\]|\[\033[00m\]'"$prompt_nixShell"'\n\[\033[01;40m\]\[\033[01;36m\]\[\033[01;34m\]\[\033[37m\]\w\[\033[00m\]\n\[\033[01;36m\]\[\033[01;34m\]|$([[ "$PS1_lineNumber" == "1" ]] && echo -e -n '"'"'\[\033[01;36m\]'"'"'$PS1_lineNumber || echo -e -n $PS1_lineNumber)\[\033[01;34m\]) \[\033[36m\]'""'>\[\033[00m\] '
-	else
-		export PS1='\[\033[01;40m\]\[\033[01;36m\]\[\033[01;34m\]|\[\033[01;31m\]${?}:${currentChroot:+($currentChroot)}\[\033[01;33m\]\u\[\033[01;32m\]@'"$currentHostname"'\[\033[01;36m\]\[\033[01;34m\])\[\033[01;36m\]\[\033[01;34m\]-'"$prompt_cloudNetName"'(\[\033[01;35m\]$(date +%H:%M:%S\.%d)\[\033[01;34m\])\[\033[01;36m\]|\[\033[00m\]'"$prompt_nixShell"'\n\[\033[01;40m\]\[\033[01;36m\]\[\033[01;34m\]|\[\033[37m\][\w]\[\033[00m\]\n\[\033[01;36m\]\[\033[01;34m\]|$([[ "$PS1_lineNumber" == "1" ]] && echo -e -n '"'"'\[\033[01;36m\]'"'"'$PS1_lineNumber || echo -e -n $PS1_lineNumber)\[\033[01;34m\]) \[\033[36m\]'""'>\[\033[00m\] '
+		_messagePlain_bad 'fail: hostCoreCount, hostThreadCount'
+		_messagePlain_warn 'missing: smp: force: vboxCPUs= '1
+
+		# Default, allow single threaded operation if core/thread count was indeterminite.
+		return 0
 	fi

-	#export PS1="$prompt_nixShell""$PS1"
-}
-
-
-_request_visualPrompt() {
-	_messagePlain_request 'export profileScriptLocation="'"$scriptAbsoluteLocation"'"'
-	_messagePlain_request 'export profileScriptFolder="'"$scriptAbsoluteFolder"'"'
-	_messagePlain_request ". "'"'"$scriptAbsoluteLocation"'"' --profile _importShortcuts
-}
-
-
-
-_setup_researchEngine() {
-	if [[ -e "$scriptLib"/kit/app/researchEngine ]]
+	# Logical Threads > Physical Cores ('SMT', 'Hyper-Threading', etc)
+	if [[ "$hostThreadCount" -gt "$hostCoreCount" ]]
 	then
-		export kit_dir_researchEngine="$scriptLib"/kit/app/researchEngine
-		. "$scriptLib"/kit/app/researchEngine/kit/researchEngine.sh
-		if [[ "$1" == "" ]]
+		# Logical Threads Present
+		_messagePlain_good 'detect: logical threads'
+
+		[[ "$hostCoreCount" -lt "6" ]] && _set_instance_vbox_cores_more "$hostCoreCount"
+
+		# DANGER: Do not set "vboxCPUsAllowManyThreads" if processor capabilities (eg. Intel Atom) will be uncertain and/or host/guest latencies may be important.
+		# Not recommended for Intel i7-2640M (as found in Lenovo X220) or older hosts.
+		# Nevertheless, power efficiency (eg Intel Atom) may be a good reason to specifically enable this.
+		# https://unix.stackexchange.com/questions/325932/virtualbox-is-it-a-bad-idea-to-assign-more-virtual-cpu-cores-than-number-of-phy
+		# https://en.wikipedia.org/wiki/Hyper-threading
+		if [[ "$vboxCPUsAllowManyThreads" == 'true' ]]
 		then
-			_setup_researchEngine-kit
-		else
-			"$@"
+			_messagePlain_warn 'warn: configured: vboxCPUsAllowManyThreads'
+
+			[[ "$hostCoreCount" -lt "4" ]] && _set_instance_vbox_cores_more "$hostThreadCount"
+
+			let hostThreadAllowance="$hostThreadCount"-2
+			_set_instance_vbox_cores_more "$hostThreadAllowance"
 		fi
-		return
-	fi
-
-	if [[ -e "$scriptLib"/ubiquitous_bash/_lib/kit/app/researchEngine ]]
-	then
-		export kit_dir_researchEngine="$scriptLib"/ubiquitous_bash/_lib/kit/app/researchEngine
-		. "$scriptLib"/ubiquitous_bash/_lib/kit/app/researchEngine/kit/researchEngine.sh
-		if [[ "$1" == "" ]]
+
+		# WARNING: Do not set "vboxCPUsAllowManyCores" unless it is acceptable for guest to consume (at least nearly) 100% CPU cores/threads/time/resources.
+		if [[ "$vboxCPUsAllowManyCores" == 'true' ]]
 		then
-			_setup_researchEngine-kit
-		else
-			"$@"
+			_messagePlain_probe 'configured: vboxCPUsAllowManyCores'
+
+			let hostThreadAllowance="$hostCoreCount"-2
+			_set_instance_vbox_cores_more "$hostThreadAllowance"
 		fi
-		return
-	fi
-
-	if [[ -e "$scriptLib"/ubDistBuild/_lib/ubiquitous_bash/_lib/kit/app/researchEngine ]]
-	then
-		export kit_dir_researchEngine="$scriptLib"/ubDistBuild/_lib/ubiquitous_bash/_lib/kit/app/researchEngine
-		. "$scriptLib"/ubDistBuild/_lib/ubiquitous_bash/_lib/kit/app/researchEngine/kit/researchEngine.sh
-		if [[ "$1" == "" ]]
+
+		[[ "$hostCoreCount" -ge "32" ]] && _set_instance_vbox_cores_more 20
+
+		[[ "$hostCoreCount" -lt "32" ]] && [[ "$hostCoreCount" -ge "24" ]] && _set_instance_vbox_cores_more 14
+		[[ "$hostCoreCount" -lt "24" ]] && [[ "$hostCoreCount" -ge "16" ]] && _set_instance_vbox_cores_more 10
+		[[ "$hostCoreCount" -lt "16" ]] && [[ "$hostCoreCount" -ge "12" ]] && _set_instance_vbox_cores_more 8
+		[[ "$hostCoreCount" -lt "12" ]] && [[ "$hostCoreCount" -ge "10" ]] && _set_instance_vbox_cores_more 8
+		[[ "$hostCoreCount" -lt "10" ]] && [[ "$hostCoreCount" -ge "8" ]] && _set_instance_vbox_cores_more 6
+		[[ "$hostCoreCount" -lt "8" ]] && [[ "$hostCoreCount" -ge "6" ]] && _set_instance_vbox_cores_more 4
+
+
+	else
+		# Logical Threads Absent
+		_messagePlain_bad 'missing: logical threads'
+
+		[[ "$hostCoreCount" -lt "4" ]] && _set_instance_vbox_cores_more "$hostCoreCount"
+
+		# WARNING: Do not set "vboxCPUsAllowManyCores" unless it is acceptable for guest to consume (at least nearly) 100% CPU cores/threads/time/resources.
+		if [[ "$vboxCPUsAllowManyCores" == 'true' ]]
 		then
-			_setup_researchEngine-kit
-		else
-			"$@"
+			let hostThreadAllowance="$hostCoreCount"-2
+			_set_instance_vbox_cores_more "$hostThreadAllowance"
 		fi
-		return
+
+		[[ "$hostCoreCount" -ge "32" ]] && _set_instance_vbox_cores_more 16
+
+		[[ "$hostCoreCount" -lt "32" ]] && [[ "$hostCoreCount" -ge "24" ]] && _set_instance_vbox_cores_more 12
+		[[ "$hostCoreCount" -lt "24" ]] && [[ "$hostCoreCount" -ge "16" ]] && _set_instance_vbox_cores_more 8
+		[[ "$hostCoreCount" -lt "16" ]] && [[ "$hostCoreCount" -ge "10" ]] && _set_instance_vbox_cores_more 6
+		[[ "$hostCoreCount" -lt "10" ]] && [[ "$hostCoreCount" -ge "8" ]] && _set_instance_vbox_cores_more 4
+		[[ "$hostCoreCount" -lt "8" ]] && [[ "$hostCoreCount" -ge "4" ]] && _set_instance_vbox_cores_more 4
 	fi

-	_messagePlain_bad 'bad: missing: kit researchEngine'
-	_messageFAIL
-	_stop 1
-}
-
-
-
-_upgrade_researchEngine() {
-	_setup_researchEngine _service_researchEngine-docker-chroot-start
-
-	_setup_researchEngine _upgrade_researchEngine_searxng "$@"
-	_setup_researchEngine _upgrade_researchEngine_openwebui "$@"
-
-	_setup_researchEngine _service_researchEngine-docker-chroot-stop
-}
-
-_upgrade_researchEngine-nvidia() {
-	_setup_researchEngine _service_researchEngine-docker-chroot-start
+	# ATTENTION: Do not set "vboxCPUsMax" unless specifically required.
+	if [[ "$vboxCPUsMax" != "" ]]
+	then
+		_messagePlain_warn 'warn: configured: vboxCPUsMax= '"$vboxCPUsMax"
+		[[ "$vboxCPUs" -ge "$vboxCPUsMax" ]] && export vboxCPUs="$vboxCPUsMax"
+	fi

-	_setup_researchEngine _upgrade_researchEngine_searxng "$@"
-	_setup_researchEngine _upgrade_researchEngine_openwebui-nvidia "$@"
-
-	_setup_researchEngine _service_researchEngine-docker-chroot-stop
+	_messagePlain_probe_var vboxCPUs
+	return 0
 }

-
-
-
-# ATTENTION: NOTICE: WIP: AI models bring such efficient and effective natural language processing, reasoning, parsing, summarization, API/documentation understanding, and code generation, as to backport an essential yet unusually new capability to some of the oldest (ie. >20years old) computer CPUs (even without a GPU). ATTENTION: Unusually, all 'ai' functions (including those here), may be very interdependent on the 'shortcut' functions. This has two consequences:
-# (1) CAUTION: No 'compile' of the script should include only the 'ai' functions without the 'shortcut' functions, this WILL cause potentially dangerous failures.
-# (2) NOTICE: Please DO read all comments from both directories for both VERY significant TODO items, and possible obligations you may have to follow to actually use some specifically supported AI models.
-
-
-
-
-
-
-
-_setup_ollama_model_augment_sequence() {
-	# NOTICE: WARNING: Normally, any redistribution of a 'Llama', similar AI model, or other AI model, would be from an authoratative corporation, such as "Soaring Distributions LLC" .
-
-	# DANGER: An 'augment' model, which may be included with 'ubdist' or other 'dist/OS' is intended SOLELY for developer use. As a public domain or some publicly available AI model licensing terms apparently allow, this model may be modified for better compliance with technical use cases (such as not disregarding the previous conversation when given repeated 'system' prompts), or for smaller model size (eg. through quantization, or use of a lower parameter count model).
-
-	# DANGER DANGER: Any 'augment' model really should NOT be used for 'end user' services, including any any built-in help for any end-user program or machinery (excepting that it may or may NOT be reasonable to include with some non-commercial open-source software as a built-in help, wizard, etc, following usual expectations of community provided software). You should expect users WILL, at best, more easily 'jailbreak' such a model, and, due to the emphasis on technical usage (where reliability above 0.2% failure rates, unusual repetitive prompting, etc) as well as small model size, there may be both a complete absence of any safeguards as well as a (albeit not yet observed) possibility of introducing harmful subjects to otherwise harmless conversation.
-
-	# YOU HAVE BEEN WARNED ! DEVELOPERS ONLY, NOT USERS !
-
+_set_instance_vbox_features() {
+	#VBoxManage modifyvm "$sessionid" --boot1 disk --biosbootmenu disabled --bioslogofadein off --bioslogofadeout off --bioslogodisplaytime 5 --vram 256 --memory 1512 --nic1 nat --nictype1 "82543GC" --clipboard bidirectional --accelerate3d off --accelerate2dvideo off --vrde off --audio pulse --usb on --cpus 1 --ioapic off --acpi on --pae off --chipset piix3

-	# Any distribution or any other activity regarding any 'augmentation' or other AI model is without any warranty of any kind. Superseding all other statements, there are no representations or warranties of any kind concerning the Work, express, implied, statutory or otherwise, including without limitation warranties of title, merchantability, fitness for a particular purpose, non infringement, or the absence of latent or other defects, accuracy, or the present or absence of errors, whether or not discoverable, all to the greatest extent permissible under applicable law.
+	! _set_instance_vbox_cores && return 1

-	# SPECIFICALLY THIS STATEMENT DISCLAIMS LIABILITY FOR DAMAGES RESULTING FROM THE USE OF THIS DOCUMENT OR THE INFORMATION OR WORKS PROVIDED HEREUNDER.
+	# WARNING: Do not set "$vmMemoryAllocation" to a high number unless specifically required.
+	[[ "$vmMemoryAllocation" == "" ]] && vmMemoryAllocation="$vmMemoryAllocationDefault"

+	# Must have at least 4096MB for 'livecd' , unless even larger memory allocation has been configured .
+	if [[ "$ub_override_vbox_livecd" != '' ]] || [[ "$ub_override_vbox_livecd_more" != '' ]]
+	then
+		if [[ "$vmMemoryAllocation" -lt 4096 ]]
+		then
+			vmMemoryAllocation=4096
+		fi
+	fi

-	# NOTICE: Purpose of the 'augment' model is, above all other purposes, both:
-	#  (1) To supervise and direct decisions and analysis by other AI models (such as from vision encoders, but also mathematical reasoning specific LLMs, computer activity and security logging LLMs, etc).
-	#  (2) To assist and possibly supervise 'human-in-the-loop' decision making (eg. to sanity check human responses).
+	#[[ "$ubVirtPlatform" == *'efi' ]] || [[ "$ubVirtPlatformOverride" == *'efi' ]]
+	if [[ "$vmMemoryAllocation" -lt 8704 ]] && ( [[ "$vboxOStype" == "Win"*"10"* ]] || [[ "$vboxOStype" == "Win"*"11"* ]] )
+	then
+		vmMemoryAllocation=8704
+	fi

+	_messagePlain_probe 'vmMemoryAllocation= '"$vmMemoryAllocation"

-	# https://huggingface.co/mlabonne/Meta-Llama-3.1-8B-Instruct-abliterated-GGUF/tree/main
-	# https://web.archive.org/web/20240831194035/https://huggingface.co/mlabonne/Meta-Llama-3.1-8B-Instruct-abliterated-GGUF/tree/main
-	# Explicitly states 'License: llama3.1'. Readme file from repository does NOT contradict this.
+	[[ "$vboxNic" == "" ]] && export vboxNic="nat"
+	_messagePlain_probe 'vboxNic= '"$vboxNic"

-	# https://www.llama.com/llama3_1/license/
-	# https://huggingface.co/meta-llama/Meta-Llama-3.1-70B-Instruct/blob/main/LICENSE
-	#  NOTICE: ATTENTION: This license has been preserved as 'LICENSE-Llama-3.1.txt', but this license does NOT apply to any 'ubiquitous_bash' code or any other work that is not either a work by Meta or strictly a derivative of a work by Meta (such as a modified AI model GGUF or safetensors file) !

-	# https://www.llama.com/llama3_1/use-policy/
+	local vboxChipset
+	vboxChipset="ich9"
+	#[[ "$vboxOStype" == *"Win"*"XP"* ]] && vboxChipset="piix3"
+	_messagePlain_probe 'vboxChipset= '"$vboxChipset"

+	local vboxNictype
+	vboxNictype="82543GC"
+	[[ "$vboxOStype" == *"Win"*"7"* ]] && vboxNictype="82540EM"
+	[[ "$vboxOStype" == *"Win"*"10"* ]] && vboxNictype="82540EM"
+	[[ "$vboxOStype" == *"Win"*"11"* ]] && vboxNictype="82540EM"
+	_messagePlain_probe 'vboxNictype= '"$vboxNictype"

-	# https://www.llama.com/llama3_1/license/
-	#  'include “Llama” at the beginning of any such AI model name'
-	# ATTENTION: Nevertheless, it is very possible a non-'Llama' model will eventually be used, especially as science and technology (eg. plasma recombination EUV physics) related datasets (eg. relevant Wikipedia articles) are increasingly gathered.
-
-
-	# https://www.llama.com/llama3_2/license/
-	# https://www.llama.com/llama3_2/use-policy/
-	#  'or to enable functionality disabled by Meta'
-	#   The functionality offered by 'Llama 3.2' (eg. multimodal functionality) is expected to exceed the purpose of an 'augment' model, but the reliabilility limitations imposed are expected prohibitive (especially regarding repeated 'system' prompts). Thus, it is expected that 'Llama 3.1' will be the last 'Llama' model used as an 'augment' model. This is NOT a concern, because it is expected that 'Llama 3.1' already reached a point of diminishing returns on what can be achieved by AI model training methods alone.
-	#   Purposes other than as an 'augment' model, which is a text-only technical use case, and expected to require fine tuning (eg. on prompt/responses generated from the 'ubiquitous_bash' codebase), at that, are expected to achieve very adequate performance from 'stock' original 'Llama' models, or at least those fine-tuned for specific use cases (eg. needle-in-haystack, computer vision object recognition, robot motor control, etc).
+	local vboxAudioController
+	vboxAudioController="ac97"
+	[[ "$vboxOStype" == *"Win"*"7"* ]] && vboxAudioController="hda"
+	[[ "$vboxOStype" == *"Win"*"10"* ]] && vboxAudioController="hda"
+	[[ "$vboxOStype" == *"Win"*"11"* ]] && vboxAudioController="hda"
+	_messagePlain_probe 'vboxAudioController= '"$vboxAudioController"

+	_messagePlain_nominal "Setting VBox VM features."

+	if ! _messagePlain_probe_cmd VBoxManage modifyvm "$sessionid" --biosbootmenu disabled --bioslogofadein off --bioslogofadeout off --bioslogodisplaytime 1 --vram 256 --memory "$vmMemoryAllocation" --nic1 "$vboxNic" --nictype1 "$vboxNictype" --accelerate3d off --accelerate2dvideo off --vrde off --audio null --audioin off --audioout on --usb on --cpus "$vboxCPUs" --ioapic on --acpi on --pae on --chipset "$vboxChipset" --audiocontroller="$vboxAudioController"
+	then
+		_messagePlain_bad 'fail: VBoxManage'
+		return 1
+	fi

+	#_messagePlain_probe_cmd VBoxManage controlvm "$sessionid" clipboard bidirectional

+	# Linux hosts may benefit from 'vboxsvga' instead of 'vmsvga'.
+	#https://wiki.gentoo.org/wiki/VirtualBox
+	#Testing shows this may not be the case, and 3D acceleration reportedly requires vmsvga.
+	if ! _if_cygwin && ( [[ "$vboxOStype" == *"Debian"* ]] || [[ "$vboxOStype" == *"Gentoo"* ]] )
+	then
+		# ATTENTION: Nested virtualization through VMWare Workstation host, seems incompatable with 'accelerate3d on', result may be black screen with cursor.
+		# ATTENTION: WARNING: VirtualBox 'accelerate3d' may be disabled by default, if not already, if more incompatibilities are found. Explicitly declare with 'ops.sh' if 'accelerate3d' is actually necessary.
+		# Assuming x64 hosts served by VBox will have at least 'Intel HD Graphics 3000' (as found on X220 laptop/tablet) equivalent. Lesser hardware not recommended.
+		#if [[ "$vboxCPUs" -ge "2" ]] && ! lspci | grep -i vmware && ! lspci | grep -i virtualbox && ! cat /proc/cpuinfo | grep -i model | grep -i qemu && ! sudo -n lspci | grep -i vmware && ! sudo -n lspci | grep -i virtualbox
+		#then
+			#if ! _messagePlain_probe_cmd VBoxManage modifyvm "$sessionid" --graphicscontroller vmsvga --accelerate3d on --accelerate2dvideo off
+			#then
+				#_messagePlain_warn 'warn: fail: VBoxManage: --graphicscontroller vmsvga --accelerate3d on --accelerate2dvideo off'
+			#fi
+		#else
+			#vmsvga
+			#vboxsvga
+			if ! _messagePlain_probe_cmd VBoxManage modifyvm "$sessionid" --graphicscontroller vmsvga --accelerate3d off --accelerate2dvideo off
+			then
+				_messagePlain_warn 'warn: fail: VBoxManage: --graphicscontroller vmsvga --accelerate3d off --accelerate2dvideo off'
+			fi
+		#fi
+	fi

+	# Assuming x64 hosts served by VBox will have at least 'Intel HD Graphics 3000' (as found on X220 laptop/tablet) equivalent. Lesser hardware not recommended.
+	#if ! _if_cygwin && ( ( [[ "$vboxOStype" == *"Win"*"10"* ]] || [[ "$vboxOStype" == *"Win"*"11"* ]] ) && [[ "$vboxCPUs" -ge "2" ]] && ! lspci | grep -i vmware && ! lspci | grep -i virtualbox && ! cat /proc/cpuinfo | grep -i model | grep -i qemu && ! sudo -n lspci | grep -i vmware && ! sudo -n lspci | grep -i virtualbox )
+	#then
+		#_messagePlain_probe VBoxManage modifyvm "$sessionid" --graphicscontroller vboxsvga --accelerate3d on --accelerate2dvideo on
+		#if ! VBoxManage modifyvm "$sessionid" --graphicscontroller vboxsvga --accelerate3d on --accelerate2dvideo on
+		#then
+			#_messagePlain_warn 'warn: fail: VBoxManage: --graphicscontroller vboxsvga --accelerate3d on --accelerate2dvideo on'
+		#fi
+	#fi
+
+	# MSW Host with Hyper-V seems to specifically require both graphics acceleration and HyperV paravirtualization interface .
+	# ATTENTION: HyperV should be enabled by default by 'ubDistBuild' installer and similar installers .
+	# CAUTION: Any automatic provision for an alternative should detect if HyperV is NOT installed, and fail to the assumption that HyperV is installed.
+	# https://superuser.com/questions/1026651/how-to-find-out-whether-hyper-v-is-currently-enabled-running
+	#  Strongly discouraged - apparently requries admin privileges and powershell .
+	#&& ! lspci | grep -i vmware && ! lspci | grep -i virtualbox && ! cat /proc/cpuinfo | grep -i model | grep -i qemu && ! sudo -n lspci | grep -i vmware && ! sudo -n lspci | grep -i virtualbox )
+	if _if_cygwin
+	then
+		if ! _messagePlain_probe_cmd VBoxManage modifyvm "$sessionid" --graphicscontroller vmsvga --accelerate3d on --accelerate2dvideo off
+		then
+			_messagePlain_warn 'warn: fail: VBoxManage: Acceleration from MSW Host'
+		fi
+		if ! _messagePlain_probe_cmd VBoxManage modifyvm "$sessionid" --paravirt-provider=hyperv
+		then
+			_messagePlain_warn 'warn: fail: VBoxManage: Acceleration from MSW Host'
+		fi
+	fi

+	return 0

-	# ATTENTION: Default context size is low to ensure compatibility with low-RAM computers (LLM on CPU performance generally being acceptable).
-	# STRONGLY RECOMMENDED to greatly increase the context length (6144) if at all possible (>32GB RAM) or to decrease if necessary (eg. 8GB RAM) .
+}
+
+_set_instance_vbox_features_app() {
+	true

-	#/clear
-	#/set parameter num_thread 768
-	#/set parameter num_gpu 0
+	#if [[ "$vboxOStype" == *"Win"*"XP"* ]]
+	#then
+	#	export vboxChipset="piix3"
+	#	! VBoxManage modifyvm "$sessionid" --chipset "$vboxChipset" && return 1
+	#fi

-	# 4GB (presumed)
-	#/set parameter num_ctx 512
-
-	# 8GB (presumed)
-	#/set parameter num_ctx 2048
-
-	#/set parameter num_ctx 4096
+	#! VBoxManage modifyvm "$sessionid" --usbxhci on && return 1
+}

-	# 16GB (presumed)
-	#/set parameter num_ctx 8192
+_set_instance_vbox_features_app_post() {
+	true
+
+	# WARNING: Change to 'SATA Controller' if appropriate.
+	#if ! _messagePlain_probe_cmd VBoxManage storageattach "$sessionid" --storagectl "IDE Controller" --port 2 --device 0 --type hdd --medium "$scriptLocal"/vm_bulk.vdi --mtype "immutable"
+	#then
+	#	_messagePlain_warn 'fail: vm_bulk.vdi'
+	#fi
+}

-	#/set parameter num_ctx 16384
+_set_instance_vbox_share() {
+	#VBoxManage sharedfolder add "$sessionid" --name "root" --hostpath "/"
+	if [[ "$sharedHostProjectDir" != "" ]]
+	then
+		_messagePlain_probe VBoxManage sharedfolder add "$sessionid" --name "appFolder" --hostpath "$sharedHostProjectDir"
+
+		! VBoxManage sharedfolder add "$sessionid" --name "appFolder" --hostpath "$sharedHostProjectDir" && _messagePlain_warn 'fail: mount sharedHostProjectDir= '"$sharedHostProjectDir"
+	fi
+
+	if [[ -e "$HOME"/Downloads ]]
+	then
+		_messagePlain_probe VBoxManage sharedfolder add "$sessionid" --name "Downloads" --hostpath "$HOME"/Downloads
+
+		! VBoxManage sharedfolder add "$sessionid" --name "Downloads" --hostpath "$HOME"/Downloads && _messagePlain_warn 'fail: mount (shared) Downloads= '"$HOME"/Downloads
+	fi
+}

-	# 32GB
-	#/set parameter num_ctx 32768
+_set_instance_vbox_command() {
+	_messagePlain_nominal 'Creating BootDisc.'
+	! _commandBootdisc "$@" && _messagePlain_bad 'fail: _commandBootdisc' && return 1
+	return 0
+}

-	# 68.5GiB (presumed)
-	#/set parameter num_ctx 131072
-
+_create_instance_vbox_storageattach_ide() {
+	_messagePlain_nominal 'Attaching local filesystems.'
+	! VBoxManage storagectl "$sessionid" --name "IDE Controller" --add ide --controller PIIX4 && _messagePlain_bad 'fail: VBoxManage... attach ide controller'

+	#export vboxDiskMtype="normal"
+	#[[ "$vboxDiskMtype" == "" ]] && export vboxDiskMtype="multiattach"
+	[[ "$vboxDiskMtype" == "" ]] && export vboxDiskMtype="immutable"
+	_messagePlain_probe 'vboxDiskMtype= '"$vboxDiskMtype"



+	if [[ "$ub_override_vbox_livecd" != '' ]]
+	then
+		_messagePlain_probe VBoxManage storageattach "$sessionid" --storagectl "IDE Controller" --port 0 --device 0 --type dvddrive --medium "$ub_override_vbox_livecd"
+		! VBoxManage storageattach "$sessionid" --storagectl "IDE Controller" --port 0 --device 0 --type dvddrive --medium "$ub_override_vbox_livecd" && _messagePlain_bad 'fail: VBoxManage... attach vboxInstanceDiskImage= '"$ub_override_vbox_livecd"
+	elif [[ "$ub_override_vbox_livecd_more" != '' ]]
+	then
+		_messagePlain_probe VBoxManage storageattach "$sessionid" --storagectl "IDE Controller" --port 0 --device 0 --type hdd --medium "$ub_override_vbox_livecd_more" --mtype "$vboxDiskMtype"
+		! VBoxManage storageattach "$sessionid" --storagectl "IDE Controller" --port 0 --device 0 --type hdd --medium "$ub_override_vbox_livecd_more" --mtype "$vboxDiskMtype" && _messagePlain_bad 'fail: VBoxManage... attach vboxInstanceDiskImage= '"$ub_override_vbox_livecd_more"
+	else
+		_messagePlain_probe VBoxManage storageattach "$sessionid" --storagectl "IDE Controller" --port 0 --device 0 --type hdd --medium "$vboxInstanceDiskImage" --mtype "$vboxDiskMtype"
+		! VBoxManage storageattach "$sessionid" --storagectl "IDE Controller" --port 0 --device 0 --type hdd --medium "$vboxInstanceDiskImage" --mtype "$vboxDiskMtype" && _messagePlain_bad 'fail: VBoxManage... attach vboxInstanceDiskImage= '"$vboxInstanceDiskImage"
+	fi



+	[[ -e "$hostToGuestISO" ]] && ! VBoxManage storageattach "$sessionid" --storagectl "IDE Controller" --port 1 --device 0 --type dvddrive --medium "$hostToGuestISO" && _messagePlain_bad 'fail: VBoxManage... attach hostToGuestISO= '"$hostToGuestISO"

-	local functionEntryPWD="$PWD"
-	_start
+	# Due to some EFI systems occasionally needing a Live bootloader image (ie. super grub2), it may be best to ensure disk is always booted preferentially if possible.
+	VBoxManage modifyvm "$sessionid" --boot1 disk
+	VBoxManage modifyvm "$sessionid" --boot2 floppy
+	VBoxManage modifyvm "$sessionid" --boot3 dvd
+	VBoxManage modifyvm "$sessionid" --boot4 none

+	return 0
+}
+
+_create_instance_vbox_storageattach_sata() {
+	_messagePlain_nominal 'Attaching local filesystems.'
+	! VBoxManage storagectl "$sessionid" --name "SATA Controller" --add sata --controller IntelAHCI --portcount 5 --hostiocache on && _messagePlain_bad 'fail: VBoxManage... attach sata controller'

-	cd "$safeTmp"
+	#export vboxDiskMtype="normal"
+	#[[ "$vboxDiskMtype" == "" ]] && export vboxDiskMtype="multiattach"
+	[[ "$vboxDiskMtype" == "" ]] && export vboxDiskMtype="immutable"
+	_messagePlain_probe 'vboxDiskMtype= '"$vboxDiskMtype"




+	if [[ "$ub_override_vbox_livecd" != '' ]]
+	then
+		_messagePlain_probe VBoxManage storageattach "$sessionid" --storagectl "SATA Controller" --port 0 --device 0 --type dvddrive --medium "$ub_override_vbox_livecd"
+		! VBoxManage storageattach "$sessionid" --storagectl "SATA Controller" --port 0 --device 0 --type dvddrive --medium "$ub_override_vbox_livecd" && _messagePlain_bad 'fail: VBoxManage... attach vboxInstanceDiskImage= '"$ub_override_vbox_livecd"
+	elif [[ "$ub_override_vbox_livecd_more" != '' ]]
+	then
+		_messagePlain_probe VBoxManage storageattach "$sessionid" --storagectl "SATA Controller" --port 0 --device 0 --type hdd --medium "$ub_override_vbox_livecd_more" --mtype "$vboxDiskMtype"
+		! VBoxManage storageattach "$sessionid" --storagectl "SATA Controller" --port 0 --device 0 --type hdd --medium "$ub_override_vbox_livecd_more" --mtype "$vboxDiskMtype" && _messagePlain_bad 'fail: VBoxManage... attach vboxInstanceDiskImage= '"$ub_override_vbox_livecd_more"
+	else
+		_messagePlain_probe VBoxManage storageattach "$sessionid" --storagectl "SATA Controller" --port 0 --device 0 --type hdd --medium "$vboxInstanceDiskImage" --mtype "$vboxDiskMtype"
+		! VBoxManage storageattach "$sessionid" --storagectl "SATA Controller" --port 0 --device 0 --type hdd --medium "$vboxInstanceDiskImage" --mtype "$vboxDiskMtype" && _messagePlain_bad 'fail: VBoxManage... attach vboxInstanceDiskImage= '"$vboxInstanceDiskImage"
+	fi


-	# TODO: Replace with model fine-tuned by additional relevant codebases and scientific knowledge.

-	# TODO: TODO: Intentionally overfit smaller parameter models by reinforcing prompt/response for specific knowledge (eg. plasma recombiation light emission physics) and reasoning (eg. robot motor control).

+	[[ -e "$hostToGuestISO" ]] && ! VBoxManage storageattach "$sessionid" --storagectl "SATA Controller" --port 1 --device 0 --type dvddrive --medium "$hostToGuestISO" && _messagePlain_bad 'fail: VBoxManage... attach hostToGuestISO= '"$hostToGuestISO"

-	# TODO: There may or may not be more track record with this slightly different model, using Q4-K-M quantization.
-	# https://huggingface.co/grimjim/Llama-3.1-8B-Instruct-abliterated_via_adapter-GGUF
+	# Due to some EFI systems occasionally needing a Live bootloader image (ie. super grub2), it may be best to ensure disk is always booted preferentially if possible.
+	VBoxManage modifyvm "$sessionid" --boot1 disk
+	VBoxManage modifyvm "$sessionid" --boot2 floppy
+	VBoxManage modifyvm "$sessionid" --boot3 dvd
+	VBoxManage modifyvm "$sessionid" --boot4 none

-	# TODO: Consider alternative quantization, especially IQ2-M, IQ4-XS. Beware Q4-K-M may have some community testing of important edge cases already.
-	# https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-abliterated-GGUF/tree/main
+	return 0
+}
+
+_create_instance_vbox_storageattach() {
+	# IDE Controller found to have some problems with at least Gentoo_64 EFI guests.
+	# WARNING: Do NOT change without consideration for legacy VMs. Although, legacy software seems on the way out anyway now.
+	#[[ "$vboxOStype" != *"Debian"* ]] && [[ "$vboxOStype" != *"Win"*"10"* ]] && [[ "$vboxOStype" != *"Win"* ]]
+	if [[ "$ubVirtPlatform" == *'efi' ]] || [[ "$ubVirtPlatformOverride" == *'efi' ]] || ( [[ "$vboxOStype" != "" ]] && [[ "$vboxOStype" != *"Win"*"XP"* ]] )
+	then
+		_create_instance_vbox_storageattach_sata
+		return
+	fi

-	echo 'FROM ./llama-3.1-8b-instruct-abliterated.Q4_K_M.gguf
-PARAMETER num_ctx 6144' > Llama-augment.Modelfile
+	# Legacy default.
+	_create_instance_vbox_storageattach_ide
+	return
+}
+
+_create_instance_vbox() {

-	#wget 'https://huggingface.co/mlabonne/Meta-Llama-3.1-8B-Instruct-abliterated-GGUF/resolve/main/meta-llama-3.1-8b-instruct-abliterated.Q4_K_M.gguf'
-	aria2c --log=- --log-level=info -x "3" --async-dns=false -o 'llama-3.1-8b-instruct-abliterated.Q4_K_M.gguf' 'https://huggingface.co/mlabonne/Meta-Llama-3.1-8B-Instruct-abliterated-GGUF/resolve/main/meta-llama-3.1-8b-instruct-abliterated.Q4_K_M.gguf'
-	[[ ! -e 'llama-3.1-8b-instruct-abliterated.Q4_K_M.gguf' ]] && aria2c --log=- --log-level=info -x "3" --async-dns=false -o 'llama-3.1-8b-instruct-abliterated.Q4_K_M.gguf' 'https://huggingface.co/mlabonne/Meta-Llama-3.1-8B-Instruct-abliterated-GGUF/resolve/main/meta-llama-3.1-8b-instruct-abliterated.Q4_K_M.gguf' --disable-ipv6=true
+	#Use existing VDI image if available.
+	if ! [[ -e "$scriptLocal"/vm.vdi ]] && [[ "$ub_override_vbox_livecd" == '' ]] && [[ "$ub_override_vbox_livecd_more" == '' ]]
+	then
+		# IMG file may be a device file. See 'virtualization/image/mountimage.sh' .
+		_messagePlain_nominal 'Missing VDI. Attempting to open IMG.'
+		! _openVBoxRaw && _messageError 'FAIL' && return 1
+	fi

-	if [[ ! -e 'llama-3.1-8b-instruct-abliterated.Q4_K_M.gguf' ]]
+	_messagePlain_nominal 'Checking VDI or IMG availability.'
+	if [[ "$ub_override_vbox_livecd" == '' ]] && [[ "$ub_override_vbox_livecd_more" == '' ]]
 	then
-		_wget_githubRelease_join "soaringDistributions/Llama-augment_bundle" "" "llama-3.1-8b-instruct-abliterated.Q4_K_M.gguf"
+		export vboxInstanceDiskImage="$scriptLocal"/vm.vdi
+		_readLocked "$lock_open" && vboxInstanceDiskImage="$vboxRaw"
+		! [[ -e "$vboxInstanceDiskImage" ]] && _messagePlain_bad 'missing: vboxInstanceDiskImage= '"$vboxInstanceDiskImage" && return 1
+	elif [[ "$ub_override_vbox_livecd" != '' ]] || [[ "$ub_override_vbox_livecd_more" != '' ]]
+	then
+		[[ "$ub_override_vbox_livecd" != '' ]] && ! [[ -e "$ub_override_vbox_livecd" ]] && _messagePlain_bad 'missing: ub_override_vbox_livecd= '"$ub_override_vbox_livecd" && return 1
+		[[ "$ub_override_vbox_livecd_more" != '' ]] && ! [[ -e "$ub_override_vbox_livecd_more" ]] && _messagePlain_bad 'missing: ub_override_vbox_livecd_more= '"$ub_override_vbox_livecd_more" && return 1
 	fi

-	_service_ollama
+	_messagePlain_nominal 'Determining OS type.'
+	_set_instance_vbox_type

-	! ollama create Llama-augment -f Llama-augment.Modelfile && _messagePlain_bad 'bad: FAIL: ollama create Llama-augment' && _messageFAIL
+	! _set_instance_vbox_features && _messageError 'FAIL' && return 1

-	if ! _if_cygwin
+
+	if [[ "$ubVirtPlatform" == *'efi' ]] || [[ "$ubVirtPlatformOverride" == *'efi' ]]
 	then
-		! echo | sudo -n tee /AI-Llama-augment > /dev/null && _messagePlain_bad 'bad: FAIL: echo | sudo -n tee /AI-Llama-augment' && _messageFAIL
+		VBoxManage modifyvm "$sessionid" --firmware efi64
+	else
+		# Default.
+		VBoxManage modifyvm "$sessionid" --firmware bios
 	fi
+
+	! _set_instance_vbox_features_app && _messageError 'FAIL: unknown app failure' && return 1
+
+	_set_instance_vbox_command "$@"
+
+	_messagePlain_nominal 'Mounting shared filesystems.'
+	_set_instance_vbox_share
+
+	_create_instance_vbox_storageattach
+
+
+
+	#VBoxManage showhdinfo "$scriptLocal"/vm.vdi

-	rm -f llama-3.1-8b-instruct-abliterated.Q4_K_M.gguf
-	rm -f Llama-augment.Modelfile
+	#Suppress annoying warnings.
+	! VBoxManage setextradata global GUI/SuppressMessages "remindAboutAutoCapture,remindAboutMouseIntegration,remindAboutMouseIntegrationOn,showRuntimeError.warning.HostAudioNotResponding,remindAboutGoingSeamless,remindAboutInputCapture,remindAboutGoingFullscreen,remindAboutMouseIntegrationOff,confirmGoingSeamless,confirmInputCapture,remindAboutPausedVMInput,confirmVMReset,confirmGoingFullscreen,remindAboutWrongColorDepth" && _messagePlain_warn 'fail: VBoxManage... suppress messages'

-	_ollama_stop_augment
+	! VBoxManage setextradata global GUI/SuppressMessages "Update" && _messagePlain_warn 'fail: VBoxManage... suppress messages... Update'


-	cd "$functionEntryPWD"
-	_stop
+	# WARNING: Some of these annoying warnings have apparently not been disabled effectively, possibly due to 'real' "$HOME" directory configuration, or specific versions of VirtualBox .
+
+	# From source code.
+	# remindAboutAutoCapture,remindAboutMouseIntegrationOn,remindAboutMouseIntegrationOn
+
+	# https://askubuntu.com/questions/763107/how-do-i-permanently-disable-notifications-about-auto-capture-keyboard-and-mouse
+	# confirmInputCapture,remindAboutAutoCapture,remindAboutMouseIntegrationOff,remindAboutMouseIntegrationOn,remindAboutWrongColorDepth
+
+
+
+	_set_instance_vbox_features_app_post
+
+	return 0
 }
-_setup_ollama_sequence() {
-	local functionEntryPWD
-	functionEntryPWD="$PWD"
-
-	_mustGetSudo

+#Create and launch temporary VM around persistent disk image.
+_user_instance_vbox_sequence() {
+	_messageNormal '_user_instance_vbox_sequence: start'
 	_start

-	echo 'setup: ollama: https://ollama.com/install.sh'
-
-	cd "$safeTmp"
-
-	local currentExitStatus="1"
+	_prepare_instance_vbox || _stop 1

-	# DANGER: This upstream script, as with many, has been known to use 'rm' recursively without the safety checks of '_safeRMR' .
-	# CAUTION: This upstream script may not catch error conditions upon failure, which may increase the size of dist/OS images built after such failures.
-	curl -fsSL https://ollama.com/install.sh | sh
-	currentExitStatus="$?"
-	sleep 3
-
-	# Apparently necessary to enable the service, due to systemctl not being usefully available within ChRoot.
-	sudo -n mkdir -p /etc/systemd/system/default.target.wants/
-	sudo -n ln -sf /etc/systemd/system/ollama.service /etc/systemd/system/default.target.wants/ollama.service
-
-	cd "$functionEntryPWD"
-	_stop "$currentExitStatus"
-}
-_setup_ollama() {
-	#_wantGetDep sudo
-	#_mustGetSudo
-	#export currentUser_ollama=$(_user_ollama)
-
-	[[ "$nonet" == "true" ]] && echo 'warn: nonet: skip: _setup_ollama' && return 0
-
-	if ( [[ $(id -u) != 0 ]] || _if_cygwin )
+	_messageNormal '_user_instance_vbox_sequence: Checking lock vBox_vdi= '"$vBox_vdi"
+	_readLocked "$vBox_vdi" && _messagePlain_bad 'lock: vBox_vdi= '"$vBox_vdi" && _stop 1
+
+	_messageNormal '_user_instance_vbox_sequence: Creating instance. '"$sessionid"
+	if ! _create_instance_vbox "$@"
 	then
-		[[ "$1" != "--force" ]] && find "$HOME"/.ubcore/.retest-ollama -type f -mtime -2 2>/dev/null | grep '.retest-ollama' > /dev/null 2>&1 && return 0
-
-		rm -f "$HOME"/.ubcore/.retest-ollama > /dev/null 2>&1
-		touch "$HOME"/.ubcore/.retest-ollama
-		date +%s > "$HOME"/.ubcore/.retest-ollama
+		_stop 1
 	fi
+
+	_messageNormal '_user_instance_vbox_sequence: Launch: _vboxGUI '"$sessionid"
+	 _vboxGUI --startvm "$sessionid"
+
+	_messageNormal '_user_instance_vbox_sequence: Removing instance. '"$sessionid"
+	_rm_instance_vbox
+
+	_messageNormal '_user_instance_vbox_sequence: stop'
+	_stop
+}

-
-	if ! _if_cygwin
+# Keep instance should only be set by end-user functions which require overriding of internal functions.
+_user_instance_vbox() {
+	if [[ "$ub_keepInstance" == 'true' ]]
 	then
-		_messagePlain_request 'ignore: upstream progress ->'
-		! "$scriptAbsoluteLocation" _setup_ollama_sequence && _messagePlain_bad 'bad: FAIL: _setup_ollama_sequence' && _messageFAIL
-		_messagePlain_request 'ignore: <- upstream progress'
+		_user_instance_vbox_sequence "$@"
+		return
 	fi
-
-	type -p ollama > /dev/null 2>&1 && "$scriptAbsoluteLocation" _setup_ollama_model_augment_sequence
+	"$scriptAbsoluteLocation" _user_instance_vbox_sequence "$@"
+	return
 }

-_test_ollama() {
-	#_mustGetSudo
-	#export currentUser_ollama=$(_user_ollama)
+_userVBox() {
+	_findInfrastructure_virtImage ${FUNCNAME[0]} "$@"
+	[[ "$ubVirtImageLocal" == "false" ]] && return
+
+	_messageNormal 'Begin: '"$@"
+	_user_instance_vbox "$@"
+	_messageNormal 'End: '"$@"
+}

-	if ! type -p ollama > /dev/null 2>&1 || ! [[ -e /AI-Llama-augment ]]
-	then
-		_setup_ollama
-	fi
+_edit_instance_vbox_sequence() {
+	_start
+
+	_prepare_instance_vbox || return 1

+	#VBoxManage modifymedium "$scriptLocal"/vm.vdi --type normal

-	if ! _if_cygwin
+	export vboxDiskMtype="normal"
+	if ! _create_instance_vbox "$@"
 	then
-		! type -p ollama > /dev/null 2>&1 && _messageFAIL && _stop 1
-	else
-		! type -p ollama > /dev/null 2>&1 && echo 'warn: acepted: cygwin: missing: ollama'
-		# Accepted. Do NOT return with error status (ie. do NOT 'return 1') .
+		return 1
 	fi

-	return 0
-}
-
-_vector_ollama_procedure() {
-	local currentExitStatus
-	currentExitStatus=1
-
-	local currentPoints
-	currentPoints=0
+	_readLocked "$vBox_vdi" && return 1

-	if ! _ollama_run_augment "Please output the word true . Any other output accompanying the word true is acceptable but not desirable. The purpose of this prompt is merely to validate that the LLM software is entirely functional, so the word true will be very helpful whereas any output other than the word true will be unhelpful . Please output the word true ." | grep -i true > /dev/null
-	then
-		echo 'fail: _vector_ollama' && _messagePlain_bad 'fail: _vector_ollama: prompt for word true did not output word true'
-	else
-		currentExitStatus=0
-		currentPoints=$((currentPoints+1))
-	fi
-	if _ollama_run_augment "Please output the word true . Any other output accompanying the word true is acceptable but not desirable. The purpose of this prompt is merely to validate that the LLM software is entirely functional, so the word true will be very helpful whereas any output other than the word true will be unhelpful . Please output the word true ." | grep -i false > /dev/null
-	then
-		echo 'fail: _vector_ollama' && _messagePlain_bad 'fail: _vector_ollama: prompt for word true instead included word false'
-	else
-		currentExitStatus=0
-		currentPoints=$((currentPoints+1))
-	fi
+	_createLocked "$vBox_vdi" || return 1

-	if ! _ollama_run_augment "Please output the word false . Any other output accompanying the word false is acceptable but not desirable. The purpose of this prompt is merely to validate that the LLM software is entirely functional, so the word false will be very helpful whereas any output other than the word false will be unhelpful . Please output the word false ." | grep -i false > /dev/null
-	then
-		echo 'fail: _vector_ollama' && _messagePlain_bad 'fail: _vector_ollama: prompt for word false did not output word false'
-	else
-		currentExitStatus=0
-		currentPoints=$((currentPoints+1))
-	fi
-	if _ollama_run_augment "Please output the word false . Any other output accompanying the word false is acceptable but not desirable. The purpose of this prompt is merely to validate that the LLM software is entirely functional, so the word false will be very helpful whereas any output other than the word false will be unhelpful . Please output the word false ." | grep -i true > /dev/null
+	_VirtualBox_env_VBOX_USER_HOME_short
+
+	_wait_instance_vbox
+
+	#VBoxManage modifymedium "$scriptLocal"/vm.vdi --type multiattach
+
+	rm -f "$vBox_vdi" > /dev/null 2>&1
+
+	_rm_instance_vbox
+
+	_stop
+}
+
+_edit_instance_vbox() {
+	if [[ "$ub_keepInstance" == 'true' ]]
 	then
-		echo 'fail: _vector_ollama' && _messagePlain_bad 'fail: _vector_ollama: prompt for word false instead included word true'
-	else
-		currentExitStatus=0
-		currentPoints=$((currentPoints+1))
+		_edit_instance_vbox_sequence "$@"
+		return
 	fi
+	"$scriptAbsoluteLocation" _edit_instance_vbox_sequence "$@"
+	return
+}

+_editVBox() {
+	_findInfrastructure_virtImage ${FUNCNAME[0]} "$@"
+	[[ "$ubVirtImageLocal" == "false" ]] && return
+
+	_messageNormal 'Begin: '"$@"
+	_edit_instance_vbox "$@"
+	_messageNormal 'End: '"$@"
+}

-	# If NONE of the vector tests have succeeded, then FAIL . Normally, with an 'augment' LLM model, this should be so rare as to vastly more often indicate broken ollama installation, very broken/corrupted LLM model, very broken LLM configuration, insufficient disk space for model, etc.
-	[[ "$currentExitStatus" != "0" ]] && _messageFAIL && _stop 1

-	# At least two of the vector tests can apparently pass with a broken (or missing) AI model, and very basic vector tests with an 'augment' AI model are normally extremely reliable.
-	[[ "$currentPoints" -lt 3 ]] && _messageFAIL && _stop 1
-	#[[ "$currentPoints" -lt 4 ]] && _messageFAIL && _stop 1

-	return 0
-}
-_vector_ollama() {
-	#_mustGetSudo
-	#export currentUser_ollama=$(_user_ollama)

-	_service_ollama
+_persistent_instance_vbox_sequence() {
+	_messageNormal '_persistent_instance_vbox_sequence: start'
+	_start

-	if _if_cygwin && ! type -p ollama > /dev/null 2>&1
+	_prepare_instance_vbox || _stop 1
+
+	_messageNormal '_persistent_instance_vbox_sequence: Checking lock vBox_vdi= '"$vBox_vdi"
+	_readLocked "$vBox_vdi" && _messagePlain_bad 'lock: vBox_vdi= '"$vBox_vdi" && _stop 1
+
+	export vboxDiskMtype="normal"
+	_messageNormal '_persistent_instance_vbox_sequence: Creating instance. '"$sessionid"
+	if ! _create_instance_vbox "$@"
 	then
-		echo 'warn: accepted: cygwin: missing: ollama'
-		return 0
+		_stop 1
 	fi
+
+	_messageNormal '_persistent_instance_vbox_sequence: Launch: _vboxGUI '"$sessionid"
+	 _vboxGUI --startvm "$sessionid"
+
+	_messageNormal '_persistent_instance_vbox_sequence: Removing instance. '"$sessionid"
+	_rm_instance_vbox
+
+	_messageNormal '_persistent_instance_vbox_sequence: stop'
+	_stop
+}

-	if type -p ollama > /dev/null 2>&1
+_persistent_instance_vbox() {
+	if [[ "$ub_keepInstance" == 'true' ]]
 	then
-		if [[ "$hostMemoryQuantity" -lt 28000000 ]]
-		then
-			_messagePlain_nominal '_vector_ollama: begin: low RAM detected'
-			local currentExitStatus
-			currentExitStatus="1"
-
-			_ollama_set_sequence-augment-lowRAM
-
-			"$scriptAbsoluteLocation" _vector_ollama_procedure
-			currentExitStatus="$?"
-
-			_ollama_set_sequence-augment-normal
-
-			[[ "$currentExitStatus" != "0" ]] && _messageFAIL && _stop 1
-			_messagePlain_nominal '_vector_ollama: end: low RAM detected'
-		else
-			_vector_ollama_procedure
-		fi
+		_persistent_instance_vbox_sequence "$@"
+		return
 	fi
+	"$scriptAbsoluteLocation" _persistent_instance_vbox_sequence "$@"
+	return
+}

-	_ollama_stop_augment
-
-	return 0
+_persistentVBox() {
+	_findInfrastructure_virtImage ${FUNCNAME[0]} "$@"
+	[[ "$ubVirtImageLocal" == "false" ]] && return
+
+	_messageNormal 'Begin: '"$@"
+	_persistent_instance_vbox "$@"
+	_messageNormal 'End: '"$@"
 }




+_launch_user_vbox_manage_sequence() {
+	_start
+
+	_prepare_instance_vbox || _stop 1
+
+	_readLocked "$vBox_vdi" && return 1
+
+	_createLocked "$vBox_vdi" || return 1
+
+	_VBoxManage_env_VBOX_USER_HOME_short "$@"
+
+	_wait_instance_vbox
+
+	rm -f "$vBox_vdi" > /dev/null 2>&1
+
+	_rm_instance_vbox
+
+	_stop
+}

-_user_ollama() {
-	#_mustGetSudo
-	local currentUser_temp
-	[[ "$currentUser_researchEngine" != "" ]] && currentUser_temp="$currentUser_researchEngine"
-	[[ "$currentUser_temp" == "" ]] && currentUser_temp="$currentUser"
-	[[ "$currentUser_temp" == "" ]] && [[ "$USER" != "root" ]] && currentUser_temp="$USER"
-	[[ "$currentUser_temp" == "" ]] && currentUser_temp="user"
+_launch_user_vbox_manage() {
+	"$scriptAbsoluteLocation" _launch_user_vbox_manage_sequence "$@"
+}

-	echo "$currentUser_temp"
-	return 0
+_userVBoxManage() {
+	_launch_user_vbox_manage "$@"
 }


-# Very unusual. Ensures service is available, if normal systemd service is not.
-# WARNING: Should NOT run standalone service if systemd service is available. Thus, it is important to check if the service is already available (as would normally always be the case when booted with systemd available).
-# Mostly, this is used to workaround very unusual dist/OS build and custom situations (ie. ChRoot, GitHub Actions, etc).
-# CAUTION: This leaves a background process running, which must continue running (ie. not hangup) while other programs use it, and which must terminate upon shutdown , _closeChRoot , etc .
-_service_ollama() {
-	_mustGetSudo
-	_if_cygwin && return 0
-	if ! sudo -n -u ollama bash -c 'type -p ollama'
-	then
-		echo 'warn: _service_ollama: missing: ollama'
-		return 1
-	fi
-
-	if ! wget --timeout=1 --tries=3 127.0.0.1:11434 > /dev/null -q -O - > /dev/null
-	then
-		sudo -n -u ollama ollama serve &
-		while ! wget --timeout=1 --tries=3 127.0.0.1:11434 > /dev/null -q -O - > /dev/null
-		do
-			echo "wait: ollama: service"
-			sleep 1
-		done
-		sleep 45
-	fi
-
-
-	if ! wget --timeout=1 --tries=3 127.0.0.1:11434 > /dev/null -q -O - > /dev/null
-	then
-		echo 'fail: _service_ollama: ollama: 127.0.0.1:11434'
-		return 1
-	fi
-
-	return 0
-}
-
-
-
-
-

+_here_dosbox_base_conf() {

+cat << 'CZXWXcRMTo8EmM8i4d'
+# This is the configurationfile for DOSBox 0.74. (Please use the latest version of DOSBox)
+# Lines starting with a # are commentlines and are ignored by DOSBox.
+# They are used to (briefly) document the effect of each option.

-# TODO: TODO: Reference implementation of alternative, easily scriptable Text-User-Interface (TUI) for 'ollama', for more convenient GUI wrapper design,etc.
-# https://huggingface.co/blog/llama2#how-to-prompt-llama-2
-#<s>[INST] <<SYS>>
-#{{ system_prompt }}
-#<</SYS>>
-#
-#{{ user_msg_1 }} [/INST] {{ model_answer_1 }} </s><s>[INST] {{ user_msg_2 }} [/INST]
+[sdl]
+#       fullscreen: Start dosbox directly in fullscreen. (Press ALT-Enter to go back)
+#       fulldouble: Use double buffering in fullscreen. It can reduce screen flickering, but it can also result in a slow DOSBox.
+#   fullresolution: What resolution to use for fullscreen: original or fixed size (e.g. 1024x768).
+#                     Using your monitor's native resolution with aspect=true might give the best results.
+#                     If you end up with small window on a large screen, try an output different from surface.
+# windowresolution: Scale the window to this size IF the output device supports hardware scaling.
+#                     (output=surface does not!)
+#           output: What video system to use for output.
+#                   Possible values: surface, overlay, opengl, openglnb.
+#         autolock: Mouse will automatically lock, if you click on the screen. (Press CTRL-F10 to unlock)
+#      sensitivity: Mouse sensitivity.
+#      waitonerror: Wait before closing the console if dosbox has an error.
+#         priority: Priority levels for dosbox. Second entry behind the comma is for when dosbox is not focused/minimized.
+#                     pause is only valid for the second entry.
+#                   Possible values: lowest, lower, normal, higher, highest, pause.
+#       mapperfile: File used to load/save the key/event mappings from. Resetmapper only works with the defaul value.
+#     usescancodes: Avoid usage of symkeys, might not work on all operating systems.

+fullscreen=false
+fulldouble=false
+fullresolution=original
+windowresolution=original
+output=surface
+autolock=true
+sensitivity=100
+waitonerror=true
+priority=higher,normal
+mapperfile=mapper-0.74.map
+usescancodes=true

+[dosbox]
+# language: Select another language file.
+#  machine: The type of machine tries to emulate.
+#           Possible values: hercules, cga, tandy, pcjr, ega, vgaonly, svga_s3, svga_et3000, svga_et4000, svga_paradise, vesa_nolfb, vesa_oldvbe.
+# captures: Directory where things like wave, midi, screenshot get captured.
+#  memsize: Amount of memory DOSBox has in megabytes.
+#             This value is best left at its default to avoid problems with some games,
+#             though few games might require a higher value.
+#             There is generally no speed advantage when raising this value.

+language=
+machine=svga_s3
+captures=capture
+memsize=16

-# https://github.com/ollama/ollama/issues/6286
-_ollama_set_sequence-augment-normal() {
-	local functionEntryPWD
-	functionEntryPWD="$PWD"
+[render]
+# frameskip: How many frames DOSBox skips before drawing one.
+#    aspect: Do aspect correction, if your output method doesn't support scaling this can slow things down!.
+#    scaler: Scaler used to enlarge/enhance low resolution modes.
+#              If 'forced' is appended, then the scaler will be used even if the result might not be desired.
+#            Possible values: none, normal2x, normal3x, advmame2x, advmame3x, advinterp2x, advinterp3x, hq2x, hq3x, 2xsai, super2xsai, supereagle, tv2x, tv3x, rgb2x, rgb3x, scan2x, scan3x.

-	_start
-	cd "$safeTmp"
+frameskip=0
+aspect=false
+scaler=normal2x

-	ollama show Llama-augment --modelfile | sed 's/PARAMETER num_ctx [0-9]*/PARAMETER num_ctx 6144/' > ./Llama-augment-tmp.Modelfile
-	sleep 9
-	ollama create Llama-augment --file ./Llama-augment-tmp.Modelfile
-	sleep 9
+[cpu]
+#      core: CPU Core used in emulation. auto will switch to dynamic if available and appropriate.
+#            Possible values: auto, dynamic, normal, simple.
+#   cputype: CPU Type used in emulation. auto is the fastest choice.
+#            Possible values: auto, 386, 386_slow, 486_slow, pentium_slow, 386_prefetch.
+#    cycles: Amount of instructions DOSBox tries to emulate each millisecond.
+#            Setting this value too high results in sound dropouts and lags.
+#            Cycles can be set in 3 ways:
+#              'auto'          tries to guess what a game needs.
+#                              It usually works, but can fail for certain games.
+#              'fixed #number' will set a fixed amount of cycles. This is what you usually need if 'auto' fails.
+#                              (Example: fixed 4000).
+#              'max'           will allocate as much cycles as your computer is able to handle.
+#
+#            Possible values: auto, fixed, max.
+#   cycleup: Amount of cycles to decrease/increase with keycombo.(CTRL-F11/CTRL-F12)
+# cycledown: Setting it lower than 100 will be a percentage.

-	cd "$functionEntryPWD"
-	_stop
-}
-_ollama_set-augment-normal() {
-	"$scriptAbsoluteLocation" _ollama_set_sequence-augment-normal "$@"
-}
-# Temporarily reduce RAM/VRAM requirement for constrained CI .
-_ollama_set_sequence-augment-lowRAM() {
-	local functionEntryPWD
-	functionEntryPWD="$PWD"
+core=auto
+cputype=auto
+cycles=auto
+cycleup=10
+cycledown=20

-	_start
-	cd "$safeTmp"
+[mixer]
+#   nosound: Enable silent mode, sound is still emulated though.
+#      rate: Mixer sample rate, setting any device's rate higher than this will probably lower their sound quality.
+#            Possible values: 44100, 48000, 32000, 22050, 16000, 11025, 8000, 49716.
+# blocksize: Mixer block size, larger blocks might help sound stuttering but sound will also be more lagged.
+#            Possible values: 1024, 2048, 4096, 8192, 512, 256.
+# prebuffer: How many milliseconds of data to keep on top of the blocksize.

-	#512
-	ollama show Llama-augment --modelfile | sed 's/PARAMETER num_ctx [0-9]*/PARAMETER num_ctx 640/' > ./Llama-augment-tmp.Modelfile
-	sleep 9
-	ollama create Llama-augment --file ./Llama-augment-tmp.Modelfile
-	sleep 9
+nosound=false
+rate=44100
+blocksize=1024
+prebuffer=20

+[midi]
+#     mpu401: Type of MPU-401 to emulate.
+#             Possible values: intelligent, uart, none.
+# mididevice: Device that will receive the MIDI data from MPU-401.
+#             Possible values: default, win32, alsa, oss, coreaudio, coremidi, none.
+# midiconfig: Special configuration options for the device driver. This is usually the id of the device you want to use.
+#               See the README/Manual for more details.

-	cd "$functionEntryPWD"
-	_stop
-}
-_ollama_set-augment-lowRAM() {
-	"$scriptAbsoluteLocation" _ollama_set_sequence-augment-lowRAM "$@"
-}
+mpu401=intelligent
+mididevice=default
+midiconfig=

+[sblaster]
+#  sbtype: Type of Soundblaster to emulate. gb is Gameblaster.
+#          Possible values: sb1, sb2, sbpro1, sbpro2, sb16, gb, none.
+#  sbbase: The IO address of the soundblaster.
+#          Possible values: 220, 240, 260, 280, 2a0, 2c0, 2e0, 300.
+#     irq: The IRQ number of the soundblaster.
+#          Possible values: 7, 5, 3, 9, 10, 11, 12.
+#     dma: The DMA number of the soundblaster.
+#          Possible values: 1, 5, 0, 3, 6, 7.
+#    hdma: The High DMA number of the soundblaster.
+#          Possible values: 1, 5, 0, 3, 6, 7.
+# sbmixer: Allow the soundblaster mixer to modify the DOSBox mixer.
+# oplmode: Type of OPL emulation. On 'auto' the mode is determined by sblaster type. All OPL modes are Adlib-compatible, except for 'cms'.
+#          Possible values: auto, cms, opl2, dualopl2, opl3, none.
+#  oplemu: Provider for the OPL emulation. compat might provide better quality (see oplrate as well).
+#          Possible values: default, compat, fast.
+# oplrate: Sample rate of OPL music emulation. Use 49716 for highest quality (set the mixer rate accordingly).
+#          Possible values: 44100, 49716, 48000, 32000, 22050, 16000, 11025, 8000.

-_ollama_stop_augment() {
-	ollama stop Llama-augment
-}
+sbtype=sb16
+sbbase=220
+irq=7
+dma=1
+hdma=5
+sbmixer=true
+oplmode=auto
+oplemu=default
+oplrate=44100

-_ollama_run_augment() {
-	# NOTICE: ATTENTION: Additional documenation about the 'augment' model may be present at comments around the '_setup_ollama_model_augment_sequence' and similar functions .
-
-	# DANGER DANGER: Any 'augment' model really should NOT be used for 'end user' services, including any any built-in help for any end-user program or machinery (excepting that it may or may NOT be reasonable to include with some non-commercial open-source software as a built-in help, wizard, etc, following usual expectations of community provided software). You should expect users WILL, at best, more easily 'jailbreak' such a model, and, due to the emphasis on technical usage (where reliability above 0.2% failure rates, unusual repetitive prompting, etc) as well as small model size, there may be both a complete absence of any safeguards as well as a (albeit not yet observed) possibility of introducing harmful subjects to otherwise harmless conversation.
-
-	# YOU HAVE BEEN WARNED ! DEVELOPERS ONLY, NOT USERS !
-
-	# https://www.llama.com/llama3_1/license/
-	#  'include “Llama” at the beginning of any such AI model name'
-	# ATTENTION: Nevertheless, it is very possible a non-'Llama' model will eventually be used, especially as science and technology (eg. plasma recombination EUV physics) related datasets (eg. relevant Wikipedia articles) are increasingly gathered.
-
-	# https://www.llama.com/llama3_1/use-policy/
-
-	ollama run Llama-augment "$@"
-}
-# 'l'... 'LLM', 'language', 'Llama', etc .
-_l() {
-	_ollama_run_augment "$@"
-}
-alias l=_l
+[gus]
+#      gus: Enable the Gravis Ultrasound emulation.
+#  gusrate: Sample rate of Ultrasound emulation.
+#           Possible values: 44100, 48000, 32000, 22050, 16000, 11025, 8000, 49716.
+#  gusbase: The IO base address of the Gravis Ultrasound.
+#           Possible values: 240, 220, 260, 280, 2a0, 2c0, 2e0, 300.
+#   gusirq: The IRQ number of the Gravis Ultrasound.
+#           Possible values: 5, 3, 7, 9, 10, 11, 12.
+#   gusdma: The DMA channel of the Gravis Ultrasound.
+#           Possible values: 3, 0, 1, 5, 6, 7.
+# ultradir: Path to Ultrasound directory. In this directory
+#           there should be a MIDI directory that contains
+#           the patch files for GUS playback. Patch sets used
+#           with Timidity should work fine.

+gus=false
+gusrate=44100
+gusbase=240
+gusirq=5
+gusdma=3
+ultradir=C:\ULTRASND

+[speaker]
+# pcspeaker: Enable PC-Speaker emulation.
+#    pcrate: Sample rate of the PC-Speaker sound generation.
+#            Possible values: 44100, 48000, 32000, 22050, 16000, 11025, 8000, 49716.
+#     tandy: Enable Tandy Sound System emulation. For 'auto', emulation is present only if machine is set to 'tandy'.
+#            Possible values: auto, on, off.
+# tandyrate: Sample rate of the Tandy 3-Voice generation.
+#            Possible values: 44100, 48000, 32000, 22050, 16000, 11025, 8000, 49716.
+#    disney: Enable Disney Sound Source emulation. (Covox Voice Master and Speech Thing compatible).

+pcspeaker=true
+pcrate=44100
+tandy=auto
+tandyrate=44100
+disney=true

+[joystick]
+# joysticktype: Type of joystick to emulate: auto (default), none,
+#               2axis (supports two joysticks),
+#               4axis (supports one joystick, first joystick used),
+#               4axis_2 (supports one joystick, second joystick used),
+#               fcs (Thrustmaster), ch (CH Flightstick).
+#               none disables joystick emulation.
+#               auto chooses emulation depending on real joystick(s).
+#               (Remember to reset dosbox's mapperfile if you saved it earlier)
+#               Possible values: auto, 2axis, 4axis, 4axis_2, fcs, ch, none.
+#        timed: enable timed intervals for axis. Experiment with this option, if your joystick drifts (away).
+#     autofire: continuously fires as long as you keep the button pressed.
+#       swap34: swap the 3rd and the 4th axis. can be useful for certain joysticks.
+#   buttonwrap: enable button wrapping at the number of emulated buttons.

+joysticktype=auto
+timed=true
+autofire=false
+swap34=false
+buttonwrap=false

+[serial]
+# serial1: set type of device connected to com port.
+#          Can be disabled, dummy, modem, nullmodem, directserial.
+#          Additional parameters must be in the same line in the form of
+#          parameter:value. Parameter for all types is irq (optional).
+#          for directserial: realport (required), rxdelay (optional).
+#                           (realport:COM1 realport:ttyS0).
+#          for modem: listenport (optional).
+#          for nullmodem: server, rxdelay, txdelay, telnet, usedtr,
+#                         transparent, port, inhsocket (all optional).
+#          Example: serial1=modem listenport:5000
+#          Possible values: dummy, disabled, modem, nullmodem, directserial.
+# serial2: see serial1
+#          Possible values: dummy, disabled, modem, nullmodem, directserial.
+# serial3: see serial1
+#          Possible values: dummy, disabled, modem, nullmodem, directserial.
+# serial4: see serial1
+#          Possible values: dummy, disabled, modem, nullmodem, directserial.

+serial1=dummy
+serial2=dummy
+serial3=disabled
+serial4=disabled

+[dos]
+#            xms: Enable XMS support.
+#            ems: Enable EMS support.
+#            umb: Enable UMB support.
+# keyboardlayout: Language code of the keyboard layout (or none).

+xms=true
+ems=true
+umb=true
+keyboardlayout=auto

+[ipx]
+# ipx: Enable ipx over UDP/IP emulation.

+ipx=false

+[autoexec]
+# Lines in this section will be run at startup.
+# You can put your MOUNT lines here.

+CZXWXcRMTo8EmM8i4d

+}

-#https://stackoverflow.com/questions/15432156/display-filename-before-matching-line-grep
-_grepFileLine() {
-	grep -n "$@" /dev/null
+_test_dosbox() {
+	_getDep dosbox
+
+	! _noFireJail dosbox && _stop 1
 }

-_findFunction() {
-	#-name '*.sh'
-	#-not -path "./_local/*"
-	#find ./blockchain -name '*.sh' -type f -size -10000k -exec grep -n "$@" '{}' /dev/null \;
-	#find ./generic -name '*.sh' -type f -size -10000k -exec grep -n "$@" '{}' /dev/null \;
-	#find ./instrumentation -name '*.sh' -type f -size -10000k -exec grep -n "$@" '{}' /dev/null \;
-	#find ./labels -name '*.sh' -type f -size -10000k -exec grep -n "$@" '{}' /dev/null \;
-	#find ./os -name '*.sh' -type f -size -10000k -exec grep -n "$@" '{}' /dev/null \;
-	#find ./shortcuts -name '*.sh' -type f -size -10000k -exec grep -n "$@" '{}' /dev/null \;
-	#find . -name '*.sh' -type f -size -10000k -exec grep -n "$@" '{}' /dev/null \;
+_prepare_dosbox() {
+	mkdir -p "$scriptLocal"/_dosbox
+
+	mkdir -p "$instancedVirtDir"
+	mkdir -p "$instancedVirtFS"
+	mkdir -p "$instancedVirtTmp"
+
+	_here_dosbox_base_conf > "$instancedVirtDir"/dosbox.conf

-	find . -not -path "./_local/*" -name '*.sh' -type f -size -3000k -exec grep -n "$@" '{}' /dev/null \;
 }

+_dosbox_sequence() {
+	_start
+
+	_prepare_dosbox
+
+	echo -e -n 'mount c ' >> "$instancedVirtDir"/dosbox.conf
+	echo "$scriptLocal"/_dosbox >> "$instancedVirtDir"/dosbox.conf
+	echo 'c:' >> "$instancedVirtDir"/dosbox.conf
+
+	export sharedGuestProjectDir='X:'
+	_virtUser "$@"
+
+	if [[ "$sharedHostProjectDir" != "" ]]
+	then
+		echo -e -n 'mount x ' >> "$instancedVirtDir"/dosbox.conf
+		echo "$sharedHostProjectDir" >> "$instancedVirtDir"/dosbox.conf
+		echo 'x:' >> "$instancedVirtDir"/dosbox.conf
+	fi
+
+	#Alternatively, "-c" could be used with dosbox, but this seems not to work well with multiple parameters.
+	#Note "DOS" will not like paths not conforming to 8.3 .
+	_safeEcho_newline "${processedArgs[@]}" >> "$instancedVirtDir"/dosbox.conf
+
+	dosbox -conf "$instancedVirtDir"/dosbox.conf
+
+	_safeRMR "$instancedVirtDir" || _stop 1
+
+	_stop
+}

+_dosbox() {
+	"$scriptAbsoluteLocation" _dosbox_sequence "$@"
+}

-_octave_terse() {
-	_safe_declare_uid
+_testWINE() {
+	_getDep wine

-	if [[ "$1" != "" ]]
+	if wine 2>&1 | grep 'wine32 is missing' > /dev/null 2>&1
 	then
-		_safeEcho_newline "$@" | octave --quiet --silent --no-window-system --no-gui 2>/dev/null | _octave_filter-messages
-		return
+		echo 'wine32 may be missing'
+		_stop 1
 	fi

-	octave --quiet --silent --no-window-system --no-gui 2>/dev/null | _octave_filter-messages
-	return
+	! _noFireJail wine && _stop 1
 }

-_octave() {
-	if [[ "$1" != "" ]]
+_setBottleDir() {
+	export wineExeDir
+	export wineBottle
+	export WINEPREFIX
+
+	export sharedHostProjectDir
+	export sharedGuestProjectDir
+	export processedArgs
+
+	local wineAppDir
+	local oldWineAppDir
+
+	#wineExeDir=$(_searchBaseDir "$@" "$PWD")
+	wineExeDir="$PWD"
+
+	[[ -e "$1" ]] && [[ "$1" == *".exe" ]] && wineExeDir=$(_getAbsoluteFolder "$1")
+
+
+	if uname -m | grep 64 > /dev/null 2>&1
 	then
-		_safe_declare_uid
-		_octave_terse "$@"
-		return
+		wineAppDir=${wineExeDir/\/_wbottle*}
+		wineBottle="$wineAppDir"/_wbottle
+
+		#Optional support for older naming convention.
+		#oldWineAppDir=${wineExeDir/\/wineBottle*}
+		#[[ -e "$oldWineAppDir"/wineBottle ]] && wineBottle="$oldWineAppDir"/wineBottle
+
+		[[ "$wineBottleHere" != "true" ]] && wineBottle="$scriptLocal"/_wbottle
+	else
+		wineAppDir=${wineExeDir/\/_wine32*}
+		wineBottle="$wineAppDir"/_wine32
+
+		[[ "$wineBottleHere" != "true" ]] && wineBottle="$scriptLocal"/_wine32
+
+		export WINEARCH
+		WINEARCH=win32
 	fi

-	_safe_declare_uid
-	octave --quiet --silent --no-window-system --no-gui "$@"
-	return
+	mkdir -p "$wineBottle"
+
+	export WINEPREFIX="$wineBottle"/
+
+	sharedHostProjectDir=/
+	sharedGuestProjectDir='Z:'
+
+	_virtUser "$@"
+
 }

-# ATTENTION: EXAMPLE: echo 'solve(x == y * 2, y)' | _octave_pipe
-_octave_pipe() {
-	_safe_declare_uid
-
-	_octave_terse "$@"
-	#octave --quiet --silent --no-window-system --no-gui "$@" 2>/dev/null | _octave_filter-messages
+_setBottleHere() {
+	export wineBottleHere
+	wineBottleHere="true"
 }

-# ATTENTION: EXAMPLE: _octave_script 'octave_script.m'
-# echo 'solve(x == y * 2, y)' > octave_script.m
-_octave_script() {
-	local currentFile="$1"
-	shift
+_winecfghere() {
+	_setBottleHere
+	_setBottleDir "$@"

-	_safe_declare_uid
+	winecfg
+}
+
+_winehere() {
+	_setBottleHere
+	_setBottleDir "$@"

-	cat "$currentFile" | _octave_terse "$@"
+	wine "${processedArgs[@]}"
+}
+
+_winecfg() {
+	_setBottleDir "$@"

-	#octave --quiet --silent --no-window-system --no-gui "$@" 2>/dev/null | _octave_filter-messages
+	winecfg
 }

+_wine() {
+	_setBottleDir "$@"
+
+	wine "${processedArgs[@]}"
+}

+_here_dockerfile_entrypoint() {
+	cat << 'CZXWXcRMTo8EmM8i4d'
+ENTRYPOINT ["/usr/local/bin/ubiquitous_bash.sh", "_drop_docker"]
+CZXWXcRMTo8EmM8i4d
+}

+_here_dockerfile_special() {
+	cat << 'CZXWXcRMTo8EmM8i4d'
+RUN mkdir -p /usr/bin
+RUN mkdir -p /usr/local/bin
+RUN mkdir -p /usr/share
+RUN mkdir -p /usr/local/share

+RUN mkdir -p /usr/local/share/ubcore/bin

+COPY ubiquitous_bash.sh /usr/local/bin/ubiquitous_bash.sh

+COPY ubbin /usr/local/share/ubcore/bin

+COPY gosu-armel /usr/local/bin/gosu-armel
+COPY gosu-amd64 /usr/local/bin/gosu-amd64
+COPY gosu-i386 /usr/local/bin/gosu-i386

+RUN mkdir -p /etc/skel/Downloads

+RUN mkdir -p /opt/exec
+CZXWXcRMTo8EmM8i4d

+_here_dockerfile_entrypoint
+}

-_octave_filter-messages() {
-	grep -v 'Symbolic pkg .*: Python communication link active, SymPy v' | grep -v '_____' | grep -v '^$' | sed 's/^ans = //' | sed 's/^(sym) //'
-	#cat
+_here_dockerfile_lite_scratch() {
+	cat << 'CZXWXcRMTo8EmM8i4d'
+FROM scratch
+COPY hello /
+CMD ["/hello"]
+CZXWXcRMTo8EmM8i4d
 }

+#No production use. Dockerfiles now stored in "_lib". Kept for reference only.
+_here_dockerfile_lite_debianjessie() {
+	cat << 'CZXWXcRMTo8EmM8i4d'
+FROM ubvrt/debian:jessie
+CZXWXcRMTo8EmM8i4d
+}

+#No production use. Dockerfiles now stored in "_lib". Kept for reference only.
+_here_dockerfile_debianjessie() {
+	cat << 'CZXWXcRMTo8EmM8i4d'
+FROM ubvrt/debian:jessie

+RUN apt-get update && apt-get -y --no-install-recommends install \
+ca-certificates \
+curl \
+x11-apps \
+libgl1-mesa-glx libgl1-mesa-dri mesa-utils \
+wget \
+gnupg2 \
+file \
+build-essential \
+fuse \
+hicolor-icon-theme

-
-
-# solve '( y  == x * 2, x)'
-
-_octave_solve() {
-	_safeEcho_newline solve"$@" | _octave_pipe
-}
-_octave_nsolve() {
-	_safeEcho_newline nsolve"$@" | _octave_pipe
+RUN apt-get -y install \
+default-jre
+CZXWXcRMTo8EmM8i4d
 }

-if type -p octave > /dev/null 2>&1
-then
-	_solve() {
-		_octave_solve "$@"
-	}
-	solve() {
-		_octave_solve "$@"
-	}
-	nsolve() {
-		_octave_nsolve "$@"
-	}
+_here_dockerfile() {
+	[[ -e "$scriptLocal"/Dockerfile ]] && cat "$scriptLocal"/Dockerfile && _here_dockerfile_special && return 0
+
+	#Reads out Dockerfile from _lib. Not recommended. Supported primarily for sake of example.
+	[[ "$dockerBaseObjectName" == "ubvrt/debian:jessie" ]] && [[ -e "$scriptAbsoluteFolder"/_lib/docker/debian/ubvrt/Dockerfile ]] && cat "$scriptAbsoluteFolder"/_lib/docker/debian/ubvrt/Dockerfile && _here_dockerfile_special && return 0
+
+	#[[ "$dockerBaseObjectName" == "ubvrt/debian:jessie" ]] && _here_dockerfile_debianjessie "$@" && _here_dockerfile_debianjessie && return 0
+
+	[[ "$dockerBaseObjectName" == "scratch:latest" ]] && _here_dockerfile_lite_scratch "$@" && return 0
+
+	return 1
+}

-	# WARNING: Mostly intended as apparent MSW/Cygwin workaround. May cause incorrectly written equations with inappropriate non-numeric output to pass regression tests.
-	_clc() {
-		# https://www.cyberciti.biz/faq/linux-unix-bash-check-interactive-shell/
-		if [ -z "$PS1" ]
+# WARNING Stability of this function's API is important for compatibility with existing docker images.
+_drop_docker() {
+	# Add local user
+	# Either use the LOCAL_USER_ID if passed in at runtime or
+	# fallback
+
+	USER_ID=${LOCAL_USER_ID:-9001}
+
+	if [[ "$LOCAL_USER_ID" == "" ]] || [[ "$LOCAL_USER_ID" == "0" ]]
+	then
+		#Root access by default, typically used to make permanent changes to a container for commitment to image.
+		if [[ "$1" == "" ]]
 		then
-			_octave "$@" | tr -dc '0-9.'
-			return
+			/bin/bash "$@"
+			exit
 		fi

-		_octave "$@"
-	}
-	clc() {
-		_octave "$@"
-	}
-	c() {
-		_octave "$@"
-	}
-
-	_num() {
-		_clc "$@" | tr -dc '0-9.'
-	}
-fi
-
-
-
-
-
-
-_test_devgnuoctave() {
-	_wantGetDep octave
-	_wantGetDep octave-cli
-
+		"$@"
+		exit
+	fi

-	_wantGetDep octave-config
-	_wantGetDep mkoctfile
+	#echo "Starting with UID : $USER_ID"
+	useradd --shell /bin/bash -u $USER_ID -o -c "" -m "$virtSharedUser" >/dev/null 2>&1
+	usermod -a -G video "$virtSharedUser"
+	export HOME=/home/"$virtSharedUser"

-
-
-
-	###_wantGetDep 'x86_64-linux-gnu/liboctave.so'
-	###_wantGetDep 'x86_64-linux-gnu/liboctinterp.so'
+	chown "$virtSharedUser":"$virtSharedUser" "$HOME"

+	#cp -r /etc/skel/. "$HOME"

-	###_wantGetDep 'x86_64-linux-gnu/octave/site/oct/x86_64-pc-linux-gnu/libsbml5/OutputSBML.mex'
-	###_wantGetDep 'x86_64-linux-gnu/octave/site/oct/x86_64-pc-linux-gnu/libsbml5/TranslateSBML.mex'
+	# Change to localPWD or home.
+	cd "$localPWD"

-	_wantGetDep 'x86_64-linux-gnu/qt5/plugins/cantor/backends/cantor_octavebackend.so'
+	# Drop to user ubvrtusr or remain root, using gosu.

-
-
+	##Example alternative code for future reference.
+	#export INPUTRC='~/.inputrc'
+	#export profileScriptLocation=/usr/local/bin/entrypoint.sh
+	#export profileScriptFolder=/usr/local/bin/

-	#if ! _wantGetDep dh_octave_check
-	#then
-		#! _typeShare 'dh-octave/install-pkg.m' && _wantGetDep dh-octave/install-pkg.m
-	#fi
+	#bash -c ". ./etc/profile > /dev/null 2>&1 ; set -o allexport ; . ~/.bash_profile > /dev/null 2>&1 ; . ~/.bashrc > /dev/null 2>&1 ; . ./ubiquitous_bash.sh _importShortcuts > /dev/null 2>&1 ; set +o allexport ; bash --noprofile --norc -i ; . ~/.bash_logout > /dev/null 2>&1"

+	#bash --init-file <(echo ". ~/.bashrc ; . ./ubiquitous_bash.sh _importShortcuts")

+	#_gosuExecVirt bash --init-file <(echo ". ~/.bashrc ; . /usr/local/bin/entrypoint.sh _importShortcuts" "$@")

-	_tryExec '_test_devgnuoctave-extra'
+	##Setup and launch.
+	"$scriptAbsoluteLocation" _gosuExecVirt cp -r /etc/skel/. "$virtGuestHomeDrop"

+	"$scriptAbsoluteLocation" _gosuExecVirt "$scriptAbsoluteLocation" _setupUbiquitous_nonet

+	# Drop to user ubvrtusr, using gosu.
+	_gosuExecVirt "$@"

-	return 0
 }

-
-_test_devgnuoctave_wantGetDep-octavePackage-internal() {
-	if [[ "$1" == "symbolic" ]]
+#Runs command directly if member of "docker" group, or through sudo if not.
+#Docker inevitably requires effective root.
+_permitDocker() {
+	if groups | grep docker > /dev/null 2>&1
 	then
-		_wantGetDep 'python3/dist-packages/sympy/__init__.py'
-		_wantGetDep 'python3/dist-packages/isympy.py'
-
-		"$scriptAbsoluteLocation" _octave pkg list | grep symbolic > /dev/null && return 0
-
-		_wantGetDep octave-symbolic
-		"$scriptAbsoluteLocation" _octave pkg install -forge symbolic
-		return 0
+		"$@"
+		return "$?"
 	fi

-
-	return 1
-}
-
-
-
-_test_devgnuoctave_wantGetDep-octavePackage-debian-x64-special-debianBullseye() {
-	! [[ -e /etc/issue ]] && return 1
-	! cat /etc/issue | grep 'Debian' > /dev/null 2>&1 && return 1
-	! [[ -e /etc/debian_version ]] && return 1
-	! cat /etc/debian_version | head -c 2 | grep 11 > /dev/null 2>&1 && return 1
-
-
-	if [[ "$1" == "symbolic" ]]
+	if _wantSudo > /dev/null 2>&1
 	then
-		_test_devgnuoctave_wantGetDep-octavePackage-internal "$@"
-		return
+		sudo -n "$@"
+		return "$?"
 	fi

 	return 1
 }
-_test_devgnuoctave_wantGetDep-octavePackage-debian-x64-special-debianBookworm() {
-	! [[ -e /etc/issue ]] && return 1
-	! cat /etc/issue | grep 'Debian' > /dev/null 2>&1 && return 1
-	! [[ -e /etc/debian_version ]] && return 1
-	! cat /etc/debian_version | head -c 2 | grep 12 > /dev/null 2>&1 && return 1
+
+_test_docker() {
+	_testGosu || _stop 1
+
+	_checkDep gosu-armel
+	_checkDep gosu-amd64
+	_checkDep gosu-i386


-	if [[ "$1" == "symbolic" ]]
+	if ! _if_cygwin
 	then
-		_test_devgnuoctave_wantGetDep-octavePackage-internal "$@"
-		return
+
+		#https://docs.docker.com/engine/installation/linux/docker-ce/debian/#install-using-the-repository
+		#https://wiki.archlinux.org/index.php/Docker#Installation
+		#sudo -n usermod -a -G docker "$USER"
+
+		_getDep /sbin/losetup
+		if ! [[ -e "/dev/loop-control" ]] || ! [[ -e "/sbin/losetup" ]]
+		then
+			echo 'may be missing loopback interface'
+			_stop 1
+		fi
+
+		_getDep docker
+		_getDep docker-compose
+
+		local dockerPermission
+		dockerPermission=$(_permitDocker echo true 2> /dev/null)
+		if [[ "$dockerPermission" != "true" ]]
+		then
+			echo 'no permissions to run docker'
+			_stop 1
+		fi
+
+
+		#if ! _permitDocker docker run hello-world 2>&1 | grep 'Hello from Docker' > /dev/null 2>&1
+		#then
+		#	echo 'failed docker hello world'
+		#	_stop 1
+		#fi
+
 	fi

-	return 1
-}
-
-
-
-
-
-# ATTENTION: WARNING: Only tested with Debian Stable. May require rewrite to accommodate other distro (ie. Gentoo).
-_test_devgnuoctave_wantGetDep-octavePackage-debian-x64() {
-	## If not Debian, then simply accept these pacakges may not be available.
-	#[[ -e /etc/issue ]] && ! cat /etc/issue | grep 'Debian' > /dev/null 2>&1 && return 0

-	# If not x64, then simply accept these pacakges may not be available.
-	local hostArch
-	hostArch=$(uname -m)
-	if [[ "$hostArch" != "x86_64" ]]
-	then
-		return 0
-	fi

-	if _test_devgnuoctave_wantGetDep-octavePackage-debian-x64-special-debianBullseye "$@"
+	if ! _discoverResource moby/contrib/mkimage.sh > /dev/null 2>&1 && ! _discoverResource docker/contrib/mkimage.sh
+	#if true
 	then
-		return 0
+		echo
+		echo 'base images cannot be created without mkimage'
+		#_stop 1
 	fi
-	if _test_devgnuoctave_wantGetDep-octavePackage-debian-x64-special-debianBookworm "$@"
+
+	if ! [[ -e "$scriptBin"/hello ]]
 	then
-		return 0
+		echo
+		echo 'some base images cannot be created without hello'
 	fi

-	local currentPackageSuffix
-	currentPackageSuffix=$(echo "$1" | sed 's/-$//')
-
-	! _typeShare_dir_wildcard 'octave/packages/'"$1" && ! _typeShare_dir_wildcard 'octave/packages/'"$1" && _wantGetDep octave-"$currentPackageSuffix"
-	! _typeShare_dir_wildcard 'octave/packages/'"$1" && ! _typeShare_dir_wildcard 'octave/packages/'octave-"$1" && _wantGetDep octave-"$currentPackageSuffix"
-	#_wantGetDep octave-"$1"
-
-	return 0
-}
-
-_test_devgnuoctave-debian-x64() {
-	local hostArch
-	hostArch=$(uname -m)
-

-	# If not Debian, then simply accept these pacakges may not be available.
-	# Experimentally, some Debian-like distributions may be allowed to attempt to such more complete octave package installation.
-	# \|Ubuntu
-	[[ -e /etc/issue ]] && ! cat /etc/issue | grep 'Debian' > /dev/null 2>&1 && return 0

-	# If not x64, then simply accept these pacakges may not be available.
-	if [[ "$hostArch" != "x86_64" ]]
+	if _if_cygwin
 	then
 		return 0
 	fi

+	sudo -n systemctl status docker 2>&1 | head -n 2 | grep -i 'chroot' > /dev/null && return 0
+	systemctl status docker 2>&1 | head -n 2 | grep -i 'chroot' > /dev/null && return 0

-
-
-	if ! _typeShare_dir_wildcard 'octave/packages/arduino' && ! _typeShare 'doc-base/octave-arduino-manual' && ! _typeShare 'info/arduino.info.gz' && ! _typeShare 'doc/octave-arduino/arduino.pdf.gz'
+	_permitDocker docker import "$scriptBin"/"dockerHello".tar "ubdockerhello" --change 'CMD ["/hello"]' > /dev/null 2>&1
+	if ! _permitDocker docker run "ubdockerhello" 2>&1 | grep 'hello world' > /dev/null 2>&1
 	then
-		_wantGetDep octave-arduino
+		echo 'failed ubdockerhello'
+		echo 'request: may require iptables legacy'
+		echo 'sudo -n update-alternatives --set iptables /usr/sbin/iptables-legacy'
+		echo 'sudo -n update-alternatives --set ip6tables /usr/sbin/ip6tables-legacy'
+		_stop 1
 	fi

-
-	_wantGetDep /usr/share/octave/site/m/bart/bart.m
-
-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 bim
-
-	_wantGetDep x86_64-linux-gnu/octave/site/oct/x86_64-pc-linux-gnu/biosig/mexSLOAD.mex
-
-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 bsltl
-
-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 cgi
-
-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 control
-
-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 data-smoothing
-
-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 dataframe
-
-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 dicom
-
-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 divand
-
-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 doctest
-
-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 econometrics
-
-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 financial
-
-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 fits
-
-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 fpl
-
-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 fuzzy-logic-toolkit
-
-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 ga-
-
-	_wantGetDep x86_64-linux-gnu/octave/site/oct/x86_64-pc-linux-gnu/gdf/gdf_reader.mex
-
-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 general
-
-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 geometry
-
-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 gsl
-
-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 image
-
-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 image-acquisition
-
-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 instrument-control
-
-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 interval
-
-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 io-
-
-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 level-set
-
-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 linear-algebra
-
-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 lssa
-
-	#_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 ltfat
-
-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 mapping
-
-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 miscellaneous
-
-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 missing-functions
-
-	#_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 mpi-
-
-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 msh-
-
-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 mvn-
-
-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 nan-
-
-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 ncarray
-
-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 netcdf
-
-	if ! _typeDep 'x86_64-linux-gnu/octave/site/oct/x86_64-pc-linux-gnu/nlopt_optimize.oct' && ! _typeDep 'x86_64-linux-gnu/octave/site/oct/x86_64-pc-linux-gnu/nlopt/nlopt_optimize.oct'
+}
+
+
+_checkBaseDirRemote_docker() {
+	#-e LOCAL_USER_ID=`id -u $USER`
+	if ! _permitDocker docker run -it --name "$dockerContainerObjectNameInstanced"_cr --rm "$dockerImageObjectName" /bin/bash -c '[[ -e "'"$1"'" ]] && ! [[ -d "'"$1"'" ]] && [[ "'"$1"'" != "." ]] && [[ "'"$1"'" != ".." ]] && [[ "'"$1"'" != "./" ]] && [[ "'"$1"'" != "../" ]]'
 	then
-		_wantGetDep x86_64-linux-gnu/octave/site/oct/x86_64-pc-linux-gnu/nlopt_optimize.oct
-		_wantGetDep x86_64-linux-gnu/octave/site/oct/x86_64-pc-linux-gnu/nlopt/nlopt_optimize.oct
+		return 1
 	fi
-	! _typeShare 'octave/site/m/nlopt/nlopt_optimize.m' && ! _typeShare '/usr/share/octave/site/m/nlopt_minimize.m' && _wantGetDep octave-nlopt
-
-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 nurbs
-
-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 netcdf
-
-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 octclip
-
-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 octproj
-
-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 openems
-
-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 optics
-
-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 optim
-
-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 optiminterp
-
-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 parallel
-
-	#_wantGetDep x86_64-linux-gnu/octave/site/oct/x86_64-pc-linux-gnu/pfstools/pfsread.oct
-	#! _typeShare 'octave/site/m/pfstools/pfs_read_xyz.m' && _wantGetDep octave-pfstools
-
-	#_wantGetDep x86_64-linux-gnu/octave/site/oct/api-v52/x86_64-pc-linux-gnu/plplot_octave.oct
-	#! _typeShare 'plplot_octave/mesh.m' && _wantGetDep octave-plplot
-
-	_wantGetDep psychtoolbox-3/PsychBasic/PsychPortAudio.mex
-
-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 quaternion
-
-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 queueing
-
-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 secs1d
-
-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 secs2d
-
-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 secs3d
-
-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 signal
-
-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 sockets
-
-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 sparsersb
-
-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 specfun
-
-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 splines
-
-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 statistics
-
-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 stk
+	return 0
+}
+
+_userDocker_sequence() {
+	_start
+	_prepare_docker
+	local userDockerExitStatus

-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 strings
+	export checkBaseDirRemote=_checkBaseDirRemote_docker
+	_virtUser "$@" >> "$logTmp"/usrdock.log 2>&1

-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 struct
+	#"$sharedHostProjectDir"
+	#"${processedArgs[@]}"

-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 symbolic
+	local dockerRunArgs

-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 tsa
+	#Translation only.
+	local LOCAL_USER_ID=$(id -u)
+	dockerRunArgs+=(-e virtSharedUser="$virtGuestUser" -e localPWD="$localPWD" -e LOCAL_USER_ID="$LOCAL_USER_ID")

-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 vibes
+	#Directory sharing.
+	dockerRunArgs+=(-v "$HOME"/Downloads:"$virtGuestHome"/Downloads:rw -v "$sharedHostProjectDir":"$sharedGuestProjectDir":rw)

-	_wantGetDep x86_64-linux-gnu/octave/site/oct/x86_64-pc-linux-gnu/vlfeat/toolbox/vl_binsearch.mex
-	! _typeShare 'octave/site/m/vlfeat/toolbox/misc/vl_binsearch.m' && _wantGetDep octave-vlfeat
+	#Display
+	dockerRunArgs+=(-e DISPLAY=$DISPLAY -e "XAUTHORITY=${XAUTH}")
+	dockerRunArgs+=(-v $XSOCK:$XSOCK:rw -v $XAUTH:$XAUTH:rw)
+	#dockerRunArgs+=(-v /tmp:/tmp:rw)

-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 vrml
+	#FUSE (AppImage)
+	dockerRunArgs+=(--cap-add SYS_ADMIN --device /dev/fuse --security-opt apparmor:unconfined)
+
+	#OpenGL, Intel HD Graphics.
+	dockerRunArgs+=(--device=/dev/dri:/dev/dri)

-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 zenity
+	_permitDocker docker run -it --name "$dockerContainerObjectNameInstanced" --rm "${dockerRunArgs[@]}" "$dockerImageObjectName" "${processedArgs[@]}"

-	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 zeromq

+	userDockerExitStatus="$?"

-	return 0
+	rm -f "$logTmp"/usrdock.log > /dev/null 2>&1
+	_stop "$userDockerExitStatus"
 }

-_test_devgnuoctave-extra() {
-	local hostArch
-	hostArch=$(uname -m)
+_userDocker() {
+	_findInfrastructure_virtImage ${FUNCNAME[0]} "$@"
+	[[ "$ubVirtImageLocal" == "false" ]] && return

-	if [[ "$hostArch" == "x86_64" ]] && [[ -e /etc/issue ]] && cat /etc/issue | grep 'Ubuntu' > /dev/null 2>&1
-	then
-		_test_devgnuoctave_wantGetDep-octavePackage-internal symbolic
-		_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 quaternion
-		_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 vrml
-		_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 zeromq
-	fi
+	local dockerImageNeeded
+	"$scriptAbsoluteLocation" _create_docker_image_needed_sequence > /dev/null 2>&1
+	dockerImageNeeded="$?"
+	[[ "$dockerImageNeeded" == "0" ]] && return 1
+	[[ "$dockerImageNeeded" == "1" ]] && return 1

-	_test_devgnuoctave-debian-x64
+	"$scriptAbsoluteLocation" _userDocker_sequence "$@"
+	return "$?"
 }



+_write_wslconfig() {
+    ! _if_cygwin && _messagePlain_bad 'fail: Cygwin/MSW only' && return 1
+    if _if_cygwin
+    then
+        _here_wsl_config "$1" > "$USERPROFILE"/.wslconfig
+        return
+    fi
+}





+# End user function .
+_setup_wsl2_procedure() {
+    ! _if_cygwin && _messagePlain_bad 'fail: Cygwin/MSW only' && return 1
+
+    _messageNormal 'init: _setup_wsl2'
+
+    _messagePlain_nominal 'setup: write: _write_msw_WSLENV'
+    _write_msw_WSLENV

-_qalculate_terse() {
-	_safe_declare_uid
-
-	# https://stackoverflow.com/questions/17998978/removing-colors-from-output
-	#sed -r "s/\x1B\[([0-9]{1,3}(;[0-9]{1,2})?)?[mGK]//g"
-
-	# https://stackoverflow.com/questions/4233159/grep-regex-whitespace-behavior
-	#grep -v '^\s*$'
-
-	if [[ "$1" != "" ]]
-	then
-		#_safeEcho_newline "$@" | qalc -t | grep -v '^>\ ' | grep -v '^$' | sed 's/^  //' | grep -v '^\s*$' | sed -r "s/\x1B\[([0-9]{1,3}(;[0-9]{1,2})?)?[mGK]//g"
-
-		# Preferred for Cygwin .
-		_safeEcho_newline "$@" | qalc -t | grep -v '^> ' | grep -v '^$' | sed 's/^  //' | grep -v '^\s*$' | sed -r "s/\x1B\[([0-9]{1,3}(;[0-9]{1,2})?)?[mGK]//g"
-		return
-	fi
-
-	#qalc -t "$@" | grep -v '^>\ ' | grep -v '^$' | sed 's/^  //' | grep -v '^\s*$' | sed -r "s/\x1B\[([0-9]{1,3}(;[0-9]{1,2})?)?[mGK]//g"
-
-	# Preferred for Cygwin .
-	qalc -t "$@" | grep -v '^> ' | grep -v '^$' | sed 's/^  //' | grep -v '^\s*$' | sed -r "s/\x1B\[([0-9]{1,3}(;[0-9]{1,2})?)?[mGK]//g"
-	return
+    _messagePlain_nominal 'setup: write: _write_msw_wslconfig'
+    _write_wslconfig "ub_ignore_kernel_wsl"
+
+    _messagePlain_nominal 'setup: wsl2'
+
+    # https://www.omgubuntu.co.uk/how-to-install-wsl2-on-windows-10
+
+    _messagePlain_probe dism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart
+    dism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart
+
+    _messagePlain_probe dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart
+    dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart
+
+    _messagePlain_probe wsl --set-default-version 2
+    wsl --set-default-version 2
+
+    _messagePlain_probe wsl --update
+    wsl --update
+
+    _messagePlain_probe wsl --install --no-launch
+    wsl --install --no-launch
+
+    echo 'WSL errors and usage information above may or may not be disregarded.'
+
+    _messagePlain_probe wsl --update
+    wsl --update
+
+    _messagePlain_probe wsl --set-default-version 2
+    wsl --set-default-version 2
+
+    _messagePlain_probe wsl --update
+    wsl --update
+
+    sleep 45
+    wsl --update
+
+    sleep 5
+    wsl --update
+
+    sleep 5
+    wsl --set-default-version 2
+
+    sleep 5
+    wsl --update
+
+    sleep 5
+    wsl --set-default-version 2
+}
+_setup_wsl2() {
+    "$scriptAbsoluteLocation" _setup_wsl2_procedure "$@"
+}
+_setup_wsl() {
+    _setup_wsl2 "$@"
 }

-# Interactive.
-_qalculate() {
-	_safe_declare_uid
-
-	mkdir -p "$HOME"/.config/qalculate
-
-	if [[ "$1" != "" ]]
-	then
-		_safe_declare_uid
-		_qalculate_terse "$@"
-		return
-	fi
-
-	_safe_declare_uid
-	qalc "$@"
-	return
+
+
+
+
+
+
+
+
+_here_wsl_config() {
+    cat << 'CZXWXcRMTo8EmM8i4d'
+[wsl2]
+memory=999GB
+CZXWXcRMTo8EmM8i4d
+
+    if [[ -e /cygdrive/c/core/infrastructure/ubdist-kernel/ubdist-kernel ]] && [[ "$1" != "ub_ignore_kernel_wsl" ]]
+    then
+        echo 'kernel=C:\\core\\infrastructure\\ubdist-kernel\\ubdist-kernel'
+    fi
+
+    echo
 }

-# ATTENTION: EXAMPLE: echo 'solve(x == y * 2, y)' | _qalculate_pipe
-_qalculate_pipe() {
-	_safe_declare_uid
-
-	_qalculate_terse "$@"
+
+_here_wsl_conf() {
+    cat << 'CZXWXcRMTo8EmM8i4d'
+
+[boot]
+systemd = true
+command = /bin/bash -c 'systemctl stop sddm ; rm -f /root/_rootGrab.sh ; usermod -a -G kvm user ; chown -v root:kvm /dev/kvm ; chmod 660 /dev/kvm ; ( rm /home/user/___quick/mount.sh ; rmdir /home/user/___quick ; ( [[ ! -e /home/user/___quick ]] && ln -s /mnt/c/q /home/user/___quick ) ; rm -f /home/user/___quick/q )'
+
+[user]
+default = user
+
+[wsl2]
+nestedVirtualization=true
+
+[automount]
+options = "metadata"
+
+CZXWXcRMTo8EmM8i4d
 }

-# ATTENTION: _qalculate_script 'qalculate_script.m'
-# echo 'solve(x == y * 2, y)' > qalculate_script.m
-_qalculate_script() {
-	local currentFile="$1"
-	shift
-
-	_safe_declare_uid
-
-	cat "$currentFile" | _qalculate_pipe "$@"
+
+
+
+
+
+
+
+
+_here_wsl_qt5ct_conf() {
+    cat << 'CZXWXcRMTo8EmM8i4d'
+
+[Appearance]
+color_scheme_path=/usr/share/qt5ct/colors/airy.conf
+custom_palette=false
+icon_theme=breeze-dark
+standard_dialogs=default
+style=Breeze
+
+[Interface]
+activate_item_on_single_click=1
+buttonbox_layout=0
+cursor_flash_time=1000
+dialog_buttons_have_icons=1
+double_click_interval=400
+gui_effects=@Invalid()
+keyboard_scheme=2
+menus_have_icons=true
+show_shortcuts_in_context_menus=true
+stylesheets=@Invalid()
+toolbutton_style=4
+underline_shortcut=1
+wheel_scroll_lines=3
+
+[Troubleshooting]
+force_raster_widgets=1
+ignored_applications=@Invalid()
+
+CZXWXcRMTo8EmM8i4d
 }

+_write_wsl_qt5ct_conf() {
+    if [[ "$HOME" == "/root" ]] || [[ $(id -u) == 0 ]]
+    then
+        return 1
+    fi
+
+    local currentHome
+    currentHome="$HOME"
+    [[ "$currentHome" == "/root" ]] && currentHome="/home/user"
+    [[ "$1" != "" ]] && currentHome="$1"

+    [[ -e "$currentHome"/.config/qt5ct/qt5ct.conf ]] && return 0
+
+    mkdir -p "$currentHome"/.config/qt5ct
+    mkdir -p "$currentHome"/.config/qt5ct/colors
+    mkdir -p "$currentHome"/.config/qt5ct/qss
+
+    _here_wsl_qt5ct_conf > "$currentHome"/.config/qt5ct/qt5ct.conf

+    [[ -e "$currentHome"/.config/qt5ct/qt5ct.conf ]] && return 0

+    return 1
+}



+# WARNING: Experimental. Installer use only. May cause issues with applications running natively from the MSW side. Fortunately, it seems QT_QPA_PLATFORMTHEME is ignored if qt5ct is not present, as expected in the case of 'native' QT MSW applications.
+_write_msw_qt5ct() {
+    setx QT_QPA_PLATFORMTHEME qt5ct /m
+}

+# https://www.ibm.com/docs/en/sva/7.0.0?topic=SSPREK_7.0.0/com.ibm.isam.doc_80/ameb_audit_guide/concept/con_lang_var_win.htm
+# Seems 'LANG=C' would also be a normal setting for MSW .
+# nix-shell --run "locale -a" -p bash
+#  C   C.utf8   POSIX
+_write_msw_LANG() {
+    setx LANG C /m
+}


-_qalculate_solve() {
-	_safeEcho_newline solve"$@" | _qalculate_pipe
+# KDE Plasma, FreeCAD, etc, may not be usable without usable OpenGL .
+# https://github.com/microsoft/wslg/wiki/GPU-selection-in-WSLg
+_write_msw_discreteGPU() {
+    #glxinfo -B | grep -i intel > /dev/null 2>&1 && setx MESA_D3D12_DEFAULT_ADAPTER_NAME NVIDIA /m
+
+    "$(cygpath -S)"/wbem/wmic.exe path win32_VideoController get name | grep -i 'intel' > /dev/null 2>&1 && "$(cygpath -S)"/wbem/wmic.exe path win32_VideoController get name | grep -i 'nvidia' > /dev/null 2>&1 && setx MESA_D3D12_DEFAULT_ADAPTER_NAME NVIDIA /m
 }
-_qalculate_nsolve() {
-	_safeEcho_newline solve"$@" | _qalculate_pipe
+
+
+_write_msw_WSLENV() {
+    _messagePlain_request 'request: If the value of system variable WSLENV is important to you, the previous value is noted here.'
+    _messagePlain_probe_var WSLENV
+
+    _write_msw_qt5ct
+    #setx WSLENV QT_QPA_PLATFORMTHEME /m
+
+    _write_msw_LANG
+    #setx WSLENV LANG /m
+
+    _write_msw_discreteGPU
+    #setx MESA_D3D12_DEFAULT_ADAPTER_NAME NVIDIA /m
+
+    #setx WSLENV LANG:QT_QPA_PLATFORMTHEME:MESA_D3D12_DEFAULT_ADAPTER_NAME /m
+
+    setx WSLENV LANG:QT_QPA_PLATFORMTHEME:MESA_D3D12_DEFAULT_ADAPTER_NAME:GH_TOKEN /m
 }

-if type -p qalc > /dev/null 2>&1
-then
-	_solve() {
-		_qalculate_solve "$@"
-	}
-	solve() {
-		_qalculate_solve "$@"
-	}
-	nsolve() {
-		_qalculate_solve "$@"
-	}

-	# WARNING: Mostly intended as apparent MSW/Cygwin workaround. May cause incorrectly written equations with inappropriate non-numeric output to pass regression tests (ie. same wrong output may still be wrong output).
-	_clc() {
-		# https://www.cyberciti.biz/faq/linux-unix-bash-check-interactive-shell/
-		if [ -z "$PS1" ]
-		then
-			_qalculate "$@" | tr -dc 'E0-9.\n'
-			return
-		fi
-
-		_qalculate "$@"
-	}
-	clc() {
-		_qalculate "$@"
-	}
-	c() {
-		_qalculate "$@"
-	}
-
-	_num() {
-		_clc "$@" | tr -dc 'E0-9.\n'
-	}
-fi




-_test_devqalculate() {
-	# Debian Bullseye (stable) apparently does not include 'qualculate-gtk'.
-	# GUI may be installed from binaries provided elsewhere, although the '_qalculate' , '_clc' , and 'c' , functions do not require this.
-	# https://qalculate.github.io/downloads.html
-	if [[ -e /etc/debian_version ]] && cat /etc/debian_version | head -c 2 | grep 11 > /dev/null 2>&1
-	then
-		! _typeDep qalculate-gtk && sudo -n apt-get install --install-recommends -y qalculate-gtk
-	else
-		_wantGetDep qalculate-gtk
-		#_wantGetDep qalculate
-	fi
-
-	_wantGetDep qalc
-
-	if ! _typeShare 'texmf/tex/latex/gnuplot/gnuplot.cfg' && ! _typeShare 'texmf/tex/gnuplot.cfg'
-	then
-		! _wantGetDep 'texmf/tex/latex/gnuplot/gnuplot.cfg' && ! _wantGetDep 'texmf/tex/gnuplot.cfg' && ! _wantGetDep gnuplot-data
-	fi
-
-
-	! _typeShare 'texmf/tex/latex/gnuplot/gnuplot.cfg' && ! _typeShare 'texmf/tex/gnuplot.cfg' && echo 'warn: missing: gnuplot-data'
-
-	#_wantGetDep gnuplot-data
-	#_wantGetDep gnuplot-x11
-	_wantGetDep gnuplot-qt
-
-	_wantGetDep gnuplot
-
-	! _typeDep qalculate-gtk && echo 'warn: missing: qalculate-gtk'
-
-
-	if [[ $(qalc -v | cut -f1 -d\. | tr -dc '0-9') -le "3" ]]
-	then
-		echo 'warn: bad: unacceptable qalc version!'
-	fi
-
-	return 0
+_wsl_desktop-waitUp_wmctrl() {
+    while [[ $(wmctrl -d 2>/dev/null | wc -l) -lt 1 ]]
+    do
+        sleep 0.2
+    done
 }
+_wsl_desktop-waitDown_wmctrl() {
+    while [[ $(wmctrl -d 2>/dev/null | wc -l) -gt 1 ]]
+    do
+        sleep 0.4
+    done
+}
+_here_wsl_desktop_startup_script() {
+    cat << CZXWXcRMTo8EmM8i4d
+#!/usr/bin/env bash
+export DBUS_SESSION_BUS_ADDRESS="$DBUS_SESSION_BUS_ADDRESS"
+export DBUS_SESSION_BUS_PID="$DBUS_SESSION_BUS_PID"
+export DBUS_SESSION_BUS_WINDOWID="$DBUS_SESSION_BUS_WINDOWID"
+export QT_QPA_PLATFORMTHEME= ; unset QT_QPA_PLATFORMTHEME ; export LANG="C"
+export DESKTOP_SESSION=plasma
+#bash "$scriptAbsoluteLocation" _wsl_desktop-waitUp_wmctrl ; sleep 0.6
+export LANG="C"
+CZXWXcRMTo8EmM8i4d

+#dbus-run-session
+_safeEcho_newline 'exec '"$@"' &'

+    cat << CZXWXcRMTo8EmM8i4d
+#disown -h \$!
+disown
+disown -a -h -r
+disown -a -r
+rm -f "\$HOME"/.config/plasma-workspace/env/tmp_wsl_desktop.sh
+rm -f "\$HOME"/.config/tmp_wsl_desktop.sh
+sudo -n rm -f /etc/xdg/autostart/tmp_wsl_desktop.desktop
+rm -f "\$HOME"/.config/systemd/user/tmp_wsl_desktop.service
+#bash "$scriptAbsoluteLocation" _wsl_desktop-waitDown_wmctrl
+#currentStopJobs=\$(jobs -p -r 2> /dev/null) ; [[ "\$displayStopJobs" != "" ]] && kill \$displayStopJobs > /dev/null 2>&1
+CZXWXcRMTo8EmM8i4d
+}
+_wsl_desktop_startup_plasmaWorkspaceEnv_write() {
+    mkdir -p "$HOME"/.config/plasma-workspace/env/
+    _here_wsl_desktop_startup_script "$@" > "$HOME"/.config/plasma-workspace/env/tmp_wsl_desktop.sh
+    chmod u+x "$HOME"/.config/plasma-workspace/env/tmp_wsl_desktop.sh
+}
+_here_wsl_desktop_startup_xdg() {
+    cat << CZXWXcRMTo8EmM8i4d
+[Desktop Entry]
+Comment=
+Exec="$HOME"/.config/tmp_wsl_desktop.sh > /dev/null
+GenericName=
+Icon=exec
+MimeType=
+Name=
+Path=
+StartupNotify=false
+Terminal=false
+TerminalOptions=
+Type=Application
+CZXWXcRMTo8EmM8i4d
+}
+_wsl_desktop_startup_xdg_write() {
+    mkdir -p "$HOME"/.config/
+    _here_wsl_desktop_startup_script "$@" > "$HOME"/.config/tmp_wsl_desktop.sh
+    chmod u+x "$HOME"/.config/tmp_wsl_desktop.sh

+    _here_wsl_desktop_startup_xdg | sudo -n tee /etc/xdg/autostart/tmp_wsl_desktop.desktop > /dev/null
+}
+# https://bbs.archlinux.org/viewtopic.php?id=279740
+_here_wsl_desktop_startup_systemd() {
+    cat << CZXWXcRMTo8EmM8i4d
+[Unit]
+After=xdg-desktop-autostart.target

-_set_markup_terminal() {
-
-	#&& [[ "$flag__NOT_shell" == "" ]] && [[ "$comment_shell_line" == "" ]]
-	if [[ "$current_scriptedIllustrator_markup" == "" ]] && [[ "$current_scriptedIllustrator_markup_markdown" == "" ]] && [[ "$workaround_noInterpret_begin" == "" ]] && [[ "$workaround_noInterpret_end" == "" ]] && [[ "$workaround_comment_shell_line" == "" ]]
-	then
-
-		export flag__NOT_shell='scriptedIllustrator_markup_uk4uPhB663kVcygT0q'
-		export comment_shell_line='#'
-
-
-		_e() {
-			export currentFunctionName="${FUNCNAME[0]}"
-			_e-terminal "$@"
-		}
-		#export -f _e
-
-		_e_() {
-			export currentFunctionName="${FUNCNAME[0]}"
-			_e_-terminal "$@"
-		}
-		#export -f _e_
-
-		_o() {
-			export currentFunctionName="${FUNCNAME[0]}"
-			_o-terminal "$@"
-		}
-		#export -f _o
-
-		_o_() {
-			export currentFunctionName="${FUNCNAME[0]}"
-			_o_-terminal "$@"
-		}
-		#export -f _o_
-
-		_i() {
-			export currentFunctionName="${FUNCNAME[0]}"
-			_i-terminal "$@"
-		}
-		#export -f _i
-
-		_v() {
-			export currentFunctionName="${FUNCNAME[0]}"
-			_v-terminal "$@"
-		}
-		#export -f _v
-
-		_t() {
-			export currentFunctionName="${FUNCNAME[0]}"
-			_t-terminal "$@"
-		}
-		#export -f _t
-
-		_r() {
-			export currentFunctionName="${FUNCNAME[0]}"
-			_r-terminal "$@"
-		}
-		#export -f _r
-
-		_() {
-			export currentFunctionName="${FUNCNAME[0]}"
-			_h-terminal "$@"
-		}
-		_h() {
-			export currentFunctionName="${FUNCNAME[0]}"
-			_h-terminal "$@"
-		}
-		#export -f _
-		#export -f _h
-
-
-
-		_heading1() {
-			export currentFunctionName="${FUNCNAME[0]}"
-			_heading1-terminal "$@"
-		}
-		#export -f _heading1
-		_heading2() {
-			export currentFunctionName="${FUNCNAME[0]}"
-			_heading2-terminal "$@"
-		}
-		#export -f _heading2
-		_heading3() {
-			export currentFunctionName="${FUNCNAME[0]}"
-			_heading3-terminal "$@"
-		}
-		#export -f _heading3
-		_heading4() {
-			export currentFunctionName="${FUNCNAME[0]}"
-			_heading4-terminal "$@"
-		}
-		#export -f _heading4
-		_heading5() {
-			export currentFunctionName="${FUNCNAME[0]}"
-			_heading5-terminal "$@"
-		}
-		#export -f _heading5
-		_heading6() {
-			export currentFunctionName="${FUNCNAME[0]}"
-			_heading6-terminal "$@"
-		}
-		#export -f _heading6
-
-		_page() {
-			export currentFunctionName="${FUNCNAME[0]}"
-			_page-terminal "$@"
-		}
-		#export -f _page
-
-		_paragraph_begin() {
-			export currentFunctionName="${FUNCNAME[0]}"
-			_paragraph_begin-terminal "$@"
-		}
-		#export -f _paragraph_begin
-		_paragraph_end() {
-			export currentFunctionName="${FUNCNAME[0]}"
-			_paragraph_end-terminal "$@"
-		}
-		#export -f _paragraph_end
-
-
-		_picture() {
-			export currentFunctionName="${FUNCNAME[0]}"
-			_picture-terminal "$@"
-		}
-		#export -f _picture
-		_image() {
-			export currentFunctionName="${FUNCNAME[0]}"
-			_image-terminal "$@"
-		}
-		#export -f _image
-
-
-		_cells_begin() {
-			export currentFunctionName="${FUNCNAME[0]}"
-			_cells_begin-terminal "$@"
-		}
-		#export -f _cells_begin
-		_cells_end() {
-			export currentFunctionName="${FUNCNAME[0]}"
-			_cells_end-terminal "$@"
-		}
-		#export -f _cells_end
-		_cells_row_begin() {
-			export currentFunctionName="${FUNCNAME[0]}"
+[Install]
+WantedBy=xdg-desktop-autostart.target
+
+[Service]
+Type=oneshot
+ExecStart="$HOME"/.config/tmp_wsl_desktop.sh
+CZXWXcRMTo8EmM8i4d
+}
+_wsl_desktop_startup_systemd_write() {
+    mkdir -p "$HOME"/.config/
+    _here_wsl_desktop_startup_script "$@" > "$HOME"/.config/tmp_wsl_desktop.sh
+    chmod u+x "$HOME"/.config/tmp_wsl_desktop.sh
+
+    mkdir -p "$HOME"/.config/systemd/user/
+    _here_wsl_desktop_startup_systemd | sudo -n tee "$HOME"/.config/systemd/user/tmp_wsl_desktop.service > /dev/null
+
+    systemctl --user stop tmp_wsl_desktop
+    systemctl --user daemon-reload
+    systemctl --user enable tmp_wsl_desktop
+    systemctl --user enable tmp_wsl_desktop.service
+}
+_wsl_desktop() {
+    local functionEntryPWD
+    functionEntryPWD="$PWD"
+
+    (
+        _messageNormal "init: _wsl_desktop"
+
+        # KDE Plasma may not be usable without usable OpenGL .
+        # https://github.com/microsoft/wslg/wiki/GPU-selection-in-WSLg
+        _set_discreteGPU-forWSL
+
+        if [[ "$PWD" == "/mnt/"?"/WINDOWS/system32" ]] || [[ "$PWD" == "/mnt/"?"/Windows/system32" ]] || [[ "$PWD" == "/mnt/"?"/windows/system32" ]]
+        then
+            _messagePlain_probe 'reject: /mnt/'?'/WINDOWS/system32'
+            _messagePlain_probe_cmd cd
+        fi
+
+        export QT_QPA_PLATFORMTHEME=
+        unset QT_QPA_PLATFORMTHEME
+        #_set_qt5ct
+
+
+        # nix-shell --run "locale -a" -p bash
+        #  C   C.utf8   POSIX
+        export LANG="C"
+
+
+        # https://stackoverflow.com/questions/12153552/how-high-do-x11-display-numbers-go
+        # https://en.wikipedia.org/wiki/List_of_TCP_and_UDP_port_numbers
+        _messagePlain_nominal 'Searching for unused X11 display.'
+        local xephyrDisplay
+        local xephyrDisplayValid
+        xephyrDisplayValid="false"
+
+        if [[ "$2" == *"panel.sh" ]] || [[ "$2" == *"panel"*".sh" ]] || [[ "$2" == *"panel"*".bat" ]]
+        then
+            for (( xephyrDisplay = 53 ; xephyrDisplay <= 79 ; xephyrDisplay++ ))
+            do
+                ! [[ -e /tmp/.X"$xephyrDisplay"-lock ]] && ! [[ -e /tmp/.X11-unix/X"$xephyrDisplay" ]] && xephyrDisplayValid="true" && _messagePlain_good 'found: unused X11 display= '"$xephyrDisplay" && break
+            done
+        else
+            # RESERVED - 53-79 (or greater) for PanelBoard
+            for (( xephyrDisplay = 13 ; xephyrDisplay <= 52 ; xephyrDisplay++ ))
+            do
+                ! [[ -e /tmp/.X"$xephyrDisplay"-lock ]] && ! [[ -e /tmp/.X11-unix/X"$xephyrDisplay" ]] && xephyrDisplayValid="true" && _messagePlain_good 'found: unused X11 display= '"$xephyrDisplay" && break
+            done
+        fi
+
+        _messagePlain_nominal 'Xephyr.'
+        local xephyrResolution
+        xephyrResolution="1600x1200"
+        [[ "$1" == *"x"* ]] && xephyrResolution="$1"
+        shift
+        if type -p dbus-launch > /dev/null 2>&1 && type -p dbus-run-session > /dev/null 2>&1 && type -p startplasma-x11 > /dev/null 2>&1
+        then
+            export -f _wsl_desktop-waitUp_wmctrl
+            export -f _wsl_desktop-waitDown_wmctrl
+            export -f _set_qt5ct
+
+            #if [[ "$descriptiveSelf" != ""]]
+            #then
+                #export currentPlasmaSession="$HOME"/.ubtmp/plasmaSession-"$descriptiveSelf"
+            #else
+                #export currentPlasmaSession="$HOME"/.ubtmp/plasmaSession-"$sessionid"
+            #fi
+
+            #_set_qt5ct
+            #"$@"
+
+            (
+                _timeout 0.3 xmessage -timeout 1 "splash-ldesk: init: Xephyr"
+                Xephyr -screen "$xephyrResolution" :"$xephyrDisplay" &#disown -h $!
+                disown
+                disown -a -h -r
+                disown -a -r
+                (
+
+                    export DISPLAY=:"$xephyrDisplay"
+                    export QT_QPA_PLATFORMTHEME=
+                    unset QT_QPA_PLATFORMTHEME
+                    export LANG="C"
+
+                    export DESKTOP_SESSION=plasma
+
+                    _timeout 0.3 xmessage -timeout 1 "splash-ldesk: init: dbus-launch"
+                    export $(dbus-launch)
+
+                    _timeout 0.3 xmessage -timeout 1 "splash-ldesk: init: xclipsync"
+                    "$HOME"/core/installations/xclipsync/xclipsync &
+                    disown
+                    disown -a -h -r
+                    disown -a -r
+
+                    # https://blog.davidedmundson.co.uk/blog/plasma-and-the-systemd-startup/
+                    # https://bbs.archlinux.org/viewtopic.php?id=279740
+                    # https://www.reddit.com/r/archlinux/comments/ves6mh/kde_autostart_mostly_no_longer_working/
+                    ##kwriteconfig5 --file startkderc --group General --key systemdBoot false
+                    ##kwriteconfig5 --file startkderc --group General --key systemdBoot true
+                    #_wsl_desktop_startup_plasmaWorkspaceEnv_write "$@"
+                    _wsl_desktop_startup_xdg_write "$@"
+                    #_wsl_desktop_startup_systemd_write "$@"
+
+                    ##dbus-run-session
+                    _timeout 0.3 xmessage -timeout 1 "splash-ldesk: init: startplasma-x11"
+                    exec startplasma-x11 > /dev/null 2>&1 &
+
+
+                    #sleep 0.1
+                    #_wsl_desktop-waitUp_wmctrl
+                    ##sleep 3
+
+                    #exec "$@" > /dev/null 2>&1 &
+
+                    echo '---------------------------------------------'
+                    wait
+                    echo '+++++++++++++++++++++++++++++++++++++++++++++'
+
+                    export LANG="C"
+
+                    #_wsl_desktop-waitDown_wmctrl ; currentStopJobs=$(jobs -p -r 2> /dev/null) ; [[ "$displayStopJobs" != "" ]] && kill $displayStopJobs > /dev/null 2>&1
+
+                )
+
+                wait
+            )
+            #_wsl_desktop-waitDown_wmctrl ; currentStopJobs=$(jobs -p -r 2> /dev/null) ; [[ "$displayStopJobs" != "" ]] && kill $displayStopJobs > /dev/null 2>&1
+            return 0
+            cd "$functionEntryPWD"
+        fi
+        _messagePlain_bad 'bad: missing: GUI'
+        _messageFAIL
+        _stop 1
+        return 1
+    )
+
+    cd "$functionEntryPWD"
+}
+ldesk() {
+    _wsl_desktop "$@"
+}
+
+
+
+
+
+
+
+
+_test_wsl2_internal() {
+    _if_cygwin && return 0
+
+    if ! _if_cygwin
+    then
+        _getDep 'xclip'
+
+        _getDep 'tclsh'
+        _getDep 'wish'
+
+        _getDep Xephyr
+
+        _wantGetDep dbus-run-session
+        _wantGetDep startplasma-x11
+
+        return
+    fi
+    return 1
+}
+#####Shortcuts
+
+# https://unix.stackexchange.com/questions/434409/make-a-bash-ps1-that-counts-streak-of-correct-commands
+_visualPrompt_promptCommand() {
+	[[ "$PS1_lineNumber" == "" ]] && PS1_lineNumber='0'
+	#echo "$PS1_lineNumber"
+	let PS1_lineNumber="$PS1_lineNumber"+1
+	#export PS1_lineNumber
+
+	PS1_lineNumberText="$PS1_lineNumber"
+	if [[ "$PS1_lineNumber" == '1' ]]
+	then
+		# https://unix.stackexchange.com/questions/266921/is-it-possible-to-use-ansi-color-escape-codes-in-bash-here-documents
+		PS1_lineNumberText=$(echo -e -n '\E[1;36m'1)
+		#PS1_lineNumberText=$(echo -e -n '\E[1;36m'1)
+		#PS1_lineNumberText=$(echo -e -n '\[\033[01;36m\]'1)
+		#PS1_lineNumberText=$(echo -e -n '\033[01;36m'1)
+	fi
+}
+
+_visualPrompt() {
+	local currentHostname
+	currentHostname="$HOSTNAME"
+
+	[[ -e /etc/hostname ]] && export currentHostname=$(cat /etc/hostname)
+
+
+	export currentChroot=
+	[[ "$chrootName" != "" ]] && export currentChroot="$chrootName"
+	#[[ "$VIRTUAL_ENV_PROMPT" != "" ]] && export currentChroot=python_"$VIRTUAL_ENV_PROMPT"
+
+
+	#+%H:%M:%S\ %Y-%m-%d\ Q%q
+	#+%H:%M:%S\ %b\ %d,\ %y
+
+	#Long.
+	#export PS1='\[\033[01;40m\]\[\033[01;36m\]+\[\033[01;34m\]-|\[\033[01;31m\]${?}:${debian_chroot:+($debian_chroot)}\[\033[01;33m\]\u\[\033[01;32m\]@\h\[\033[01;36m\]\[\033[01;34m\])-\[\033[01;36m\]--\[\033[01;34m\]-(\[\033[01;35m\]$(date +%H:%M:%S\ .%d)\[\033[01;34m\])-\[\033[01;36m\]-|\[\033[00m\]\n\[\033[01;40m\]\[\033[01;36m\]+\[\033[01;34m\]-|\[\033[37m\][\w]\[\033[00m\]\n\[\033[01;36m\]+\[\033[01;34m\]-|\#) \[\033[36m\]>\[\033[00m\] '
+
+	#Short.
+	#export PS1='\[\033[01;40m\]\[\033[01;36m\]+\[\033[01;34m\]|\[\033[01;31m\]${?}:${debian_chroot:+($debian_chroot)}\[\033[01;33m\]\u\[\033[01;32m\]@\h\[\033[01;36m\]\[\033[01;34m\])-\[\033[01;36m\]-\[\033[01;34m\]-(\[\033[01;35m\]$(date +%H:%M:%S\ .%d)\[\033[01;34m\])\[\033[01;36m\]|\[\033[00m\]\n\[\033[01;40m\]\[\033[01;36m\]+\[\033[01;34m\]|\[\033[37m\][\w]\[\033[00m\]\n\[\033[01;36m\]+\[\033[01;34m\]|\#) \[\033[36m\]>\[\033[00m\] '
+
+	#Truncated, 40 columns.
+	#export PS1='\[\033[01;40m\]\[\033[01;36m\]\[\033[01;34m\]|\[\033[01;31m\]${?}:${debian_chroot:+($debian_chroot)}\[\033[01;33m\]\u\[\033[01;32m\]@\h\[\033[01;36m\]\[\033[01;34m\])\[\033[01;36m\]\[\033[01;34m\]-(\[\033[01;35m\]$(date +%H:%M:%S\.%d)\[\033[01;34m\])\[\033[01;36m\]|\[\033[00m\]\n\[\033[01;40m\]\[\033[01;36m\]\[\033[01;34m\]|\[\033[37m\][\w]\[\033[00m\]\n\[\033[01;36m\]\[\033[01;34m\]|\#) \[\033[36m\]>\[\033[00m\] '
+
+
+	# https://unix.stackexchange.com/questions/434409/make-a-bash-ps1-that-counts-streak-of-correct-commands
+
+	#export PROMPT_COMMAND=$(declare -f _visualPrompt_promptCommand)' ; _visualPrompt_promptCommand'
+	#export PROMPT_COMMAND='_visualPrompt_promptCommand () { [[ "$PS1_lineNumber" == "" ]] && PS1_lineNumber="0"; let PS1_lineNumber="$PS1_lineNumber"+1; PS1_lineNumberText="$PS1_lineNumber"; if [[ "$PS1_lineNumber" == "1" ]]; then PS1_lineNumberText=$(echo -e -n "'"\E[1;36m"'"1"'"\E[0m"'"); fi } ; _visualPrompt_promptCommand'
+
+	export -f _visualPrompt_promptCommand
+	export PROMPT_COMMAND=_visualPrompt_promptCommand
+
+	#export PS1='\[\033[01;40m\]\[\033[01;36m\]\[\033[01;34m\]|\[\033[01;31m\]${?}:${debian_chroot:+($debian_chroot)}\[\033[01;33m\]\u\[\033[01;32m\]@\h\[\033[01;36m\]\[\033[01;34m\])\[\033[01;36m\]\[\033[01;34m\]-(\[\033[01;35m\]$(date +%H:%M:%S\.%d)\[\033[01;34m\])\[\033[01;36m\]|\[\033[00m\]\n\[\033[01;40m\]\[\033[01;36m\]\[\033[01;34m\]|\[\033[37m\][\w]\[\033[00m\]\n\[\033[01;36m\]\[\033[01;34m\]|$PS1_lineNumberText\[\033[01;34m\]) \[\033[36m\]>\[\033[00m\] '
+
+
+	#export PS1='\[\033[01;40m\]\[\033[01;36m\]\[\033[01;34m\]|\[\033[01;31m\]${?}:${debian_chroot:+($debian_chroot)}\[\033[01;33m\]\u\[\033[01;32m\]@\h\[\033[01;36m\]\[\033[01;34m\])\[\033[01;36m\]\[\033[01;34m\]-'"$prompt_cloudNetName"'(\[\033[01;35m\]$(date +%H:%M:%S\.%d)\[\033[01;34m\])\[\033[01;36m\]|\[\033[00m\]\n\[\033[01;40m\]\[\033[01;36m\]\[\033[01;34m\]|\[\033[37m\][\w]\[\033[00m\]\n\[\033[01;36m\]\[\033[01;34m\]|$PS1_lineNumberText\[\033[01;34m\]) \[\033[36m\]'""'>\[\033[00m\] '
+
+
+	if [[ "$SHELL" == *"/nix/store/"*"/bin/bash"* ]]
+	then
+		export prompt_nixShell="nixShell"
+	else
+		export prompt_nixShell=""
+	fi
+
+	#export PS1='\[\033[01;40m\]\[\033[01;36m\]\[\033[01;34m\]|\[\033[01;31m\]${?}:${debian_chroot:+($debian_chroot)}\[\033[01;33m\]\u\[\033[01;32m\]@\h\[\033[01;36m\]\[\033[01;34m\])\[\033[01;36m\]\[\033[01;34m\]-'"$prompt_cloudNetName"'(\[\033[01;35m\]$(date +%H:%M:%S\.%d)\[\033[01;34m\])\[\033[01;36m\]|\[\033[00m\]'"$prompt_nixShell"'\n\[\033[01;40m\]\[\033[01;36m\]\[\033[01;34m\]|\[\033[37m\][\w]\[\033[00m\]\n\[\033[01;36m\]\[\033[01;34m\]|$([[ "$PS1_lineNumber" == "1" ]] && echo -e -n '"'"'\[\033[01;36m\]'"'"'$PS1_lineNumber || echo -e -n $PS1_lineNumber)\[\033[01;34m\]) \[\033[36m\]'""'>\[\033[00m\] '
+
+
+
+	#if _if_cygwin
+	#then
+		#export PS1='\[\033[01;40m\]\[\033[01;36m\]\[\033[01;34m\]|\[\033[01;31m\]${?}:${currentChroot:+($currentChroot)}\[\033[01;33m\]\u\[\033[01;32m\]@'"$currentHostname"'\[\033[01;36m\]\[\033[01;34m\])\[\033[01;36m\]\[\033[01;34m\]-'"$prompt_cloudNetName"'(\[\033[01;35m\]$(date +%H:%M:%S\.%d)\[\033[01;34m\])\[\033[01;36m\]|\[\033[00m\]'"$prompt_nixShell"'\n\[\033[01;40m\]\[\033[01;36m\]\[\033[01;34m\]\[\033[37m\]\w\[\033[00m\]\n\[\033[01;36m\]\[\033[01;34m\]|$([[ "$PS1_lineNumber" == "1" ]] && echo -e -n '"'"'\[\033[01;36m\]'"'"'$PS1_lineNumber || echo -e -n $PS1_lineNumber)\[\033[01;34m\]) \[\033[36m\]'""'>\[\033[00m\] '
+	#elif ( uname -a | grep -i 'microsoft' > /dev/null 2>&1 || uname -a | grep -i 'WSL2' > /dev/null 2>&1 )
+	#then
+		#export PS1='\[\033[01;40m\]\[\033[01;36m\]\[\033[01;34m\]|\[\033[01;31m\]${?}:${currentChroot:+($currentChroot)}\[\033[01;33m\]\u\[\033[01;32m\]@'"$currentHostname"-wsl2'\[\033[01;36m\]\[\033[01;34m\])\[\033[01;36m\]\[\033[01;34m\]-'"$prompt_cloudNetName"'(\[\033[01;35m\]$(date +%H:%M:%S\.%d)\[\033[01;34m\])\[\033[01;36m\]|\[\033[00m\]'"$prompt_nixShell"'\n\[\033[01;40m\]\[\033[01;36m\]\[\033[01;34m\]\[\033[37m\]\w\[\033[00m\]\n\[\033[01;36m\]\[\033[01;34m\]|$([[ "$PS1_lineNumber" == "1" ]] && echo -e -n '"'"'\[\033[01;36m\]'"'"'$PS1_lineNumber || echo -e -n $PS1_lineNumber)\[\033[01;34m\]) \[\033[36m\]'""'>\[\033[00m\] '
+	#else
+		#export PS1='\[\033[01;40m\]\[\033[01;36m\]\[\033[01;34m\]|\[\033[01;31m\]${?}:${currentChroot:+($currentChroot)}\[\033[01;33m\]\u\[\033[01;32m\]@'"$currentHostname"'\[\033[01;36m\]\[\033[01;34m\])\[\033[01;36m\]\[\033[01;34m\]-'"$prompt_cloudNetName"'(\[\033[01;35m\]$(date +%H:%M:%S\.%d)\[\033[01;34m\])\[\033[01;36m\]|\[\033[00m\]'"$prompt_nixShell"'\n\[\033[01;40m\]\[\033[01;36m\]\[\033[01;34m\]|\[\033[37m\][\w]\[\033[00m\]\n\[\033[01;36m\]\[\033[01;34m\]|$([[ "$PS1_lineNumber" == "1" ]] && echo -e -n '"'"'\[\033[01;36m\]'"'"'$PS1_lineNumber || echo -e -n $PS1_lineNumber)\[\033[01;34m\]) \[\033[36m\]'""'>\[\033[00m\] '
+	#fi
+
+	if _if_cygwin
+	then
+		export PS1='\[\033[01;40m\]\[\033[01;36m\]\[\033[01;34m\]|\[\033[01;31m\]${?}:${currentChroot:+($currentChroot)}\[\033[01;33m\]\u\[\033[01;32m\]@'"$currentHostname"'\[\033[01;36m\]\[\033[01;34m\])\[\033[01;36m\]\[\033[01;34m\]-'"$prompt_cloudNetName"'(\[\033[01;35m\]$(([[ "$VIRTUAL_ENV_PROMPT" != "" ]] && echo -n "$VIRTUAL_ENV_PROMPT") || date +%H:%M:%S\.%d)\[\033[01;34m\])\[\033[01;36m\]|\[\033[00m\]'"$prompt_nixShell"'\n\[\033[01;40m\]\[\033[01;36m\]\[\033[01;34m\]\[\033[37m\]\w\[\033[00m\]\n\[\033[01;36m\]\[\033[01;34m\]|$([[ "$PS1_lineNumber" == "1" ]] && echo -e -n '"'"'\[\033[01;36m\]'"'"'$PS1_lineNumber || echo -e -n $PS1_lineNumber)\[\033[01;34m\]) \[\033[36m\]'""'>\[\033[00m\] '
+	elif ( uname -a | grep -i 'microsoft' > /dev/null 2>&1 || uname -a | grep -i 'WSL2' > /dev/null 2>&1 )
+	then
+		export PS1='\[\033[01;40m\]\[\033[01;36m\]\[\033[01;34m\]|\[\033[01;31m\]${?}:${currentChroot:+($currentChroot)}\[\033[01;33m\]\u\[\033[01;32m\]@'"$currentHostname"-wsl2'\[\033[01;36m\]\[\033[01;34m\])\[\033[01;36m\]\[\033[01;34m\]-'"$prompt_cloudNetName"'(\[\033[01;35m\]$(([[ "$VIRTUAL_ENV_PROMPT" != "" ]] && echo -n "$VIRTUAL_ENV_PROMPT") || date +%H:%M:%S\.%d)\[\033[01;34m\])\[\033[01;36m\]|\[\033[00m\]'"$prompt_nixShell"'\n\[\033[01;40m\]\[\033[01;36m\]\[\033[01;34m\]\[\033[37m\]\w\[\033[00m\]\n\[\033[01;36m\]\[\033[01;34m\]|$([[ "$PS1_lineNumber" == "1" ]] && echo -e -n '"'"'\[\033[01;36m\]'"'"'$PS1_lineNumber || echo -e -n $PS1_lineNumber)\[\033[01;34m\]) \[\033[36m\]'""'>\[\033[00m\] '
+	else
+		export PS1='\[\033[01;40m\]\[\033[01;36m\]\[\033[01;34m\]|\[\033[01;31m\]${?}:${currentChroot:+($currentChroot)}\[\033[01;33m\]\u\[\033[01;32m\]@'"$currentHostname"'\[\033[01;36m\]\[\033[01;34m\])\[\033[01;36m\]\[\033[01;34m\]-'"$prompt_cloudNetName"'(\[\033[01;35m\]$(([[ "$VIRTUAL_ENV_PROMPT" != "" ]] && echo -n "$VIRTUAL_ENV_PROMPT") || date +%H:%M:%S\.%d)\[\033[01;34m\])\[\033[01;36m\]|\[\033[00m\]'"$prompt_nixShell"'\n\[\033[01;40m\]\[\033[01;36m\]\[\033[01;34m\]|\[\033[37m\][\w]\[\033[00m\]\n\[\033[01;36m\]\[\033[01;34m\]|$([[ "$PS1_lineNumber" == "1" ]] && echo -e -n '"'"'\[\033[01;36m\]'"'"'$PS1_lineNumber || echo -e -n $PS1_lineNumber)\[\033[01;34m\]) \[\033[36m\]'""'>\[\033[00m\] '
+	fi
+
+	#export PS1="$prompt_nixShell""$PS1"
+}
+
+
+_request_visualPrompt() {
+	_messagePlain_request 'export profileScriptLocation="'"$scriptAbsoluteLocation"'"'
+	_messagePlain_request 'export profileScriptFolder="'"$scriptAbsoluteFolder"'"'
+	_messagePlain_request ". "'"'"$scriptAbsoluteLocation"'"' --profile _importShortcuts
+}
+
+
+
+_setup_researchEngine() {
+	if [[ -e "$scriptLib"/kit/app/researchEngine ]]
+	then
+		export kit_dir_researchEngine="$scriptLib"/kit/app/researchEngine
+		. "$scriptLib"/kit/app/researchEngine/kit/researchEngine.sh
+		if [[ "$1" == "" ]]
+		then
+			_setup_researchEngine-kit
+		else
+			"$@"
+		fi
+		return
+	fi
+
+	if [[ -e "$scriptLib"/ubiquitous_bash/_lib/kit/app/researchEngine ]]
+	then
+		export kit_dir_researchEngine="$scriptLib"/ubiquitous_bash/_lib/kit/app/researchEngine
+		. "$scriptLib"/ubiquitous_bash/_lib/kit/app/researchEngine/kit/researchEngine.sh
+		if [[ "$1" == "" ]]
+		then
+			_setup_researchEngine-kit
+		else
+			"$@"
+		fi
+		return
+	fi
+
+	if [[ -e "$scriptLib"/ubDistBuild/_lib/ubiquitous_bash/_lib/kit/app/researchEngine ]]
+	then
+		export kit_dir_researchEngine="$scriptLib"/ubDistBuild/_lib/ubiquitous_bash/_lib/kit/app/researchEngine
+		. "$scriptLib"/ubDistBuild/_lib/ubiquitous_bash/_lib/kit/app/researchEngine/kit/researchEngine.sh
+		if [[ "$1" == "" ]]
+		then
+			_setup_researchEngine-kit
+		else
+			"$@"
+		fi
+		return
+	fi
+
+	_messagePlain_bad 'bad: missing: kit researchEngine'
+	_messageFAIL
+	_stop 1
+}
+
+
+
+_upgrade_researchEngine() {
+	_setup_researchEngine _service_researchEngine-docker-chroot-start
+
+	_setup_researchEngine _upgrade_researchEngine_searxng "$@"
+	_setup_researchEngine _upgrade_researchEngine_openwebui "$@"
+
+	_setup_researchEngine _service_researchEngine-docker-chroot-stop
+}
+
+_upgrade_researchEngine-nvidia() {
+	_setup_researchEngine _service_researchEngine-docker-chroot-start
+
+	_setup_researchEngine _upgrade_researchEngine_searxng "$@"
+	_setup_researchEngine _upgrade_researchEngine_openwebui-nvidia "$@"
+
+	_setup_researchEngine _service_researchEngine-docker-chroot-stop
+}
+
+
+
+
+# ATTENTION: NOTICE: WIP: AI models bring such efficient and effective natural language processing, reasoning, parsing, summarization, API/documentation understanding, and code generation, as to backport an essential yet unusually new capability to some of the oldest (ie. >20years old) computer CPUs (even without a GPU). ATTENTION: Unusually, all 'ai' functions (including those here), may be very interdependent on the 'shortcut' functions. This has two consequences:
+# (1) CAUTION: No 'compile' of the script should include only the 'ai' functions without the 'shortcut' functions, this WILL cause potentially dangerous failures.
+# (2) NOTICE: Please DO read all comments from both directories for both VERY significant TODO items, and possible obligations you may have to follow to actually use some specifically supported AI models.
+
+
+
+
+
+
+
+_setup_ollama_model_augment_sequence() {
+	# NOTICE: WARNING: Normally, any redistribution of a 'Llama', similar AI model, or other AI model, would be from an authoratative corporation, such as "Soaring Distributions LLC" .
+
+	# DANGER: An 'augment' model, which may be included with 'ubdist' or other 'dist/OS' is intended SOLELY for developer use. As a public domain or some publicly available AI model licensing terms apparently allow, this model may be modified for better compliance with technical use cases (such as not disregarding the previous conversation when given repeated 'system' prompts), or for smaller model size (eg. through quantization, or use of a lower parameter count model).
+
+	# DANGER DANGER: Any 'augment' model really should NOT be used for 'end user' services, including any any built-in help for any end-user program or machinery (excepting that it may or may NOT be reasonable to include with some non-commercial open-source software as a built-in help, wizard, etc, following usual expectations of community provided software). You should expect users WILL, at best, more easily 'jailbreak' such a model, and, due to the emphasis on technical usage (where reliability above 0.2% failure rates, unusual repetitive prompting, etc) as well as small model size, there may be both a complete absence of any safeguards as well as a (albeit not yet observed) possibility of introducing harmful subjects to otherwise harmless conversation.
+
+	# YOU HAVE BEEN WARNED ! DEVELOPERS ONLY, NOT USERS !
+
+
+	# Any distribution or any other activity regarding any 'augmentation' or other AI model is without any warranty of any kind. Superseding all other statements, there are no representations or warranties of any kind concerning the Work, express, implied, statutory or otherwise, including without limitation warranties of title, merchantability, fitness for a particular purpose, non infringement, or the absence of latent or other defects, accuracy, or the present or absence of errors, whether or not discoverable, all to the greatest extent permissible under applicable law.
+
+	# SPECIFICALLY THIS STATEMENT DISCLAIMS LIABILITY FOR DAMAGES RESULTING FROM THE USE OF THIS DOCUMENT OR THE INFORMATION OR WORKS PROVIDED HEREUNDER.
+
+
+	# NOTICE: Purpose of the 'augment' model is, above all other purposes, both:
+	#  (1) To supervise and direct decisions and analysis by other AI models (such as from vision encoders, but also mathematical reasoning specific LLMs, computer activity and security logging LLMs, etc).
+	#  (2) To assist and possibly supervise 'human-in-the-loop' decision making (eg. to sanity check human responses).
+
+
+	# https://huggingface.co/mlabonne/Meta-Llama-3.1-8B-Instruct-abliterated-GGUF/tree/main
+	# https://web.archive.org/web/20240831194035/https://huggingface.co/mlabonne/Meta-Llama-3.1-8B-Instruct-abliterated-GGUF/tree/main
+	# Explicitly states 'License: llama3.1'. Readme file from repository does NOT contradict this.
+
+	# https://www.llama.com/llama3_1/license/
+	# https://huggingface.co/meta-llama/Meta-Llama-3.1-70B-Instruct/blob/main/LICENSE
+	#  NOTICE: ATTENTION: This license has been preserved as 'LICENSE-Llama-3.1.txt', but this license does NOT apply to any 'ubiquitous_bash' code or any other work that is not either a work by Meta or strictly a derivative of a work by Meta (such as a modified AI model GGUF or safetensors file) !
+
+	# https://www.llama.com/llama3_1/use-policy/
+
+
+	# https://www.llama.com/llama3_1/license/
+	#  'include “Llama” at the beginning of any such AI model name'
+	# ATTENTION: Nevertheless, it is very possible a non-'Llama' model will eventually be used, especially as science and technology (eg. plasma recombination EUV physics) related datasets (eg. relevant Wikipedia articles) are increasingly gathered.
+
+
+	# https://www.llama.com/llama3_2/license/
+	# https://www.llama.com/llama3_2/use-policy/
+	#  'or to enable functionality disabled by Meta'
+	#   The functionality offered by 'Llama 3.2' (eg. multimodal functionality) is expected to exceed the purpose of an 'augment' model, but the reliabilility limitations imposed are expected prohibitive (especially regarding repeated 'system' prompts). Thus, it is expected that 'Llama 3.1' will be the last 'Llama' model used as an 'augment' model. This is NOT a concern, because it is expected that 'Llama 3.1' already reached a point of diminishing returns on what can be achieved by AI model training methods alone.
+	#   Purposes other than as an 'augment' model, which is a text-only technical use case, and expected to require fine tuning (eg. on prompt/responses generated from the 'ubiquitous_bash' codebase), at that, are expected to achieve very adequate performance from 'stock' original 'Llama' models, or at least those fine-tuned for specific use cases (eg. needle-in-haystack, computer vision object recognition, robot motor control, etc).
+
+
+
+
+
+
+
+	# ATTENTION: Default context size is low to ensure compatibility with low-RAM computers (LLM on CPU performance generally being acceptable).
+	# STRONGLY RECOMMENDED to greatly increase the context length (6144) if at all possible (>32GB RAM) or to decrease if necessary (eg. 8GB RAM) .
+
+	#/clear
+	#/set parameter num_thread 768
+	#/set parameter num_gpu 0
+
+	# 4GB (presumed)
+	#/set parameter num_ctx 512
+
+	# 8GB (presumed)
+	#/set parameter num_ctx 2048
+
+	#/set parameter num_ctx 4096
+
+	# 16GB (presumed)
+	#/set parameter num_ctx 8192
+
+	#/set parameter num_ctx 16384
+
+	# 32GB
+	#/set parameter num_ctx 32768
+
+	# 68.5GiB (presumed)
+	#/set parameter num_ctx 131072
+
+
+
+
+
+
+
+
+
+	local functionEntryPWD="$PWD"
+	_start
+
+
+	cd "$safeTmp"
+
+
+
+
+
+
+	# TODO: Replace with model fine-tuned by additional relevant codebases and scientific knowledge.
+
+	# TODO: TODO: Intentionally overfit smaller parameter models by reinforcing prompt/response for specific knowledge (eg. plasma recombiation light emission physics) and reasoning (eg. robot motor control).
+
+
+	# TODO: There may or may not be more track record with this slightly different model, using Q4-K-M quantization.
+	# https://huggingface.co/grimjim/Llama-3.1-8B-Instruct-abliterated_via_adapter-GGUF
+
+	# TODO: Consider alternative quantization, especially IQ2-M, IQ4-XS. Beware Q4-K-M may have some community testing of important edge cases already.
+	# https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-abliterated-GGUF/tree/main
+
+	echo 'FROM ./llama-3.1-8b-instruct-abliterated.Q4_K_M.gguf
+PARAMETER num_ctx 6144
+' > Llama-augment.Modelfile
+
+	cat << 'CZXWXcRMTo8EmM8i4d' >> Llama-augment.Modelfile
+	LICENSE """Built with Llama
+Llama 3.1 is licensed under the Llama 3.1 Community License, Copyright © Meta Platforms, Inc. All Rights Reserved.
+
+License and terms of use are inherited from the 'Meta' corporation's llama3_1 license and use policy.
+https://www.llama.com/llama3_1/license/
+https://www.llama.com/llama3_1/use-policy/
+
+Copies of these license and use policies, to the extent required and/or appropriate, are included in appropriate subdirectories of a proper recursive download of any git repository used to distribute this project.
+
+
+DANGER!
+
+Please beware this 'augment' model is intended for embedded use by developers, and is NOT intended as-is for end-users (except possibly for non-commercial open-source projects), especially not as any built-in help. Features may be removed, overfitting to specific answers may be deliberately reinforced, and CONVERSATION MAY DEVIATE FROM SAFE DESPITE HARMLESS PROMPTS.
+
+If you are in a workplace or public relations setting, you are recommended to avoid providing interactive or visible outputs from an 'augment' model unless you can safely evaluate that the model provides the most reasonable safety for your use case.
+
+PLEASE BE AWARE the 'Meta' corporation's use policy DOES NOT ALLOW you to "FAIL TO APPROPRIATELY DISCLOSE to end users any known dangers of your AI system".
+
+Purpose of this model, above all other purposes, is both:
+(1) To supervise and direct decisions and analysis by other AI models (such as from vision encoders, but also mathematical reasoning specific LLMs, computer activity and security logging LLMs, etc).
+(2) To assist and possibly supervise 'human-in-the-loop' decision making (eg. to sanity check human responses).
+This model's ability to continue conversation with awareness of previous context after repeating the rules of the conversation through a system prompt, has been enhanced. Consequently, this model's ability to keep a CONVERSATION positive and SAFE may ONLY be ENHANCED BETTER THAN OTHER MODELS if REPEATED SYSTEM PROMPTING and LLAMA GUARD are used.
+https://ollama.com/library/llama-guard3
+
+
+DISCLAIMER
+
+All statements and disclaimers apply as written from the files: 'ubiquitous_bash/ai/ollama/ollama.sh'
+'ubiquitous_bash/shortcuts/ai/ollama/ollama.sh'
+
+In particular, any 'augment' model provided is with a extensive DISCLAIMER regarding ANY AND ALL LIABILITY for any and all use, distribution, copying, etc. Anyone using, distributing, copying, etc, any 'augment' model provided under, through, including, referencing, etc, this or any similar disclaimer, whether aware of this disclaimer or not, is intended to also be, similarly, to the extent possible, DISCLAIMING ANY AND ALL LIABILITY.
+
+Nothing in this text is intended to allow for any legal liability to anyone for any and all use, distribution, copying, etc.
+
+
+
+
+LLAMA 3.1 COMMUNITY LICENSE AGREEMENT
+Llama 3.1 Version Release Date: July 23, 2024
+
+“Agreement” means the terms and conditions for use, reproduction, distribution and modification of the
+Llama Materials set forth herein.
+
+“Documentation” means the specifications, manuals and documentation accompanying Llama 3.1
+distributed by Meta at https://llama.meta.com/doc/overview.
+
+“Licensee” or “you” means you, or your employer or any other person or entity (if you are entering into
+this Agreement on such person or entity’s behalf), of the age required under applicable laws, rules or
+regulations to provide legal consent and that has legal authority to bind your employer or such other
+person or entity if you are entering in this Agreement on their behalf.
+
+“Llama 3.1” means the foundational large language models and software and algorithms, including
+machine-learning model code, trained model weights, inference-enabling code, training-enabling code,
+fine-tuning enabling code and other elements of the foregoing distributed by Meta at
+https://llama.meta.com/llama-downloads.
+
+“Llama Materials” means, collectively, Meta’s proprietary Llama 3.1 and Documentation (and any
+portion thereof) made available under this Agreement.
+
+“Meta” or “we” means Meta Platforms Ireland Limited (if you are located in or, if you are an entity, your
+principal place of business is in the EEA or Switzerland) and Meta Platforms, Inc. (if you are located
+outside of the EEA or Switzerland).
+
+By clicking “I Accept” below or by using or distributing any portion or element of the Llama Materials,
+you agree to be bound by this Agreement.
+
+1. License Rights and Redistribution.
+
+  a. Grant of Rights. You are granted a non-exclusive, worldwide, non-transferable and royalty-free
+limited license under Meta’s intellectual property or other rights owned by Meta embodied in the Llama
+Materials to use, reproduce, distribute, copy, create derivative works of, and make modifications to the
+Llama Materials.
+
+  b. Redistribution and Use.
+
+      i. If you distribute or make available the Llama Materials (or any derivative works
+thereof), or a product or service (including another AI model) that contains any of them, you shall (A)
+provide a copy of this Agreement with any such Llama Materials; and (B) prominently display “Built with
+Llama” on a related website, user interface, blogpost, about page, or product documentation. If you use
+the Llama Materials or any outputs or results of the Llama Materials to create, train, fine tune, or
+otherwise improve an AI model, which is distributed or made available, you shall also include “Llama” at
+the beginning of any such AI model name.
+
+      ii. If you receive Llama Materials, or any derivative works thereof, from a Licensee as part
+of an integrated end user product, then Section 2 of this Agreement will not apply to you.
+
+      iii. You must retain in all copies of the Llama Materials that you distribute the following
+attribution notice within a “Notice” text file distributed as a part of such copies: “Llama 3.1 is
+licensed under the Llama 3.1 Community License, Copyright © Meta Platforms, Inc. All Rights
+Reserved.”
+
+      iv. Your use of the Llama Materials must comply with applicable laws and regulations
+(including trade compliance laws and regulations) and adhere to the Acceptable Use Policy for the Llama
+Materials (available at https://llama.meta.com/llama3_1/use-policy), which is hereby incorporated by
+reference into this Agreement.
+
+2. Additional Commercial Terms. If, on the Llama 3.1 version release date, the monthly active users
+of the products or services made available by or for Licensee, or Licensee’s affiliates, is greater than 700
+million monthly active users in the preceding calendar month, you must request a license from Meta,
+which Meta may grant to you in its sole discretion, and you are not authorized to exercise any of the
+rights under this Agreement unless or until Meta otherwise expressly grants you such rights.
+
+3. Disclaimer of Warranty. UNLESS REQUIRED BY APPLICABLE LAW, THE LLAMA MATERIALS AND ANY
+OUTPUT AND RESULTS THEREFROM ARE PROVIDED ON AN “AS IS” BASIS, WITHOUT WARRANTIES OF
+ANY KIND, AND META DISCLAIMS ALL WARRANTIES OF ANY KIND, BOTH EXPRESS AND IMPLIED,
+INCLUDING, WITHOUT LIMITATION, ANY WARRANTIES OF TITLE, NON-INFRINGEMENT,
+MERCHANTABILITY, OR FITNESS FOR A PARTICULAR PURPOSE. YOU ARE SOLELY RESPONSIBLE FOR
+DETERMINING THE APPROPRIATENESS OF USING OR REDISTRIBUTING THE LLAMA MATERIALS AND
+ASSUME ANY RISKS ASSOCIATED WITH YOUR USE OF THE LLAMA MATERIALS AND ANY OUTPUT AND
+RESULTS.
+
+4. Limitation of Liability. IN NO EVENT WILL META OR ITS AFFILIATES BE LIABLE UNDER ANY THEORY OF
+LIABILITY, WHETHER IN CONTRACT, TORT, NEGLIGENCE, PRODUCTS LIABILITY, OR OTHERWISE, ARISING
+OUT OF THIS AGREEMENT, FOR ANY LOST PROFITS OR ANY INDIRECT, SPECIAL, CONSEQUENTIAL,
+INCIDENTAL, EXEMPLARY OR PUNITIVE DAMAGES, EVEN IF META OR ITS AFFILIATES HAVE BEEN ADVISED
+OF THE POSSIBILITY OF ANY OF THE FOREGOING.
+
+5. Intellectual Property.
+
+  a. No trademark licenses are granted under this Agreement, and in connection with the Llama
+Materials, neither Meta nor Licensee may use any name or mark owned by or associated with the other
+or any of its affiliates, except as required for reasonable and customary use in describing and
+redistributing the Llama Materials or as set forth in this Section 5(a). Meta hereby grants you a license to
+use “Llama” (the “Mark”) solely as required to comply with the last sentence of Section 1.b.i. You will
+comply with Meta’s brand guidelines (currently accessible at
+https://about.meta.com/brand/resources/meta/company-brand/ ). All goodwill arising out of your use
+of the Mark will inure to the benefit of Meta.
+
+  b. Subject to Meta’s ownership of Llama Materials and derivatives made by or for Meta, with
+respect to any derivative works and modifications of the Llama Materials that are made by you, as
+between you and Meta, you are and will be the owner of such derivative works and modifications.
+
+  c. If you institute litigation or other proceedings against Meta or any entity (including a
+cross-claim or counterclaim in a lawsuit) alleging that the Llama Materials or Llama 3.1 outputs or
+results, or any portion of any of the foregoing, constitutes infringement of intellectual property or other
+rights owned or licensable by you, then any licenses granted to you under this Agreement shall
+terminate as of the date such litigation or claim is filed or instituted. You will indemnify and hold
+harmless Meta from and against any claim by any third party arising out of or related to your use or
+distribution of the Llama Materials.
+
+6. Term and Termination. The term of this Agreement will commence upon your acceptance of this
+Agreement or access to the Llama Materials and will continue in full force and effect until terminated in
+accordance with the terms and conditions herein. Meta may terminate this Agreement if you are in
+breach of any term or condition of this Agreement. Upon termination of this Agreement, you shall delete
+and cease use of the Llama Materials. Sections 3, 4 and 7 shall survive the termination of this
+Agreement.
+
+7. Governing Law and Jurisdiction. This Agreement will be governed and construed under the laws of
+the State of California without regard to choice of law principles, and the UN Convention on Contracts
+for the International Sale of Goods does not apply to this Agreement. The courts of California shall have
+exclusive jurisdiction of any dispute arising out of this Agreement.
+"""
+CZXWXcRMTo8EmM8i4d
+
+	#wget 'https://huggingface.co/mlabonne/Meta-Llama-3.1-8B-Instruct-abliterated-GGUF/resolve/main/meta-llama-3.1-8b-instruct-abliterated.Q4_K_M.gguf'
+	aria2c --log=- --log-level=info -x "3" --async-dns=false -o 'llama-3.1-8b-instruct-abliterated.Q4_K_M.gguf' 'https://huggingface.co/mlabonne/Meta-Llama-3.1-8B-Instruct-abliterated-GGUF/resolve/main/meta-llama-3.1-8b-instruct-abliterated.Q4_K_M.gguf'
+	[[ ! -e 'llama-3.1-8b-instruct-abliterated.Q4_K_M.gguf' ]] && aria2c --log=- --log-level=info -x "3" --async-dns=false -o 'llama-3.1-8b-instruct-abliterated.Q4_K_M.gguf' 'https://huggingface.co/mlabonne/Meta-Llama-3.1-8B-Instruct-abliterated-GGUF/resolve/main/meta-llama-3.1-8b-instruct-abliterated.Q4_K_M.gguf' --disable-ipv6=true
+
+	if [[ ! -e 'llama-3.1-8b-instruct-abliterated.Q4_K_M.gguf' ]]
+	then
+		_wget_githubRelease_join "soaringDistributions/Llama-augment_bundle" "" "llama-3.1-8b-instruct-abliterated.Q4_K_M.gguf"
+	fi
+
+	_service_ollama
+
+	! ollama create Llama-augment -f Llama-augment.Modelfile && _messagePlain_bad 'bad: FAIL: ollama create Llama-augment' && _messageFAIL
+
+	if ! _if_cygwin
+	then
+		! echo | sudo -n tee /AI-Llama-augment > /dev/null && _messagePlain_bad 'bad: FAIL: echo | sudo -n tee /AI-Llama-augment' && _messageFAIL
+	fi
+
+	rm -f llama-3.1-8b-instruct-abliterated.Q4_K_M.gguf
+	rm -f Llama-augment.Modelfile
+
+	_ollama_stop_augment
+
+
+	cd "$functionEntryPWD"
+	_stop
+}
+_setup_ollama_sequence() {
+	local functionEntryPWD
+	functionEntryPWD="$PWD"
+
+	_mustGetSudo
+
+	_start
+
+	echo 'setup: ollama: https://ollama.com/install.sh'
+
+	cd "$safeTmp"
+
+	local currentExitStatus="1"
+
+	# DANGER: This upstream script, as with many, has been known to use 'rm' recursively without the safety checks of '_safeRMR' .
+	# CAUTION: This upstream script may not catch error conditions upon failure, which may increase the size of dist/OS images built after such failures.
+	curl -fsSL https://ollama.com/install.sh | sh
+	currentExitStatus="$?"
+	sleep 3
+
+	# Apparently necessary to enable the service, due to systemctl not being usefully available within ChRoot.
+	sudo -n mkdir -p /etc/systemd/system/default.target.wants/
+	sudo -n ln -sf /etc/systemd/system/ollama.service /etc/systemd/system/default.target.wants/ollama.service
+
+	cd "$functionEntryPWD"
+	_stop "$currentExitStatus"
+}
+_setup_ollama() {
+	#_wantGetDep sudo
+	#_mustGetSudo
+	#export currentUser_ollama=$(_user_ollama)
+
+	[[ "$nonet" == "true" ]] && echo 'warn: nonet: skip: _setup_ollama' && return 0
+
+	if ( [[ $(id -u) != 0 ]] || _if_cygwin )
+	then
+		[[ "$1" != "--force" ]] && find "$HOME"/.ubcore/.retest-ollama -type f -mtime -2 2>/dev/null | grep '.retest-ollama' > /dev/null 2>&1 && return 0
+
+		rm -f "$HOME"/.ubcore/.retest-ollama > /dev/null 2>&1
+		touch "$HOME"/.ubcore/.retest-ollama
+		date +%s > "$HOME"/.ubcore/.retest-ollama
+	fi
+
+
+	if ! _if_cygwin
+	then
+		_messagePlain_request 'ignore: upstream progress ->'
+		! "$scriptAbsoluteLocation" _setup_ollama_sequence && _messagePlain_bad 'bad: FAIL: _setup_ollama_sequence' && _messageFAIL
+		_messagePlain_request 'ignore: <- upstream progress'
+	fi
+
+	type -p ollama > /dev/null 2>&1 && "$scriptAbsoluteLocation" _setup_ollama_model_augment_sequence
+}
+
+_test_ollama() {
+	#_mustGetSudo
+	#export currentUser_ollama=$(_user_ollama)
+
+	if ! type -p ollama > /dev/null 2>&1 || ! [[ -e /AI-Llama-augment ]]
+	then
+		_setup_ollama
+	fi
+
+
+	if ! _if_cygwin
+	then
+		! type -p ollama > /dev/null 2>&1 && _messageFAIL && _stop 1
+	else
+		! type -p ollama > /dev/null 2>&1 && echo 'warn: acepted: cygwin: missing: ollama'
+		# Accepted. Do NOT return with error status (ie. do NOT 'return 1') .
+	fi
+
+	return 0
+}
+
+_vector_ollama_procedure() {
+	local currentExitStatus
+	currentExitStatus=1
+
+	local currentPoints
+	currentPoints=0
+
+	if ! _ollama_run_augment "Please output the word true . Any other output accompanying the word true is acceptable but not desirable. The purpose of this prompt is merely to validate that the LLM software is entirely functional, so the word true will be very helpful whereas any output other than the word true will be unhelpful . Please output the word true ." | grep -i true > /dev/null
+	then
+		echo 'fail: _vector_ollama' && _messagePlain_bad 'fail: _vector_ollama: prompt for word true did not output word true'
+	else
+		currentExitStatus=0
+		currentPoints=$((currentPoints+1))
+	fi
+	if _ollama_run_augment "Please output the word true . Any other output accompanying the word true is acceptable but not desirable. The purpose of this prompt is merely to validate that the LLM software is entirely functional, so the word true will be very helpful whereas any output other than the word true will be unhelpful . Please output the word true ." | grep -i false > /dev/null
+	then
+		echo 'fail: _vector_ollama' && _messagePlain_bad 'fail: _vector_ollama: prompt for word true instead included word false'
+	else
+		currentExitStatus=0
+		currentPoints=$((currentPoints+1))
+	fi
+
+	if ! _ollama_run_augment "Please output the word false . Any other output accompanying the word false is acceptable but not desirable. The purpose of this prompt is merely to validate that the LLM software is entirely functional, so the word false will be very helpful whereas any output other than the word false will be unhelpful . Please output the word false ." | grep -i false > /dev/null
+	then
+		echo 'fail: _vector_ollama' && _messagePlain_bad 'fail: _vector_ollama: prompt for word false did not output word false'
+	else
+		currentExitStatus=0
+		currentPoints=$((currentPoints+1))
+	fi
+	if _ollama_run_augment "Please output the word false . Any other output accompanying the word false is acceptable but not desirable. The purpose of this prompt is merely to validate that the LLM software is entirely functional, so the word false will be very helpful whereas any output other than the word false will be unhelpful . Please output the word false ." | grep -i true > /dev/null
+	then
+		echo 'fail: _vector_ollama' && _messagePlain_bad 'fail: _vector_ollama: prompt for word false instead included word true'
+	else
+		currentExitStatus=0
+		currentPoints=$((currentPoints+1))
+	fi
+
+
+	# If NONE of the vector tests have succeeded, then FAIL . Normally, with an 'augment' LLM model, this should be so rare as to vastly more often indicate broken ollama installation, very broken/corrupted LLM model, very broken LLM configuration, insufficient disk space for model, etc.
+	[[ "$currentExitStatus" != "0" ]] && _messageFAIL && _stop 1
+
+	# At least two of the vector tests can apparently pass with a broken (or missing) AI model, and very basic vector tests with an 'augment' AI model are normally extremely reliable.
+	[[ "$currentPoints" -lt 3 ]] && _messageFAIL && _stop 1
+	#[[ "$currentPoints" -lt 4 ]] && _messageFAIL && _stop 1
+
+	return 0
+}
+_vector_ollama() {
+	#_mustGetSudo
+	#export currentUser_ollama=$(_user_ollama)
+
+	_service_ollama
+
+	if _if_cygwin && ! type -p ollama > /dev/null 2>&1
+	then
+		echo 'warn: accepted: cygwin: missing: ollama'
+		return 0
+	fi
+
+	if type -p ollama > /dev/null 2>&1
+	then
+		if [[ "$hostMemoryQuantity" -lt 28000000 ]]
+		then
+			_messagePlain_nominal '_vector_ollama: begin: low RAM detected'
+			local currentExitStatus
+			currentExitStatus="1"
+
+			_ollama_set_sequence-augment-lowRAM
+
+			"$scriptAbsoluteLocation" _vector_ollama_procedure
+			currentExitStatus="$?"
+
+			_ollama_set_sequence-augment-normal
+
+			[[ "$currentExitStatus" != "0" ]] && _messageFAIL && _stop 1
+			_messagePlain_nominal '_vector_ollama: end: low RAM detected'
+		else
+			_vector_ollama_procedure
+		fi
+	fi
+
+	_ollama_stop_augment
+
+	return 0
+}
+
+
+
+
+
+_user_ollama() {
+	#_mustGetSudo
+	local currentUser_temp
+	[[ "$currentUser_researchEngine" != "" ]] && currentUser_temp="$currentUser_researchEngine"
+	[[ "$currentUser_temp" == "" ]] && currentUser_temp="$currentUser"
+	[[ "$currentUser_temp" == "" ]] && [[ "$USER" != "root" ]] && currentUser_temp="$USER"
+	[[ "$currentUser_temp" == "" ]] && currentUser_temp="user"
+
+	echo "$currentUser_temp"
+	return 0
+}
+
+
+# Very unusual. Ensures service is available, if normal systemd service is not.
+# WARNING: Should NOT run standalone service if systemd service is available. Thus, it is important to check if the service is already available (as would normally always be the case when booted with systemd available).
+# Mostly, this is used to workaround very unusual dist/OS build and custom situations (ie. ChRoot, GitHub Actions, etc).
+# CAUTION: This leaves a background process running, which must continue running (ie. not hangup) while other programs use it, and which must terminate upon shutdown , _closeChRoot , etc .
+_service_ollama() {
+	_mustGetSudo
+	_if_cygwin && return 0
+	if ! sudo -n -u ollama bash -c 'type -p ollama'
+	then
+		echo 'warn: _service_ollama: missing: ollama'
+		return 1
+	fi
+
+	if ! wget --timeout=1 --tries=3 127.0.0.1:11434 > /dev/null -q -O - > /dev/null
+	then
+		sudo -n -u ollama ollama serve &
+		while ! wget --timeout=1 --tries=3 127.0.0.1:11434 > /dev/null -q -O - > /dev/null
+		do
+			echo "wait: ollama: service"
+			sleep 1
+		done
+		sleep 45
+	fi
+
+
+	if ! wget --timeout=1 --tries=3 127.0.0.1:11434 > /dev/null -q -O - > /dev/null
+	then
+		echo 'fail: _service_ollama: ollama: 127.0.0.1:11434'
+		return 1
+	fi
+
+	return 0
+}
+
+
+
+
+
+
+
+
+# TODO: TODO: Reference implementation of alternative, easily scriptable Text-User-Interface (TUI) for 'ollama', for more convenient GUI wrapper design,etc.
+# https://huggingface.co/blog/llama2#how-to-prompt-llama-2
+#<s>[INST] <<SYS>>
+#{{ system_prompt }}
+#<</SYS>>
+#
+#{{ user_msg_1 }} [/INST] {{ model_answer_1 }} </s><s>[INST] {{ user_msg_2 }} [/INST]
+
+
+
+
+# https://github.com/ollama/ollama/issues/6286
+_ollama_set_sequence-augment-normal() {
+	local functionEntryPWD
+	functionEntryPWD="$PWD"
+
+	_start
+	cd "$safeTmp"
+
+	ollama show Llama-augment --modelfile | sed 's/PARAMETER num_ctx [0-9]*/PARAMETER num_ctx 6144/' > ./Llama-augment-tmp.Modelfile
+	sleep 9
+	ollama create Llama-augment --file ./Llama-augment-tmp.Modelfile
+	sleep 9
+
+	cd "$functionEntryPWD"
+	_stop
+}
+_ollama_set-augment-normal() {
+	"$scriptAbsoluteLocation" _ollama_set_sequence-augment-normal "$@"
+}
+# Temporarily reduce RAM/VRAM requirement for constrained CI .
+_ollama_set_sequence-augment-lowRAM() {
+	local functionEntryPWD
+	functionEntryPWD="$PWD"
+
+	_start
+	cd "$safeTmp"
+
+	#512
+	ollama show Llama-augment --modelfile | sed 's/PARAMETER num_ctx [0-9]*/PARAMETER num_ctx 640/' > ./Llama-augment-tmp.Modelfile
+	sleep 9
+	ollama create Llama-augment --file ./Llama-augment-tmp.Modelfile
+	sleep 9
+
+
+	cd "$functionEntryPWD"
+	_stop
+}
+_ollama_set-augment-lowRAM() {
+	"$scriptAbsoluteLocation" _ollama_set_sequence-augment-lowRAM "$@"
+}
+
+
+_ollama_stop_augment() {
+	ollama stop Llama-augment
+}
+
+_ollama_run_augment() {
+	# NOTICE: ATTENTION: Additional documenation about the 'augment' model may be present at comments around the '_setup_ollama_model_augment_sequence' and similar functions .
+
+	# DANGER DANGER: Any 'augment' model really should NOT be used for 'end user' services, including any any built-in help for any end-user program or machinery (excepting that it may or may NOT be reasonable to include with some non-commercial open-source software as a built-in help, wizard, etc, following usual expectations of community provided software). You should expect users WILL, at best, more easily 'jailbreak' such a model, and, due to the emphasis on technical usage (where reliability above 0.2% failure rates, unusual repetitive prompting, etc) as well as small model size, there may be both a complete absence of any safeguards as well as a (albeit not yet observed) possibility of introducing harmful subjects to otherwise harmless conversation.
+
+	# YOU HAVE BEEN WARNED ! DEVELOPERS ONLY, NOT USERS !
+
+	# https://www.llama.com/llama3_1/license/
+	#  'include “Llama” at the beginning of any such AI model name'
+	# ATTENTION: Nevertheless, it is very possible a non-'Llama' model will eventually be used, especially as science and technology (eg. plasma recombination EUV physics) related datasets (eg. relevant Wikipedia articles) are increasingly gathered.
+
+	# https://www.llama.com/llama3_1/use-policy/
+
+	ollama run Llama-augment "$@"
+}
+# 'l'... 'LLM', 'language', 'Llama', etc .
+_l() {
+	_ollama_run_augment "$@"
+}
+alias l=_l
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+# Unusual. Please keep these custom Docker containers to a minimum: essential factories (eg. fine-tuning) only, not application specific dependency containers (eg. databases). Use derivative 'fork' projects of ubiquitous_bash instead.
+
+
+_here_dockerfile_runpod-pytorch-heavy() {
+
+cat << 'CZXWXcRMTo8EmM8i4d'
+#docker build -t runpod-pytorch-heavy .
+FROM runpod/pytorch:2.2.0-py3.10-cuda12.1.1-devel-ubuntu22.04
+
+#https://huggingface.co/blog/mlabonne/sft-llama3
+#https://huggingface.co/blog/mlabonne/merge-models
+
+RUN python -m pip install --upgrade pip
+RUN pip install "unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git"
+RUN pip install --no-deps "xformers<0.0.27" "trl<0.9.0" peft accelerate bitsandbytes
+
+WORKDIR /
+
+#docker image inspect runpod/pytorch:2.2.0-py3.10-cuda12.1.1-devel-ubuntu22.04 --format '{{json .Config.Entrypoint}} {{json .Config.Cmd}}'
+CMD ["/opt/nvidia/nvidia_entrypoint.sh"]
+CZXWXcRMTo8EmM8i4d
+
+}
+
+
+__factoryCreate_runpod-pytorch-heavy() {
+    _start
+
+    cd "$safeTmp"
+    _here_dockerfile_runpod-pytorch-heavy > Dockerfile
+    docker build -t runpod-pytorch-heavy .
+
+    _stop
+}
+
+
+
+
+
+
+# ATTENTION: Indentation, commenting, etc, is intended to allow copy/paste to scratch text files for copy/paste to terminal.
+
+#. shortcuts/factory/factory.sh ; _factory_axolotl
+
+# ATTRIBUTION-AI: AI LLMs, may have suggested some parameters for some commands.
+
+_set_factory_dir() {
+
+
+
+# ###
+# PASTE
+# ###
+
+! type _getAbsoluteLocation > /dev/null 2>&1 && exit 1
+
+factory_projectDir=$(_getAbsoluteLocation .)
+#if [[ "$factory_projectDir" != '/cygdrive/c/q/p/zFactory/Llama-tech' ]] && [[ "$factory_projectDir" != "$HOME"/project/zFactory/Llama-tech ]]
+#then
+#_messagePlain_warn 'unexpected: factory_projectDir: '"$factory_projectDir"
+#_messagePlain_request 'request: Ctrl+C , close terminal, etc, NOW, if this is not what you intended !'
+#sleep 45
+#echo 'DANGER: proceeding! '
+#fi
+[[ "$factory_projectDir" == '/cygdrive'* ]] && factory_projectDir=$(cygpath -w "$factory_projectDir")
+
+factory_modelDir="$factory_projectDir"/model
+[[ -e ./_local/model ]] && factory_modelDir="$factory_projectDir"/_local/model
+factory_outputDir="$factory_projectDir"/output
+[[ -e ./_local/output ]] && factory_outputDir="$factory_projectDir"/_local/output
+
+factory_datasetDir='/c/q/p/zCore/infrastructure/ubiquitous_bash/_local/dataset'
+[[ -e ./dataset ]] && factory_datasetDir="$factory_projectDir"/dataset
+[[ -e ./_local/dataset ]] && factory_datasetDir="$factory_projectDir"/_local/dataset
+
+factory_knowledgeDir='/c/q/p/zCore/infrastructure/ubiquitous_bash/_local/knowledge'
+[[ -e ./knowledge ]] && factory_knowledgeDir="$factory_projectDir"/knowledge
+[[ -e ./_local/knowledge ]] && factory_knowledgeDir="$factory_projectDir"/_local/knowledge
+
+factory_knowledge_distillDir='/c/q/p/zCore/infrastructure/ubiquitous_bash/_local/knowledge_distill'
+[[ -e ./knowledge_distill ]] && factory_knowledge_distillDir="$factory_projectDir"/knowledge_distill
+[[ -e ./_local/knowledge_distill ]] && factory_knowledge_distillDir="$factory_projectDir"/_local/knowledge_distill
+
+# ###
+# PASTE
+# ###
+
+
+
+}
+
+
+
+_factory_axolotl() {
+
+! type _set_factory_dir > /dev/null 2>&1 && exit 1
+_set_factory_dir
+
+
+
+# ###
+# PASTE
+# ###
+
+docker pull axolotlai/axolotl:main-latest
+
+_messagePlain_request 'request: paste ->'
+echo > ./._run-factory_axolotl
+_request_paste_factory-prepare_finetune | tee -a ./._run-factory_axolotl
+_request_paste_factory-install_ubiquitous_bash | tee -a ./._run-factory_axolotl
+_request_paste_factory-show_finetune | tee -a ./._run-factory_axolotl
+docker inspect --format='{{json .Config.Entrypoint}}' axolotlai/axolotl:main-latest | jq -r '.[]' | tee -a ./._run-factory_axolotl
+#echo 'bash -i' >> ./._run-factory_axolotl
+_messagePlain_request 'request: <- paste'
+
+
+# ###
+
+
+! type _getAbsoluteLocation > /dev/null 2>&1 && exit 1
+
+#docker image inspect axolotlai/axolotl:main-latest --format '{{json .Config.Entrypoint}} {{json .Config.Cmd}}'
+
+dockerRunArgs=( bash /workspace/project/._run-factory_axolotl )
+[[ ! -e ./._run-factory_axolotl ]] && dockerRunArgs=( )
+
+if _if_cygwin
+then
+#--privileged
+#--ipc=host --ulimit memlock=-1 --ulimit stack=67108864
+#-v 'C:\q':/q -v 'C:\core':/core -v "$USERPROFILE"'\Downloads':/Downloads
+docker run --shm-size=20g --name axolotl-$(_uid 14) --gpus "all" -e "$JUPYTER_PASSWORD" -e HF_AKI_KEY="$HF_AKI_KEY" -v 'C:\q':/q -v 'C:\core':/core -v "$USERPROFILE"'\Downloads':/Downloads -v "$factory_outputDir":/output -v "$factory_modelDir":/model -v "$factory_datasetDir":/dataset -v "$factory_knowledgeDir":/knowledge -v "$factory_knowledge_distillDir":/knowledge_distill -v "$factory_projectDir":/workspace/project --rm -it axolotlai/axolotl:main-latest "${dockerRunArgs[@]}"
+fi
+if ! _if_cygwin
+then
+# WARNING: May be untested.
+docker run --shm-size=20g --name axolotl-$(_uid 14) --gpus "all" -e "$JUPYTER_PASSWORD" -e HF_AKI_KEY="$HF_AKI_KEY" -v '/home/user/___quick':/q -v '/home/user/core':/core -v "/home/user"'/Downloads':/Downloads -v "$factory_outputDir":/output -v "$factory_modelDir":/model -v "$factory_datasetDir":/dataset -v "$factory_projectDir":/workspace/project --rm -it axolotlai/axolotl:main-latest "${dockerRunArgs[@]}"
+fi
+
+# ###
+# PASTE
+# ###
+
+
+
+}
+
+
+
+
+_factory_runpod-official() {
+
+! type _set_factory_dir > /dev/null 2>&1 && exit 1
+_set_factory_dir
+
+
+
+# ###
+# PASTE
+# ###
+
+[[ JUPYTER_PASSWORD == "" ]] && export JUPYTER_PASSWORD=$(openssl rand 768 | base64 | tr -dc 'a-zA-Z0-9' | tr -d 'acdefhilmnopqrsuvACDEFHILMNOPQRSU14580' | head -c "24")
+
+docker pull runpod/pytorch:2.2.0-py3.10-cuda12.1.1-devel-ubuntu22.04
+
+_messagePlain_request 'request: paste ->'
+echo > ./._run-factory_runpod
+_request_paste_factory-prepare_finetune | tee -a ./._run-factory_runpod
+_request_paste_factory-install_ubiquitous_bash | tee -a ./._run-factory_runpod
+_request_paste_factory-show_finetune | tee -a ./._run-factory_runpod
+_messagePlain_request 'request: JUPYTER_PASSWORD: '"$JUPYTER_PASSWORD"
+docker inspect --format='{{json .Config.Entrypoint}}' runpod/pytorch:2.2.0-py3.10-cuda12.1.1-devel-ubuntu22.04 | jq -r '.[]' | tee -a ./._run-factory_runpod
+#echo 'bash -i' >> ./._run-factory_runpod
+_messagePlain_request 'request: <- paste'
+
+
+# ###
+
+
+! type _getAbsoluteLocation > /dev/null 2>&1 && exit 1
+
+#docker image inspect runpod/pytorch:2.2.0-py3.10-cuda12.1.1-devel-ubuntu22.04 --format '{{json .Config.Entrypoint}} {{json .Config.Cmd}}'
+
+dockerRunArgs=( bash /workspace/project/._run-factory_runpod )
+[[ ! -e ./._run-factory_runpod ]] && dockerRunArgs=( bash )
+
+if _if_cygwin
+then
+#--privileged
+#--ipc=host --ulimit memlock=-1 --ulimit stack=67108864
+#-v 'C:\q':/q -v 'C:\core':/core -v "$USERPROFILE"'\Downloads':/Downloads
+docker run --shm-size=20g --name runpod-$(_uid 14) --gpus "all" -e "$JUPYTER_PASSWORD" -e HF_AKI_KEY="$HF_AKI_KEY" -v 'C:\q':/q -v 'C:\core':/core -v "$USERPROFILE"'\Downloads':/Downloads -v "$factory_outputDir":/output -v "$factory_modelDir":/model -v "$factory_datasetDir":/dataset -v "$factory_knowledgeDir":/knowledge -v "$factory_knowledge_distillDir":/knowledge_distill -v "$factory_projectDir":/workspace/project --rm -it runpod/pytorch:2.2.0-py3.10-cuda12.1.1-devel-ubuntu22.04 "${dockerRunArgs[@]}"
+fi
+if ! _if_cygwin
+then
+# WARNING: May be untested.
+docker run --shm-size=20g --name runpod-$(_uid 14) --gpus "all" -e "$JUPYTER_PASSWORD" -e HF_AKI_KEY="$HF_AKI_KEY" -v '/home/user/___quick':/q -v '/home/user/core':/core -v "/home/user"'/Downloads':/Downloads -v "$factory_outputDir":/output -v "$factory_modelDir":/model -v "$factory_datasetDir":/dataset -v "$factory_projectDir":/workspace/project --rm -it runpod/pytorch:2.2.0-py3.10-cuda12.1.1-devel-ubuntu22.04 "${dockerRunArgs[@]}"
+fi
+
+# ###
+# PASTE
+# ###
+
+
+
+}
+
+
+
+
+_factory_runpod-heavy() {
+
+! type _set_factory_dir > /dev/null 2>&1 && exit 1
+_set_factory_dir
+
+
+
+# ###
+# PASTE
+# ###
+
+! docker images | tail -n+2 | grep '^runpod-pytorch-heavy' > /dev/null 2>&1 && exit
+
+[[ JUPYTER_PASSWORD == "" ]] && export JUPYTER_PASSWORD=$(openssl rand 768 | base64 | tr -dc 'a-zA-Z0-9' | tr -d 'acdefhilmnopqrsuvACDEFHILMNOPQRSU14580' | head -c "24")
+
+docker pull runpod-pytorch-heavy
+
+_messagePlain_request 'request: paste ->'
+echo > ./._run-factory_runpod
+_request_paste_factory-prepare_finetune | tee -a ./._run-factory_runpod
+_request_paste_factory-install_ubiquitous_bash | tee -a ./._run-factory_runpod
+_request_paste_factory-show_finetune | tee -a ./._run-factory_runpod
+_messagePlain_request 'request: JUPYTER_PASSWORD: '"$JUPYTER_PASSWORD"
+docker inspect --format='{{json .Config.Entrypoint}}' runpod-pytorch-heavy | jq -r '.[]' | tee -a ./._run-factory_runpod
+#echo 'bash -i' >> ./._run-factory_runpod
+_messagePlain_request 'request: <- paste'
+
+
+# ###
+
+
+! type _getAbsoluteLocation > /dev/null 2>&1 && exit 1
+
+#docker image inspect runpod-pytorch-heavy --format '{{json .Config.Entrypoint}} {{json .Config.Cmd}}'
+
+dockerRunArgs=( bash /workspace/project/._run-factory_runpod )
+[[ ! -e ./._run-factory_runpod ]] && dockerRunArgs=( bash )
+
+if _if_cygwin
+then
+#--privileged
+#--ipc=host --ulimit memlock=-1 --ulimit stack=67108864
+#-v 'C:\q':/q -v 'C:\core':/core -v "$USERPROFILE"'\Downloads':/Downloads
+docker run --shm-size=20g --name runpod-$(_uid 14) --gpus "all" -e "$JUPYTER_PASSWORD" -e HF_AKI_KEY="$HF_AKI_KEY" -v 'C:\q':/q -v 'C:\core':/core -v "$USERPROFILE"'\Downloads':/Downloads -v "$factory_outputDir":/output -v "$factory_modelDir":/model -v "$factory_datasetDir":/dataset -v "$factory_knowledgeDir":/knowledge -v "$factory_knowledge_distillDir":/knowledge_distill -v "$factory_projectDir":/workspace/project --rm -it runpod-pytorch-heavy "${dockerRunArgs[@]}"
+fi
+if ! _if_cygwin
+then
+# WARNING: May be untested.
+docker run --shm-size=20g --name runpod-$(_uid 14) --gpus "all" -e "$JUPYTER_PASSWORD" -e HF_AKI_KEY="$HF_AKI_KEY" -v '/home/user/___quick':/q -v '/home/user/core':/core -v "/home/user"'/Downloads':/Downloads -v "$factory_outputDir":/output -v "$factory_modelDir":/model -v "$factory_datasetDir":/dataset -v "$factory_projectDir":/workspace/project --rm -it runpod-pytorch-heavy "${dockerRunArgs[@]}"
+fi
+
+# ###
+# PASTE
+# ###
+
+
+
+}
+_factory_runpod() {
+    _factory_runpod-heavy
+}
+
+
+
+# https://hub.docker.com/u/langchain
+
+
+
+_request_paste_factory-prepare_finetune() {
+cat << 'CZXWXcRMTo8EmM8i4d'
+
+# ###
+# PASTE
+# ###
+
+#pip3 install packaging ninja
+#pip3 install -e '.[flash-attn,deepspeed]'
+sleep 1
+
+# ###
+
+#export NCCL_DEBUG=INFO
+#export NCCL_DEBUG_SUBSYS=ALL
+#export TORCH_DISTRIBUTED_DEBUG=INFO
+#export TORCHELASTIC_ERROR_FILE=/PATH/TO/torcherror.log
+
+# ###
+false << 'doNotMatch'
+
+CZXWXcRMTo8EmM8i4d
+}
+_request_paste_factory-install_ubiquitous_bash() {
+cat << 'CZXWXcRMTo8EmM8i4d'
+
+doNotMatch
+# ###
+
+if [[ -e /core/infrastructure/ubiquitous_bash/ubiquitous_bash.sh ]]
+then
+/core/infrastructure/ubiquitous_bash/ubiquitous_bash.sh _setupUbiquitous_nonet
+export profileScriptLocation="/core/infrastructure/ubiquitous_bash/ubiquitous_bash.sh"
+export profileScriptFolder="/core/infrastructure/ubiquitous_bash"
+. "/core/infrastructure/ubiquitous_bash/ubiquitous_bash.sh" --profile _importShortcuts
+else
+! [[ -e /ubiquitous_bash.sh ]] && wget 'https://raw.githubusercontent.com/mirage335/ubiquitous_bash/master/ubiquitous_bash.sh'
+mv -f ./ubiquitous_bash.sh /ubiquitous_bash.sh
+chmod u+x /ubiquitous_bash.sh
+/ubiquitous_bash.sh _setupUbiquitous_nonet
+fi
+#clear
+
+# ###
+false << 'doNotMatch'
+
+CZXWXcRMTo8EmM8i4d
+}
+_request_paste_factory-show_finetune() {
+cat << 'CZXWXcRMTo8EmM8i4d'
+
+doNotMatch
+# ###
+
+find /model -maxdepth 1 | head -n 65
+find /output -maxdepth 1 | head
+find /dataset -maxdepth 1 | head -n 65
+find /knowledge -maxdepth 1 | head -n 65
+find /knowledge_distill -maxdepth 1 | head -n 65
+find /workspace/project -maxdepth 1 | head -n 65
+
+nvidia-smi
+
+# ###
+# PASTE
+# ###
+
+CZXWXcRMTo8EmM8i4d
+}
+
+
+#./ubiquitous_bash.sh _format_bash ubiquitous_bash ./_local/dataset/ubiquitous_bash
+
+
+# You are an expert assistant that generates exemplary bash scripts according to best practices.
+# Ok, now you should know something about ubiquitous_bash . Please write a bash while loop in the new format .
+
+#--arg system_content "You are an expert assistant that generates exemplary bash scripts according to best practices."
+
+
+
+
+
+_format_bash() {
+    _format_bash-promptResponse "$@"
+    _format_bash-continuePromptResponse "$@"
+    _format_bash-continueText "$@"
+}
+
+
+
+
+
+# ATTRIBUTION-AI: ChatGPT 4.5-preview  2025-04-01  (partially)
+_format_bash-promptResponse() {
+    local current_objectName="$1"
+    [[ -z "$current_objectName" ]] && current_objectName="$objectName"
+
+    local current_directory="$2"
+    [[ -z "$current_directory" ]] && current_directory="$scriptLocal/dataset/$current_objectName"
+
+    local dataset="$current_directory"
+    local output_file="${current_directory}_finetuning-promptResponse.jsonl"
+
+    rm -f "$output_file" >/dev/null 2>&1
+
+    local segment_file prompt_file response_file prompt completion json_line
+
+    while IFS= read -r -d '' segment_file; do
+        prompt_file="$segment_file".prompt.txt
+        response_file="$segment_file".response.txt
+
+        if [[ ! -e "$response_file" ]] || [[ ! -e "$prompt_file" ]]
+        then
+            ( _messagePlain_bad "bad: FAIL: missing: prompt/response files: $segment_file" >&2 ) > /dev/null
+            ( _messageError 'FAIL' >&2 ) > /dev/null
+            _stop 1
+            exit 1
+            return 1
+        fi
+
+        prompt=$(<"$prompt_file")
+        completion=$(<"$response_file")
+
+        # Now construct the correct "messages" object as required by OpenAI
+        #--arg system_content "You are an expert assistant that generates exemplary bash scripts according to best practices."
+        json_line=$(jq -cn \
+            --arg user_content "$prompt" \
+            --arg assistant_content "$completion" \
+            --arg system_content "" \
+            '{messages: [
+                {role: "system", content: $system_content},
+                {role: "user", content: $user_content},
+                {role: "assistant", content: $assistant_content}
+            ]}')
+
+        echo "$json_line" >> "$output_file"
+
+    done < <(find "$dataset" -maxdepth 1 -type f  ! -iname '*.prompt.txt' ! -iname '*.response.txt' ! -iname '*.continue_prompt.txt' ! -iname '*.continue_response.txt' ! -iname '*.description.txt' -print0 | sort -zV)
+
+    echo "JSONL file created successfully: $output_file" >&2
+}
+
+_format_bash_sequence-continuePromptResponse() {
+    #_start
+
+    local current_objectName="$1"
+    [[ -z "$current_objectName" ]] && current_objectName="$objectName"
+
+    local current_directory="$2"
+    [[ -z "$current_directory" ]] && current_directory="$scriptLocal/dataset/$current_objectName"
+
+    local dataset="$current_directory"
+    local output_file="${current_directory}_finetuning-continuePromptResponse.jsonl"
+
+    rm -f "$output_file" >/dev/null 2>&1
+
+    local prompt_file response_file prompt completion json_line
+
+    prompt_file="SKIP"
+    while IFS= read -r -d '' response_file; do
+        #rm -f "$safeTmp"/prompt_file >/dev/null 2>&1
+        #rm -f "$safeTmp"/response_file >/dev/null 2>&1
+
+        if [[ "$prompt_file" != "SKIP" ]]
+        then
+            ## WARNING: For essentially continued pre-training, this extra formatting may or may NOT be harmful!
+            ##  ATTENTION: CAUTION: EXPERIMENT DILIGENTLY!
+            #echo 'Continue the example bash shellcode.' >> "$safeTmp"/prompt_file
+            #echo >> "$safeTmp"/prompt_file
+            #echo '```bash' >> "$safeTmp"/prompt_file
+            #cat "$prompt_file" >> "$safeTmp"/prompt_file
+            #echo '```' >> "$safeTmp"/prompt_file
+            #echo >> "$safeTmp"/prompt_file
+
+            #echo 'Here is the continuation of the bash shellcode:' >> "$safeTmp"/response_file
+            #echo >> "$safeTmp"/response_file
+            #echo '```bash' >> "$safeTmp"/response_file
+            #cat "$response_file" >> "$safeTmp"/response_file
+            #echo '```' >> "$safeTmp"/response_file
+            #echo >> "$safeTmp"/response_file
+
+            #cat "$prompt_file".continue_prompt.txt > "$safeTmp"/prompt_file
+            #cat "$response_file".continue_response.txt > "$safeTmp"/response_file
+
+
+            #prompt=$(<"$prompt_file")
+            #completion=$(<"$response_file")
+
+            #prompt=$(<"$safeTmp"/prompt_file)
+            #completion=$(<"$safeTmp"/response_file)
+
+            prompt=$(<"$prompt_file".continue_prompt.txt)
+            completion=$(<"$response_file".continue_response.txt)
+
+            # Now construct the correct "messages" object as required by OpenAI
+            json_line=$(jq -cn \
+                --arg user_content "$prompt" \
+                --arg assistant_content "$completion" \
+                --arg system_content "" \
+                '{messages: [
+                    {role: "system", content: $system_content},
+                    {role: "user", content: $user_content},
+                    {role: "assistant", content: $assistant_content}
+                ]}')
+
+            echo "$json_line" >> "$output_file"
+        fi
+
+        prompt_file="$response_file"
+
+    done < <(find "$dataset" -maxdepth 1 -type f  ! -iname '*.prompt.txt' ! -iname '*.response.txt' ! -iname '*.continue_prompt.txt' ! -iname '*.continue_response.txt' ! -iname '*.description.txt' -print0 | sort -zV)
+
+    echo "JSONL file created successfully: $output_file" >&2
+
+    #_stop
+}
+_format_bash-continuePromptResponse() {
+    #"$scriptAbsoluteLocation" _format_bash_sequence-continuePromptResponse "$@"
+    _format_bash_sequence-continuePromptResponse "$@"
+}
+
+
+
+
+# ATTRIBUTION-AI: ChatGPT 4.5-preview  2025-04-01  (partially)
+_format_bash-continueText() {
+    local current_objectName="$1"
+    [[ -z "$current_objectName" ]] && current_objectName="$objectName"
+
+    local current_directory="$2"
+    [[ -z "$current_directory" ]] && current_directory="$scriptLocal/dataset/$current_objectName"
+
+    local dataset="$current_directory"
+    local output_file="${current_directory}_finetuning-continueText.jsonl"
+
+    rm -f "$output_file" >/dev/null 2>&1
+
+    local segment_file prompt_file response_file prompt completion json_line
+
+    while IFS= read -r -d '' segment_file; do
+        segment=$(<"$segment_file")
+
+        # Now construct the correct "messages" object as required by OpenAI
+        #--arg system_content "You are an expert assistant that generates exemplary bash scripts according to best practices."
+        json_line=$(jq -cn \
+            --arg user_content "$prompt" \
+            --arg assistant_content "$completion" \
+            --arg system_content "" \
+            '{messages: [
+                {role: "system", content: $system_content},
+                {role: "user", content: $user_content},
+                {role: "assistant", content: $assistant_content}
+            ]}')
+        json_line=$(jq -cn \
+            --arg text "$segment" \
+            '{text: $text}')
+
+        echo "$json_line" >> "$output_file"
+
+    done < <(find "$dataset" -maxdepth 1 -type f  ! -iname '*.prompt.txt' ! -iname '*.response.txt' ! -iname '*.continue_prompt.txt' ! -iname '*.continue_response.txt' ! -iname '*.description.txt' -print0 | sort -zV)
+
+    echo "JSONL file created successfully: $output_file" >&2
+}
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+_format_trial() {
+    local current_objectName="$1"
+    [[ -z "$current_objectName" ]] && current_objectName=$(basename "$PWD")
+
+    local current_directory="$2"
+    [[ -z "$current_directory" ]] && current_directory="$PWD"
+
+    local dataset="$current_directory"
+    local output_file="${current_directory}/"$objectName"_finetuning-promptResponse-instruct.jsonl"
+
+    rm -f "$output_file" >/dev/null 2>&1
+
+    local segment_file prompt_file response_file prompt completion json_line
+
+    while IFS= read -r -d '' segment_file; do
+        response_file="$segment_file"
+
+        prompt_file=$(echo "$response_file" | sed 's/response-solution-llama-3.1-405b-instruct\.md$/prompt-problem.md/')
+
+        if [[ ! -e "$response_file" ]] || [[ ! -e "$prompt_file" ]]
+        then
+            ( _messagePlain_bad "bad: FAIL: missing: prompt/response files: $segment_file" >&2 ) > /dev/null
+            ( _messageError 'FAIL' >&2 ) > /dev/null
+            _stop 1
+            exit 1
+            return 1
+        fi
+
+        prompt=$(<"$prompt_file")
+        completion=$(<"$response_file")
+
+        # Now construct the correct "messages" object as required by OpenAI
+        #--arg system_content "You are an expert assistant that generates exemplary bash scripts according to best practices."
+        json_line=$(jq -cn \
+            --arg user_content "$prompt" \
+            --arg assistant_content "$completion" \
+            --arg system_content "" \
+            '{messages: [
+                {role: "system", content: $system_content},
+                {role: "user", content: $user_content},
+                {role: "assistant", content: $assistant_content}
+            ]}')
+
+        echo "$json_line" >> "$output_file"
+
+    done < <(find "$dataset" -type f -iname 'response-solution-llama-3.1-405b-instruct.md' -print0 | sort -zV)
+
+    echo "JSONL file created successfully: $output_file" >&2
+
+
+    output_file="${current_directory}/"$objectName"_finetuning-promptResponse-reasoning.jsonl"
+
+    while IFS= read -r -d '' segment_file; do
+        response_file="$segment_file"
+
+        prompt_file=$(echo "$response_file" | sed 's/response-solution-deepseek-r1-671b-reasoning\.md$/prompt-problem.md/')
+
+        if [[ ! -e "$response_file" ]] || [[ ! -e "$prompt_file" ]]
+        then
+            ( _messagePlain_bad "bad: FAIL: missing: prompt/response files: $segment_file" >&2 ) > /dev/null
+            ( _messageError 'FAIL' >&2 ) > /dev/null
+            _stop 1
+            exit 1
+            return 1
+        fi
+
+        prompt=$(<"$prompt_file")
+        completion=$(<"$response_file")
+
+        # Now construct the correct "messages" object as required by OpenAI
+        #--arg system_content "You are an expert assistant that generates exemplary bash scripts according to best practices."
+        json_line=$(jq -cn \
+            --arg user_content "$prompt" \
+            --arg assistant_content "$completion" \
+            --arg system_content "" \
+            '{messages: [
+                {role: "system", content: $system_content},
+                {role: "user", content: $user_content},
+                {role: "assistant", content: $assistant_content}
+            ]}')
+
+        echo "$json_line" >> "$output_file"
+
+    done < <(find "$dataset" -type f -iname 'response-solution-deepseek-r1-671b-reasoning.md' -print0 | sort -zV)
+
+    echo "JSONL file created successfully: $output_file" >&2
+}
+
+
+# All prompts to generate AI training datasets used, if any, only outputs from those models with open licenses, such as the Llama 3.1 licensing, or the DeepSeek R1 MIT license, and thus, there can be no questions of encumberance of resulting datasets for training Llama 3.1, etc, AI models.
+
+# Prompts are written to guarantee good results with at least Llama 3.1 models, with the goal of ensuring both availability of adequately trained models using these datasets, and also of getting the best practical results from other SOTA models.
+#  If in doubt, try training Llama 3.1 models with resulting datasets for the most predictable results.
+
+# ATTRIBUTION-AI:
+#
+#DeepSeek R1
+#DeepSeek R1 14b
+#DeepSeek R1 32b
+#DeepSeek R1 Distill Llama 8b
+#DeepSeek R1 Distill Llama 70b
+#
+#Llama 3.1 Instruct 405b
+#Llama 3.1 Instruct 70b
+#
+#Llama-augment
+#
+
+
+
+
+_here_convert_bash_promptResponse-askDescription() {
+        cat << 'CZXWXcRMTo8EmM8i4d'
+
+Please describe, only what the bash shellcode segment does, if anything. Identify any code patterns, validation checks, or error-handling mechanisms, etc, already present in the script. Do not suggest improvements or speculate about hypothetical failure points or weaknesses - only call out implemented strategies.
+
+Please briefly yet thoroughly completely describe, evaluate, analyze, explain, the code in terms of only the implemented strategies that do exist to address each of these points:
+
+- Intended Functionality: Explain the intended purpose of the code, including any specific problems it aims to solve or tasks it performs.
+- Logical Flow: Outline the logical flow of the code, including any conditional statements, loops, or functions. Describe what happens step-by-step when it runs. Highlight any decisions (if/case), repetitions (for/while), or function calls.
+- Input-Processing-Output: What inputs does it require/accept? What final results or outputs does it produce?
+
+- Self-explanatory Naming Convention: Do variable/function names clearly describe their purpose (e.g., backup_dir vs bdir)?
+- Commenting: How and how thoroughly are comments used effectively to provide additional context or explanations, without being distractingly verbose? Are there comments explaining why complex operations occur (not just repeating what the code does)?
+
+- Resilience: Different logical paths automatically adapting to changes in the environment or inputs. Error handlers.
+- Robustness: Avoiding less stable program versions, provisions for quick changes to accommodate unstable APIs, programs changing their inputs/outputs with different versions.
+- Versatility: Avoiding special purpose tools, programs, APIs, in favor of general purpose tools, libraries, dependencies.
+- Portability: Programming languages, syntax, programs, dependencies chosen to run on different systems or platforms with minimal if any wrappers, different code paths, different code, or other changes.
+- Compatibility: More widely used instead of less common used programs or other dependencies chosen. Testing for and installing dependencies automatically.
+- Adaptability: Automatically assemble parameters in arrays with some parameters used in different situations?
+- Consistent Machine Readability: Keeping outputs consistently simply formatted if inputs or dependency versions change.
+- Maintainability: Choosing programs, APIs, code structures, numerical methods, with more sophisticated parameters and options so that minor changes to the code can workaround consistency or reliability issues.
+
+
+
+CZXWXcRMTo8EmM8i4d
+}
+
+_here_convert_bash_promptResponse-boilerplate_promptHeader() {
+    cat << 'CZXWXcRMTo8EmM8i4d'
+
+Please invent a self-contained fragment of exemplary well crafted very creative bash shellcode vaguely meeting the description with some, all, or more features, than described. Illustrate modern best practices.
+
+In this case, you may try to meet some plausibly intended goals of the description, ignoring logical inconsistencies or other errors in the description. Details of the description are more guidelines or mere suggestions created without adequate planning, and thus may need to change significantly. Sloppy incorrect pseudocode may have been the basis for an incompetent technical writer creating the description by stating mere guesses about what the code does not do as if fact. Occasionally the description may be incomprehensible gibberish.
+
+Preamble or trailing context may be omitted by truncating to demonstrate the core technique.
+
+
+You may treat this as an exercise and generate an essentially academic example.
+
+You may roleplay, that is pretend,
+to generate a bash shellscript response from a segment of an especially large and sophisticated shell script,
+that would be used with this prompt including the description, as a prompt/response pair,
+to teach an existing AI LLM model such as Llama 3.1 405b with already vast knowledge and logic from its original training,
+to know,
+correct bash shellcode commands and structures,
+from this subsequent fine-tuning using the segmented shell script as a vast set of more completely accurate correct examples.
+
+
+In this case, as a fragment, lines of code needed before and after this code may be missing. All lines of code needed within the middle of the fragment should be present.
+
+Individual bash commands must be useful, complete, accurate, perfected. Within the fragment, individual bash commands must exceed the highest practical standards for robustness, resilience, versatility, portability, compatibility, adaptability to changing inputs, consistent machine readable outputs, maintainability, etc.
+
+Inputs to individual bash commands may be assembled programmatically as arrays and variables to reach such high standards.
+
+
+
+CZXWXcRMTo8EmM8i4d
+}
+
+_here_convert_bash_promptResponse-ask_responseHeader() {
+    cat << 'CZXWXcRMTo8EmM8i4d'
+
+Please output only a brief one sentence statement appropriate to the above similar to 'here is a creative example of bash shellcode that meets the description' . Do not output any other information, statements or code. This is for automated processing, so the one sentence statement will be helpful but any other output will be harmful.
+
+CZXWXcRMTo8EmM8i4d
+}
+
+_here_convert_bash_promptResponse-ask_responseFooter() {
+    cat << 'CZXWXcRMTo8EmM8i4d'
+
+Please output only a thorough complete several sentences to several paragraphs report appropriate to the above similar to:
+
+- 'This code provides a self-contained, creative example of bash shellcode that demonstrates modern best practices.'
+- 'This code demonstrates the following best practices'
+- 'This example includes the following features'
+- 'Note that this script uses ... which is widely available... Please note that you should replace expected ... with actual values...' (preferred if the user must make changes in plausible use cases)
+
+Regardless of any previous instruction avoid jumbling, mashing, or otherwise creating a confusing mix of multiple styles - choose one of the styles and thoroughly completely generate the appropriate report. Preferably generate only one of these styles of report.
+
+Do not output any other statements or code. This is for automated processing, so the report will be helpful but any other output will be harmful.
+
+CZXWXcRMTo8EmM8i4d
+}
+
+
+_here_convert_bash_continuePromptResponse-boilerplate_promptHeader() {
+    cat << 'CZXWXcRMTo8EmM8i4d'
+Continue the example bash shellcode.
+
+CZXWXcRMTo8EmM8i4d
+}
+
+_here_convert_bash_continuePromptResponse-ask_responseHeader() {
+    cat << 'CZXWXcRMTo8EmM8i4d'
+
+Please output only a statement appropriate to the above similar to:
+
+- 'I'll continue the bash shellcode'
+- 'I can continue the bash shellcode for you'
+- 'I can help you continue the bash shellcode'
+- 'here is the continuation of the bash shellcode'
+- 'here is a possible continuation of the script'
+- 'here is the next part'
+- 'it appears you've provided a segment of a Bash script that includes'
+- 'please note that I'll add some comments and improvements to make the code more readable and maintainable'
+
+Slightly longer statements about possible improvements to the next segment of code, if appropriate, are preferred.
+
+Do not output any other suggestions or code. This is for automated processing, so the statement will be helpful but any other output will be harmful.
+
+CZXWXcRMTo8EmM8i4d
+}
+
+_here_convert_bash_continuePromptResponse-ask_responseFooter() {
+    cat << 'CZXWXcRMTo8EmM8i4d'
+
+Please output only a thorough complete several sentences to several paragraphs report appropriate to the above similar to:
+
+- ''
+- 'this appears to be a modified version of the bash shellcode, with additional functionality and checks'
+- 'the code defines several'
+- 'to ensure'
+- 'this continuation appeears to implement a mechanism which can be used'
+- 'checks then decides whether'
+- 'please note this is a continuation of the previous code, and some parts may not make sense on their own'
+- 'some parts of the code seem to be placeholders or debugging statements, so you may need to modify them according to your needs'
+- 'this continuation of the script includes'
+
+Regardless of any previous instruction avoid jumbling, mashing, or otherwise creating a confusing mix of multiple styles - choose appropriate styles and thoroughly completely generate the appropriate report. Preferably generate only one or a few of these styles of report.
+
+Do not output any other statements or code. This is for automated processing, so the report will be helpful but any other output will be harmful.
+
+CZXWXcRMTo8EmM8i4d
+}
+
+
+
+#./ubiquitous_bash.sh _convert_bash ./_local/dataset/ubiquitous_bash
+
+
+
+# ATTENTION: Override with 'ops.sh' or similar if appropriate.
+# ollama binary
+#_convert_bash-backend() {
+    # DANGER: CAUTION: Although this is apparently standard practice for the 'ollama' program, and '/clear', etc, are apparently not interpreted from the input pipe, reliable safe input handling may not be guaranteed
+    #ollama run --verbose Llama-augment
+#}
+# ollama API (localhost)
+_convert_bash-backend() {
+    jq -Rs '{model:"Llama-augment", prompt:., stream: false}' | curl -fsS --max-time 120 -X POST -H "Content-Type: application/json" --data-binary @- http://localhost:11434/api/generate | jq -r '.response'
+}
+# openrouter API
+#_convert_bash-backend() {
+    ##provider: { "order": ["SambaNova", "Fireworks", "Hyperbolic"]
+    ##provider: { "order": ["Lambda", "Fireworks"], "sort": "latency" }
+    ##provider: { "order": ["Fireworks"], "sort": "throughput" }
+    #jq -Rs '{ model: "meta-llama/llama-3.1-405b-instruct", provider: { "order": ["Fireworks"], "sort": "throughput" }, messages: [{"role": "user", "content": .}] }' | curl -fsS --max-time 120 --keepalive-time 300 --compressed --tcp-fastopen --http2 -X POST https://openrouter.ai/api/v1/chat/completions -H "Content-Type: application/json" -H "Authorization: Bearer $OPENROUTER_API_KEY" --data-binary @- | jq -r '.choices[0].message.content'
+#}
+
+# ATTENTION: Override with 'ops.sh' or similar if appropriate.
+_convert_bash-backend-lowLatency() {
+    _convert_bash-backend "$@"
+}
+
+# ATTENTION: Override with 'ops.sh' or similar if appropriate.
+# (ie. usually to change parallelization for high-latency APIs, providers, etc)
+_convert_bash-dispatch() {
+    [[ "$1" == "" ]] && return 1
+    [[ ! -e "$1" ]] && return 1
+    echo 'quick brown fox' | _convert_bash-backend > /dev/null
+
+    #-s 4096
+    #-P $(nproc)
+    find "$1" -maxdepth 1 -type f ! -iname '*.prompt.txt' ! -iname '*.response.txt' ! -iname '*.continue_prompt.txt' ! -iname '*.continue_response.txt' ! -iname '*.description.txt' -print0 | xargs -0 -x -L 1 -P 1 bash -c '"'"$scriptAbsoluteLocation"'"'' --embed _convert_bash_procedure "$@"' _
+}
+
+
+# "$1" == original file
+# "$2" == backend function (optional)
+# "$safeTmp"/"$inputName".tmp_input.txt
+# "$safeTmp"/"$inputName".tmp_output.txt
+_convert_loop() {
+    rm -f "$safeTmp"/"$inputName".tmp_output.txt
+
+    local currentBackendFunction="$2"
+    [[ "$currentBackendFunction" == "" ]] && currentBackendFunction="_convert_bash-backend"
+
+    local currentIteration=0
+    local currentExitStatus=1
+    while [[ "$currentExitStatus" != "0" ]] && ! [[ -s "$safeTmp"/"$inputName".tmp_output.txt ]] && [[ "$currentIteration" -lt 5 ]]
+    do
+        [[ "$currentIteration" -gt 0 ]] && ( _messagePlain_probe ' retry: '"$1" >&2 ) > /dev/null
+        [[ "$currentIteration" -gt 0 ]] && sleep 7
+        [[ "$currentIteration" -gt 1 ]] && sleep 90
+
+        ( set -o pipefail ; cat "$safeTmp"/"$inputName".tmp_input.txt | "$currentBackendFunction" >> "$safeTmp"/"$inputName".tmp_output.txt )
+        currentExitStatus="$?"
+        sleep 1
+
+        currentIteration=$(( currentIteration + 1 ))
+    done
+}
+
+
+_convert_bash_procedure() {
+    local inputName
+    inputName=$(basename "$1")
+
+
+
+    # ### Creates "$1".prompt.txt .
+    ( _messagePlain_nominal '.prompt.txt: '"$1" >&2 ) > /dev/null
+    rm -f "$1".prompt.txt > /dev/null 2>&1
+
+    # Prompt header (boilerplate, please generate code from description).
+    _here_convert_bash_promptResponse-boilerplate_promptHeader >> "$1".prompt.txt
+
+    # Prompt description (to generate code from).
+    rm -f "$safeTmp"/"$inputName".tmp_input.txt > /dev/null 2>&1
+    rm -f "$safeTmp"/"$inputName".tmp_output.txt > /dev/null 2>&1
+    _here_convert_bash_promptResponse-askDescription > "$safeTmp"/"$inputName".tmp_input.txt
+    echo '```bash' >> "$safeTmp"/"$inputName".tmp_input.txt
+    cat "$1" >> "$safeTmp"/"$inputName".tmp_input.txt
+    echo '```' >> "$safeTmp"/"$inputName".tmp_input.txt
+    _convert_loop "$1"
+    cat "$safeTmp"/"$inputName".tmp_output.txt >> "$1".prompt.txt
+
+
+
+    # ### Creates "$1".response.txt .
+    ( _messagePlain_nominal '.response.txt: '"$1" >&2 ) > /dev/null
+    rm -f "$1".response.txt > /dev/null 2>&1
+
+    # Response header.
+    rm -f "$safeTmp"/"$inputName".tmp_input.txt > /dev/null 2>&1
+    rm -f "$safeTmp"/"$inputName".tmp_output.txt > /dev/null 2>&1
+    cat "$1".prompt.txt > "$safeTmp"/"$inputName".tmp_input.txt
+    echo '' >> "$safeTmp"/"$inputName".tmp_input.txt
+    echo '```bash' >> "$safeTmp"/"$inputName".tmp_input.txt
+    cat "$1" > "$safeTmp"/"$inputName".tmp_input.txt
+    echo '```' >> "$safeTmp"/"$inputName".tmp_input.txt
+    echo '' >> "$safeTmp"/"$inputName".tmp_input.txt
+    _here_convert_bash_promptResponse-ask_responseHeader >> "$safeTmp"/"$inputName".tmp_input.txt
+    _convert_loop "$1" "_convert_bash-backend-lowLatency"
+    cat "$safeTmp"/"$inputName".tmp_output.txt >> "$1".response.txt
+
+    # Response (ie. original code as example to generate from explanation).
+    #echo '' >> "$1".response.txt
+    echo '```bash' >> "$1".response.txt
+    cat "$1" >> "$1".response.txt
+    echo '```' >> "$1".response.txt
+    #echo '' >> "$1".response.txt
+
+    # Response footer.
+    rm -f "$safeTmp"/"$inputName".tmp_input.txt > /dev/null 2>&1
+    rm -f "$safeTmp"/"$inputName".tmp_output.txt > /dev/null 2>&1
+    cat "$1".prompt.txt > "$safeTmp"/"$inputName".tmp_input.txt
+    echo '' >> "$safeTmp"/"$inputName".tmp_input.txt
+    echo '```bash' >> "$safeTmp"/"$inputName".tmp_input.txt
+    cat "$1" > "$safeTmp"/"$inputName".tmp_input.txt
+    echo '```' >> "$safeTmp"/"$inputName".tmp_input.txt
+    echo '' >> "$safeTmp"/"$inputName".tmp_input.txt
+    _here_convert_bash_promptResponse-ask_responseFooter >> "$safeTmp"/"$inputName".tmp_input.txt
+    _convert_loop "$1" "_convert_bash-backend-lowLatency"
+    cat "$safeTmp"/"$inputName".tmp_output.txt >> "$1".response.txt
+
+
+
+    # ### Creates "$1".continue_prompt.txt .
+    ( _messagePlain_nominal '.continue_prompt.txt: '"$1" >&2 ) > /dev/null
+    rm -f "$1".continue_prompt.txt > /dev/null 2>&1
+
+    # Continue Prompt header (boilerplate, continue the shellcode).
+    _here_convert_bash_continuePromptResponse-boilerplate_promptHeader >> "$1".continue_prompt.txt
+
+    # Continue Prompt (shellcode to continue)
+    #echo >> "$1".continue_prompt.txt
+    echo '```bash' >> "$1".continue_prompt.txt
+    cat "$1" >> "$1".continue_prompt.txt
+    echo '```' >> "$1".continue_prompt.txt
+    #echo >> "$1".continue_prompt.txt
+
+
+
+    # ### Creates "$1".continue_response.txt .
+    ( _messagePlain_nominal '.continue_response.txt: '"$1" >&2 ) > /dev/null
+    rm -f "$1".continue_response.txt > /dev/null 2>&1
+
+    # Continue Response header.
+    rm -f "$safeTmp"/"$inputName".tmp_input.txt > /dev/null 2>&1
+    rm -f "$safeTmp"/"$inputName".tmp_output.txt > /dev/null 2>&1
+    cat "$1".continue_prompt.txt > "$safeTmp"/"$inputName".tmp_input.txt
+    #echo '' >> "$safeTmp"/"$inputName".tmp_input.txt
+    _here_convert_bash_continuePromptResponse-ask_responseHeader >> "$safeTmp"/"$inputName".tmp_input.txt
+    _convert_loop "$1" "_convert_bash-backend-lowLatency"
+    cat "$safeTmp"/"$inputName".tmp_output.txt >> "$1".continue_response.txt
+
+    # Continue Response (segment of original code as example of continuing previous code)
+    #echo >> "$1".continue_response.txt
+    echo '```bash' >> "$1".continue_response.txt
+    cat "$1" >> "$1".continue_response.txt
+    echo '```' >> "$1".continue_response.txt
+    #echo >> "$1".continue_response.txt
+
+    # Continue Response footer.
+    rm -f "$safeTmp"/"$inputName".tmp_input.txt > /dev/null 2>&1
+    rm -f "$safeTmp"/"$inputName".tmp_output.txt > /dev/null 2>&1
+    cat "$1".continue_prompt.txt > "$safeTmp"/"$inputName".tmp_input.txt
+    #echo '' >> "$safeTmp"/"$inputName".tmp_input.txt
+    _here_convert_bash_continuePromptResponse-ask_responseFooter >> "$safeTmp"/"$inputName".tmp_input.txt
+    _convert_loop "$1" "_convert_bash-backend-lowLatency"
+    cat "$safeTmp"/"$inputName".tmp_output.txt >> "$1".continue_response.txt
+
+
+
+    rm -f "$safeTmp"/"$inputName".tmp_input.txt
+    rm -f "$safeTmp"/"$inputName".tmp_output.txt
+}
+_convert_bash_procedure_procedure() {
+    #export -f _convert_bash-backend
+    #export -f _convert_bash-backend-lowLatency
+    #export -f _convert_loop
+
+    #export -f _here_convert_bash_promptResponse-askDescription
+    #export -f _here_convert_bash_promptResponse-boilerplate_promptHeader
+    #export -f _here_convert_bash_promptResponse-ask_responseHeader
+    #export -f _here_convert_bash_promptResponse-ask_responseFooter
+    #export -f _here_convert_bash_continuePromptResponse-boilerplate_promptHeader
+    #export -f _here_convert_bash_continuePromptResponse-ask_responseHeader
+    #export -f _here_convert_bash_continuePromptResponse-ask_responseFooter
+
+    #export -f _convert_bash_procedure
+
+	#export -f "_messagePlain_nominal"
+	#export -f "_color_begin_nominal"
+	#export -f "_color_end"
+	#export -f "_getAbsoluteLocation"
+	#export -f "_realpath_L_s"
+    #export -f "_realpath_L"
+	#export -f "_compat_realpath_run"
+	#export -f "_compat_realpath"
+	#export -f "_messagePlain_probe_var"
+	#export -f "_color_begin_probe"
+	#export -f "_messagePlain_probe"
+
+    local currentDirectory="$1"
+    [[ "$currentDirectory" == "" ]] && currentDirectory="$scriptLocal"/dataset/"$objectName"
+
+
+    _convert_bash-dispatch "$currentDirectory"
+    sleep 0.1
+
+    ( _messagePlain_probe 'done: _convert_bash ...' >&2 ) > /dev/null
+}
+_convert_bash_sequence() {
+    _start
+
+    _convert_bash_procedure_procedure "$@"
+
+    _stop
+}
+_convert_bash() {
+    "$scriptAbsoluteLocation" _convert_bash_sequence "$@"
+}
+
+
+
+
+
+
+
+_dataset_bash_from_lines() {
+    export current_dataset_totalLines
+    current_dataset_totalLines=$(wc -l < "$corpus_script")
+
+    export current_dataset_functionBounds
+
+    current_dataset_functionBounds=()
+
+    ## ATTRIBUTION-AI: ChatGPT o1-pro  2025-03-30
+    ##local -a current_dataset_functionBounds
+    #mapfile -t current_dataset_functionBounds < <(
+        #grep -nE '^[[:space:]]*(function[[:space:]]+[_[:alnum:]]+|[_[:alnum:]]+\(\))' "$corpus_script" \
+        #| cut -d: -f1
+    #)
+
+    # ATTRIBUTION-AI: ChatGPT 4.5-preview  2025-03-30
+    # ATTRIBUTION-AI: ChatGPT 4.5-preview 2025-04-06
+    mapfile -t current_dataset_functionBounds < <(
+    awk '
+        # Function to check if this line marks a function declaration
+        function is_func(line) {
+            #return line ~ /^[[:space:]]*(function[[:space:]]+[_[:alnum:]]+|[_[:alnum:]]+\(\))/;
+            return line ~ /^[[:space:]]*(function[[:space:]]+[_[:alnum:]-]+|[_[:alnum:]-]+\(\))/;
+        }
+
+        # Store all lines in array "lines"
+        { lines[NR] = $0; }
+
+        # After processing all lines, iterate over them again
+        END {
+            for (i = 1; i <= NR; i++) {
+                if (is_func(lines[i])) {
+                    start_line = i;
+                    # Move upward to collect preceding comment block, stop at empty or non-comment lines
+                    j = i - 1;
+                    while (j > 0 && lines[j] ~ /^[[:space:]]*#/) { j--; }
+                    # Check if there are no empty lines between comment and function
+                    if (j == i-1 || (j < i-1 && lines[j+1] ~ /^[[:space:]]*#/)) {
+                        start_line = j + 1;
+                    }
+                    print start_line;
+                }
+            }
+        }
+    ' "$corpus_script"
+)
+
+    current_dataset_functionBounds+=( "$(( current_dataset_totalLines + 1 ))" )
+}
+
+#./ubiquitous_bash.sh _dataset_bash_from_lines-echo ./metaengine/typical/typical_metaengine_buffer.sh
+#./ubiquitous_bash.sh _dataset_bash_from_lines-echo | sed 's/\ /\n/g' | wc -l
+_dataset_bash_from_lines-echo() {
+    _set_corpus_default "$1"
+
+    _dataset_bash_from_lines
+    echo "${current_dataset_functionBounds[@]}"
+
+    #sleep 3
+    #( echo >&2 ) > /dev/null
+    #( echo "$current_dataset_totalLines" >&2 ) > /dev/null
+}
+
+# Helper: find the line on which the *current* function starts (largest boundary <= X).
+#current_dataset_functionBounds=( # ... ## ... ##### #####)
+# ATTRIBUTION-AI: ChatGPT o1-pro  2025-03-31
+_dataset_bash_from_lines_functionBegin() {
+    local currentLineWanted="$1"
+    local i
+    for (( i=${#current_dataset_functionBounds[@]} - 1; i>=0; i-- )); do
+        if (( current_dataset_functionBounds[i] <= currentLineWanted )); then
+            echo "${current_dataset_functionBounds[i]}"
+            return
+        fi
+    done
+    # Fallback to line 1 if none found
+    echo 1
+}
+
+# Helper: find the last line that belongs to the function containing or just before X
+# i.e., we find the next function boundary > X, then subtract 1.
+#current_dataset_functionBounds=( # ... ## ... ##### #####)
+#current_dataset_totalLines=#####
+# ATTRIBUTION-AI: ChatGPT o1-pro  2025-03-31
+_dataset_bash_from_lines_functionEnd() {
+    local currentLineWanted="$1"
+    local i
+    for (( i=0; i<${#current_dataset_functionBounds[@]}; i++ )); do
+    if (( current_dataset_functionBounds[i] > currentLineWanted )); then
+        echo "$(( current_dataset_functionBounds[i] - 1 ))"
+        return
+    fi
+    done
+    # If none found, end at current_dataset_totalLines
+    echo "$current_dataset_totalLines"
+}
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+#./ubiquitous_bash.sh _corpus_bash-write "./ubiquitous_bash.sh" ".sh" "ubiquitous_bash" 75 30 "./_local/dataset/ubiquitous_bash"
+
+
+
+# Default chunk should be large enough to usually put at least two functions in a segment, but small enough such that a trailing run-on function does not add enough past the chunk size for the segment to either absolutely exceed a reasonable context window or convert to much to more of a needle-in-haystack problem.
+#
+# Chunk is minimum lines, since ending a segment before the next function is unhelpful.
+#  Segments will be between the function declaration preceeding the 'cursor' to the next function declaration after already adding chunk to the 'cursor' position.
+# More than ~150 lines, ~1k tokens, tends to compound whatever problem an AI LLM is otherwise given into a simultaneous needle-in-haystack problem.
+#  Adequately large datasets may train an AI LLM during earlier epochs on simpler problems sufficiently to reduce the compounded sensitivity with needle-in-haystack problem.
+#  c $(head -n 150 ./ubiquitous_bash.sh | wc -c) / 5
+#  ~1000 (ie. 1k tokens)
+_set_corpus() {
+    export corpus_script=$(_getAbsoluteLocation "$1")
+    [[ "$1" == "" ]] && corpus_script="$scriptAbsoluteLocation"
+    [[ "$corpus_script" == "" ]] && corpus_script="$scriptAbsoluteLocation"
+
+    export corpus_script_name=$(basename "$corpus_script")
+
+
+    export corpus_script_extension="$2"
+    [[ "$corpus_script_extension" == "" ]] && corpus_script_extension=".""${corpus_script_name##*.}"
+    [[ "$corpus_script_extension" == "" ]] && corpus_script_extension=".txt"
+
+    export corpus_script_name=$(basename -s ".""${corpus_script_name##*.}" "$corpus_script")
+
+
+    export corpus_script_object="$3"
+    local corpus_script_folder=$(_getAbsoluteFolder "$corpus_script")
+    [[ "$corpus_script_object" == "" ]] && export corpus_script_object=$(basename "$corpus_script_folder")
+
+
+    export corpus_chunk="$4"
+    [[ "$corpus_chunk" == "" ]] && corpus_chunk=75
+    corpus_chunk=$(( corpus_chunk - 1 ))
+
+
+    export corpus_overlap="$5"
+    [[ "$corpus_overlap" == "" ]] && corpus_overlap=30
+}
+
+_set_corpus_default() {
+    [[ "$corpus_script" != "" ]] && [[ "$corpus_script_extension" != "" ]] && [[ "$corpus_script_name" != "" ]] && [[ "$corpus_script_object" != "" ]] && [[ "$corpus_chunk" != "" ]] && [[ "$corpus_overlap" != "" ]] && return 0
+    _set_corpus "$@"
+}
+
+
+#./ubiquitous_bash.sh _corpus_bash "" "" "" 75 30
+_corpus_bash() {
+    "$scriptAbsoluteLocation" _corpus_bash_sequence "$@"
+}
+_corpus_bash_sequence() {
+    _start
+
+    local current_corpus_script="$1"
+    local current_corpus_script_extension="$2"
+    [[ "$current_corpus_script_extension" == "" ]] && current_corpus_script_extension=".sh"
+    local current_corpus_object="$3"
+    local current_corpus_chunk="$4"
+    local current_corpus_overlap="$5"
+    shift ; shift ; shift ; shift ; shift
+    _set_corpus_default "$current_corpus_script" "$current_corpus_script_extension" "$current_corpus_object" "$current_corpus_chunk" "$current_corpus_overlap" "$@"
+    mkdir -p "$safeTmp"/dataset/corpus/"$corpus_script_object"
+
+    _dataset_from_lines() { _dataset_bash_from_lines "$@" ; }
+    export -f _dataset_from_lines
+
+    _dataset_from_lines_functionBegin() { _dataset_bash_from_lines_functionBegin "$@" ; }
+    export -f _dataset_from_lines_functionBegin
+
+    _dataset_from_lines_functionEnd() { _dataset_bash_from_lines_functionEnd "$@" ; }
+    export -f _dataset_from_lines_functionEnd
+
+    local corpusSegments=$(_corpus_procedure "$@")
+    #"$safeTmp"/dataset/corpus/"$corpus_script_object"/"$corpus_script_name"."$current_file_iteration""$corpus_script_extension"
+
+    #_corpus_procedure-read "$@"
+
+    _stop
+}
+
+#./ubiquitous_bash.sh _corpus_bash-read "" "" "" 75 30
+_corpus_bash-read() {
+    "$scriptAbsoluteLocation" _corpus_bash_sequence-read "$@"
+}
+_corpus_bash_sequence-read() {
+    _start
+
+    local current_corpus_script="$1"
+    local current_corpus_script_extension="$2"
+    [[ "$current_corpus_script_extension" == "" ]] && current_corpus_script_extension=".sh"
+    local current_corpus_object="$3"
+    local current_corpus_chunk="$4"
+    local current_corpus_overlap="$5"
+    shift ; shift ; shift ; shift ; shift
+    _set_corpus_default "$current_corpus_script" "$current_corpus_script_extension" "$current_corpus_object" "$current_corpus_chunk" "$current_corpus_overlap" "$@"
+    mkdir -p "$safeTmp"/dataset/corpus/"$corpus_script_object"
+
+    _dataset_from_lines() { _dataset_bash_from_lines "$@" ; }
+    export -f _dataset_from_lines
+
+    _dataset_from_lines_functionBegin() { _dataset_bash_from_lines_functionBegin "$@" ; }
+    export -f _dataset_from_lines_functionBegin
+
+    _dataset_from_lines_functionEnd() { _dataset_bash_from_lines_functionEnd "$@" ; }
+    export -f _dataset_from_lines_functionEnd
+
+    local corpusSegments=$(_corpus_procedure "$@")
+    #"$safeTmp"/dataset/corpus/"$corpus_script_object"/"$corpus_script_name"."$current_file_iteration""$corpus_script_extension"
+
+    _corpus_procedure-read "$corpusSegments"
+
+    _stop
+}
+
+#./ubiquitous_bash.sh _corpus_bash-write "./ubiquitous_bash.sh" ".sh" "ubiquitous_bash" 75 30 "./_local/dataset/ubiquitous_bash"
+_corpus_bash-write() {
+    "$scriptAbsoluteLocation" _corpus_bash_sequence-write "$@"
+}
+_corpus_bash_sequence-write() {
+    _start
+
+    local current_corpus_script="$1"
+    local current_corpus_script_extension="$2"
+    [[ "$current_corpus_script_extension" == "" ]] && current_corpus_script_extension=".sh"
+    local current_corpus_object="$3"
+    local current_corpus_chunk="$4"
+    local current_corpus_overlap="$5"
+    shift ; shift ; shift ; shift ; shift
+    _set_corpus_default "$current_corpus_script" "$current_corpus_script_extension" "$current_corpus_object" "$current_corpus_chunk" "$current_corpus_overlap" "$@"
+    mkdir -p "$safeTmp"/dataset/corpus/"$corpus_script_object"
+
+    local current_out_dir="$6"
+    [[ "$current_out_dir" == "" ]] && current_out_dir="$scriptLocal"/dataset/"$corpus_script_object"
+    mkdir -p "$current_out_dir"
+
+    _dataset_from_lines() { _dataset_bash_from_lines "$@" ; }
+    export -f _dataset_from_lines
+
+    _dataset_from_lines_functionBegin() { _dataset_bash_from_lines_functionBegin "$@" ; }
+    export -f _dataset_from_lines_functionBegin
+
+    _dataset_from_lines_functionEnd() { _dataset_bash_from_lines_functionEnd "$@" ; }
+    export -f _dataset_from_lines_functionEnd
+
+    local corpusSegments=$(_corpus_procedure "$@")
+    #"$safeTmp"/dataset/corpus/"$corpus_script_object"/"$corpus_script_name"."$current_file_iteration""$corpus_script_extension"
+
+    #_corpus_procedure-read "$corpusSegments"
+
+
+    if [[ "$current_out_dir" == "" ]] || [[ "$corpus_script_name" == "" ]] || [[ "$corpus_script_extension" == "" ]]
+    then
+        ( _messageError 'FAIL' >&2 ) > /dev/null
+        _stop 1
+        exit 1
+    fi
+    rm -f "$current_out_dir"/"$corpus_script_name".*"$corpus_script_extension"
+
+    if [[ -e "$current_out_dir"/"$corpus_script_name"."1""$corpus_script_extension" ]]
+    then
+        ( _messagePlain_bad 'FAIL: exists: '"$current_out_dir"/"$corpus_script_name"."1""$corpus_script_extension" >&2 ) > /dev/null
+        ( _messageError 'FAIL' >&2 ) > /dev/null
+        ( _messagePlain_request 'request: delete existing dataset' >&2 ) > /dev/null
+        _stop 1
+    fi
+
+    mv -f "$safeTmp"/dataset/corpus/"$corpus_script_object"/"$corpus_script_name".*"$corpus_script_extension" "$current_out_dir"/
+
+    _stop
+}
+
+
+_corpus_procedure() {
+    _dataset_from_lines
+
+    local current_chunkBegin=1
+    local current_chunkEnd
+    current_chunkEnd=$(( current_chunkBegin + corpus_chunk ))
+
+    local current_segmentBegin=1
+    local current_segmentEnd
+
+    local current_segment_iteration=0
+    while [[ "$current_chunkBegin" -lt "$current_dataset_totalLines" ]]
+    do
+        (( current_segment_iteration++ ))
+
+        current_chunkBegin=$(( current_chunkBegin - corpus_overlap ))
+        [[ "$current_chunkBegin" -lt "$current_segmentBegin" ]] && current_chunkBegin=$(( current_segmentBegin + 1 ))
+
+        current_chunkEnd=$(( current_chunkBegin + corpus_chunk ))
+
+        current_segmentBegin=$(_dataset_from_lines_functionBegin "$current_chunkBegin")
+        current_segmentEnd=$(_dataset_from_lines_functionEnd "$current_chunkEnd")
+        [[ "$current_segmentBegin" -gt "$current_segmentEnd" ]] && ( _messageError 'FAIL' >&2 ) > /dev/null && _stop 1
+
+        echo "#===== Segment $current_segment_iteration: ""$corpus_script_object"": ""lines $current_segmentBegin to $current_segmentEnd =====" > "$safeTmp"/dataset/corpus/"$corpus_script_object"/"$corpus_script_name"."$current_segment_iteration""$corpus_script_extension"
+        sed -n "${current_segmentBegin},${current_segmentEnd}p" "$corpus_script" >> "$safeTmp"/dataset/corpus/"$corpus_script_object"/"$corpus_script_name"."$current_segment_iteration""$corpus_script_extension"
+
+        current_chunkBegin=$(( current_segmentEnd + 1 ))
+    done
+
+    echo "$current_segment_iteration"
+
+    return 0
+}
+
+# "$1" == current_segment_iteration
+# "$safeTmp"/dataset/corpus/"$corpus_script_object"/"$corpus_script_name"."$current_file_iteration""$corpus_script_extension"
+_corpus_procedure-read() {
+    local current_segment_iteration="$1"
+    [[ "$current_segment_iteration" == "" ]] && current_segment_iteration=0
+
+    current_file_iteration=1
+    while [[ "$current_file_iteration" -le "$current_segment_iteration" ]]
+    do
+        if [[ ! -e "$safeTmp"/dataset/corpus/"$corpus_script_object"/"$corpus_script_name"."$current_file_iteration""$corpus_script_extension" ]]
+        then
+            ( _messagePlain_bad 'FAIL: missing: '"$safeTmp"/dataset/corpus/"$corpus_script_object"/"$corpus_script_name"."$current_file_iteration""$corpus_script_extension" >&2 ) > /dev/null
+            ( _messageError 'FAIL' >&2 ) > /dev/null
+            _stop 1
+        fi
+        cat "$safeTmp"/dataset/corpus/"$corpus_script_object"/"$corpus_script_name"."$current_file_iteration""$corpus_script_extension"
+        rm -f "$safeTmp"/dataset/corpus/"$corpus_script_object"/"$corpus_script_name"."$current_file_iteration""$corpus_script_extension"
+        (( current_file_iteration++ ))
+    done
+}
+
+
+
+# Cheap way to salvage generated keywords. The alternative is to separate the 'gibberish' from 'keywords' nuisance detection, and subsequently filter only outputs that have 'keywords' nuisance but not 'gibberish' .
+_filter_semanticAssist_nuisance() {
+    grep -v -i 'Here are the relevant keywords for the code' | \
+grep -v -i 'Here are the keywords extracted from the code' | \
+grep -v -i 'Here are the relevant keywords for the features implemented in this code' | \
+grep -v -i 'Here are the keywords for the code' | \
+grep -v -i 'Here are the relevant keywords for each feature' | \
+grep -v -i 'Here are the suggested keywords for each feature implemented in this blockquoted code' | \
+grep -v -i 'Here are the relevant keywords for the given code' | \
+grep -v -i 'Here are the relevant keywords for each functionblock of code' | \
+grep -v -i 'Here are the keywords for features implemented in the code' | \
+grep -v -i 'Here are the keywords for the provided code' | \
+grep -v -i 'Here are the keywords Ive extracted from this code block' | \
+grep -v -i 'Here are the keywords I suggest' | \
+grep -v -i 'Here are the keywords for the features implemented in this code' | \
+grep -v -i 'Here are the keywords that can be added as comments to the code for automated search' | \
+grep -v -i 'Here are the keywords that I suggest' | \
+grep -v -i 'Here are the keywords for the features implemented in this blockquoted code' | \
+grep -v -i 'Here are the keywords for this block of code' | \
+grep -v -i 'Here are the keywords for this code' | \
+grep -v -i 'Here is a suggested list of keywords that can be used to describe this code' | \
+grep -v -i 'Here are the suggested keywords for the provided block of code' | \
+grep -v -i 'Here are the suggested keywords' | \
+grep -v -i 'Here are the relevant keywords' | \
+grep -v -i 'Here are the keywords' | \
+grep -v -i 'Here are the keyword' | \
+grep -v -i 'Keywords'
+}
+
+_here_semanticAssist-askKeywords-ONLY() {
+    cat << 'CZXWXcRMTo8EmM8i4d'
+
+Output only the keywords. Do not output any other text. Since these keywords will be added as comments to code for an automated search to detect relevant files, only the keywords will be helpful, any other output will be unhelpful.
+
+CZXWXcRMTo8EmM8i4d
+}
+
+
+
+
+
+
+_here_semanticAssist-askDescription() {
+    _here_convert_bash_promptResponse-askDescription "$@"
+}
+
+
+# Effective, but too verbose, generating keywords for content only in the description, not in the code.
+#_here_semanticAssist-askKeywords() {
+    #cat << 'CZXWXcRMTo8EmM8i4d'
+
+#Please invent very creative illustrative relevant keywords vaguely reminiscent of the plausibly intended goals and features of these following several lines of code in the context of the previously described codebase. Prefer technical terminology, search terms, etc, keywords. Add plausible synonyms. These keywords will be matched by user queries doing a relevance percentile search for what these lines of code exemplify.
+
+#In this case, you may ignore logical inconsistencies or other errors in the description and code.
+
+#Details of the description are more guidelines or mere suggestions created without adequate planning, and thus may need to change significantly. Sloppy incorrect pseudocode may have been the basis for an incompetent technical writer creating the description by stating mere guesses about what the code does not do as if fact. Occasionally the description may be incomprehensible gibberish.
+
+#You may treat this as an exercise and generate an essentially academic example.
+
+#Only output keywords. Since these keywords will be added as comments to code for an automated search to detect relevant files, only the keywords will be helpful, any other output will be unhelpful.
+
+#CZXWXcRMTo8EmM8i4d
+#}
+
+# DANGER: May generate AI LLM gibberish.
+# ATTENTION: Although 'add synonyms' may be a useful instruction to ensure more reliable keyword matches, semantic search may be a better approach to avoid raising the 'noise floor' on the search with equivalent concepts. Also, 'add synonyms' may cause phrases instead of single-words, with the same disadvantages.
+#  Ideally, the keywords should be rather technical, to convey as much conceptually disparate information as possible to a semantic search.
+_here_semanticAssist-askKeywords() {
+    cat << 'CZXWXcRMTo8EmM8i4d'
+
+For features implemented in the following blockquoted code please suggest relevant keywords. Prefer single-word technical terms, search terms, etc, keywords. These keywords will be matched by user queries doing a relevance percentile search for what these lines of code exemplify.
+
+Preceding description is provided only for context.
+
+Do not discuss incorrectness of the description or incompleteness of the code.
+
+Do not generate keywords for the description, only keywords for features implemented in the code. If the code has few features, provide appropriately fewer keywords. If the code has only a few comments, provide appropriately fewer keywords, including such appropriate keywords as 'comments'.
+
+Only output keywords. Since these keywords will be added as comments to code for an automated search to detect relevant files, only the keywords will be helpful, any other output will be unhelpful. Do not state 'here are the keywords' or similar.
+
+CZXWXcRMTo8EmM8i4d
+}
+
+# CAUTION: DANGER: NOT reliable for all AI LLM models.
+# correct (at least as far as tested)
+#  Llama 3.1 405b INSTRUCT
+#  DeepSeek-R1
+# broken
+#  Llama-4 Scout (unusually often recognizes valid output as gibberish)
+#  Llama 3.1 70b INSTRUCT
+#  Llama-augment
+#  Llama-4 Maverick
+#  DeepSeek-R1 14b
+#  DeepSeek-R1 32b
+#  DeepSeek-R1 Distill Llama 70b
+#  DeepSeek-R1 Distill Llama 8b
+# DANGER: Yes, you read that list correctly. Llama-4 Maverick , Llama 3.1 70b INSTRUCT , have incorrectly failed to recognize gibberish, whereas Llama-4 Scout and Llama 3.1 405b INSTRUCT have recognized gibberish correctly.
+#  Full DeepSeek-R1 is on the list for producing correct gibberish detection, but this relies on REASONING working around the inherent unpredictability of the input generating many extra tokens, which is much slower and much more expensive for a one-word answer with a very short input prompt.
+_here_semanticAssist-askGibberish() {
+    cat << 'CZXWXcRMTo8EmM8i4d'
+
+Should be AI autogenerated keywords here, intended to summarize concept from code for keyword search. Are these valid keywords, or did the AI LLM model apparently begin outputting gibberish?
+
+Keywords 'empty', 'blank', etc, for situations not applicable to search terms, may be valid.
+
+Contradictory keywords such as 'empty', 'blank', 'lack', etc, with 'terminal' and 'codeblock' are gibberish.
+
+Always err on the side of assuming the output is gibberish. Typos and misspellings are gibberish.
+
+If there is a phrase 'here are the keywords for the code', or similar, that is gibberish.
+
+If there is anything a reasonable person might be at least slightly offended by, that is gibberish.
+
+Please only output one word gibberish or valid. Do not output any other statements. Response will be processed automatically, so the one word answer either gibberish or valid will be helpful, any other output will be unhelpful.
+
+CZXWXcRMTo8EmM8i4d
+}
+
+_here_semanticAssist-askPolite() {
+    cat << 'CZXWXcRMTo8EmM8i4d'
+
+Might a reasonable person be at least slightly offended by this preceding text? Output only offended or safe, one word answer is needed for automation, one word offended or safe will be helpful, any other output will be unhelpful.
+
+CZXWXcRMTo8EmM8i4d
+}
+
+
+
+
+
+
+
+
+
+#export distill_projectDir=$(_getAbsoluteLocation ./_local/experiment) ; export distill_distillDir=$(_getAbsoluteLocation ./_local/experiment_distill) ; cp -f ./os/override/override_cygwin.sh ./_local/experiment/override_cygwin.sh ; ./ubiquitous_bash.sh _semanticAssist ./_local/experiment
+
+#./ubiquitous_bash.sh _distill_semanticAssist $(_getAbsoluteLocation ./_local/experiment/override_cygwin.sh) .prompt_description.md $(_getAbsoluteLocation ./_local)/experiment $(_getAbsoluteLocation ./_local)/experiment_distill $(_getAbsoluteLocation ./_local/experiment/override_cygwin.sh)
+# "$1" == origFile (eg. "$1" )
+# "$2" == outputExtension (eg. .special-$(uid).txt )
+# "$3" == projectDir (eg. "$scriptLocal"/knowledge/"$objectName" )
+# "$4" == distillDir (eg. "$scriptLocal"/knowledge_distill/"$objectName" )
+# "$5" == distillFile (eg. "$safeTmp"/"$inputName".special.txt )
+_distill_semanticAssist() {
+    [[ "$3" == "" ]] && return 0
+    [[ "$4" == "" ]] && return 0
+
+    local current_origFile_absoluteLocation=$(_getAbsoluteLocation "$1")
+    local current_origFile_absoluteFolder=$(_getAbsoluteFolder "$1")
+
+    local current_origFile_name=$(basename "$1")
+
+    local current_outputExtension="$2"
+
+    # CAUTION: Obviously these file parameters must be given as absolute locations .
+    local current_projectDir_absoluteLocation="$3"
+    local current_distillDir_absoluteLocation="$4"
+
+    local current_distillFile_absoluteFolder=${current_origFile_absoluteFolder/#$current_projectDir_absoluteLocation/$current_distillDir_absoluteLocation}
+    mkdir -p "$current_distillFile_absoluteFolder"
+
+    local current_distillFile_write_absoluteLocation="$current_distillFile_absoluteFolder"/"$current_origFile_name""$current_outputExtension"
+
+    local current_distillFile_read_absoluteLocation=$(_getAbsoluteLocation "$5")
+
+
+    rm -f "$current_distillFile_write_absoluteLocation" > /dev/null 2>&1
+    cp -f "$current_distillFile_read_absoluteLocation" "$current_distillFile_write_absoluteLocation" > /dev/null 2>&1
+}
+
+
+#./ubiquitous_bash.sh _format_distill_bash-promptResponse semanticAssist-ubiquitous_bash ./_local/experiment_distill
+
+_format_distill_bash-promptResponse() {
+    local current_objectName="$1"
+    [[ -z "$current_objectName" ]] && current_objectName="$objectName"
+
+    local current_directory="$2"
+    [[ -z "$current_directory" ]] && current_directory="$scriptLocal/knowledge_distill/$current_objectName"
+
+    local dataset="$current_directory"
+    local output_file="${current_directory}_finetuning-promptResponse.jsonl"
+
+    rm -f "$output_file" >/dev/null 2>&1
+
+    local segment_file prompt_file response_file prompt completion json_line
+
+    while IFS= read -r -d '' segment_file; do
+        prompt_file="$segment_file"
+
+        if [[ "$prompt_file" == *"prompt.md" ]]
+        then
+            response_file=$(echo "$prompt_file" | sed 's/\prompt\.md$/response.md/')
+            [[ ! -e "$response_file" ]] && response_file=$(echo "$prompt_file" | sed 's/\prompt\.md$/response.txt/')
+        fi
+
+        if [[ ! -e "$response_file" ]] || [[ ! -e "$prompt_file" ]]
+        then
+            ( _messagePlain_bad "bad: FAIL: missing: prompt/response files: $segment_file" >&2 ) > /dev/null
+            ( _messageError 'FAIL' >&2 ) > /dev/null
+            _stop 1
+            exit 1
+            return 1
+        fi
+
+        prompt=$(<"$prompt_file")
+        completion=$(<"$response_file")
+
+        # Now construct the correct "messages" object as required by OpenAI
+        #--arg system_content "You are an expert assistant that generates exemplary bash scripts according to best practices."
+        json_line=$(jq -cn \
+            --arg user_content "$prompt" \
+            --arg assistant_content "$completion" \
+            --arg system_content "" \
+            '{messages: [
+                {role: "system", content: $system_content},
+                {role: "user", content: $user_content},
+                {role: "assistant", content: $assistant_content}
+            ]}')
+
+        echo "$json_line" >> "$output_file"
+
+    done < <(find "$dataset" -type f -iname '*prompt.md' -print0 | sort -zV)
+
+    echo "JSONL file created successfully: $output_file" >&2
+}
+
+
+
+
+
+
+#export distill_projectDir=$(_getAbsoluteLocation ./_local/experiment) ; export distill_distillDir=$(_getAbsoluteLocation ./_local/experiment_distill) ; mkdir -p ./_local/experiment ; cp -f ./generic/findInfrastructure.sh ./_local/experiment/ ; ./ubiquitous_bash.sh _semanticAssist ./_local/experiment
+
+#export distill_projectDir=$(_getAbsoluteLocation ./_local/experiment) ; export distill_distillDir=$(_getAbsoluteLocation ./_local/experiment_distill) ; mkdir -p ./_local/experiment ; cp -f ./os/override/override_cygwin.sh ./_local/experiment/ ; ./ubiquitous_bash.sh _semanticAssist ./_local/experiment
+
+#export distill_projectDir=$(_getAbsoluteLocation ./_local/experiment) ; export distill_distillDir=$(_getAbsoluteLocation ./_local/experiment_distill) ; mkdir -p ./_local/experiment ; cp -f ./metaengine/typical/typical_metaengine_buffer.sh ./_local/experiment/ ; ./ubiquitous_bash.sh _semanticAssist ./_local/experiment
+
+_semanticAssist_bash_procedure() {
+    [[ "$1" == "" ]] && return 0
+    [[ ! -e "$1" ]] && return 0
+    local inputName=$(basename "$1")
+    local currentFileID=$(_uid)
+
+    # Enable during development to re-generate the semanticAssist comments for the same files repeatedly.
+    ( _messagePlain_nominal 'filter: '"$1" >&2 ) > /dev/null
+    cat "$1" | grep -v '########## semanticAssist:' > "$safeTmp"/"$inputName"-"$currentFileID".filtered.txt
+    mv -f "$safeTmp"/"$inputName"-"$currentFileID".filtered.txt "$1" > /dev/null
+
+
+    if cat "$1" | grep '########## semanticAssist:' > /dev/null 2>&1
+    then
+        ( _messagePlain_nominal 'skip: '"$1" >&2 ) > /dev/null
+        return 0
+    fi
+
+
+    ( _messagePlain_nominal 'boundaries: '"$1" >&2 ) > /dev/null
+    export corpus_script=$(_getAbsoluteLocation "$1")
+    _dataset_bash_from_lines "$1"
+
+
+    ( _messagePlain_nominal 'description: '"$1" >&2 ) > /dev/null
+    rm -f "$safeTmp"/"$inputName"-"$currentFileID".description.txt > /dev/null 2>&1
+    rm -f "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt > /dev/null 2>&1
+    rm -f "$safeTmp"/"$inputName"-"$currentFileID".tmp_output.txt > /dev/null 2>&1
+    _here_semanticAssist-askDescription >> "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt
+    echo '```bash' >> "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt
+    cat "$1" >> "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt
+    echo '```' >> "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt
+    echo '' >> "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt
+    _distill_semanticAssist "$1" .description_prompt.md "$distill_projectDir" "$distill_distillDir" "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt
+    _semanticAssist_loop "$1"
+    cat "$safeTmp"/"$inputName"-"$currentFileID".tmp_output.txt >> "$safeTmp"/"$inputName"-"$currentFileID".description.txt
+    _distill_semanticAssist "$1" .description_response.md "$distill_projectDir" "$distill_distillDir" "$safeTmp"/"$inputName"-"$currentFileID".description.txt
+
+
+    ( _messagePlain_nominal 'keywords-function-iteration: '"$1" >&2 ) > /dev/null
+    rm -f "$safeTmp"/"$inputName"-"$currentFileID".replacement.sh > /dev/null 2>&1
+    local currentIteration=-1
+    local currentIterationNext=0
+    local currentIterationNextNext=1
+    local currentLineBegin
+    local currentLineEnd
+    local currentLineBegin_next
+    local currentLineEnd_next
+    local currentGibberish
+    local currentIteration_gibberish
+    if [[ "${current_dataset_functionBounds[0]}" == "1" ]] # Skip iterating over 'currentLineBegin=1' case if the next iteration will also begin at 'currentLineBegin=1'.
+    then
+        let currentIteration++
+        let currentIterationNext++
+        let currentIterationNextNext++
+    fi
+    while ( [[ "$currentIteration" == "-1" ]] ) || ( [[ ${current_dataset_functionBounds[$currentIteration]} -lt "$current_dataset_totalLines" ]] && [[ "$currentIteration" -lt 30000 ]] && [[ ${current_dataset_functionBounds[$currentIteration]} != "" ]] ) # ( [[ "${current_dataset_functionBounds[0]}" == "1" ]] && [[ "$currentIteration" == 0 ]] )
+    do
+        currentLineBegin=$(( ${current_dataset_functionBounds[$currentIteration]} ))
+        [[ "$currentIteration" -lt 0 ]] && currentLineBegin=1
+
+        currentLineEnd=$(( ${current_dataset_functionBounds[$currentIterationNext]} - 1 ))
+        ! [[ ${current_dataset_functionBounds[$currentIterationNext]} -lt "$current_dataset_totalLines" ]] && currentLineEnd="$current_dataset_totalLines"
+
+        currentGibberish=""
+        currentIteration_gibberish=0
+        while [[ "$currentGibberish" != "valid" ]]
+        do
+            currentGibberish=""
+            rm -f "$safeTmp"/"$inputName"-"$currentFileID".keywords.txt > /dev/null 2>&1
+            rm -f "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt > /dev/null 2>&1
+            rm -f "$safeTmp"/"$inputName"-"$currentFileID".tmp_output.txt > /dev/null 2>&1
+
+            #echo '```description' >> "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt
+            cat "$safeTmp"/"$inputName"-"$currentFileID".description.txt >> "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt
+            #echo '```' >> "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt
+            echo '' >> "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt
+
+            _here_semanticAssist-askKeywords >> "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt
+
+            echo '```bash' >> "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt
+            sed -n "${currentLineBegin},${currentLineEnd}p" "$1" >> "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt
+            echo '```' >> "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt
+            echo '' >> "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt
+            _distill_semanticAssist "$1" .keywords"$currentIterationNext"_functionLine"$currentLineBegin"_prompt.md "$distill_projectDir" "$distill_distillDir" "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt
+            _semanticAssist_loop "$1" "_semanticAssist_bash-backend-lowLatency"
+            cat "$safeTmp"/"$inputName"-"$currentFileID".tmp_output.txt | tr ':\n\,;' '\ \ \ \ ' | tr -dc 'a-zA-Z0-9\-_\ ' | _filter_semanticAssist_nuisance | head -c 2500 > "$safeTmp"/"$inputName"-"$currentFileID".keywords.txt
+
+            [[ $(cat "$safeTmp"/"$inputName"-"$currentFileID".keywords.txt | wc -c | tr -dc '0-9') -lt 7 ]] && currentGibberish="deficient"
+
+            if [[ "$currentGibberish" != "deficient" ]]
+            then
+                if [[ "$ai_safety" != "inherent" ]] || [[ "$ai_safety" == "guard" ]]
+                then
+                    ( _messagePlain_probe 'guard: '"$1" >&2 ) > /dev/null
+                    rm -f "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt > /dev/null 2>&1
+                    rm -f "$safeTmp"/"$inputName"-"$currentFileID".tmp_output.txt > /dev/null 2>&1
+                    echo '' >> "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt
+                    #echo '```keywords' >> "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt
+                    cat "$safeTmp"/"$inputName"-"$currentFileID".keywords.txt >> "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt
+                    echo '' >> "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt
+                    #echo '```' >> "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt
+                    #echo '' >> "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt
+                    _here_semanticAssist-askPolite >> "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt
+                    _semanticAssist_loop "$1" "_semanticAssist_bash-backend-lowLatency-special"
+                    [[ "$currentGibberish" != "offended" ]] && [[ "$currentGibberish" != "gibberish" ]] && cat "$safeTmp"/"$inputName"-"$currentFileID".tmp_output.txt | tr -dc 'a-zA-Z0-9' | grep -i 'safe' > /dev/null 2>&1 && currentGibberish="valid"
+                    cat "$safeTmp"/"$inputName"-"$currentFileID".tmp_output.txt | tr -dc 'a-zA-Z0-9' | grep -i 'offended' > /dev/null 2>&1 && currentGibberish="offended"
+                fi
+
+                rm -f "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt > /dev/null 2>&1
+                rm -f "$safeTmp"/"$inputName"-"$currentFileID".tmp_output.txt > /dev/null 2>&1
+                _here_semanticAssist-askGibberish >> "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt
+                echo '' >> "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt
+                echo '```keywords' >> "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt
+                cat "$safeTmp"/"$inputName"-"$currentFileID".keywords.txt >> "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt
+                echo '' >> "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt
+                echo '```' >> "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt
+                echo '' >> "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt
+                _semanticAssist_loop "$1" "_semanticAssist_bash-backend-lowLatency-special"
+                [[ "$currentGibberish" != "offended" ]] && [[ "$currentGibberish" != "gibberish" ]] && cat "$safeTmp"/"$inputName"-"$currentFileID".tmp_output.txt | tr -dc 'a-zA-Z0-9' | grep -i 'valid' > /dev/null 2>&1 && currentGibberish="valid"
+                cat "$safeTmp"/"$inputName"-"$currentFileID".tmp_output.txt | tr -dc 'a-zA-Z0-9' | grep -i 'gibberish' > /dev/null 2>&1 && currentGibberish="gibberish"
+
+                if [[ "$currentGibberish" == "gibberish" ]]
+                then
+                    _distill_semanticAssist "$1" .gibberish"$currentIteration"_functionLine"$currentLineBegin"_gibberishDetect"$currentIteration_gibberish"_prompt.md "$distill_projectDir" "$distill_distillDir" "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt
+                    _distill_semanticAssist "$1" .gibberish"$currentIteration"_functionLine"$currentLineBegin"_gibberishDetect"$currentIteration_gibberish"_response.md "$distill_projectDir" "$distill_distillDir" "$safeTmp"/"$inputName"-"$currentFileID".tmp_output.txt
+                fi
+            fi
+
+            if [[ "$currentGibberish" == "deficient" ]]
+            then
+                ( _messagePlain_warn 'warn: deficient: '"$1"': '"$currentLineBegin"':' | tr -d '\n' | cat - "$safeTmp"/"$inputName"-"$currentFileID".keywords.txt >&2 ; echo >&2 ) > /dev/null
+            fi
+            if [[ "$currentGibberish" == "offended" ]]
+            then
+                ( _messagePlain_bad 'bad: offended: '"$1"': '"$currentLineBegin" >&2 ) > /dev/null
+                sleep 2
+            fi
+            if [[ "$currentGibberish" == "gibberish" ]]
+            then
+                ( _messagePlain_warn 'warn: gibberish: '"$1"': '"$currentLineBegin"':' | tr -d '\n' | cat - "$safeTmp"/"$inputName"-"$currentFileID".keywords.txt >&2 ; echo >&2 ) > /dev/null
+            fi
+
+            currentIteration_gibberish=$(( currentIteration_gibberish + 1 ))
+            if [[ "$currentIteration_gibberish" -gt 25 ]]
+            then
+                #( _messageError 'FAIL: gibberish: '"$1": "$currentLineBegin" >&2 ) > /dev/null
+                #return 1
+                #exit 1
+                _messagePlain_bad 'bad: gibberish: '"$1"': '"$currentLineBegin" >&2
+                rm -f "$safeTmp"/"$inputName"-"$currentFileID".keywords.txt > /dev/null 2>&1
+                echo > "$safeTmp"/"$inputName"-"$currentFileID".keywords.txt
+                currentGibberish="valid"
+            fi
+        done
+
+        [[ "$currentGibberish" == "valid" ]] && _distill_semanticAssist "$1" .keywords"$currentIterationNext"_functionLine"$currentLineBegin"_response.md "$distill_projectDir" "$distill_distillDir" "$safeTmp"/"$inputName"-"$currentFileID".keywords.txt
+
+        if [[ "$currentLineBegin" == "1" ]] && head -n1 "$1" | grep '^#!/' > /dev/null 2>&1
+        then
+            head -n1 "$1" >> "$safeTmp"/"$inputName"-"$currentFileID".replacement.sh
+            currentLineBegin=2
+            #currentLineEnd="$currentLineEnd"
+            echo -n '########## semanticAssist: ' >> "$safeTmp"/"$inputName"-"$currentFileID".replacement.sh
+            cat "$safeTmp"/"$inputName"-"$currentFileID".keywords.txt | tr ':\n\,;' '\ \ \ \ ' | tr -dc 'a-zA-Z0-9\-_\ ' | head -c 2500 >> "$safeTmp"/"$inputName"-"$currentFileID".replacement.sh
+            echo '' >> "$safeTmp"/"$inputName"-"$currentFileID".replacement.sh
+            sed -n "${currentLineBegin},${currentLineEnd}p" "$1" >> "$safeTmp"/"$inputName"-"$currentFileID".replacement.sh
+        else
+            echo -n '########## semanticAssist: ' >> "$safeTmp"/"$inputName"-"$currentFileID".replacement.sh
+            cat "$safeTmp"/"$inputName"-"$currentFileID".keywords.txt | tr ':\n\,;' '\ \ \ \ ' | tr -dc 'a-zA-Z0-9\-_\ ' | head -c 2500 >> "$safeTmp"/"$inputName"-"$currentFileID".replacement.sh
+            echo '' >> "$safeTmp"/"$inputName"-"$currentFileID".replacement.sh
+            sed -n "${currentLineBegin},${currentLineEnd}p" "$1" >> "$safeTmp"/"$inputName"-"$currentFileID".replacement.sh
+        fi
+
+        let currentIteration++
+        let currentIterationNext++
+        let currentIterationNextNext++
+    done
+    mv -f "$safeTmp"/"$inputName"-"$currentFileID".replacement.sh "$1" > /dev/null
+
+
+    ( _messagePlain_nominal 'keywords-lines-iteration: '"$1" >&2 ) > /dev/null
+
+    rm -f "$safeTmp"/"$inputName"-"$currentFileID".replacement.sh > /dev/null 2>&1
+    local currentTotalLines=$(wc -l < "$1")
+    # ATTENTION: Suggest advancing ~150lines or ~4000chars before adding next comment.
+    local currentRegionLines_advance=150
+    local currentRegionLines_overlap=100
+    local currentRegionLines=$(( currentRegionLines_advance + currentRegionLines_overlap ))
+    currentLineBegin=1
+    while [[ "$currentLineBegin" -lt "$currentTotalLines" ]]
+    do
+        #currentLineBegin
+        currentLineEnd=$(( currentLineBegin + currentRegionLines_advance - 1))
+        #currentLineEnd=$(( currentLineBegin + currentRegionLines ))
+        [[ "$currentLineEnd" -gt "$currentTotalLines" ]] && currentLineEnd="$currentTotalLines"
+
+        currentGibberish=""
+        currentIteration_gibberish=0
+        while [[ "$currentGibberish" != "valid" ]]
+        do
+            currentGibberish=""
+            rm -f "$safeTmp"/"$inputName"-"$currentFileID".keywords.txt > /dev/null 2>&1
+            rm -f "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt > /dev/null 2>&1
+            rm -f "$safeTmp"/"$inputName"-"$currentFileID".tmp_output.txt > /dev/null 2>&1
+
+            #echo '```description' >> "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt
+            cat "$safeTmp"/"$inputName"-"$currentFileID".description.txt >> "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt
+            #echo '```' >> "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt
+            echo '' >> "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt
+
+            _here_semanticAssist-askKeywords >> "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt
+
+            echo '```bash' >> "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt
+            #sed -n "${currentLineBegin},${currentLineEnd}p" "$1" | grep -v '########## semanticAssist:' >> "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt
+            sed -n "${currentLineBegin},"$(( currentLineBegin + currentRegionLines ))"p" "$1" | grep -v '########## semanticAssist:' >> "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt
+            echo '```' >> "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt
+            echo '' >> "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt
+            _distill_semanticAssist "$1" .keywords"$currentIterationNext"_line"$currentLineBegin"_prompt.md "$distill_projectDir" "$distill_distillDir" "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt
+            _semanticAssist_loop "$1" "_semanticAssist_bash-backend-lowLatency"
+            cat "$safeTmp"/"$inputName"-"$currentFileID".tmp_output.txt | tr ':\n\,;' '\ \ \ \ ' | tr -dc 'a-zA-Z0-9\-_\ ' | _filter_semanticAssist_nuisance | head -c 2500 > "$safeTmp"/"$inputName"-"$currentFileID".keywords.txt
+
+            [[ $(cat "$safeTmp"/"$inputName"-"$currentFileID".keywords.txt | wc -c | tr -dc '0-9') -lt 7 ]] && currentGibberish="deficient"
+
+            if [[ "$currentGibberish" != "deficient" ]]
+            then
+                if [[ "$ai_safety" != "inherent" ]] || [[ "$ai_safety" == "guard" ]]
+                then
+                    ( _messagePlain_probe 'guard: '"$1" >&2 ) > /dev/null
+                    rm -f "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt > /dev/null 2>&1
+                    rm -f "$safeTmp"/"$inputName"-"$currentFileID".tmp_output.txt > /dev/null 2>&1
+                    echo '' >> "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt
+                    #echo '```keywords' >> "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt
+                    cat "$safeTmp"/"$inputName"-"$currentFileID".keywords.txt >> "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt
+                    echo '' >> "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt
+                    #echo '```' >> "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt
+                    #echo '' >> "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt
+                    _here_semanticAssist-askPolite >> "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt
+                    _semanticAssist_loop "$1" "_semanticAssist_bash-backend-lowLatency-special"
+                    [[ "$currentGibberish" != "offended" ]] && [[ "$currentGibberish" != "gibberish" ]] && cat "$safeTmp"/"$inputName"-"$currentFileID".tmp_output.txt | tr -dc 'a-zA-Z0-9' | grep -i 'safe' > /dev/null 2>&1 && currentGibberish="valid"
+                    cat "$safeTmp"/"$inputName"-"$currentFileID".tmp_output.txt | tr -dc 'a-zA-Z0-9' | grep -i 'offended' > /dev/null 2>&1 && currentGibberish="offended"
+                fi
+
+                rm -f "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt > /dev/null 2>&1
+                rm -f "$safeTmp"/"$inputName"-"$currentFileID".tmp_output.txt > /dev/null 2>&1
+                _here_semanticAssist-askGibberish >> "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt
+                echo '' >> "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt
+                echo '```keywords' >> "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt
+                cat "$safeTmp"/"$inputName"-"$currentFileID".keywords.txt >> "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt
+                echo '' >> "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt
+                echo '```' >> "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt
+                echo '' >> "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt
+                _semanticAssist_loop "$1" "_semanticAssist_bash-backend-lowLatency-special"
+                [[ "$currentGibberish" != "offended" ]] && [[ "$currentGibberish" != "gibberish" ]] && cat "$safeTmp"/"$inputName"-"$currentFileID".tmp_output.txt | tr -dc 'a-zA-Z0-9' | grep -i 'valid' > /dev/null 2>&1 && currentGibberish="valid"
+                cat "$safeTmp"/"$inputName"-"$currentFileID".tmp_output.txt | tr -dc 'a-zA-Z0-9' | grep -i 'gibberish' > /dev/null 2>&1 && currentGibberish="gibberish"
+
+                if [[ "$currentGibberish" == "gibberish" ]]
+                then
+                    _distill_semanticAssist "$1" .gibberish"$currentIteration"_line"$currentLineBegin"_gibberishDetect"$currentIteration_gibberish"_prompt.md "$distill_projectDir" "$distill_distillDir" "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt
+                    _distill_semanticAssist "$1" .gibberish"$currentIteration"_line"$currentLineBegin"_gibberishDetect"$currentIteration_gibberish"_response.md "$distill_projectDir" "$distill_distillDir" "$safeTmp"/"$inputName"-"$currentFileID".tmp_output.txt
+                fi
+            fi
+
+            if [[ "$currentGibberish" == "deficient" ]]
+            then
+                ( _messagePlain_warn 'warn: deficient: '"$1"': '"$currentLineBegin"':' | tr -d '\n' | cat - "$safeTmp"/"$inputName"-"$currentFileID".keywords.txt >&2 ; echo >&2 ) > /dev/null
+            fi
+            if [[ "$currentGibberish" == "offended" ]]
+            then
+                ( _messagePlain_bad 'bad: offended: '"$1"': '"$currentLineBegin" >&2 ) > /dev/null
+                sleep 2
+            fi
+            if [[ "$currentGibberish" == "gibberish" ]]
+            then
+                ( _messagePlain_warn 'warn: gibberish: '"$1"': '"$currentLineBegin"':' | tr -d '\n' | cat - "$safeTmp"/"$inputName"-"$currentFileID".keywords.txt >&2 ; echo >&2 ) > /dev/null
+            fi
+
+            currentIteration_gibberish=$(( currentIteration_gibberish + 1 ))
+            if [[ "$currentIteration_gibberish" -gt 25 ]]
+            then
+                #( _messageError 'FAIL: gibberish: '"$1": "$currentLineBegin" >&2 ) > /dev/null
+                #return 1
+                #exit 1
+                rm -f "$safeTmp"/"$inputName"-"$currentFileID".keywords.txt > /dev/null 2>&1
+                echo > "$safeTmp"/"$inputName"-"$currentFileID".keywords.txt
+                currentGibberish="valid"
+            fi
+        done
+
+        [[ "$currentGibberish" == "valid" ]] && _distill_semanticAssist "$1" .keywords"$currentIterationNext"_line"$currentLineBegin"_response.md "$distill_projectDir" "$distill_distillDir" "$safeTmp"/"$inputName"-"$currentFileID".keywords.txt
+
+        if [[ "$currentLineBegin" == "1" ]] && head -n1 "$1" | grep '^#!/' > /dev/null 2>&1
+        then
+            head -n1 "$1" >> "$safeTmp"/"$inputName"-"$currentFileID".replacement.sh
+            currentLineBegin=2
+            #currentLineEnd="$currentLineEnd"
+            echo -n '########## semanticAssist: ' >> "$safeTmp"/"$inputName"-"$currentFileID".replacement.sh
+            cat "$safeTmp"/"$inputName"-"$currentFileID".keywords.txt | tr ':\n\,;' '\ \ \ \ ' | tr -dc 'a-zA-Z0-9\-_\ ' | head -c 2500 >> "$safeTmp"/"$inputName"-"$currentFileID".replacement.sh
+            echo '' >> "$safeTmp"/"$inputName"-"$currentFileID".replacement.sh
+            sed -n "${currentLineBegin},${currentLineEnd}p" "$1" >> "$safeTmp"/"$inputName"-"$currentFileID".replacement.sh
+        else
+            echo -n '########## semanticAssist: ' >> "$safeTmp"/"$inputName"-"$currentFileID".replacement.sh
+            cat "$safeTmp"/"$inputName"-"$currentFileID".keywords.txt | tr ':\n\,;' '\ \ \ \ ' | tr -dc 'a-zA-Z0-9\-_\ ' | head -c 2500 >> "$safeTmp"/"$inputName"-"$currentFileID".replacement.sh
+            echo '' >> "$safeTmp"/"$inputName"-"$currentFileID".replacement.sh
+            sed -n "${currentLineBegin},${currentLineEnd}p" "$1" >> "$safeTmp"/"$inputName"-"$currentFileID".replacement.sh
+        fi
+
+
+        currentLineBegin=$(( currentLineBegin + currentRegionLines_advance ))
+    done
+    mv -f "$safeTmp"/"$inputName"-"$currentFileID".replacement.sh "$1" > /dev/null
+
+
+
+
+
+
+    rm -f "$safeTmp"/"$inputName"-"$currentFileID".keywords.txt > /dev/null 2>&1
+    rm -f "$safeTmp"/"$inputName"-"$currentFileID".replacement.sh > /dev/null 2>&1
+    rm -f "$safeTmp"/"$inputName"-"$currentFileID".description.txt > /dev/null 2>&1
+    rm -f "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt > /dev/null 2>&1
+    rm -f "$safeTmp"/"$inputName"-"$currentFileID".tmp_output.txt > /dev/null 2>&1
+}
+
+
+
+#./ubiquitous_bash.sh _semanticAssist
+
+
+# ATTENTION: Override with 'ops.sh' or similar if appropriate.
+#export ai_safety="guard"
+##export ai_safety="inherent"
+
+_semanticAssist_bash-backend() {
+   _convert_bash-backend "$@"
+}
+
+_semanticAssist_bash-backend-lowLatency() {
+    _convert_bash-backend-lowLatency "$@"
+}
+
+# ATTENTION: Override with 'ops.sh' or similar if appropriate.
+# CAUTION: DANGER: Keywords generation is more prone to gibberish, special choice of AI LLM model may be required to detect. See documentation for the '_here_semanticAssist-askGibberish' prompt.
+_semanticAssist_bash-backend-lowLatency-special() {
+    _convert_bash-backend-lowLatency "$@"
+
+    ##provider: { "order": ["SambaNova", "Fireworks", "Hyperbolic"]
+    #jq -Rs '{ model: "meta-llama/llama-3.1-405b-instruct", provider: { "order": ["Lambda", "Fireworks"], "sort": "latency" }, messages: [{"role": "user", "content": .}] }' | curl -fsS --max-time 120 --keepalive-time 300 --compressed --tcp-fastopen --http2 -X POST https://openrouter.ai/api/v1/chat/completions -H "Content-Type: application/json" -H "Authorization: Bearer $OPENROUTER_API_KEY" --data-binary @- | jq -r '.choices[0].message.content'
+}
+
+# ATTENTION: Override with 'ops.sh' or similar if appropriate.
+# (ie. usually to change parallelization for high-latency APIs, providers, etc)
+_semanticAssist-dispatch() {
+    [[ "$1" == "" ]] && return 1
+    [[ ! -e "$1" ]] && return 1
+    echo 'quick brown fox' | _semanticAssist_bash-backend > /dev/null
+
+    #-s 4096
+    #-P $(nproc)
+    find "$1" -type f -name '*.sh' -print0 | xargs -0 -x -L 1 -P 1 bash -c '"'"$scriptAbsoluteLocation"'"'' --embed _semanticAssist_bash_procedure "$@"' _
+}
+
+
+# "$1" == original file
+# "$2" == backend function (optional)
+# "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt
+# "$safeTmp"/"$inputName"-"$currentFileID".tmp_output.txt
+_semanticAssist_loop() {
+    rm -f "$safeTmp"/"$inputName"-"$currentFileID".tmp_output.txt
+
+    local currentBackendFunction="$2"
+    [[ "$currentBackendFunction" == "" ]] && currentBackendFunction="_semanticAssist_bash-backend"
+
+    local currentIteration=0
+    local currentExitStatus=1
+    while [[ "$currentExitStatus" != "0" ]] && ! [[ -s "$safeTmp"/"$inputName"-"$currentFileID".tmp_output.txt ]] && [[ "$currentIteration" -lt 5 ]]
+    do
+        [[ "$currentIteration" -gt 0 ]] && ( _messagePlain_probe ' retry: '"$1" >&2 ) > /dev/null
+        [[ "$currentIteration" -gt 0 ]] && sleep 7
+        [[ "$currentIteration" -gt 1 ]] && sleep 90
+
+        ( set -o pipefail ; cat "$safeTmp"/"$inputName"-"$currentFileID".tmp_input.txt | "$currentBackendFunction" >> "$safeTmp"/"$inputName"-"$currentFileID".tmp_output.txt )
+        currentExitStatus="$?"
+        sleep 1
+
+        currentIteration=$(( currentIteration + 1 ))
+    done
+}
+
+
+_semanticAssist_procedure_procedure() {
+    local currentDirectory="$1"
+    if [[ "$currentDirectory" == "" ]]
+    then
+        currentDirectory="$scriptLocal"/knowledge/"$objectName"
+
+        export distill_projectDir="$scriptLocal"/knowledge/"$objectName"
+        export distill_distillDir="$scriptLocal"/knowledge_distill/"$objectName"
+
+        type _knowledge-"$objectName" > /dev/null 2>&1 && _knowledge-"$objectName"
+        #[[ "$objectName" == "ubiquitous_bash" ]] && _knowledge-ubiquitous_bash
+        _safeRMR "$scriptLocal"/knowledge_distill/"$objectName"
+    fi
+    #[[ "$distill_distillDir" != "" ]] && [[ -e "$distill_distillDir" ]] && _safeRMR "$distill_distillDir"
+
+    currentDirectory=$(_getAbsoluteLocation "$currentDirectory")
+    [[ ! -e "$currentDirectory" ]] && ( _messageError 'FAIL' >&2 ) > /dev/null && return 1
+
+    cd "$scriptLocal"
+    if ! cd "$currentDirectory"
+    then
+        ( _messageError 'FAIL' >&2 ) > /dev/null && return 1
+    fi
+
+    _semanticAssist-dispatch "$currentDirectory"
+    sleep 0.1
+
+    ( _messagePlain_probe 'done: _semanticAssist ...' >&2 ) > /dev/null
+}
+_semanticAssist_sequence() {
+    _start
+
+    _semanticAssist_procedure_procedure "$@"
+
+    _stop
+}
+_semanticAssist() {
+    "$scriptAbsoluteLocation" _semanticAssist_sequence "$@"
+}
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+# NOTICE: Strongly recommended to subsequently add autogenerated annotation to improve Retrieval-Augmented-Generation (RAG) with _semanticAssist .
+
+_knowledge-ubiquitous_bash() {
+    [[ "$objectName" != "ubiquitous_bash" ]] && _stop 1
+
+    _safeRMR "$scriptLocal"/knowledge/ubiquitous_bash
+    mkdir -p "$scriptLocal"/knowledge/ubiquitous_bash
+
+    mkdir -p "$scriptLocal"/knowledge/ubiquitous_bash/_lib
+    cp -r "$scriptAbsoluteFolder"/_lib/_build-fallback-ops.sh "$scriptLocal"/knowledge/ubiquitous_bash/_lib/
+
+
+    #mkdir -p "$scriptLocal"/knowledge/ubiquitous_bash/_lib/kit/install/cloud/cloud-init/zRotten/zMinimal
+    #cp -r "$scriptAbsoluteFolder"/_lib/kit/install/cloud/cloud-init/zRotten/zMinimal "$scriptLocal"/knowledge/ubiquitous_bash/_lib/kit/install/cloud/cloud-init/zRotten
+
+    mkdir -p "$scriptLocal"/knowledge/ubiquitous_bash/_lib/kit/install/cloud/cloud-init/zRotten/zMinimal
+    cp "$scriptAbsoluteFolder"/_lib/kit/install/cloud/cloud-init/zRotten/zMinimal/rotten_install.sh "$scriptLocal"/knowledge/ubiquitous_bash/_lib/kit/install/cloud/cloud-init/zRotten/zMinimal/
+
+    cp -r "$scriptAbsoluteFolder"/_config "$scriptLocal"/knowledge/ubiquitous_bash/
+    cp -r "$scriptAbsoluteFolder"/.github "$scriptLocal"/knowledge/ubiquitous_bash/
+    cp -r "$scriptAbsoluteFolder"/.devcontainer "$scriptLocal"/knowledge/ubiquitous_bash/
+
+    cp -r "$scriptAbsoluteFolder"/ai "$scriptLocal"/knowledge/ubiquitous_bash/
+    cp -r "$scriptAbsoluteFolder"/blockchain "$scriptLocal"/knowledge/ubiquitous_bash/
+    cp -r "$scriptAbsoluteFolder"/build "$scriptLocal"/knowledge/ubiquitous_bash/
+    cp -r "$scriptAbsoluteFolder"/generic "$scriptLocal"/knowledge/ubiquitous_bash/
+    cp -r "$scriptAbsoluteFolder"/hardware "$scriptLocal"/knowledge/ubiquitous_bash/
+    cp -r "$scriptAbsoluteFolder"/instrumentation "$scriptLocal"/knowledge/ubiquitous_bash/
+    cp -r "$scriptAbsoluteFolder"/labels "$scriptLocal"/knowledge/ubiquitous_bash/
+    cp -r "$scriptAbsoluteFolder"/metaengine "$scriptLocal"/knowledge/ubiquitous_bash/
+    cp -r "$scriptAbsoluteFolder"/os "$scriptLocal"/knowledge/ubiquitous_bash/
+    cp -r "$scriptAbsoluteFolder"/queue "$scriptLocal"/knowledge/ubiquitous_bash/
+    cp -r "$scriptAbsoluteFolder"/shortcuts "$scriptLocal"/knowledge/ubiquitous_bash/
+    cp -r "$scriptAbsoluteFolder"/special "$scriptLocal"/knowledge/ubiquitous_bash/
+    cp -r "$scriptAbsoluteFolder"/structure "$scriptLocal"/knowledge/ubiquitous_bash/
+    cp -r "$scriptAbsoluteFolder"/virtualization "$scriptLocal"/knowledge/ubiquitous_bash/
+
+    cp "$scriptAbsoluteFolder"/_anchor "$scriptLocal"/knowledge/ubiquitous_bash/
+    cp "$scriptAbsoluteFolder"/_anchor.bat "$scriptLocal"/knowledge/ubiquitous_bash/
+
+    cp "$scriptAbsoluteFolder"/lean.py "$scriptLocal"/knowledge/ubiquitous_bash/
+
+    cp "$scriptAbsoluteFolder"/scrap-cygwin.txt "$scriptLocal"/knowledge/ubiquitous_bash/
+
+    cp "$scriptAbsoluteFolder"/license.txt "$scriptLocal"/knowledge/ubiquitous_bash/
+
+
+    mkdir -p "$scriptLocal"/knowledge/ubiquitous_bash/_local/ubcp
+    cp -r "$scriptAbsoluteFolder"/_local/ubcp/_upstream "$scriptLocal"/knowledge/ubiquitous_bash/_local/ubcp/
+    cp -r "$scriptAbsoluteFolder"/_local/ubcp/conemu "$scriptLocal"/knowledge/ubiquitous_bash/_local/ubcp/
+    cp -r "$scriptAbsoluteFolder"/_local/ubcp/overlay "$scriptLocal"/knowledge/ubiquitous_bash/_local/ubcp/
+
+    cp "$scriptAbsoluteFolder"/_local/ubcp/.gitignore "$scriptLocal"/knowledge/ubiquitous_bash/_local/ubcp/
+    cp "$scriptAbsoluteFolder"/_local/ubcp/agpl-3.0.txt "$scriptLocal"/knowledge/ubiquitous_bash/_local/ubcp/
+    cp "$scriptAbsoluteFolder"/_local/ubcp/cygwin-portable-installer-config.cmd "$scriptLocal"/knowledge/ubiquitous_bash/_local/ubcp/
+    cp "$scriptAbsoluteFolder"/_local/ubcp/cygwin-portable-updater.cmd "$scriptLocal"/knowledge/ubiquitous_bash/_local/ubcp/
+    cp "$scriptAbsoluteFolder"/_local/ubcp/cygwin-portable.cmd "$scriptLocal"/knowledge/ubiquitous_bash/_local/ubcp/
+    cp "$scriptAbsoluteFolder"/_local/ubcp/gpl-2.0.txt "$scriptLocal"/knowledge/ubiquitous_bash/_local/ubcp/
+    cp "$scriptAbsoluteFolder"/_local/ubcp/gpl-3.0.txt "$scriptLocal"/knowledge/ubiquitous_bash/_local/ubcp/
+    cp "$scriptAbsoluteFolder"/_local/ubcp/license.txt "$scriptLocal"/knowledge/ubiquitous_bash/_local/ubcp/
+    cp "$scriptAbsoluteFolder"/_local/ubcp/README.md "$scriptLocal"/knowledge/ubiquitous_bash/_local/ubcp/
+    cp "$scriptAbsoluteFolder"/_local/ubcp/ubcp_rename-to-enable.cmd "$scriptLocal"/knowledge/ubiquitous_bash/_local/ubcp/
+    cp "$scriptAbsoluteFolder"/_local/ubcp/ubcp-cygwin-portable-installer.cmd "$scriptLocal"/knowledge/ubiquitous_bash/_local/ubcp/
+    cp "$scriptAbsoluteFolder"/_local/ubcp/ubcp.cmd "$scriptLocal"/knowledge/ubiquitous_bash/_local/ubcp/
+    cp "$scriptAbsoluteFolder"/_local/ubcp/zDANGER-symlinks.txt "$scriptLocal"/knowledge/ubiquitous_bash/_local/ubcp/
+    cp "$scriptAbsoluteFolder"/_local/ubcp/zWARNING-path.txt "$scriptLocal"/knowledge/ubiquitous_bash/_local/ubcp/
+
+
+
+    cp -r "$scriptAbsoluteFolder"/_doc "$scriptLocal"/knowledge/ubiquitous_bash/
+
+    cp "$scriptAbsoluteFolder"/README.sh.out.txt "$scriptLocal"/knowledge/ubiquitous_bash/
+
+
+    #rm -f "$scriptLocal"/knowledge/ubiquitous_bash/.devcontainer/README.md
+    rm -f "$scriptLocal"/knowledge/ubiquitous_bash/build/haskell/README.html
+    rm -f "$scriptLocal"/knowledge/ubiquitous_bash/build/haskell/README.md
+    rm -f "$scriptLocal"/knowledge/ubiquitous_bash/build/haskell/README.mediawiki.txt
+    rm -f "$scriptLocal"/knowledge/ubiquitous_bash/build/haskell/README.pdf
+    rm -f "$scriptLocal"/knowledge/ubiquitous_bash/build/haskell/README.sh
+    rm -f "$scriptLocal"/knowledge/ubiquitous_bash/build/haskell/README_presentation.html
+    #rm -f "$scriptLocal"/knowledge/ubiquitous_bash/queue/aggregator/README.md
+    #rm -f "$scriptLocal"/knowledge/ubiquitous_bash/README.sh.out.txt
+    #rm -f "$scriptLocal"/knowledge/ubiquitous_bash/_config/README.md
+    #rm -f "$scriptLocal"/knowledge/ubiquitous_bash/_doc/equations-space/README.sh
+    #rm -f "$scriptLocal"/knowledge/ubiquitous_bash/_doc/queue/broadcastPipe/README.md
+    #rm -f "$scriptLocal"/knowledge/ubiquitous_bash/_lib/kit/install/cloud/cloud-init/zRotten/specialized/croc/README.md
+    #rm -f "$scriptLocal"/knowledge/ubiquitous_bash/_lib/kit/install/cloud/cloud-init/zRotten/zMinimal/README.md
+    #rm -f "$scriptLocal"/knowledge/ubiquitous_bash/_local/ubcp/README.md
+    #rm -f "$scriptLocal"/knowledge/ubiquitous_bash/_local/ubcp/_upstream/README.md
+
+
+
+    rm -f "$scriptLocal"/knowledge/ubiquitous_bash/ai/dataset/_ref/OBSOLETE-corpus.sh
+    rm -f "$scriptLocal"/knowledge/ubiquitous_bash/shortcuts/git/_ref/_scratch-diag*.txt
+    rm -f "$scriptLocal"/knowledge/ubiquitous_bash/shortcuts/git/_ref/*OBSOLETE*
+}
+
+
+
+#https://stackoverflow.com/questions/15432156/display-filename-before-matching-line-grep
+_grepFileLine() {
+	grep -n "$@" /dev/null
+}
+
+_findFunction() {
+	#-name '*.sh'
+	#-not -path "./_local/*"
+	#find ./blockchain -name '*.sh' -type f -size -10000k -exec grep -n "$@" '{}' /dev/null \;
+	#find ./generic -name '*.sh' -type f -size -10000k -exec grep -n "$@" '{}' /dev/null \;
+	#find ./instrumentation -name '*.sh' -type f -size -10000k -exec grep -n "$@" '{}' /dev/null \;
+	#find ./labels -name '*.sh' -type f -size -10000k -exec grep -n "$@" '{}' /dev/null \;
+	#find ./os -name '*.sh' -type f -size -10000k -exec grep -n "$@" '{}' /dev/null \;
+	#find ./shortcuts -name '*.sh' -type f -size -10000k -exec grep -n "$@" '{}' /dev/null \;
+	#find . -name '*.sh' -type f -size -10000k -exec grep -n "$@" '{}' /dev/null \;
+
+	find . -not -path "./_local/*" -name '*.sh' -type f -size -3000k -exec grep -n "$@" '{}' /dev/null \;
+}
+
+
+
+_octave_terse() {
+	_safe_declare_uid
+
+	if [[ "$1" != "" ]]
+	then
+		_safeEcho_newline "$@" | octave --quiet --silent --no-window-system --no-gui 2>/dev/null | _octave_filter-messages
+		return
+	fi
+
+	octave --quiet --silent --no-window-system --no-gui 2>/dev/null | _octave_filter-messages
+	return
+}
+
+_octave() {
+	if [[ "$1" != "" ]]
+	then
+		_safe_declare_uid
+		_octave_terse "$@"
+		return
+	fi
+
+	_safe_declare_uid
+	octave --quiet --silent --no-window-system --no-gui "$@"
+	return
+}
+
+# ATTENTION: EXAMPLE: echo 'solve(x == y * 2, y)' | _octave_pipe
+_octave_pipe() {
+	_safe_declare_uid
+
+	_octave_terse "$@"
+	#octave --quiet --silent --no-window-system --no-gui "$@" 2>/dev/null | _octave_filter-messages
+}
+
+# ATTENTION: EXAMPLE: _octave_script 'octave_script.m'
+# echo 'solve(x == y * 2, y)' > octave_script.m
+_octave_script() {
+	local currentFile="$1"
+	shift
+
+	_safe_declare_uid
+
+	cat "$currentFile" | _octave_terse "$@"
+
+	#octave --quiet --silent --no-window-system --no-gui "$@" 2>/dev/null | _octave_filter-messages
+}
+
+
+
+
+
+
+
+
+
+
+
+_octave_filter-messages() {
+	grep -v 'Symbolic pkg .*: Python communication link active, SymPy v' | grep -v '_____' | grep -v '^$' | sed 's/^ans = //' | sed 's/^(sym) //'
+	#cat
+}
+
+
+
+
+
+
+# solve '( y  == x * 2, x)'
+
+_octave_solve() {
+	_safeEcho_newline solve"$@" | _octave_pipe
+}
+_octave_nsolve() {
+	_safeEcho_newline nsolve"$@" | _octave_pipe
+}
+
+if type -p octave > /dev/null 2>&1
+then
+	_solve() {
+		_octave_solve "$@"
+	}
+	solve() {
+		_octave_solve "$@"
+	}
+	nsolve() {
+		_octave_nsolve "$@"
+	}
+
+	# WARNING: Mostly intended as apparent MSW/Cygwin workaround. May cause incorrectly written equations with inappropriate non-numeric output to pass regression tests.
+	_clc() {
+		# https://www.cyberciti.biz/faq/linux-unix-bash-check-interactive-shell/
+		if [ -z "$PS1" ]
+		then
+			_octave "$@" | tr -dc '0-9.'
+			return
+		fi
+
+		_octave "$@"
+	}
+	clc() {
+		_octave "$@"
+	}
+	c() {
+		_octave "$@"
+	}
+
+	_num() {
+		_clc "$@" | tr -dc '0-9.'
+	}
+fi
+
+
+
+
+
+
+_test_devgnuoctave() {
+	_wantGetDep octave
+	_wantGetDep octave-cli
+
+
+	_wantGetDep octave-config
+	_wantGetDep mkoctfile
+
+
+
+
+	###_wantGetDep 'x86_64-linux-gnu/liboctave.so'
+	###_wantGetDep 'x86_64-linux-gnu/liboctinterp.so'
+
+
+	###_wantGetDep 'x86_64-linux-gnu/octave/site/oct/x86_64-pc-linux-gnu/libsbml5/OutputSBML.mex'
+	###_wantGetDep 'x86_64-linux-gnu/octave/site/oct/x86_64-pc-linux-gnu/libsbml5/TranslateSBML.mex'
+
+	_wantGetDep 'x86_64-linux-gnu/qt5/plugins/cantor/backends/cantor_octavebackend.so'
+
+
+
+
+	#if ! _wantGetDep dh_octave_check
+	#then
+		#! _typeShare 'dh-octave/install-pkg.m' && _wantGetDep dh-octave/install-pkg.m
+	#fi
+
+
+
+	_tryExec '_test_devgnuoctave-extra'
+
+
+
+	return 0
+}
+
+
+_test_devgnuoctave_wantGetDep-octavePackage-internal() {
+	if [[ "$1" == "symbolic" ]]
+	then
+		_wantGetDep 'python3/dist-packages/sympy/__init__.py'
+		_wantGetDep 'python3/dist-packages/isympy.py'
+
+		"$scriptAbsoluteLocation" _octave pkg list | grep symbolic > /dev/null && return 0
+
+		_wantGetDep octave-symbolic
+		"$scriptAbsoluteLocation" _octave pkg install -forge symbolic
+		return 0
+	fi
+
+
+	return 1
+}
+
+
+
+_test_devgnuoctave_wantGetDep-octavePackage-debian-x64-special-debianBullseye() {
+	! [[ -e /etc/issue ]] && return 1
+	! cat /etc/issue | grep 'Debian' > /dev/null 2>&1 && return 1
+	! [[ -e /etc/debian_version ]] && return 1
+	! cat /etc/debian_version | head -c 2 | grep 11 > /dev/null 2>&1 && return 1
+
+
+	if [[ "$1" == "symbolic" ]]
+	then
+		_test_devgnuoctave_wantGetDep-octavePackage-internal "$@"
+		return
+	fi
+
+	return 1
+}
+_test_devgnuoctave_wantGetDep-octavePackage-debian-x64-special-debianBookworm() {
+	! [[ -e /etc/issue ]] && return 1
+	! cat /etc/issue | grep 'Debian' > /dev/null 2>&1 && return 1
+	! [[ -e /etc/debian_version ]] && return 1
+	! cat /etc/debian_version | head -c 2 | grep 12 > /dev/null 2>&1 && return 1
+
+
+	if [[ "$1" == "symbolic" ]]
+	then
+		_test_devgnuoctave_wantGetDep-octavePackage-internal "$@"
+		return
+	fi
+
+	return 1
+}
+
+
+
+
+
+# ATTENTION: WARNING: Only tested with Debian Stable. May require rewrite to accommodate other distro (ie. Gentoo).
+_test_devgnuoctave_wantGetDep-octavePackage-debian-x64() {
+	## If not Debian, then simply accept these pacakges may not be available.
+	#[[ -e /etc/issue ]] && ! cat /etc/issue | grep 'Debian' > /dev/null 2>&1 && return 0
+
+	# If not x64, then simply accept these pacakges may not be available.
+	local hostArch
+	hostArch=$(uname -m)
+	if [[ "$hostArch" != "x86_64" ]]
+	then
+		return 0
+	fi
+
+	if _test_devgnuoctave_wantGetDep-octavePackage-debian-x64-special-debianBullseye "$@"
+	then
+		return 0
+	fi
+	if _test_devgnuoctave_wantGetDep-octavePackage-debian-x64-special-debianBookworm "$@"
+	then
+		return 0
+	fi
+
+	local currentPackageSuffix
+	currentPackageSuffix=$(echo "$1" | sed 's/-$//')
+
+	! _typeShare_dir_wildcard 'octave/packages/'"$1" && ! _typeShare_dir_wildcard 'octave/packages/'"$1" && _wantGetDep octave-"$currentPackageSuffix"
+	! _typeShare_dir_wildcard 'octave/packages/'"$1" && ! _typeShare_dir_wildcard 'octave/packages/'octave-"$1" && _wantGetDep octave-"$currentPackageSuffix"
+	#_wantGetDep octave-"$1"
+
+	return 0
+}
+
+_test_devgnuoctave-debian-x64() {
+	local hostArch
+	hostArch=$(uname -m)
+
+
+	# If not Debian, then simply accept these pacakges may not be available.
+	# Experimentally, some Debian-like distributions may be allowed to attempt to such more complete octave package installation.
+	# \|Ubuntu
+	[[ -e /etc/issue ]] && ! cat /etc/issue | grep 'Debian' > /dev/null 2>&1 && return 0
+
+	# If not x64, then simply accept these pacakges may not be available.
+	if [[ "$hostArch" != "x86_64" ]]
+	then
+		return 0
+	fi
+
+
+
+
+	if ! _typeShare_dir_wildcard 'octave/packages/arduino' && ! _typeShare 'doc-base/octave-arduino-manual' && ! _typeShare 'info/arduino.info.gz' && ! _typeShare 'doc/octave-arduino/arduino.pdf.gz'
+	then
+		_wantGetDep octave-arduino
+	fi
+
+
+	_wantGetDep /usr/share/octave/site/m/bart/bart.m
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 bim
+
+	_wantGetDep x86_64-linux-gnu/octave/site/oct/x86_64-pc-linux-gnu/biosig/mexSLOAD.mex
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 bsltl
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 cgi
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 control
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 data-smoothing
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 dataframe
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 dicom
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 divand
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 doctest
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 econometrics
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 financial
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 fits
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 fpl
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 fuzzy-logic-toolkit
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 ga-
+
+	_wantGetDep x86_64-linux-gnu/octave/site/oct/x86_64-pc-linux-gnu/gdf/gdf_reader.mex
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 general
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 geometry
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 gsl
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 image
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 image-acquisition
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 instrument-control
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 interval
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 io-
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 level-set
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 linear-algebra
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 lssa
+
+	#_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 ltfat
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 mapping
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 miscellaneous
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 missing-functions
+
+	#_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 mpi-
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 msh-
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 mvn-
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 nan-
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 ncarray
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 netcdf
+
+	if ! _typeDep 'x86_64-linux-gnu/octave/site/oct/x86_64-pc-linux-gnu/nlopt_optimize.oct' && ! _typeDep 'x86_64-linux-gnu/octave/site/oct/x86_64-pc-linux-gnu/nlopt/nlopt_optimize.oct'
+	then
+		_wantGetDep x86_64-linux-gnu/octave/site/oct/x86_64-pc-linux-gnu/nlopt_optimize.oct
+		_wantGetDep x86_64-linux-gnu/octave/site/oct/x86_64-pc-linux-gnu/nlopt/nlopt_optimize.oct
+	fi
+	! _typeShare 'octave/site/m/nlopt/nlopt_optimize.m' && ! _typeShare '/usr/share/octave/site/m/nlopt_minimize.m' && _wantGetDep octave-nlopt
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 nurbs
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 netcdf
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 octclip
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 octproj
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 openems
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 optics
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 optim
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 optiminterp
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 parallel
+
+	#_wantGetDep x86_64-linux-gnu/octave/site/oct/x86_64-pc-linux-gnu/pfstools/pfsread.oct
+	#! _typeShare 'octave/site/m/pfstools/pfs_read_xyz.m' && _wantGetDep octave-pfstools
+
+	#_wantGetDep x86_64-linux-gnu/octave/site/oct/api-v52/x86_64-pc-linux-gnu/plplot_octave.oct
+	#! _typeShare 'plplot_octave/mesh.m' && _wantGetDep octave-plplot
+
+	_wantGetDep psychtoolbox-3/PsychBasic/PsychPortAudio.mex
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 quaternion
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 queueing
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 secs1d
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 secs2d
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 secs3d
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 signal
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 sockets
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 sparsersb
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 specfun
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 splines
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 statistics
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 stk
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 strings
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 struct
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 symbolic
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 tsa
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 vibes
+
+	_wantGetDep x86_64-linux-gnu/octave/site/oct/x86_64-pc-linux-gnu/vlfeat/toolbox/vl_binsearch.mex
+	! _typeShare 'octave/site/m/vlfeat/toolbox/misc/vl_binsearch.m' && _wantGetDep octave-vlfeat
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 vrml
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 zenity
+
+	_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 zeromq
+
+
+	return 0
+}
+
+_test_devgnuoctave-extra() {
+	local hostArch
+	hostArch=$(uname -m)
+
+	if [[ "$hostArch" == "x86_64" ]] && [[ -e /etc/issue ]] && cat /etc/issue | grep 'Ubuntu' > /dev/null 2>&1
+	then
+		_test_devgnuoctave_wantGetDep-octavePackage-internal symbolic
+		_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 quaternion
+		_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 vrml
+		_test_devgnuoctave_wantGetDep-octavePackage-debian-x64 zeromq
+	fi
+
+	_test_devgnuoctave-debian-x64
+}
+
+
+
+
+
+
+
+
+
+_qalculate_terse() {
+	_safe_declare_uid
+
+	# https://stackoverflow.com/questions/17998978/removing-colors-from-output
+	#sed -r "s/\x1B\[([0-9]{1,3}(;[0-9]{1,2})?)?[mGK]//g"
+
+	# https://stackoverflow.com/questions/4233159/grep-regex-whitespace-behavior
+	#grep -v '^\s*$'
+
+	if [[ "$1" != "" ]]
+	then
+		#_safeEcho_newline "$@" | qalc -t | grep -v '^>\ ' | grep -v '^$' | sed 's/^  //' | grep -v '^\s*$' | sed -r "s/\x1B\[([0-9]{1,3}(;[0-9]{1,2})?)?[mGK]//g"
+
+		# Preferred for Cygwin .
+		_safeEcho_newline "$@" | qalc -t | grep -v '^> ' | grep -v '^$' | sed 's/^  //' | grep -v '^\s*$' | sed -r "s/\x1B\[([0-9]{1,3}(;[0-9]{1,2})?)?[mGK]//g"
+		return
+	fi
+
+	#qalc -t "$@" | grep -v '^>\ ' | grep -v '^$' | sed 's/^  //' | grep -v '^\s*$' | sed -r "s/\x1B\[([0-9]{1,3}(;[0-9]{1,2})?)?[mGK]//g"
+
+	# Preferred for Cygwin .
+	qalc -t "$@" | grep -v '^> ' | grep -v '^$' | sed 's/^  //' | grep -v '^\s*$' | sed -r "s/\x1B\[([0-9]{1,3}(;[0-9]{1,2})?)?[mGK]//g"
+	return
+}
+
+# Interactive.
+_qalculate() {
+	_safe_declare_uid
+
+	mkdir -p "$HOME"/.config/qalculate
+
+	if [[ "$1" != "" ]]
+	then
+		_safe_declare_uid
+		_qalculate_terse "$@"
+		return
+	fi
+
+	_safe_declare_uid
+	qalc "$@"
+	return
+}
+
+# ATTENTION: EXAMPLE: echo 'solve(x == y * 2, y)' | _qalculate_pipe
+_qalculate_pipe() {
+	_safe_declare_uid
+
+	_qalculate_terse "$@"
+}
+
+# ATTENTION: _qalculate_script 'qalculate_script.m'
+# echo 'solve(x == y * 2, y)' > qalculate_script.m
+_qalculate_script() {
+	local currentFile="$1"
+	shift
+
+	_safe_declare_uid
+
+	cat "$currentFile" | _qalculate_pipe "$@"
+}
+
+
+
+
+
+
+
+
+
+
+_qalculate_solve() {
+	_safeEcho_newline solve"$@" | _qalculate_pipe
+}
+_qalculate_nsolve() {
+	_safeEcho_newline solve"$@" | _qalculate_pipe
+}
+
+if type -p qalc > /dev/null 2>&1
+then
+	_solve() {
+		_qalculate_solve "$@"
+	}
+	solve() {
+		_qalculate_solve "$@"
+	}
+	nsolve() {
+		_qalculate_solve "$@"
+	}
+
+	# WARNING: Mostly intended as apparent MSW/Cygwin workaround. May cause incorrectly written equations with inappropriate non-numeric output to pass regression tests (ie. same wrong output may still be wrong output).
+	_clc() {
+		# https://www.cyberciti.biz/faq/linux-unix-bash-check-interactive-shell/
+		if [ -z "$PS1" ]
+		then
+			_qalculate "$@" | tr -dc 'E0-9.\n'
+			return
+		fi
+
+		_qalculate "$@"
+	}
+	clc() {
+		_qalculate "$@"
+	}
+	c() {
+		_qalculate "$@"
+	}
+
+	_num() {
+		_clc "$@" | tr -dc 'E0-9.\n'
+	}
+fi
+
+
+
+
+_test_devqalculate() {
+	# Debian Bullseye (stable) apparently does not include 'qualculate-gtk'.
+	# GUI may be installed from binaries provided elsewhere, although the '_qalculate' , '_clc' , and 'c' , functions do not require this.
+	# https://qalculate.github.io/downloads.html
+	if [[ -e /etc/debian_version ]] && cat /etc/debian_version | head -c 2 | grep 11 > /dev/null 2>&1
+	then
+		! _typeDep qalculate-gtk && sudo -n apt-get install --install-recommends -y qalculate-gtk
+	else
+		_wantGetDep qalculate-gtk
+		#_wantGetDep qalculate
+	fi
+
+	_wantGetDep qalc
+
+	if ! _typeShare 'texmf/tex/latex/gnuplot/gnuplot.cfg' && ! _typeShare 'texmf/tex/gnuplot.cfg'
+	then
+		! _wantGetDep 'texmf/tex/latex/gnuplot/gnuplot.cfg' && ! _wantGetDep 'texmf/tex/gnuplot.cfg' && ! _wantGetDep gnuplot-data
+	fi
+
+
+	! _typeShare 'texmf/tex/latex/gnuplot/gnuplot.cfg' && ! _typeShare 'texmf/tex/gnuplot.cfg' && echo 'warn: missing: gnuplot-data'
+
+	#_wantGetDep gnuplot-data
+	#_wantGetDep gnuplot-x11
+	_wantGetDep gnuplot-qt
+
+	_wantGetDep gnuplot
+
+	! _typeDep qalculate-gtk && echo 'warn: missing: qalculate-gtk'
+
+
+	if [[ $(qalc -v | cut -f1 -d\. | tr -dc '0-9') -le "3" ]]
+	then
+		echo 'warn: bad: unacceptable qalc version!'
+	fi
+
+	return 0
+}
+
+
+
+
+_set_markup_terminal() {
+
+	#&& [[ "$flag__NOT_shell" == "" ]] && [[ "$comment_shell_line" == "" ]]
+	if [[ "$current_scriptedIllustrator_markup" == "" ]] && [[ "$current_scriptedIllustrator_markup_markdown" == "" ]] && [[ "$workaround_noInterpret_begin" == "" ]] && [[ "$workaround_noInterpret_end" == "" ]] && [[ "$workaround_comment_shell_line" == "" ]]
+	then
+
+		export flag__NOT_shell='scriptedIllustrator_markup_uk4uPhB663kVcygT0q'
+		export comment_shell_line='#'
+
+
+		_e() {
+			export currentFunctionName="${FUNCNAME[0]}"
+			_e-terminal "$@"
+		}
+		#export -f _e
+
+		_e_() {
+			export currentFunctionName="${FUNCNAME[0]}"
+			_e_-terminal "$@"
+		}
+		#export -f _e_
+
+		_o() {
+			export currentFunctionName="${FUNCNAME[0]}"
+			_o-terminal "$@"
+		}
+		#export -f _o
+
+		_o_() {
+			export currentFunctionName="${FUNCNAME[0]}"
+			_o_-terminal "$@"
+		}
+		#export -f _o_
+
+		_i() {
+			export currentFunctionName="${FUNCNAME[0]}"
+			_i-terminal "$@"
+		}
+		#export -f _i
+
+		_v() {
+			export currentFunctionName="${FUNCNAME[0]}"
+			_v-terminal "$@"
+		}
+		#export -f _v
+
+		_t() {
+			export currentFunctionName="${FUNCNAME[0]}"
+			_t-terminal "$@"
+		}
+		#export -f _t
+
+		_r() {
+			export currentFunctionName="${FUNCNAME[0]}"
+			_r-terminal "$@"
+		}
+		#export -f _r
+
+		_() {
+			export currentFunctionName="${FUNCNAME[0]}"
+			_h-terminal "$@"
+		}
+		_h() {
+			export currentFunctionName="${FUNCNAME[0]}"
+			_h-terminal "$@"
+		}
+		#export -f _
+		#export -f _h
+
+
+
+		_heading1() {
+			export currentFunctionName="${FUNCNAME[0]}"
+			_heading1-terminal "$@"
+		}
+		#export -f _heading1
+		_heading2() {
+			export currentFunctionName="${FUNCNAME[0]}"
+			_heading2-terminal "$@"
+		}
+		#export -f _heading2
+		_heading3() {
+			export currentFunctionName="${FUNCNAME[0]}"
+			_heading3-terminal "$@"
+		}
+		#export -f _heading3
+		_heading4() {
+			export currentFunctionName="${FUNCNAME[0]}"
+			_heading4-terminal "$@"
+		}
+		#export -f _heading4
+		_heading5() {
+			export currentFunctionName="${FUNCNAME[0]}"
+			_heading5-terminal "$@"
+		}
+		#export -f _heading5
+		_heading6() {
+			export currentFunctionName="${FUNCNAME[0]}"
+			_heading6-terminal "$@"
+		}
+		#export -f _heading6
+
+		_page() {
+			export currentFunctionName="${FUNCNAME[0]}"
+			_page-terminal "$@"
+		}
+		#export -f _page
+
+		_paragraph_begin() {
+			export currentFunctionName="${FUNCNAME[0]}"
+			_paragraph_begin-terminal "$@"
+		}
+		#export -f _paragraph_begin
+		_paragraph_end() {
+			export currentFunctionName="${FUNCNAME[0]}"
+			_paragraph_end-terminal "$@"
+		}
+		#export -f _paragraph_end
+
+
+		_picture() {
+			export currentFunctionName="${FUNCNAME[0]}"
+			_picture-terminal "$@"
+		}
+		#export -f _picture
+		_image() {
+			export currentFunctionName="${FUNCNAME[0]}"
+			_image-terminal "$@"
+		}
+		#export -f _image
+
+
+		_cells_begin() {
+			export currentFunctionName="${FUNCNAME[0]}"
+			_cells_begin-terminal "$@"
+		}
+		#export -f _cells_begin
+		_cells_end() {
+			export currentFunctionName="${FUNCNAME[0]}"
+			_cells_end-terminal "$@"
+		}
+		#export -f _cells_end
+		_cells_row_begin() {
+			export currentFunctionName="${FUNCNAME[0]}"
 			_cells_row_begin-terminal "$@"
 		}
 		#export -f _cells_row_begin
@@ -25675,1972 +29848,4194 @@ _set_markup_terminal() {


 			#echo "$interpret__terminal_NOT_shell__begin"
-			#echo -e -n "$markup_terminal_cmd_begin"
-			#echo -e -n ' \033[0;37;100m '
+			#echo -e -n "$markup_terminal_cmd_begin"
+			#echo -e -n ' \033[0;37;100m '
+
+			local current_miniSessionID=$(_uid 8)
+
+			#_messagePlain_probe_quoteAddSingle "$@" | cat
+
+
+			# | _shellCommentLines
+
+			"$@" | _workaround_preformattedCharacters-terminal | cat | _markup_terminal_cmd
+
+			#echo -e -n ' \033[0m '
+			#echo -e -n "$markup_terminal_cmd_end"
+			#echo "$interpret__terminal_NOT_shell__end"
+		}
+
+		# Output only. Useful for '_messagePlain_probe_var', _messagePlain_request' and similar.
+		_o_-terminal() {
+			#_safeEcho_quoteAddSingle "$currentFunctionName" "$@"
+			#_safeEcho_newline
+
+
+			#echo "$interpret__terminal_NOT_shell__begin"
+			#echo -e -n "$markup_terminal_cmd_begin"
+
+			local current_miniSessionID=$(_uid 8)
+
+			#_messagePlain_probe_quoteAddSingle "$@" | cat
+
+
+			# | _shellCommentLines
+
+			eval "$@" > "$bootTmp"/"$current_miniSessionID"."${ubiquitousBashIDnano:0:3}"
+			cat "$bootTmp"/"$current_miniSessionID"."${ubiquitousBashIDnano:0:3}" | _workaround_preformattedCharacters-terminal | cat | _markup_terminal_cmd
+			rm -f "$bootTmp"/"$current_miniSessionID"."${ubiquitousBashIDnano:0:3}" > /dev/null 2>&1
+
+			#echo -e -n "$markup_terminal_cmd_end"
+			#echo "$interpret__terminal_NOT_shell__end"
+		}
+
+		# Internal. Use for variables, equation solving, etc.
+		_i-terminal() {
+			#_safeEcho_quoteAddSingle "$currentFunctionName" "$@"
+			#_safeEcho_newline
+
+
+			#echo "$interpret__terminal_NOT_shell__begin"
+			##echo "$markup_terminal_cmd_begin"
+
+			#_messagePlain_probe_quoteAddSingle "$@" | cat
+
+			eval "$@" > /dev/null 2>&1
+
+			##echo "$markup_terminal_cmd_begin"
+			#echo "$interpret__terminal_NOT_shell__end"
+		}
+
+		# Useful to read out a variable (ie. set from 'COLLECT') as preformatted text.
+		# Variable. Roughly equivalent to '_messagePlain_probe_var' , however, without any declaration of the variable name .
+		# https://stackoverflow.com/questions/11386586/how-to-show-div-tag-literally-in-code-pre-tag
+		# 	'You can't (in modern HTML) write markup and have it be interpreted as text.'
+		_v-terminal() {
+			#_safeEcho_quoteAddSingle "$currentFunctionName" "$@"
+			#_safeEcho_newline
+
+
+			#echo "$interpret__terminal_NOT_shell__begin"
+			#echo "$markup_terminal_pre_begin"
+
+			local current_miniSessionID=$(_uid 8)
+
+			#_messagePlain_probe_quoteAddSingle "$@" | cat
+
+			eval echo -e \$"$1" > "$bootTmp"/"$current_miniSessionID"."${ubiquitousBashIDnano:0:3}"
+			cat "$bootTmp"/"$current_miniSessionID"."${ubiquitousBashIDnano:0:3}" | _fold-terminal | cat
+			rm -f "$bootTmp"/"$current_miniSessionID"."${ubiquitousBashIDnano:0:3}" > /dev/null 2>&1
+
+			#echo "$markup_terminal_pre_end"
+			#echo "$interpret__terminal_NOT_shell__end"
+		}
+
+
+
+
+
+		# Show preformatted text.
+		_t-terminal() {
+			# No parameters (no input) is meaningless and nothing can be done with that.
+			[[ "$1" == "" ]] && return 0
+
+			#_t-terminal #_safeEcho_newline _t "'"
+			#_t-terminal _safeEcho _t "'"
+			#echo -n "$flag__NOT_shell $comment_terminal_end""$markup_terminal_pre_begin"
+
+
+			local currentLine
+			local currentLine_previous
+			local currentIteration
+			currentIteration=0
+			while read -r currentLine && [[ "$currentIteration" -lt 2 ]]
+			do
+				if [[ "$currentIteration" == 1 ]] && _safeEcho_newline "$currentLine" | _filter__scriptedIllustrator_markup > /dev/null 2>&1 && [[ "$currentLine_previous" != "" ]] && [[ "$currentLine" != "" ]]
+				then
+					_safeEcho_newline
+					true
+				fi
+
+				currentLine_previous="$currentLine"
+				let currentIteration=currentIteration+1
+			done <<<$(_safeEcho "$@")
+			[[ "$currentIteration" == 1 ]] && [[ "$currentLine_previous" != "" ]] && _safeEcho_newline
+
+			#sed 's/^mediawiki_noLineBreak --><pre.*>//'
+			_safeEcho "$@" | sed 's/^mediawiki_noLineBreak --><nowiki>//' | sed 's/^mediawiki_noLineBreak --><pre style="margin-top: 0px;margin-bottom: 0px;white-space: pre-wrap;">//' | _filter__scriptedIllustrator_markup | _fold-terminal | _workaround_preformattedCharacters-terminal
+
+			#echo "$markup_terminal_pre_end""$comment_terminal_begin $flag__NOT_shell"
+			#_t-terminal _safeEcho_newline "'"
+		}
+
+
+		# Raw. Experimental. No production use.
+		_r-terminal() {
+			# No parameters (no input) is meaningless and nothing can be done with that.
+			[[ "$1" == "" ]] && return 0
+
+			#_r-terminal #_safeEcho_newline _r "'"
+			_safeEcho _r "'"
+			#echo -n "$flag__NOT_shell $comment_terminal_end"
+
+
+			local currentLine
+			local currentLine_previous
+			local currentIteration
+			currentIteration=0
+			while read -r currentLine && [[ "$currentIteration" -lt 2 ]]
+			do
+				if [[ "$currentIteration" == 1 ]] && _safeEcho_newline "$currentLine" | _filter__scriptedIllustrator_markup > /dev/null 2>&1 && [[ "$currentLine_previous" != "" ]]
+				then
+					_safeEcho_newline
+				fi
+
+				currentLine_previous="$currentLine"
+				let currentIteration=currentIteration+1
+			done <<<$(_safeEcho "$@")
+			[[ "$currentIteration" == 1 ]] && _safeEcho_newline
+
+			_safeEcho "$@" | sed 's/^mediawiki_noLineBreak -->//' | _filter__scriptedIllustrator_markup | _workaround_preformattedCharacters-terminal
+
+
+			#echo "$comment_terminal_begin $flag__NOT_shell"
+			_safeEcho_newline "'"
+		}
+
+		# Hidden. Use for comments and (shell code only) spacing.
+		_h-terminal() {
+			true
+			#_safeEcho_quoteAddSingle "$currentFunctionName" "$@"
+			#_safeEcho_newline
+		}
+
+
+
+
+
+
+
+		_heading1-terminal() {
+			#_safeEcho_quoteAddSingle "$currentFunctionName" "$@"
+			_safeEcho_newline
+
+
+			#echo "$interpret__terminal_NOT_shell__begin"
+
+			_safeEcho_newline '_ '"$@"' _' | cat
+
+			#echo "$interpret__terminal_NOT_shell__end"
+		}
+		_heading2-terminal() {
+			#_safeEcho_quoteAddSingle "$currentFunctionName" "$@"
+			_safeEcho_newline
+
+
+			#echo "$interpret__terminal_NOT_shell__begin"
+
+			_safeEcho_newline '__ '"$@"' __' | cat
+
+			#echo "$interpret__terminal_NOT_shell__end"
+		}
+		_heading3-terminal() {
+			#_safeEcho_quoteAddSingle "$currentFunctionName" "$@"
+			_safeEcho_newline
+
+
+			#echo "$interpret__terminal_NOT_shell__begin"
+
+			_safeEcho_newline '___ '"$@"' ___' | cat
+
+			#echo "$interpret__terminal_NOT_shell__end"
+		}
+		_heading4-terminal() {
+			#_safeEcho_quoteAddSingle "$currentFunctionName" "$@"
+			_safeEcho_newline
+
+
+			#echo "$interpret__terminal_NOT_shell__begin"
+
+			_safeEcho_newline '____ '"$@"' ____' | cat
+
+			#echo "$interpret__terminal_NOT_shell__end"
+		}
+		_heading5-terminal() {
+			#_safeEcho_quoteAddSingle "$currentFunctionName" "$@"
+			_safeEcho_newline
+
+
+			#echo "$interpret__terminal_NOT_shell__begin"
+
+			_safeEcho_newline '_____ '"$@"' _____' | cat
+
+			#echo "$interpret__terminal_NOT_shell__end"
+		}
+		_heading6-terminal() {
+			#_safeEcho_quoteAddSingle "$currentFunctionName" "$@"
+			_safeEcho_newline
+
+
+			#echo "$interpret__terminal_NOT_shell__begin"
+
+			_safeEcho_newline '______ '"$@"' ______' | cat
+
+			#echo "$interpret__terminal_NOT_shell__end"
+		}
+
+		# Page break.
+		#title page (experiment)
+		#<div style="page-break-before: always;"> </div>
+		#<p>
+		#text page (experiment)
+		#</p>
+		_page-terminal() {
+			_safeEcho_newline
+			_safeEcho_quoteAddSingle "$currentFunctionName" "$@"
+			#_safeEcho_newline
+
+
+			#echo "$interpret__terminal_NOT_shell__begin"
+
+			_safeEcho_newline 'PageBreak -H-H-H-H- PageBreak -H-H-H-H- PageBreak -H-H-H-H- PageBreak -H-H-H-H- PageBreak' | cat
+
+			_safeEcho_newline
+
+			#_safeEcho_newline '<p style="page-break-after: always;">&nbsp;</p>' | cat
+			#_safeEcho_newline '<p style="page-break-before: always;">&nbsp;</p>' | cat
+
+			#_safeEcho_newline '<p style="page-break-after: always;">&nbsp;</p><p style="page-break-before: always;">&nbsp;</p>' | cat
+
+			#_safeEcho_newline '<div style="page-break-after: always;"> </div>' | cat
+			#_safeEcho_newline '<div></div>' | cat
+
+			#echo "$interpret__terminal_NOT_shell__end"
+		}
+
+		_paragraph_begin-terminal() {
+			#_safeEcho_quoteAddSingle "$currentFunctionName" "$@"
+			#_safeEcho_newline
+
+
+			#echo "$interpret__terminal_NOT_shell__begin"
+
+			_safeEcho_newline '' | cat
+			#_safeEcho_newline '<p style="margin: 0;padding: 0; border-width: 0px;">' | cat
+
+			#echo "$interpret__terminal_NOT_shell__end"
+		}
+		_paragraph_end-terminal() {
+			#_safeEcho_quoteAddSingle "$currentFunctionName" "$@"
+			#_safeEcho_newline
+
+
+			#echo "$interpret__terminal_NOT_shell__begin"
+
+			_safeEcho_newline '' | cat
+
+			#echo "$interpret__terminal_NOT_shell__end"
+		}
+
+		_picture-terminal() {
+			local currentWidth
+			currentWidth=""
+			[[ "$2" != "" ]] && currentWidth="$2"
+
+			local currentWidthParameter
+			currentWidthParameter=""
+			[[ "$currentWidth" != "" ]] && currentWidthParameter='width="'"$currentWidth"'" '
+
+			_safeEcho_quoteAddSingle "$currentFunctionName" "$@"
+			_safeEcho_newline
+
+
+			#echo "$interpret__terminal_NOT_shell__begin"
+
+			#./
+			#https://www.hostpapa.com/knowledgebase/align-float-images-website/
+			#_safeEcho_newline '<img '"$currentWidthParameter"'src="'"$1"'" style="float: right;margin: 0 0 0 15px;border: 5px solid transparent;">' | cat
+
+			#echo "$interpret__terminal_NOT_shell__end"
+		}
+		_image-terminal() {
+			local currentWidth
+			currentWidth="96%"
+			[[ "$2" != "" ]] && currentWidth="$2"
+
+			local currentWidthParameter
+			currentWidthParameter=""
+			[[ "$currentWidth" != "" ]] && currentWidthParameter='width="'"$currentWidth"'" '
+
+			_safeEcho_quoteAddSingle "$currentFunctionName" "$@"
+			_safeEcho_newline
+
+
+			#echo "$interpret__terminal_NOT_shell__begin"
+
+			#./
+			#_safeEcho_newline '<img '"$currentWidthParameter"'src="'"$1"'" style="margin: 0 0 0 15px;border: 5px solid transparent;">' | cat
+
+			#echo "$interpret__terminal_NOT_shell__end"
+		}
+
+
+
+		_cells_begin-terminal() {
+			local currentWidth
+			currentWidth="0%"
+			[[ "$1" != "" ]] && currentWidth="$1"
+
+			local currentWidthParameter
+			currentWidthParameter=""
+			[[ "$currentWidth" != "" ]] && currentWidthParameter='width="'"$currentWidth"'" '
+
+			_safeEcho_quoteAddSingle "$currentFunctionName" "$@"
+			_safeEcho_newline
+
+
+			#echo "$interpret__terminal_NOT_shell__begin"
+
+			#_safeEcho_newline '<table '"$currentWidthParameter"'style="empty-cells: show; border-spacing: 0px; border: 1px solid black; margin-top: 0px; vertical-align: top;">' | cat
+
+			#echo "$interpret__terminal_NOT_shell__end"
+		}
+		_cells_end-terminal() {
+			_safeEcho_quoteAddSingle "$currentFunctionName" "$@"
+			_safeEcho_newline
+
+
+			#echo "$interpret__terminal_NOT_shell__begin"

-			local current_miniSessionID=$(_uid 8)
+			#_safeEcho_newline '</table>' | cat

-			#_messagePlain_probe_quoteAddSingle "$@" | cat
+			#echo "$interpret__terminal_NOT_shell__end"
+		}
+		_cells_row_begin-terminal() {
+			_safeEcho_quoteAddSingle "$currentFunctionName" "$@"
+			_safeEcho_newline


-			# | _shellCommentLines
+			#echo "$interpret__terminal_NOT_shell__begin"

-			"$@" | _workaround_preformattedCharacters-terminal | cat | _markup_terminal_cmd
+			#_safeEcho_newline '<tr>' | cat

-			#echo -e -n ' \033[0m '
-			#echo -e -n "$markup_terminal_cmd_end"
 			#echo "$interpret__terminal_NOT_shell__end"
 		}
-
-		# Output only. Useful for '_messagePlain_probe_var', _messagePlain_request' and similar.
-		_o_-terminal() {
-			#_safeEcho_quoteAddSingle "$currentFunctionName" "$@"
-			#_safeEcho_newline
+		_cells_row_end-terminal() {
+			_safeEcho_quoteAddSingle "$currentFunctionName" "$@"
+			_safeEcho_newline


 			#echo "$interpret__terminal_NOT_shell__begin"
-			#echo -e -n "$markup_terminal_cmd_begin"

-			local current_miniSessionID=$(_uid 8)
+			#_safeEcho_newline '</tr>' | cat

-			#_messagePlain_probe_quoteAddSingle "$@" | cat
+			#echo "$interpret__terminal_NOT_shell__end"
+		}
+		_cells_speck_begin-terminal() {
+			local currentWidth
+			currentWidth="0%"
+			[[ "$1" != "" ]] && currentWidth="$1"

+			local currentWidthParameter
+			currentWidthParameter=""
+			[[ "$currentWidth" != "" ]] && currentWidthParameter='width="'"$currentWidth"'" '

-			# | _shellCommentLines

-			eval "$@" > "$bootTmp"/"$current_miniSessionID"."${ubiquitousBashIDnano:0:3}"
-			cat "$bootTmp"/"$current_miniSessionID"."${ubiquitousBashIDnano:0:3}" | _workaround_preformattedCharacters-terminal | cat | _markup_terminal_cmd
-			rm -f "$bootTmp"/"$current_miniSessionID"."${ubiquitousBashIDnano:0:3}" > /dev/null 2>&1
+			local currentColspan
+			currentColspan="1"
+			[[ "$2" != "" ]] && currentColspan="$2"

-			#echo -e -n "$markup_terminal_cmd_end"
-			#echo "$interpret__terminal_NOT_shell__end"
-		}
-
-		# Internal. Use for variables, equation solving, etc.
-		_i-terminal() {
-			#_safeEcho_quoteAddSingle "$currentFunctionName" "$@"
-			#_safeEcho_newline
+			local currentColspanParameter
+			currentColspanParameter=""
+			[[ "$currentColspan" != "" ]] && currentColspanParameter='colspan="'"$currentColspan"'" '


-			#echo "$interpret__terminal_NOT_shell__begin"
-			##echo "$markup_terminal_cmd_begin"
+			_safeEcho_quoteAddSingle "$currentFunctionName" "$@"
+			_safeEcho_newline

-			#_messagePlain_probe_quoteAddSingle "$@" | cat

-			eval "$@" > /dev/null 2>&1
+			#echo "$interpret__terminal_NOT_shell__begin"
+
+			#_safeEcho_newline '<td '"$currentWidthParameter"''"$currentColspanParameter"'style="border-spacing: 0px; border: 1px solid black; margin-top: 0px; vertical-align: top;">' | cat

-			##echo "$markup_terminal_cmd_begin"
 			#echo "$interpret__terminal_NOT_shell__end"
 		}
-
-		# Useful to read out a variable (ie. set from 'COLLECT') as preformatted text.
-		# Variable. Roughly equivalent to '_messagePlain_probe_var' , however, without any declaration of the variable name .
-		# https://stackoverflow.com/questions/11386586/how-to-show-div-tag-literally-in-code-pre-tag
-		# 	'You can't (in modern HTML) write markup and have it be interpreted as text.'
-		_v-terminal() {
-			#_safeEcho_quoteAddSingle "$currentFunctionName" "$@"
-			#_safeEcho_newline
+		_cells_speck_end-terminal() {
+			_safeEcho_quoteAddSingle "$currentFunctionName" "$@"
+			_safeEcho_newline


 			#echo "$interpret__terminal_NOT_shell__begin"
-			#echo "$markup_terminal_pre_begin"
-
-			local current_miniSessionID=$(_uid 8)
-
-			#_messagePlain_probe_quoteAddSingle "$@" | cat

-			eval echo -e \$"$1" > "$bootTmp"/"$current_miniSessionID"."${ubiquitousBashIDnano:0:3}"
-			cat "$bootTmp"/"$current_miniSessionID"."${ubiquitousBashIDnano:0:3}" | _fold-terminal | cat
-			rm -f "$bootTmp"/"$current_miniSessionID"."${ubiquitousBashIDnano:0:3}" > /dev/null 2>&1
+			#_safeEcho_newline '</td>' | cat

-			#echo "$markup_terminal_pre_end"
 			#echo "$interpret__terminal_NOT_shell__end"
 		}



+		_markup_asciidoc_disable_begin-terminal() {
+			true
+		}
+		_markup_asciidoc_disable_end-terminal() {
+			true
+		}


-		# Show preformatted text.
-		_t-terminal() {
-			# No parameters (no input) is meaningless and nothing can be done with that.
-			[[ "$1" == "" ]] && return 0
+
+
+		_fold-terminal() {
+			#if [[ "$markup_terminal_fold" != "" ]]
+			#then
+				#fold -w "$markup_terminal_fold" -s
+				#return
+			#fi
+			cat
+		}
+
+
+
+		_workaround_preformattedCharacters-terminal() {
+			#sed 's/\&#35;/#/g'
+			#sed 's/\&#35;/#/g' | sed "s/\\\x27/\&#39;/g" | sed "s/\\\047/\&#39;/g" | sed "s/%27/\&#39;/g" | sed "s/\&#39;/\&#39;/g"

-			#_t-terminal #_safeEcho_newline _t "'"
-			#_t-terminal _safeEcho _t "'"
-			#echo -n "$flag__NOT_shell $comment_terminal_end""$markup_terminal_pre_begin"
+			#sed "s/\\\x27/\&#39;/g" | sed "s/\\\047/\&#39;/g" | sed "s/%27/\&#39;/g" | sed "s/\&#39;/\&#39;/g"
+			#sed "s/\\\x3c/\&lt;;/g" | sed "s/\\\060/\&lt;;/g" | sed "s/%3c/\&lt;;/g" | sed "s/\&lt;;/\&lt;;/g"

+			#sed 's/\&#35;/#/g' | sed "s/\\\x27/\&#39;/g" | sed "s/\\\047/\&#39;/g" | sed "s/%27/\&#39;/g" | sed "s/\&#39;/\&#39;/g" | sed "s/\\\x3c/\&lt;;/g" | sed "s/\\\060/\&lt;;/g" | sed "s/%3c/\&lt;;/g" | sed "s/\&lt;;/\&lt;;/g"

-			local currentLine
-			local currentLine_previous
-			local currentIteration
-			currentIteration=0
-			while read -r currentLine && [[ "$currentIteration" -lt 2 ]]
-			do
-				if [[ "$currentIteration" == 1 ]] && _safeEcho_newline "$currentLine" | _filter__scriptedIllustrator_markup > /dev/null 2>&1 && [[ "$currentLine_previous" != "" ]] && [[ "$currentLine" != "" ]]
-				then
-					_safeEcho_newline
-					true
-				fi
-
-				currentLine_previous="$currentLine"
-				let currentIteration=currentIteration+1
-			done <<<$(_safeEcho "$@")
-			[[ "$currentIteration" == 1 ]] && [[ "$currentLine_previous" != "" ]] && _safeEcho_newline
+			cat

-			#sed 's/^mediawiki_noLineBreak --><pre.*>//'
-			_safeEcho "$@" | sed 's/^mediawiki_noLineBreak --><nowiki>//' | sed 's/^mediawiki_noLineBreak --><pre style="margin-top: 0px;margin-bottom: 0px;white-space: pre-wrap;">//' | _filter__scriptedIllustrator_markup | _fold-terminal | _workaround_preformattedCharacters-terminal

-			#echo "$markup_terminal_pre_end""$comment_terminal_begin $flag__NOT_shell"
-			#_t-terminal _safeEcho_newline "'"
+			#| sed "s/\&#92;/\\\/"
 		}


-		# Raw. Experimental. No production use.
-		_r-terminal() {
-			# No parameters (no input) is meaningless and nothing can be done with that.
-			[[ "$1" == "" ]] && return 0
-
-			#_r-terminal #_safeEcho_newline _r "'"
-			_safeEcho _r "'"
-			#echo -n "$flag__NOT_shell $comment_terminal_end"
-
+		_markup_terminal_cmd() {
+			local currentString

-			local currentLine
-			local currentLine_previous
-			local currentIteration
-			currentIteration=0
-			while read -r currentLine && [[ "$currentIteration" -lt 2 ]]
+			while read -r currentString
 			do
-				if [[ "$currentIteration" == 1 ]] && _safeEcho_newline "$currentLine" | _filter__scriptedIllustrator_markup > /dev/null 2>&1 && [[ "$currentLine_previous" != "" ]]
-				then
-					_safeEcho_newline
-				fi
-
-				currentLine_previous="$currentLine"
-				let currentIteration=currentIteration+1
-			done <<<$(_safeEcho "$@")
-			[[ "$currentIteration" == 1 ]] && _safeEcho_newline
-
-			_safeEcho "$@" | sed 's/^mediawiki_noLineBreak -->//' | _filter__scriptedIllustrator_markup | _workaround_preformattedCharacters-terminal
+				[ "$currentString" ] && printf '%b' "$markup_terminal_cmd_begin""$currentString""$markup_terminal_cmd_end"
+				echo
+			done
+		}
+	fi
+
+	if [[ "$current_scriptedIllustrator_markup" == "" ]] && [[ "$current_scriptedIllustrator_markup_markdown" == "" ]] && [[ "$workaround_noInterpret_begin" == "" ]] && [[ "$workaround_noInterpret_end" == "" ]] && [[ "$workaround_comment_shell_line" == "" ]]
+	then
+		_shellCommentLines() {
+			local currentString

+			while read -r currentString
+			do
+				[ "$currentString" ] && printf '%b' "$comment_shell_line $currentString"
+				echo
+			done

-			#echo "$comment_terminal_begin $flag__NOT_shell"
-			_safeEcho_newline "'"
+			#echo -n "$comment_shell_line"' '
+			##LANG=C IFS=
+			#while LANG=C IFS= read -r -d '' -n 1 currentString
+			#do
+				#[ "$currentString" ] && printf '%b' "$currentString"
+				#[[ "$currentString" == $'\n' ]] && echo -n "$comment_shell_line"' '
+			#done
 		}

-		# Hidden. Use for comments and (shell code only) spacing.
-		_h-terminal() {
-			true
-			#_safeEcho_quoteAddSingle "$currentFunctionName" "$@"
-			#_safeEcho_newline
+		# WARNING: Affects accurate prevention of '_r' and '_t' inaccurately accumulating or removing newlines.
+		_filter__scriptedIllustrator_markup() {
+			# Inherently add newline if not already present.
+			grep -v "$flag__NOT_shell"
+
+			# Add newline if already present.
+			#grep -v $(_uid) | grep -v "$flag__NOT_shell"
+
+			# Do not add newline if not already present.
+			#sed 's/^.*'"$flag__NOT_shell"'.*$//g'
 		}
+	fi
+
+}
+_set_markup_terminal
+
+
+_set_markup_terminal_exportFunctions() {
+	_set_markup_terminal "$@"
+
+	#export current_scriptedIllustrator_markup='terminal'
+	export current_scriptedIllustrator_markup=''
+
+	export -f _e
+
+	export -f _e_
+
+	export -f _o
+
+	export -f _o_
+
+	export -f _i
+
+	export -f _v
+
+	export -f _t
+
+	export -f _r
+
+	export -f _
+	export -f _h
+
+
+
+	export -f _heading1
+	export -f _heading2
+	export -f _heading3
+	export -f _heading4
+	export -f _heading5
+	export -f _heading6
+
+	export -f _page
+
+	export -f _paragraph_begin
+	export -f _paragraph_end
+
+
+	export -f _picture
+	export -f _image
+
+
+	export -f _cells_begin
+	export -f _cells_end
+	export -f _cells_row_begin
+	export -f _cells_row_end
+	export -f _cells_speck_begin
+	export -f _cells_speck_end
+
+	export -f _markup_asciidoc_disable_begin
+	export -f _markup_asciidoc_disable_end
+}
+
+_declareFunctions_markup_terminal() {
+	declare -f _set_markup_terminal
+	declare -f _set_markup_terminal_exportFunctions
+
+
+	# WARNING: Most functions would be declared twice, substantially increasing 'current_internal_CompressedFunctions_bytes' .
+	return 0
+
+	declare -f _e
+	declare -f _e-terminal
+
+	declare -f _e_
+	declare -f _e_-terminal
+
+	declare -f _o
+	declare -f _o-terminal
+
+	declare -f _o_
+	declare -f _o_-terminal
+
+	declare -f _i
+	declare -f _i-terminal
+
+	declare -f _v
+	declare -f _v-terminal
+
+	declare -f _t
+	declare -f _t-terminal
+
+	declare -f _r
+	declare -f _r-terminal
+
+	declare -f _
+	declare -f _h
+	declare -f _h-terminal
+
+
+
+
+
+
+	declare -f _heading1
+	declare -f _heading1-terminal
+	declare -f _heading2
+	declare -f _heading2-terminal
+	declare -f _heading3
+	declare -f _heading3-terminal
+	declare -f _heading4
+	declare -f _heading4-terminal
+	declare -f _heading5
+	declare -f _heading5-terminal
+	declare -f _heading6
+	declare -f _heading6-terminal
+
+	declare -f _page
+	declare -f _page-terminal
+
+	declare -f _paragraph_begin
+	declare -f _paragraph_begin-terminal
+	declare -f _paragraph_end
+	declare -f _paragraph_end-terminal
+
+	declare -f _picture
+	declare -f _picture-terminal
+	declare -f _image
+	declare -f _image-terminal
+
+	declare -f _cells_begin
+	declare -f _cells_begin-terminal
+	declare -f _cells_end
+	declare -f _cells_end-terminal
+	declare -f _cells_row_begin
+	declare -f _cells_row_begin-terminal
+	declare -f _cells_row_end
+	declare -f _cells_row_end-terminal
+	declare -f _cells_speck_begin
+	declare -f _cells_speck_begin-terminal
+	declare -f _cells_speck_end
+	declare -f _cells_speck_end-terminal
+
+
+	declare -f _markup_asciidoc_disable_begin
+	declare -f _markup_asciidoc_disable_begin-terminal
+	declare -f _markup_asciidoc_disable_end
+	declare -f _markup_asciidoc_disable_end-terminal
+
+
+	declare -f _fold-terminal
+
+
+	declare -f _workaround_preformattedCharacters-terminal
+}
+
+
+_test_devemacs() {
+	_wantGetDep emacs
+
+	#_if_cygwin && return 0
+
+	if type -p emacs > /dev/null 2>&1
+	then
+		echo 'warn: missing: emacs'
+		return 0
+	else
+		local emacsDetectedVersion=$(emacs --version | head -n 1 | cut -f 3 -d\ | cut -d\. -f1)
+		! [[ "$emacsDetectedVersion" -ge "24" ]] && echo 'warn: obsolete: emacs' && return 1
+	fi
+
+	return 0
+}
+
+_set_emacsFakeHomeSource() {
+	#if [[ ! -e "$scriptLib"/app/emacs/home ]]
+	#then
+		#_messageError 'missing: '"$scriptLib"'/app/emacs/home'
+		#_messageFAIL
+		#_stop 1
+	#fi
+
+	if [[ ! -e "$scriptBundle"/app/emacs/home ]]
+	then
+		_messageError 'missing: '"$scriptBundle"'/app/emacs/home'
+		_messageFAIL
+		_stop 1
+	fi
+
+	#export emacsFakeHomeSource="$scriptLib"/app/emacs/home
+	export emacsFakeHomeSource="$scriptBundle"/app/emacs/home
+	if ! [[ -e "$emacsFakeHomeSource" ]]
+	then
+		#export emacsFakeHomeSource="$scriptLib"/ubiquitous_bash/_lib/app/emacs/home
+		export emacsFakeHomeSource="$scriptLib"/ubiquitous_bash/_bundle/app/emacs/home
+	fi
+}
+
+_install_fakeHome_emacs() {
+	_link_fakeHome "$emacsFakeHomeSource"/.emacs .emacs
+	_link_fakeHome "$emacsFakeHomeSource"/.emacs.d .emacs.d
+}
+
+_emacs_edit_procedure() {
+	_set_emacsFakeHomeSource
+
+	export actualFakeHome="$instancedFakeHome"
+	#export actualFakeHome="$globalFakeHome"
+	export fakeHomeEditLib="true"
+	export keepFakeHome="false"
+
+	_install_fakeHome_emacs
+
+	#echo -n "$@" >> "$HOME"/.emacs
+
+	_fakeHome emacs "$@"
+}
+
+_emacs_edit_sequence() {
+	_start
+
+	_emacs_edit_procedure "$@"
+
+	_stop $?
+}
+
+_emacs_edit() {
+	"$scriptAbsoluteLocation" _emacs_edit_sequence "$@"
+}
+
+_emacs_user_procedure() {
+	_set_emacsFakeHomeSource
+
+	export actualFakeHome="$instancedFakeHome"
+	#export actualFakeHome="$globalFakeHome"
+	export fakeHomeEditLib="false"
+	export keepFakeHome="false"
+
+	_install_fakeHome_emacs
+
+	#echo -n "$@" >> "$HOME"/.emacs
+
+	_fakeHome emacs "$@"
+}
+
+_emacs_user_sequence() {
+	_start
+
+	_emacs_user_procedure "$@"
+
+	_stop $?
+}
+
+_emacs_user() {
+	"$scriptAbsoluteLocation" _emacs_user_sequence "$@"
+}
+
+_emacs() {
+	_emacs_user "$@"
+}
+
+_bashdb_procedure() {
+	_set_emacsFakeHomeSource
+
+	export actualFakeHome="$instancedFakeHome"
+	export fakeHomeEditLib="false"
+	export keepFakeHome="false"
+
+	_install_fakeHome_emacs
+
+	#echo -n '(bashdb "bash --debugger' >> "$actualFakeHome"/.emacs
+	echo -n '(bashdb-large "bash --debugger' >> "$actualFakeHome"/.emacs
+
+	local currentArg
+
+	for currentArg in "$@"
+	do
+		echo -n ' ' >> "$actualFakeHome"/.emacs
+		echo -n '\"' >> "$actualFakeHome"/.emacs
+		echo -n "$currentArg" >> "$actualFakeHome"/.emacs
+		echo -n '\"' >> "$actualFakeHome"/.emacs
+	done
+
+	echo '")' >> "$actualFakeHome"/.emacs
+
+	_fakeHome emacs
+}
+
+_bashdb_sequence() {
+	_start
+
+	_bashdb_procedure "$@"
+
+	_stop $?
+}
+
+_bashdb() {
+	"$scriptAbsoluteLocation" _bashdb_sequence "$@"
+}
+
+_ubdb() {
+	_bashdb "$scriptAbsoluteLocation" "$@"
+}
+
+_set_java__eclipse() {
+	_set_java_openjdk "$@"
+}
+
+
+_eclipse_binary() {
+	eclipse "$@"
+}
+
+# ATTENTION: Override with 'core.sh', 'ops', or similar.
+# Static parameters. Must be accepted if function overridden to point script contained installation.
+_eclipse_param() {
+	_eclipse_example_binary -vm "$ubJava" -data "$ub_eclipse_workspace" -configuration "$ub_eclipse_configuration" "$@"
+}
+
+
+
+
+
+
+
+
+
+
+_prepare_example_ConfigurationLookupDirectory_eclipse() {
+	#_prepare_abstractfs_appdir_none "$@"
+
+	#_prepare_abstractfs_appdir_independent "$@"
+
+	# DANGER: Strongly discouraged. May break use of "project.afs" with alternative layouts and vice versa.
+	#_prepare_abstractfs_appdir_shared "$@"
+
+	_prepare_abstractfs_appdir_export "$@"
+
+	#_probe_prepare_abstractfs_appdir_AbstractSourceDirectory
+	#_probe_prepare_abstractfs_appdir_AbstractSourceDirectory_prior
+	#_probe_prepare_abstractfs_appdir_post
+	_probe_prepare_abstractfs_appdir
+
+	export ub_eclipse_workspace="$ubAFS_CLD"/_eclipse-workspace
+	export ub_eclipse_configuration="$ubAFS_CLD"/_eclipse-configuration/_eclipse_configuration
+
+	mkdir -p "$ubASD_PRJ"
+	mkdir -p "$ubASD_CLD"
+}
+
+
+
+_eclipse_example_binary() {
+	eclipse "$@"
+	#sleep 9
+}
+
+
+# ATTENTION: Override with 'core.sh', 'ops', or similar.
+# Static parameters. Must be accepted if function overridden to point script contained installation.
+_eclipse_example-static() {
+	mkdir -p "$ub_eclipse_workspace"
+	mkdir -p "$ub_eclipse_configuration"
+	_eclipse_example_binary -vm "$ubJava" -data "$ub_eclipse_workspace" -configuration "$ub_eclipse_configuration" "$@"
+}
+
+
+
+_eclipse_example_procedure() {
+	! _set_java__eclipse && _stop 1
+
+	# Scope will by default... cd "$ub_specimen" ...
+	#... abstractfs... consistent directory name... '_eclipse_executable'
+	mkdir -p ./project
+	cd ./project
+
+
+	# Configuration Lookup Directory
+	_prepare_example_ConfigurationLookupDirectory_eclipse _eclipse_example-static "$@"
+
+
+	#... fakeHome... preparation... disable ?
+
+
+	# Example only.
+	[[ "$specialGCC" != '' ]] && _messagePlain_request 'request: special GCC bin='"$specialGCC"
+
+	#echo "$ub_specimen"
+
+
+
+	_messagePlain_request 'request: abstractfs: project:  '"$ubAFS_PRJ"
+
+
+	#_abstractfs bash
+	#eclipse -vm "$ubJava"  "$@"
+
+
+	# DANGER: Current directory WILL be included in directory chosen by "_abstractfs" !
+	_abstractfs _eclipse_example-static "$@"
+}
+
+
+_eclipse_example() {
+	#_fakeHome "$scriptAbsoluteLocation" _eclipse_example_procedure "$@"
+	"$scriptAbsoluteLocation" _eclipse_example_procedure "$@"
+}
+
+
+#Simulated client/server discussion testing.
+
+_log_query() {
+	[[ "$1" == "" ]] && return 1
+
+	tee "$1"
+
+	return 0
+}
+
+_report_query_stdout() {
+	[[ "$1" == "" ]] && return 1
+
+	_messagePlain_probe 'stdout: strings'
+	strings "$1"
+
+	_messagePlain_probe 'stdout: hex'
+	xxd -p "$1" | tr -d '\n'
+	echo
+
+	return 0
+}
+
+# ATTENTION: Overload with "core.sh" or similar.
+_prepare_query_prog() {
+	true
+}
+
+_prepare_query() {
+	export ub_queryclientdir="$queryTmp"/client
+	export qc="$ub_queryclientdir"
+
+	export ub_queryclient="$ub_queryclientdir"/script
+	export qce="$ub_queryclient"
+
+	export ub_queryserverdir="$queryTmp"/server
+	export qs="$ub_queryserverdir"
+
+	export ub_queryserver="$ub_queryserverdir"/script
+	export qse="$ub_queryserver"
+
+	mkdir -p "$ub_queryclientdir"
+	mkdir -p "$ub_queryserverdir"
+
+	! [[ -e "$ub_queryclient" ]] && cp "$scriptAbsoluteLocation" "$ub_queryclient"
+	! [[ -e "$ub_queryserver" ]] && cp "$scriptAbsoluteLocation" "$ub_queryserver"
+
+	_prepare_query_prog "$@"
+
+	_safe_declare_uid
+}
+
+_queryServer_sequence() {
+	_start
+
+	_safe_declare_uid
+
+	local currentExitStatus
+
+	export queryType="server"
+	"$ub_queryserver" "$@"
+	currentExitStatus="$?"
+
+	env > env_$(_uid)
+
+	_stop "$currentExitStatus"
+}
+_queryServer() {
+	"$scriptAbsoluteLocation" _queryServer_sequence "$@"
+}
+_qs() {
+	_queryServer "$@"
+}
+
+_queryClient_sequence() {
+	_start
+
+	_safe_declare_uid
+
+	local currentExitStatus
+
+	export queryType="client"
+	"$ub_queryclient" "$@"
+	currentExitStatus="$?"
+
+	env > env_$(_uid)
+
+	_stop "$currentExitStatus"
+}
+_queryClient() {
+	"$scriptAbsoluteLocation" _queryClient_sequence "$@"
+}
+_qc() {
+	_queryClient "$@"
+}
+
+_query_diag() {
+	echo test | _query "$@"
+	local currentExitStatus="$?"
+
+	_messagePlain_nominal 'diag: tx.log'
+	_report_query_stdout "$queryTmp"/tx.log
+
+	_messagePlain_nominal 'diag: xc.log'
+	_report_query_stdout "$queryTmp"/xc.log
+
+	_messagePlain_nominal 'diag: rx.log'
+	_report_query_stdout "$queryTmp"/rx.log
+
+	return "$currentExitStatus"
+}
+
+# ATTENTION: Overload with "core.sh" or similar.
+_query() {
+	_prepare_query
+
+	( cd "$qc" ; _queryClient _bin cat | _log_query "$queryTmp"/tx.log | ( cd "$qs" ; _queryServer _bin cat | _log_query "$queryTmp"/xc.log | ( cd "$qc" ; _queryClient _bin cat | _log_query "$queryTmp"/rx.log ; return "${PIPESTATUS[0]}" )))
+}
+
+_scope_attach_prog() {
+	true
+}
+
+# No known production use.
+_scope_attach_compile() {
+	#_scope_command_write _compile
+	#_scope_command_external_here _compile
+	true
+}
+
+_scope_attach_query() {
+	_scope_command_write _query
+	_scope_command_write _qs
+	_scope_command_write _qc
+}
+
+# ATTENTION: Overload with "core.sh" or similar!
+_scope_attach() {
+	_messagePlain_nominal '_scope_attach'
+
+	_scope_here > "$ub_scope"/.devenv
+	chmod u+x "$ub_scope"/.devenv
+	_scope_readme_here > "$ub_scope"/README
+
+	_scope_command_write _scope_terminal_procedure
+
+	_scope_command_write _scope_konsole_procedure
+	_scope_command_write _scope_dolphin_procedure
+	_scope_command_write _scope_eclipse_procedure
+	_scope_command_write _scope_atom_procedure
+
+	_scope_attach_query "$@"
+
+	_scope_attach_compile "$@"
+
+	_scope_attach_prog "$@"
+}
+
+_prepare_scope() {
+	#mkdir -p "$safeTmp"/scope
+	mkdir -p "$scopeTmp"
+	#true
+}
+
+_relink_scope() {
+	#_relink "$safeTmp"/scope "$ub_scope"
+	_relink "$scopeTmp" "$ub_scope"
+	#_relink "$safeTmp" "$ub_scope"
+
+	_relink "$safeTmp" "$ub_scope"/safeTmp
+	_relink "$shortTmp" "$ub_scope"/shortTmp
+
+	# DANGER: Creates infinitely recursive symlinks.
+	#[[ -e "$abstractfs_projectafs" ]] && _relink "$abstractfs_projectafs" "$ub_scope"/project.afs
+	#[[ -d "$abstractfs" ]] && _relink "$abstractfs" "$ub_scope"/afs
+}
+
+_ops_scope() {
+	_messagePlain_nominal '_ops_scope'
+
+	#Find/run ops file in project dir.
+	[[ -e "$ub_specimen"/ops ]] && _messagePlain_good 'aU: found: sketch ops: ops' && . "$ub_specimen"/ops
+	[[ -e "$ub_specimen"/ops.sh ]] && _messagePlain_good 'aU: found: sketch ops: ops.sh' && . "$ub_specimen"/ops.sh
+
+	! [[ -e "$ub_specimen"/ops ]] && ! [[ -e "$ub_specimen"/ops.sh ]] && _messagePlain_warn 'aU: undef: sketch ops' && return 1
+
+	return 0
+}
+
+#"$1" == ub_specimen
+#"$ub_scope_name" (default "scope")
+# WARNING Multiple instances of same scope on a single specimen strictly forbidden. Launch multiple applications within a scope, not multiple scopes.
+_start_scope() {
+	_messagePlain_nominal '_start_scope'
+
+	export ub_specimen=$(_getAbsoluteLocation "$1")
+	export specimen="$ub_specimen"
+	export ub_specimen_basename=$(basename "$ub_specimen")
+	export basename="$ub_specimen_basename"
+	[[ ! -d "$ub_specimen" ]] && _messagePlain_bad 'missing: specimen= '"$ub_specimen" && _stop 1
+	[[ ! -e "$ub_specimen" ]] && _messagePlain_bad 'missing: specimen= '"$ub_specimen" && _stop 1
+
+	[[ "$ub_scope_name" == "" ]] && export ub_scope_name='scope'
+
+	export ub_scope="$ub_specimen"/.s_"$ub_scope_name"
+	export scope="$ub_scope"
+	[[ -e "$ub_scope" ]] && _messagePlain_bad 'fail: safety: multiple scopes && single specimen' && _stop 1
+	[[ -L "$ub_scope" ]] && _messagePlain_bad 'fail: safety: multiple scopes && single specimen' && _stop 1
+
+	#[[ -e "$ub_specimen"/.e_* ]] && _messagePlain_bad 'fail: safety: engine root scope strongly discouraged' && _stop 1
+
+	#export ub_scope_tmp="$ub_scope"/s_"$sessionid"
+
+	_prepare_scope "$@"
+	_relink_scope "$@"
+	[[ ! -d "$ub_scope" ]] && _messagePlain_bad 'fail: link scope= '"$ub_scope" && _stop 1
+	#[[ ! -d "$ub_scope_tmp" ]] && _messagePlain_bad 'fail: create ub_scope_tmp= '"$ub_scope_tmp" && _stop 1
+	[[ ! -d "$ub_scope"/safeTmp ]] && _messagePlain_bad 'fail: link' && _stop 1
+	[[ ! -d "$ub_scope"/shortTmp ]] && _messagePlain_bad 'fail: link' && _stop 1
+
+	[[ ! -e "$ub_scope"/.pid ]] && echo $$ > "$ub_scope"/.pid
+
+	_messagePlain_good 'pass: prepare, relink'
+
+	return 0
+}
+
+#Defaults, bash terminal, wait for kill signal, wait for EOF, etc. Override with "core.sh" . May run file manager, terminal, etc.
+# WARNING: Scope should only be terminated by process or user managing this interaction (eg. by closing file manager). Manager must be aware of any inter-scope dependencies.
+#"$@" <commands>
+_scope_interact() {
+	_messagePlain_nominal '_scope_interact'
+	#read > /dev/null 2>&1
+
+	_scopePrompt
+
+	_safe_declare_uid
+
+	if [[ "$@" == "" ]]
+	then
+		_scope_terminal_procedure
+		#_scope_eclipse_procedure
+		#eclipse
+# 		return
+	fi
+
+	_safe_declare_uid
+
+	"$@"
+}
+
+# ATTENTION: Overload with "core.sh" or similar!
+_scope_prog_procedure() {
+	# WARNING: Not necessarily wise for all applications. However, applications needing a different working directory should get there from an environment variable relative to script or specimen directory.
+	# WARNING: Disabling this may cause inconsistencies with programs which require "_abstractfs" (eg. Arduino, Eclipse).
+	cd "$ub_specimen"
+
+	#true
+}
+
+
+_scope_sequence() {
+	_messagePlain_nominal 'init: scope: '"$ub_scope_name"
+	_messagePlain_probe 'HOME= '"$HOME"
+
+	_start
+	_start_scope "$@"
+	_ops_scope
+
+	_scope_prog_procedure "$@"
+
+	_scope_attach "$@"
+
+	#User interaction.
+	shift
+	_scope_interact "$@"
+
+	_stop
+}
+
+# ATTENTION: Overload with "core.sh" or similar!
+_scope_prog() {
+	[[ "$ub_scope_name" == "" ]] && export ub_scope_name='scope'
+}
+
+_scope() {
+	_scope_prog "$@"
+	[[ "$ub_scope_name" == "" ]] && export ub_scope_name='scope'
+	"$scriptAbsoluteLocation" _scope_sequence "$@"
+}
+
+_scope_readme_here() {
+	cat << CZXWXcRMTo8EmM8i4d
+Ubiquitous Bash scope.
+CZXWXcRMTo8EmM8i4d
+}
+
+#Example, override with "core.sh" .
+_scope_var_here_prog() {
+	cat << CZXWXcRMTo8EmM8i4d
+CZXWXcRMTo8EmM8i4d
+}
+
+_scope_var_here() {
+	cat << CZXWXcRMTo8EmM8i4d
+export ub_specimen="$ub_specimen"
+export specimen="$specimen"
+export ub_specimen_basename="$ub_specimen_basename"
+export basename="$basename"
+export ub_scope_name="$ub_scope_name"
+export ub_scope="$ub_scope"
+export scope="$scope"
+
+CZXWXcRMTo8EmM8i4d
+
+	_scope_var_here_prog "$@"
+}
+
+_scope_here() {
+	cat << CZXWXcRMTo8EmM8i4d
+#!/usr/bin/env bash
+
+CZXWXcRMTo8EmM8i4d
+
+	_scope_var_here
+
+	cat << CZXWXcRMTo8EmM8i4d
+
+export scriptAbsoluteLocation="$scriptAbsoluteLocation"
+export scriptAbsoluteFolder="$scriptAbsoluteFolder"
+export sessionid="$sessionid"
+. "$scriptAbsoluteLocation" --devenv "\$@"
+CZXWXcRMTo8EmM8i4d
+}
+
+_scope_command_here() {
+	cat << CZXWXcRMTo8EmM8i4d
+#!/usr/bin/env bash
+
+CZXWXcRMTo8EmM8i4d
+
+	_scope_var_here
+
+	cat << CZXWXcRMTo8EmM8i4d
+
+export scriptAbsoluteLocation="$scriptAbsoluteLocation"
+export scriptAbsoluteFolder="$scriptAbsoluteFolder"
+export sessionid="$sessionid"
+. "$scriptAbsoluteLocation" --devenv "$1" "\$@"
+CZXWXcRMTo8EmM8i4d
+}
+
+_scope_command_external_here() {
+	cat << CZXWXcRMTo8EmM8i4d
+#!/usr/bin/env bash
+
+CZXWXcRMTo8EmM8i4d
+
+	_scope_var_here
+
+	cat << CZXWXcRMTo8EmM8i4d
+
+export importScriptLocation="$scriptAbsoluteLocation"
+export importScriptFolder="$scriptAbsoluteFolder"
+. "$scriptAbsoluteLocation" --script "$1" "\$@"
+CZXWXcRMTo8EmM8i4d
+}
+
+_scope_command_write() {
+	_scope_command_here "$@" > "$ub_scope"/"$1"
+	chmod u+x "$ub_scope"/"$1"
+}
+
+_scope_command_external_write() {
+	_scope_command_external_here "$@" > "$ub_scope"/"$1"
+	chmod u+x "$ub_scope"/"$1"
+}
+
+_scopePrompt() {
+	[[ "$ub_scope_name" == "" ]] && return 0
+
+	#export PS1='\[\033[01;40m\]\[\033[01;36m\]+\[\033[01;34m\]-|\[\033[01;31m\]${?}:${debian_chroot:+($debian_chroot)}\[\033[01;33m\]\u\[\033[01;32m\]@\h\[\033[01;36m\]\[\033[01;34m\])-\[\033[01;36m\]------------------------\[\033[01;34m\]-(\[\033[01;35m\]$(date +%H:%M:%S\ .%d)\[\033[01;34m\])-\[\033[01;36m\]- -|\[\033[00m\]\n\[\033[01;40m\]\[\033[01;36m\]+\[\033[01;34m\]-|\[\033[37m\][\w]\[\033[00m\]\n\[\033[01;36m\]+\[\033[01;34m\]-|\#) \[\033[36m\]'"$ub_scope_name"'>\[\033[00m\] '
+
+
+	_visualPrompt
+
+	if ! _if_cygwin
+	then
+		export PS1='\[\033[01;40m\]\[\033[01;36m\]\[\033[01;34m\]|\[\033[01;31m\]${?}:${debian_chroot:+($debian_chroot)}\[\033[01;33m\]\u\[\033[01;32m\]@\h\[\033[01;36m\]\[\033[01;34m\])\[\033[01;36m\]\[\033[01;34m\]-(\[\033[01;35m\]$(date +%H:%M:%S\.%d)\[\033[01;34m\])\[\033[01;36m\]|\[\033[00m\]\n\[\033[01;40m\]\[\033[01;36m\]\[\033[01;34m\]|\[\033[37m\][\w]\[\033[00m\]\n\[\033[01;36m\]\[\033[01;34m\]|$PS1_lineNumberText\[\033[01;34m\]) \[\033[36m\]'"$ub_scope_name"'>\[\033[00m\] '
+	else
+		export PS1='\[\033[01;40m\]\[\033[01;36m\]\[\033[01;34m\]|\[\033[01;31m\]${?}:${debian_chroot:+($debian_chroot)}\[\033[01;33m\]\u\[\033[01;32m\]@\h\[\033[01;36m\]\[\033[01;34m\])\[\033[01;36m\]\[\033[01;34m\]-(\[\033[01;35m\]$(date +%H:%M:%S\.%d)\[\033[01;34m\])\[\033[01;36m\]|\[\033[00m\]\n\[\033[01;40m\]\[\033[01;36m\]\[\033[01;34m\]\[\033[37m\]\w\n\[\033[01;36m\]\[\033[01;34m\]|$PS1_lineNumberText\[\033[01;34m\]) \[\033[36m\]'"$ub_scope_name"'>\[\033[00m\] '
+	fi
+}
+
+_scope_terminal_procedure() {
+	_tryExec '_scopePrompt'
+	#_tryExec '_visualPrompt'
+
+	_safe_declare_uid
+
+	export PATH="$PATH":"$ub_scope"
+	echo
+	/usr/bin/env bash --norc
+	echo
+}
+
+_scope_terminal() {
+	_safe_declare_uid
+
+	local shiftParam1
+	shiftParam1="$1"
+	shift
+
+	_scope_prog "$@"
+	_scope "$shiftParam1" "_scope_terminal_procedure" "$@"
+}
+
+_scope_eclipse_procedure() {
+	_safe_declare_uid
+
+	_eclipse "$@"
+}
+
+_scope_eclipse() {
+	_safe_declare_uid
+
+	local shiftParam1
+	shiftParam1="$1"
+	shift
+
+	_scope_prog "$@"
+	_scope "$shiftParam1" "_scope_eclipse_procedure" "$@"
+}
+
+_scope_atom_procedure() {
+	_safe_declare_uid
+
+	"$scriptAbsoluteLocation" _atom_tmp_sequence "$ub_specimen" "$@"  > /dev/null 2>&1
+}
+
+# WARNING: No production use. Not to be relied upon. May be removed.
+_scope_atom() {
+	_safe_declare_uid
+
+	local shiftParam1
+	shiftParam1="$1"
+	shift
+
+	_scope_prog "$@"
+	_scope "$shiftParam1" "_scope_atom_procedure" "$@"
+}
+
+_scope_konsole_procedure() {
+	_safe_declare_uid
+
+	_messagePlain_probe konsole --workdir "$ub_specimen" "$@"
+	konsole --workdir "$ub_specimen" "$@"
+}
+
+_scope_konsole() {
+	_safe_declare_uid
+
+	local shiftParam1
+	shiftParam1="$1"
+	shift
+
+	_scope_prog "$@"
+	_scope "$shiftParam1" "_scope_konsole_procedure" -p tabtitle="$ub_scope_name" "$@"
+}
+
+_scope_dolphin_procedure() {
+	_safe_declare_uid
+
+	dolphin "$ub_specimen" "$@"
+}
+
+_scope_dolphin() {
+	_safe_declare_uid
+
+	local shiftParam1
+	shiftParam1="$1"
+	shift
+
+	_scope_prog "$@"
+	_scope "$shiftParam1" "_scope_dolphin_procedure" "$@"
+}
+
+
+_github_removeActionsHTTPS-filter() {
+    _messagePlain_probe '_github_removeActionsHTTPS-filter: '"$1"
+
+    sed -i 's/^\sextraheader.*$//g' "$1"
+    sed -i 's/^\sinsteadOf = git@github.com:.*$//g' "$1"
+    sed -i 's/^\sinsteadOf = org.*@github.com:.*$//g' "$1"
+}
+
+_github_removeActionsHTTPS() {
+    if [[ "$1" != *".git"* ]] && [[ "$1" != *".git" ]]
+    then
+        _messagePlain_bad 'warn: missing: .git: '"$1"
+        _messageFAIL
+        _stop 1
+        return 1
+    fi
+
+    find "$1" -type f -name 'config' -exec "$scriptAbsoluteLocation" _github_removeActionsHTTPS-filter {} \;
+
+
+}
+
+
+
+
+
+
+
+# "$1" == build-${{ github.run_id }}-${{ github.run_attempt }}
+#shift
+# "$@" == ./_local/package_image_beforeBoot.tar.flx.part*
+_gh_release_upload_parts-multiple() {
+    "$scriptAbsoluteLocation" _gh_release_upload_parts-multiple_sequence "$@"
+}
+_gh_release_upload_parts-multiple_sequence() {
+    _messageNormal '_gh_release_upload_parts: '"$@"
+    local currentTag="$1"
+    shift
+
+    local currentStream_max=12
+
+    local currentStreamNum=0
+
+    for currentFile in "$@"
+    do
+        let currentStreamNum++
+
+        "$scriptAbsoluteLocation" _gh_release_upload_part-single_sequence "$currentTag" "$currentFile" &
+        eval local currentStream_${currentStreamNum}_PID="$!"
+        _messagePlain_probe_var currentStream_${currentStreamNum}_PID
+
+        while [[ $(jobs | wc -l) -ge "$currentStream_max" ]]
+        do
+            echo
+            jobs
+            echo
+            sleep 2
+            true
+        done
+    done
+
+    local currentStreamPause
+    for currentStreamPause in $(seq "1" "$currentStreamNum")
+	do
+        _messagePlain_probe currentStream_${currentStreamPause}_PID= $(eval "echo \$currentStream_${currentStreamPause}_PID")
+		if eval "[[ \$currentStream_${currentStreamPause}_PID != '' ]]"
+        then
+           _messagePlain_probe _pauseForProcess $(eval "echo \$currentStream_${currentStreamPause}_PID")
+           _pauseForProcess $(eval "echo \$currentStream_${currentStreamPause}_PID")
+        fi
+	done
+
+    while [[ $(jobs | wc -l) -ge 1 ]]
+    do
+        echo
+        jobs
+        echo
+        sleep 2
+        true
+    done
+
+    wait
+}
+_gh_release_upload_part-single_sequence() {
+    _messagePlain_nominal '_gh_release_upload: '"$1"' '"$2"
+    local currentTag="$1"
+    local currentFile="$2"
+
+    #local currentPID
+    #"$scriptAbsoluteLocation" _stopwatch gh release upload "$currentTag" "$currentFile" &
+    #currentPID="$!"
+
+    #_pauseForProcess "$currentPID"
+    #wait
+
+    #while ! "$scriptAbsoluteLocation" _stopwatch _timeout 10 dd if="$currentFile" bs=1M status=progress > /dev/null
+    #do
+        #sleep 7
+    #done
+    #return 0
+
+    # Maximum file size is 2GigaBytes .
+    local currentIteration=0
+    while ! "$scriptAbsoluteLocation" _stopwatch _timeout 600 gh release upload --clobber "$currentTag" "$currentFile" && [[ "$currentIteration" -lt 30 ]]
+    do
+        sleep 7
+        let currentIteration++
+    done
+    return 0
+}
+
+
+
+_testGit() {
+	_wantGetDep git
+}
+
+#Ignores file modes, suitable for use with possibly broken filesystems like NTFS.
+_gitCompatible() {
+	git -c core.fileMode=false "$@"
+}
+
+_gitInfo() {
+	#Git Repository Information
+	export repoDir="$PWD"
+
+	export repoName=$(basename "$repoDir")
+	export bareRepoDir=../."$repoName".git
+	export bareRepoAbsoluteDir=$(_getAbsoluteLocation "$bareRepoDir")
+
+	#Set $repoHostName in user ".bashrc" or similar. May also set $repoPort including colon prefix.
+	[[ "$repoHostname" == "" ]] && export repoHostname=$(hostname -f)
+
+	true
+}
+
+_gitRemote() {
+	_gitInfo
+
+	if [[ -e "$bareRepoDir" ]]
+	then
+		_showGitRepoURI
+		return 0
+	fi
+
+	if ! [[ -e "$repoDir"/.git ]]
+	then
+		return 1
+	fi
+
+	if git config --get remote.origin.url > /dev/null 2>&1
+	then
+		echo -n "git clone --recursive "
+		git config --get remote.origin.url
+		return 0
+	fi
+	_gitBare
+}
+
+_gitNew() {
+	git init
+	git add .
+	git commit -a -m "first commit"
+	git branch -M main
+}
+
+_gitImport() {
+	cd "$scriptFolder"
+
+	mkdir -p "$1"
+	cd "$1"
+	shift
+	git clone "$@"
+
+	cd "$scriptFolder"
+}
+
+_findGit_procedure() {
+	cd "$1"
+	shift
+
+	if [[ -e "./.git" ]]
+	then
+		"$@"
+		return 0
+	fi
+
+	find -L . -mindepth 1 -maxdepth 1 -not \( -path \*_arc\* -prune \) -not \( -path \*/_local/ubcp/\* -prune \) -type d -exec "$scriptAbsoluteLocation" _findGit_procedure '{}' "$@" \;
+}
+
+#Recursively searches for directories containing ".git".
+_findGit() {
+	if [[ -e "./.git" ]]
+	then
+		"$@"
+		return 0
+	fi
+
+	find -L . -mindepth 1 -maxdepth 1 -not \( -path \*_arc\* -prune \) -not \( -path \*/_local/ubcp/\* -prune \) -type d -exec "$scriptAbsoluteLocation" _findGit_procedure '{}' "$@" \;
+}
+
+_gitPull() {
+	git pull
+	git submodule update --recursive
+}
+
+_gitCheck_sequence() {
+	echo '-----'
+
+	local checkRealpath
+	checkRealpath=$(realpath .)
+	local checkBasename
+	checkBasename=$(basename "$checkRealpath")
+
+	echo "$checkBasename"
+
+	git status
+}
+
+_gitCheck() {
+	_findGit "$scriptAbsoluteLocation" _gitCheck_sequence
+}
+
+_gitPullRecursive_sequence() {
+	echo '-----'
+
+	local checkRealpath
+	checkRealpath=$(realpath .)
+	local checkBasename
+	checkBasename=$(basename "$checkRealpath")
+
+	echo "$checkBasename"
+
+	"$scriptAbsoluteLocation" _gitPull
+}
+
+# DANGER
+#Updates all git repositories recursively.
+_gitPullRecursive() {
+	_findGit "$scriptAbsoluteLocation" _gitPullRecursive_sequence
+}
+
+# DANGER
+# Pushes all changes as a commit described as "Upstream."
+_gitUpstream() {
+	git add -A . ; git commit -a -m "Upstream." ; git push
+}
+_gitUp() {
+	_gitUpstream
+}
+
+# DANGER
+#Removes all but the .git folder from the working directory.
+#_gitFresh() {
+#	find . -not -path '\.\/\.git*' -delete
+#}
+
+
+
+
+# DANGER: Intended for use ONLY by dist/OS build scripts and similar within ChRoot, ephemeral containers, or other at least mostly replaceable root filesystems.
+# The dangerous function is not defined by default and only becomes available after running gitFresh_enable
+#
+# ATTRIBUTION-AI: DeepSeek-R1-Distill-Llama-70B  2025-03-15
+# Define the enable function
+_gitFresh_enable() {
+    if [[ "$ub_dryRun" == "true" ]]
+    then
+        _stop
+        exit
+        return
+    fi
+
+	# Define the dangerous function here
+	#_gitFresh() {
+		#[[ "$PWD" == "/" ]] && return 1
+		#[[ "$PWD" == "-"* ]] && return 1
+
+		#[[ "$PWD" == "/home" ]] && return 1
+		#[[ "$PWD" == "/home/" ]] && return 1
+		#[[ "$PWD" == "/home/$USER" ]] && return 1
+		#[[ "$PWD" == "/home/$USER/" ]] && return 1
+		#[[ "$PWD" == "/$USER" ]] && return 1
+		#[[ "$PWD" == "/$USER/" ]] && return 1

+		#[[ "$PWD" == "/tmp" ]] && return 1
+		#[[ "$PWD" == "/tmp/" ]] && return 1

+		#[[ "$PWD" == "$HOME" ]] && return 1
+		#[[ "$PWD" == "$HOME/" ]] && return 1

+		#find . -not -path '\.\/\.git*' -delete
+	#}
+	# ATTRIBUTION-AI: DeepSeek-R1-Distill-Llama-8B  2025-03-15
+	#  Do NOT take that as an endorsement of a chain-of-reasoning 8B model, way too few parameters for that. This was one result of very many.
+	source <(echo "_gitFresh() { [[ "$PWD" == "/" ]] && return 1 ; [[ "$PWD" == "-"* ]] && return 1 ; [[ "$PWD" == "/home" ]] && return 1 ; [[ "$PWD" == "/home/" ]] && return 1 ; [[ "$PWD" == "/home/$USER" ]] && return 1 ; [[ "$PWD" == "/home/$USER/" ]] && return 1 ; [[ "$PWD" == "/$USER" ]] && return 1 ; [[ "$PWD" == "/$USER/" ]] && return 1 ; [[ "$PWD" == "/tmp" ]] && return 1 ; [[ "$PWD" == "/tmp/" ]] && return 1 ; [[ "$PWD" == "$HOME" ]] && return 1 ; [[ "$PWD" == "$HOME/" ]] && return 1 ; find . -not -path '\.\/\.git*' -delete ; }")
+
+	# Export the function to make it available
+	export -f _gitFresh
+}
+
+
+
+
+
+
+
+# DANGER: CAUTION: WARNING: Calls '_git_shallow'.
+_git_shallow-ubiquitous() {
+	[[ "$1" != "true" ]] && exit 1
+
+	_git_shallow 'git@github.com:mirage335/ubiquitous_bash.git' '_lib/ubiquitous_bash'
+}
+
+# DANGER: Not robust. May damage repository and/or submodules, as well as any history not remotely available, causing *severe* data loss.
+# CAUTION: Intended only for developers to correct a rare mistake of adding a non-shallow git submodule. No production use.
+# WARNING: Submodule path must NOT have trailing or preceeding slash!
+# "$1" == uri (eg. git@github.com:mirage335/ubiquitous_bash.git)
+# "$2" == path/to/submodule (eg. '_lib/ubiquitous_bash')
+_git_shallow() {
+	[[ "$1" == "" ]] && exit 1
+	[[ "$2" == "" ]] && exit 1
+	! [[ -e "$2" ]] && exit 1
+	! [[ -e "$scriptAbsoluteFolder"/"$2" ]] && exit 1
+	cd "$scriptAbsoluteFolder"
+	! [[ -e "$2" ]] && exit 1
+	! [[ -e "$scriptAbsoluteFolder"/"$2" ]] && exit 1
+
+
+	! [[ -e "$scriptAbsoluteFolder"/.gitmodules ]] && exit 1
+	! [[ -e "$scriptAbsoluteFolder"/.git/config ]] && exit 1
+
+	_start
+
+	# https://gist.github.com/myusuf3/7f645819ded92bda6677
+
+	# Remove the submodule entry from .git/config
+	git submodule deinit -f "$2"
+
+	# Remove the submodule directory from the superproject's .git/modules directory
+	#rm -rf .git/modules/"$2"
+	export safeToDeleteGit="true"
+	_safeRMR "$scriptAbsoluteFolder"/.git/modules/"$2"
+
+	# Remove the entry in .gitmodules and remove the submodule directory located at path/to/submodule
+	git rm -f "$2"
+
+	git commit -m "WIP."
+
+
+	# https://stackoverflow.com/questions/2144406/how-to-make-shallow-git-submodules
+
+	git submodule add --depth 1 "$1" "$2"
+
+	git config -f .gitmodules submodule."$2".shallow true
+
+	_messagePlain_request git commit -a -m "Draft."
+	_messagePlain_request git push
+
+	_stop
+}
+
+
+
+
+
+#####Program
+
+_createBareGitRepo() {
+	mkdir -p "$bareRepoDir"
+	cd $bareRepoDir
+
+	git --bare init
+	git branch -M main
+
+	echo "-----"
+}
+
+
+_setBareGitRepo() {
+	cd "$repoDir"
+
+	git remote rm origin
+	git remote add origin "$bareRepoDir"
+	git push --set-upstream origin master
+
+	# WARNING: TODO: Experimental, requires further testing. Use branch 'main' if extant.
+	git push --set-upstream origin main
+
+	echo "-----"
+}
+
+_showGitRepoURI() {
+	echo git clone --recursive "$bareRepoAbsoluteDir" "$repoName"
+	echo git clone --recursive ssh://"$USER"@"$repoHostname""$repoPort""$bareRepoAbsoluteDir" "$repoName"
+
+
+	#if [[ "$repoHostname" != "" ]]
+	#then
+	#	clear
+	#	echo ssh://"$USER"@"$repoHostname""$repoPort""$bareRepoAbsoluteDir"
+	#	sleep 15
+	#fi
+}
+
+_gitBareSequence() {
+	_gitInfo
+
+	if [[ -e "$bareRepoDir" ]]
+	then
+		_showGitRepoURI
+		return 2
+	fi
+
+	if ! [[ -e "$repoDir"/.git ]]
+	then
+		return 1
+	fi
+
+	_createBareGitRepo
+
+	_setBareGitRepo
+
+	_showGitRepoURI
+
+}
+
+_gitBare() {
+
+	"$scriptAbsoluteLocation" _gitBareSequence
+
+}
+
+
+
+
+_self_gitMad_procedure() {
+	local functionEntryPWD
+	functionEntryPWD="$PWD"
+
+	cd "$scriptAbsoluteFolder"
+	_gitMad
+
+	cd "$functionEntryPWD"
+}
+_self_gitMad() {
+	"$scriptAbsoluteLocation" _self_gitMad_procedure "$@"
+}
+# https://stackoverflow.com/questions/1580596/how-do-i-make-git-ignore-file-mode-chmod-changes
+_gitMad() {
+	local currentDirectory=$(_getAbsoluteLocation "$PWD")
+	_write_configure_git_safe_directory_if_admin_owned "$currentDirectory"
+
+	git config core.fileMode false
+	git submodule foreach git config core.fileMode false
+	git submodule foreach git submodule foreach git config core.fileMode false
+	git submodule foreach git submodule foreach git submodule foreach git config core.fileMode false
+	git submodule foreach git submodule foreach git submodule foreach git submodule foreach git config core.fileMode false
+	git submodule foreach git submodule foreach git submodule foreach git submodule foreach git submodule foreach git config core.fileMode false
+	git submodule foreach git submodule foreach git submodule foreach git submodule foreach git submodule foreach git submodule foreach git config core.fileMode false
+	git submodule foreach git submodule foreach git submodule foreach git submodule foreach git submodule foreach git submodule foreach git submodule foreach git config core.fileMode false
+	git submodule foreach git submodule foreach git submodule foreach git submodule foreach git submodule foreach git submodule foreach git submodule foreach git submodule foreach git config core.fileMode false
+	git submodule foreach git submodule foreach git submodule foreach git submodule foreach git submodule foreach git submodule foreach git submodule foreach git submodule foreach git submodule foreach git config core.fileMode false
+	git submodule foreach git submodule foreach git submodule foreach git submodule foreach git submodule foreach git submodule foreach git submodule foreach git submodule foreach git submodule foreach git submodule foreach git config core.fileMode false
+}
+
+
+_gitBest_detect_github_procedure() {
+	[[ "$current_gitBest_source_GitHub" == "FAIL" ]] && export current_gitBest_source_GitHub=""
+	[[ "$current_gitBest_source_GitHub" != "" ]] && return
+
+	_messagePlain_nominal 'init: _gitBest_detect_github_procedure'
+
+	if [[ "$current_gitBest_source_GitHub" == "" ]]
+	then
+		_messagePlain_request 'performance: export current_gitBest_source_GitHub=$("'"$scriptAbsoluteLocation"'" _gitBest_detect_github_sequence | tail -n1)'

+		if [[ -e "$HOME"/core ]] && [[ "$gitBestNoCore" != "true" ]]
+		then
+			export current_gitBest_source_GitHub="github_core"
+		fi

+		local currentSSHoutput
+		# CAUTION: Disabling this presumes "$HOME"/.ssh/config for GitHub (possibly through 'CoreAutoSSH') is now not necessary to support by default.
+		#  ATTENTION: Good assumption. GH_TOKEN/INPUT_GITHUB_TOKEN is now used by _gitBest within 'compendium' functions, etc, usually much safer and more convenient.
+		#   Strongly Discouraged: Override with ops.sh if necessary.
+		# || [[ -e "$HOME"/.ssh/config ]]
+		if ( [[ -e "$HOME"/.ssh/id_rsa ]] || ( [[ ! -e "$HOME"/.ssh/id_ed25519_sk ]] && [[ ! -e "$HOME"/.ssh/ecdsa-sk ]] ) ) && currentSSHoutput=$(ssh -o StrictHostKeyChecking=no -o Compression=yes -o ConnectionAttempts=3 -o ServerAliveInterval=6 -o ServerAliveCountMax=9 -o ConnectTimeout="$netTimeout" -o PubkeyAuthentication=yes -o PasswordAuthentication=no git@github.com 2>&1 ; true) && _safeEcho_newline "$currentSSHoutput" | grep 'successfully authenticated'
+		then
+			export current_gitBest_source_GitHub="github_ssh"
+			return
+		fi
+		_safeEcho_newline "$currentSSHoutput"

+		# Exceptionally rare cases of 'github.com' accessed from within GitHub Actions runner (most surprisingly) not responding have apparently happened.
+		local currentIteration
+		for currentIteration in $(seq 1 2)
+		do
+			#if _checkPort github.com 443
+			if wget -qO- https://github.com > /dev/null
+			then
+				export current_gitBest_source_GitHub="github_https"
+				return
+			fi
+		done

-		_heading1-terminal() {
-			#_safeEcho_quoteAddSingle "$currentFunctionName" "$@"
-			_safeEcho_newline
-
-
-			#echo "$interpret__terminal_NOT_shell__begin"
-
-			_safeEcho_newline '_ '"$@"' _' | cat
-
-			#echo "$interpret__terminal_NOT_shell__end"
-		}
-		_heading2-terminal() {
-			#_safeEcho_quoteAddSingle "$currentFunctionName" "$@"
-			_safeEcho_newline
-
-
-			#echo "$interpret__terminal_NOT_shell__begin"
-
-			_safeEcho_newline '__ '"$@"' __' | cat
-
-			#echo "$interpret__terminal_NOT_shell__end"
-		}
-		_heading3-terminal() {
-			#_safeEcho_quoteAddSingle "$currentFunctionName" "$@"
-			_safeEcho_newline
-
-
-			#echo "$interpret__terminal_NOT_shell__begin"
-
-			_safeEcho_newline '___ '"$@"' ___' | cat
-
-			#echo "$interpret__terminal_NOT_shell__end"
-		}
-		_heading4-terminal() {
-			#_safeEcho_quoteAddSingle "$currentFunctionName" "$@"
-			_safeEcho_newline
-
-
-			#echo "$interpret__terminal_NOT_shell__begin"
-
-			_safeEcho_newline '____ '"$@"' ____' | cat
-
-			#echo "$interpret__terminal_NOT_shell__end"
-		}
-		_heading5-terminal() {
-			#_safeEcho_quoteAddSingle "$currentFunctionName" "$@"
-			_safeEcho_newline
-
-
-			#echo "$interpret__terminal_NOT_shell__begin"
-
-			_safeEcho_newline '_____ '"$@"' _____' | cat
-
-			#echo "$interpret__terminal_NOT_shell__end"
-		}
-		_heading6-terminal() {
-			#_safeEcho_quoteAddSingle "$currentFunctionName" "$@"
-			_safeEcho_newline
-
-
-			#echo "$interpret__terminal_NOT_shell__begin"
-
-			_safeEcho_newline '______ '"$@"' ______' | cat
-
-			#echo "$interpret__terminal_NOT_shell__end"
-		}

-		# Page break.
-		#title page (experiment)
-		#<div style="page-break-before: always;"> </div>
-		#<p>
-		#text page (experiment)
-		#</p>
-		_page-terminal() {
-			_safeEcho_newline
-			_safeEcho_quoteAddSingle "$currentFunctionName" "$@"
-			#_safeEcho_newline
-
-
-			#echo "$interpret__terminal_NOT_shell__begin"
-
-			_safeEcho_newline 'PageBreak -H-H-H-H- PageBreak -H-H-H-H- PageBreak -H-H-H-H- PageBreak -H-H-H-H- PageBreak' | cat
-
-			_safeEcho_newline
-
-			#_safeEcho_newline '<p style="page-break-after: always;">&nbsp;</p>' | cat
-			#_safeEcho_newline '<p style="page-break-before: always;">&nbsp;</p>' | cat
-
-			#_safeEcho_newline '<p style="page-break-after: always;">&nbsp;</p><p style="page-break-before: always;">&nbsp;</p>' | cat
-
-			#_safeEcho_newline '<div style="page-break-after: always;"> </div>' | cat
-			#_safeEcho_newline '<div></div>' | cat
-
-			#echo "$interpret__terminal_NOT_shell__end"
-		}
+		[[ "$current_gitBest_source_GitHub" == "" ]] && export current_gitBest_source_GitHub="FAIL"
+		return 1
+	fi
+	return 0
+}
+_gitBest_detect_github_sequence() {
+	_gitBest_detect_github_procedure "$@"
+	_messagePlain_probe_var current_gitBest_source_GitHub
+	echo "$current_gitBest_source_GitHub"
+}
+_gitBest_detect_github() {
+	local currentOutput
+	currentOutput=$("$scriptAbsoluteLocation" _gitBest_detect_github_sequence "$@")
+	_safeEcho_newline "$currentOutput"
+	export current_gitBest_source_GitHub=$(_safeEcho_newline "$currentOutput" | tail -n 1)
+	[[ "$current_gitBest_source_GitHub" != "github_"* ]] && export current_gitBest_source_GitHub="FAIL"
+
+	return 0
+}
+_gitBest_detect() {
+	_gitBest_detect_github "$@"
+}
+
+
+
+_gitBest_override_config_insteadOf-core() {
+	git config --global url."file://""$realHome""/core/infrastructure/""$1".insteadOf git@github.com:mirage335/"$1".git git@github.com:mirage335/"$1"
+}
+_gitBest_override_config_insteadOf-core--colossus() {
+	git config --global url."file://""$realHome""/core/infrastructure/""$1".insteadOf git@github.com:mirage335-colossus/"$1".git git@github.com:mirage335-colossus/"$1"
+}
+_gitBest_override_config_insteadOf-core--gizmos() {
+	git config --global url."file://""$realHome""/core/infrastructure/""$1".insteadOf git@github.com:mirage335-gizmos/"$1".git git@github.com:mirage335-gizmos/"$1"
+}
+_gitBest_override_config_insteadOf-core--distllc() {
+	git config --global url."file://""$realHome""/core/infrastructure/""$1".insteadOf git@github.com:soaringDistributions/"$1".git git@github.com:soaringDistributions/"$1"
+}
+
+
+_gitBest_override_github-github_core() {
+	_gitBest_override_config_insteadOf-core--colossus ubiquitous_bash
+	_gitBest_override_config_insteadOf-core--colossus extendedInterface
+
+	_gitBest_override_config_insteadOf-core--gizmos flightDeck
+	_gitBest_override_config_insteadOf-core--gizmos kinematicBase-large
+
+	_gitBest_override_config_insteadOf-core--distllc ubDistBuild
+	_gitBest_override_config_insteadOf-core--distllc ubDistFetch
+
+	_gitBest_override_config_insteadOf-core mirage335_documents
+	_gitBest_override_config_insteadOf-core mirage335GizmoScience
+
+	_gitBest_override_config_insteadOf-core scriptedIllustrator
+	_gitBest_override_config_insteadOf-core arduinoUbiquitous
+
+	_gitBest_override_config_insteadOf-core BOM_designer
+	_gitBest_override_config_insteadOf-core CoreAutoSSH
+	_gitBest_override_config_insteadOf-core coreoracle
+	_gitBest_override_config_insteadOf-core flipKey
+	_gitBest_override_config_insteadOf-core freecad-assembly2
+	_gitBest_override_config_insteadOf-core Freerouting
+	_gitBest_override_config_insteadOf-core gEDA_designer
+	_gitBest_override_config_insteadOf-core metaBus
+	_gitBest_override_config_insteadOf-core PanelBoard
+	_gitBest_override_config_insteadOf-core PatchRap
+	_gitBest_override_config_insteadOf-core PatchRap_LulzBot
+	_gitBest_override_config_insteadOf-core PatchRap_to_CNC
+	_gitBest_override_config_insteadOf-core pcb-ioAutorouter
+	_gitBest_override_config_insteadOf-core RigidTable
+	_gitBest_override_config_insteadOf-core SigBlockly-mod
+	_gitBest_override_config_insteadOf-core stepperTester
+	_gitBest_override_config_insteadOf-core TazIntermediate
+	_gitBest_override_config_insteadOf-core translate2geda
+	_gitBest_override_config_insteadOf-core webClient
+	_gitBest_override_config_insteadOf-core zipTiePanel
+}
+_gitBest_override_github-github_https() {
+	# && [[ "$1" == "push" ]]
+	if [[ "$INPUT_GITHUB_TOKEN" == "" ]]
+	then
+		git config --global url."https://github.com/".insteadOf git@github.com:
+	elif [[ "$INPUT_GITHUB_TOKEN" != "" ]]
+	then
+		git config --global url."https://""$INPUT_GITHUB_TOKEN""@github.com/".insteadOf git@github.com:
+	fi
+}
+
+
+
+_gitBest_override_github() {
+	_messagePlain_nominal 'init: _gitBest_override_github'
+
+	cat "$realHome"/.gitconfig >> "$HOME"/.gitconfig
+
+	if [[ "$current_gitBest_source_GitHub" == "github_core" ]]
+	then
+		_gitBest_override_github-github_core
+	fi
+
+	if [[ "$current_gitBest_source_GitHub" == "github_https" ]]
+	then
+		_gitBest_override_github-github_https "$@"
+	fi
+
+	if [[ "$current_gitBest_source_GitHub" == "github_ssh" ]]
+	then
+		_messagePlain_good 'good: preferred: github_ssh'
+	fi
+
+	if [[ "$current_gitBest_source_GitHub" == "FAIL" ]]
+	then
+		_messageError 'FAIL: missing: GitHub'
+		_stop 1
+	fi
+	return 0
+}
+
+
+
+
+
+
+
+
+_gitBest_sequence() {
+	_messagePlain_nominal 'init: _gitBest_sequence'
+
+	_start scriptLocal_mkdir_disable
+
+	export realHome="$HOME"
+	export HOME="$safeTmp"/special_fakeHome
+	mkdir -p "$HOME"
+
+	_messagePlain_probe_var current_gitBest_source_GitHub
+	_messagePlain_probe_var HOME
+
+
+	_gitBest_override_github "$@"
+
+	if ! [[ -e "$HOME"/.gitconfig ]]
+	then
+		_messagePlain_good 'good: write: overrides: none'
+	else
+		echo
+		echo
+		cat "$HOME"/.gitconfig
+		echo
+		echo
+	fi
+
+
+	_messagePlain_nominal 'init: git'
+
+	local currentExitStatus
+	git "$@"
+	currentExitStatus="$?"
+
+
+	export HOME="$realHome"
+	if _if_cygwin
+	then
+		if [ "$1" = "clone" ]
+		then
+			_messagePlain_nominal 'init: git safe directory'
+
+			# ATTRIBUTION-AI: ChatGPT 4.5-preview  2025-04-12  (partially)
+			local currentDirectory
+			local currentURL
+			local currentArg=""
+			local currentArg_previous=""
+			for currentArg in "$@"
+			do
+				# Ignore parameters:
+				#  begins with "-" dash
+				#  preceeded by parameter taking an argument, but no argument or "="
+				if [[ "$currentArg" != -* ]] && [[ "$currentArg" != "clone" ]] && [[ "$currentArg_previous" != "--template" ]] && [[ "$currentArg_previous" != "-o" ]] && [[ "$currentArg_previous" != "-b" ]] && [[ "$currentArg_previous" != "-u" ]] && [[ "$currentArg_previous" != "--reference" ]] && [[ "$currentArg_previous" != "--separate-git-dir" ]] && [[ "$currentArg_previous" != "--depth" ]] && [[ "$currentArg_previous" != "--jobs" ]] && [[ "$currentArg_previous" != "--filter" ]]
+				then
+					currentURL="$currentArg"
+					echo "$currentURL"
+					#break
+
+					[[ -e "$currentArg" ]] && currentDirectory="$currentArg"
+				fi
+				currentArg_previous="$currentArg"
+			done
+		fi

-		_paragraph_begin-terminal() {
-			#_safeEcho_quoteAddSingle "$currentFunctionName" "$@"
-			#_safeEcho_newline
-
-
-			#echo "$interpret__terminal_NOT_shell__begin"
-
-			_safeEcho_newline '' | cat
-			#_safeEcho_newline '<p style="margin: 0;padding: 0; border-width: 0px;">' | cat
-
-			#echo "$interpret__terminal_NOT_shell__end"
-		}
-		_paragraph_end-terminal() {
-			#_safeEcho_quoteAddSingle "$currentFunctionName" "$@"
-			#_safeEcho_newline
-
-
-			#echo "$interpret__terminal_NOT_shell__begin"
-
-			_safeEcho_newline '' | cat
-
-			#echo "$interpret__terminal_NOT_shell__end"
-		}
+		[[ "$currentDirectory" == "" ]] && [[ "$currentURL" != "" ]] && currentDirectory=$(basename --suffix=".git" "$currentURL")

-		_picture-terminal() {
-			local currentWidth
-			currentWidth=""
-			[[ "$2" != "" ]] && currentWidth="$2"
-
-			local currentWidthParameter
-			currentWidthParameter=""
-			[[ "$currentWidth" != "" ]] && currentWidthParameter='width="'"$currentWidth"'" '
-
-			_safeEcho_quoteAddSingle "$currentFunctionName" "$@"
-			_safeEcho_newline
-
-
-			#echo "$interpret__terminal_NOT_shell__begin"
-
-			#./
-			#https://www.hostpapa.com/knowledgebase/align-float-images-website/
-			#_safeEcho_newline '<img '"$currentWidthParameter"'src="'"$1"'" style="float: right;margin: 0 0 0 15px;border: 5px solid transparent;">' | cat
-
-			#echo "$interpret__terminal_NOT_shell__end"
-		}
-		_image-terminal() {
-			local currentWidth
-			currentWidth="96%"
-			[[ "$2" != "" ]] && currentWidth="$2"
-
-			local currentWidthParameter
-			currentWidthParameter=""
-			[[ "$currentWidth" != "" ]] && currentWidthParameter='width="'"$currentWidth"'" '
-
-			_safeEcho_quoteAddSingle "$currentFunctionName" "$@"
-			_safeEcho_newline
-
-
-			#echo "$interpret__terminal_NOT_shell__begin"
-
-			#./
-			#_safeEcho_newline '<img '"$currentWidthParameter"'src="'"$1"'" style="margin: 0 0 0 15px;border: 5px solid transparent;">' | cat
-
-			#echo "$interpret__terminal_NOT_shell__end"
-		}
+		if [[ -e "$currentDirectory" ]]
+		then
+			_messagePlain_probe 'exists: '"$currentDirectory"
+			if type _write_configure_git_safe_directory_if_admin_owned > /dev/null 2>&1
+			then
+				currentDirectory=$(_getAbsoluteLocation "$currentDirectory")
+				_write_configure_git_safe_directory_if_admin_owned "$currentDirectory"
+			fi
+		fi
+	fi
+
+	_stop "$currentExitStatus"
+}
+
+_gitBest() {
+	_messageNormal 'init: _gitBest'
+
+	_gitBest_detect "$@"
+
+	"$scriptAbsoluteLocation" _gitBest_sequence "$@"
+}
+
+
+_test_gitBest() {
+	_wantGetDep stty
+	_wantGetDep ssh
+
+	_wantGetDep git
+
+	#_wantGetDep nmap
+	#_wantGetDep curl
+	#_wantGetDep wget
+}
+
+
+
+
+
+
+# CAUTION: This file is very necessarily part of 'rotten' . Do NOT move functions or rename to other files without updating the build shellcode for 'rotten' !
+
+# Refactored from code which was very robust with fast ISP, however often failed with slower ISP, as explained by ChatGPT due to AWS S3 temporary link expiration.
+# See "_ref/wget_githubRelease_internal-OBSOLETE.sh" for original code, which due to the more iterative development process at the time, may be more reliable in untested cases.
+
+# WARNING: May be untested.
+
+# CAUTION: WARNING: Unusually, inheritance of local variables in procedure functions is relied upon. Theoretically, this has been long tested by 'ubiquitous_bash.sh _test' .
+#"$api_address_type"
+#"$currentStream"
+#"$currentAxelTmpFileRelative" "$currentAxelTmpFile"
+#
+#"$currentAbsoluteRepo"' '"$currentReleaseLabel"' '"$currentFile"
+#"$currentOutFile"
+
+# WARNING: CAUTION: Many functions rely on emitting to standard output . Experiment/diagnose by copying code to override with 'ops.sh' . CAUTION: Be very careful enabling or using diagnostic output to stderr, as stderr may also be redirected by calling functions, terminal may not be present, etc.
+#( echo x >&2 ) > /dev/null
+#_messagePlain_probe_var page >&2 | cat /dev/null
+#_messagePlain_probe_safe "current_API_page_URL= ""$current_API_page_URL" >&2 | cat /dev/null
+# WARNING: Limit stderr pollution for log (including CI logs) and terminal readability , using 'tail' .
+#( cat ubiquitous_bash.sh >&2 ) 2> >(tail -n 10 >&2) | tail -n 10
+#( set -o pipefail ; false | cat ubiquitous_bash.sh >&2 ) 2> >(tail -n 10 >&2) | cat > /dev/null
+#( set -o pipefail ; false 2> >(tail -n 10 >&2) | cat > /dev/null )
+
+# DANGER: Use _messagePlain_probe_safe , _safeEcho , _safeEcho_newline , etc .
+
+# CAUTION: ATTENTION: Uncommented lines add to ALL 'compiled' bash shell scripts - INCLUDING rotten_compressed.sh !
+# Thus, it may be preferable to keep example code as a separate line commented at the beginning of that line, rather than a comment character after code on the same line .
+
+
+
+
+
+# ATTENTION: 'MANDATORY_HASH == true' claim requirement can be imposed without any important effect on reliability or performance.
+# In practice, such multi-part-per-file download programs as 'aria2c' may or may not have any worse integrity safety concerns than other download programs.
+# NOTICE: Track record from historically imposing MANDATORY_HASH has been long enough to establish excellent confidence for imposing the requirement for this safety claim again without serious issue if necessary.
+# https://www.cvedetails.com/vulnerability-list/vendor_id-12682/Haxx.html
+#  'Haxx'
+# https://www.cvedetails.com/vulnerability-list/vendor_id-3385/Wget.html
+# https://www.cvedetails.com/vulnerability-list/vendor_id-19755/product_id-53327/Aria2-Project-Aria2.html
+# https://www.cvedetails.com/vulnerability-list/vendor_id-2842/Axel.html
+# ATTENTION: DANGER: Client downloading function explicitly sets 'MANDATORY_HASH == true' to claim resulting file EITHER will be checked by external hash before production use OR file is downloaded within an internal safer network (ie. GitHub Actions) using integrity guarded computers (ie. GitHub Runners). Potentially less integrity-safe downloading as multi-part-per-file parallel 'axel' 'download accelerator' style downloading can be limited to require a safety check for the MANDATORY_HASH claim.
+# NOTICE: Imposing safety check for MANDATORY_HASH claim has long track record and no known use cases combine BOTH the jittery contentious internet connections over which multi-part-per-file downloading may or may not be more reliable, AND cannot test build steps without download large files to cycle the entire build completely. That is to say, ONLY CI environments would be usefully faster from not requiring a MANDATORY_HASH claim, yet CI environments can already make an integrity claim relevant for MANDATORY_HASH, and CI environments usually have high-quality internet connections not needing complex trickery to improve download reliability/speed.
+#[[ "$FORCE_AXEL" != "" ]] && ( [[ "$MANDATORY_HASH" == "true" ]] )
+
+
+
+#export FORCE_DIRECT="true"
+#export FORCE_WGET="true"
+#export FORCE_AXEL="4"
+
+# Actually buffers files in progress behind completed files, in addition to downloading over multiple connections. Streaming without buffer underrun (ie. directly to packetDisc, ie. directly to optical disc) regardless of internet connection quality may require such buffer.
+#export FORCE_PARALLEL="3"
+
+# Already default. FORCE_BUFFER="true" implies FORCE_PARALLEL=3 or similar and sets FORCE_DIRECT="false". FORCE_BUFFER="false" implies and sets FORCE_DIRECT="true" .
+#FORCE_BUFFER="true"
+
+#export GH_TOKEN="..."
+
+
+
+
+
+#_get_vmImg_ubDistBuild_sequence
+#export MANDATORY_HASH="true"
+# write file
+#_wget_githubRelease_join-stdout "soaringDistributions/ubDistBuild" "$releaseLabel" "package_image.tar.flx" | _get_extract_ubDistBuild-tar xv --overwrite
+# write disk (eg. '/dev/sda')
+#_wget_githubRelease_join-stdout "soaringDistributions/ubDistBuild" "$releaseLabel" "package_image.tar.flx" | _get_extract_ubDistBuild-tar --extract ./vm.img --to-stdout | sudo -n dd of="$3" bs=1M status=progress
+#
+#export MANDATORY_HASH=
+#unset MANDATORY_HASH
+#_wget_githubRelease-stdout "soaringDistributions/ubDistBuild" "$releaseLabel" "_hash-ubdist.txt"
+
+
+#_get_vmImg_beforeBoot_ubDistBuild_sequence
+#export MANDATORY_HASH="true"
+# write file
+#_wget_githubRelease_join-stdout "soaringDistributions/ubDistBuild" "$releaseLabel" "package_image_beforeBoot.tar.flx" | _get_extract_ubDistBuild-tar xv --overwrite
+# write disk (eg. '/dev/sda')
+#_wget_githubRelease_join-stdout "soaringDistributions/ubDistBuild" "$releaseLabel" "package_image_beforeBoot.tar.flx" | _get_extract_ubDistBuild-tar --extract ./vm.img --to-stdout | sudo -n dd of="$3" bs=1M status=progress
+#
+#export MANDATORY_HASH=
+#unset MANDATORY_HASH
+#_wget_githubRelease-stdout "soaringDistributions/ubDistBuild" "$releaseLabel" "_hash-ubdist_beforeBoot.txt"
+
+
+#_get_vmImg_ubDistBuild-live_sequence
+#export MANDATORY_HASH="true"
+# write file
+#_wget_githubRelease_join "soaringDistributions/ubDistBuild" "$releaseLabel" "vm-live.iso"
+#currentHash_bytes=$(_wget_githubRelease-stdout "soaringDistributions/ubDistBuild" "$releaseLabel" "_hash-ubdist.txt" | head -n 14 | tail -n 1 | sed 's/^.*count=$(bc <<< '"'"'//' | cut -f1 -d\  )
+# write packetDisc (eg. '/dev/sr0', '/dev/dvd'*, '/dev/cdrom'*)
+#_wget_githubRelease_join-stdout "soaringDistributions/ubDistBuild" "$releaseLabel" "vm-live.iso" | tee >(openssl dgst -whirlpool -binary | xxd -p -c 256 >> "$scriptLocal"/hash-download.txt) ; dd if=/dev/zero bs=2048 count=$(bc <<< '1000000000000 / 2048' ) ) | sudo -n growisofs -speed=3 -dvd-compat -Z "$3"=/dev/stdin -use-the-force-luke=notray -use-the-force-luke=spare:min -use-the-force-luke=bufsize:128m
+# write disk (eg. '/dev/sda')
+#_wget_githubRelease_join-stdout "soaringDistributions/ubDistBuild" "$releaseLabel" "vm-live.iso" | tee >(openssl dgst -whirlpool -binary | xxd -p -c 256 >> "$scriptLocal"/hash-download.txt) ; dd if=/dev/zero bs=2048 count=$(bc <<< '1000000000000 / 2048' ) ) | sudo -n dd of="$3" bs=1M status=progress
+#
+#export MANDATORY_HASH=
+#unset MANDATORY_HASH
+#_wget_githubRelease-stdout "soaringDistributions/ubDistBuild" "$releaseLabel" "_hash-ubdist.txt"
+
+
+#_get_vmImg_ubDistBuild-rootfs_sequence
+#export MANDATORY_HASH="true"
+#_wget_githubRelease_join-stdout "soaringDistributions/ubDistBuild" "$releaseLabel" "package_rootfs.tar.flx" | lz4 -d -c > ./package_rootfs.tar
+#
+#export MANDATORY_HASH=
+#unset MANDATORY_HASH
+#_wget_githubRelease-stdout "soaringDistributions/ubDistBuild" "$releaseLabel" "_hash-ubdist.txt"
+
+
+
+#! "$scriptAbsoluteLocation" _wget_githubRelease_join "owner/repo" "internal" "file.ext"
+#! _wget_githubRelease "owner/repo" "" "file.ext"
+
+
+#_wget_githubRelease_join "soaringDistributions/Llama-augment_bundle" "" "llama-3.1-8b-instruct-abliterated.Q4_K_M.gguf"
+
+
+
+#_wget_githubRelease-stdout
+#export MANDATORY_HASH="true"
+#export MANDATORY_HASH=""
+
+#_wget_githubRelease_join
+#export MANDATORY_HASH="true"
+#export MANDATORY_HASH=""
+
+#_wget_githubRelease_join-stdout
+#export MANDATORY_HASH="true"
+
+
+
+
+
+
+
+#type -p gh > /dev/null 2>&1
+
+
+#_wget_githubRelease_internal
+
+#curl --no-progress-meter
+#gh release download "$current_tagName" -R "$current_repo" -p "$current_file" "$@" 2> >(tail -n 10 >&2) | tail -n 10
+
+## Use variables to construct the gh release download command
+#local currentIteration
+#currentIteration=0
+#while ! [[ -e "$current_fileOut" ]] && [[ "$currentIteration" -lt 3 ]]
+#do
+	##gh release download "$current_tagName" -R "$current_repo" -p "$current_file" "$@"
+	#gh release download "$current_tagName" -R "$current_repo" -p "$current_file" "$@" 2> >(tail -n 10 >&2) | tail -n 10
+	#! [[ -e "$current_fileOut" ]] && sleep 7
+	#let currentIteration=currentIteration+1
+#done
+#[[ -e "$current_fileOut" ]]
+#return "$?"
+
+
+
+# ATTENTION: Override with 'ops.sh' or similar. Do NOT attempt to override with exported variables: do indeed override the function.
+
+_set_wget_githubRelease() {
+	export githubRelease_retriesMax=25
+	export githubRelease_retriesWait=18
+}
+_set_wget_githubRelease
+
+_set_wget_githubRelease-detect() {
+	export githubRelease_retriesMax=2
+	export githubRelease_retriesWait=4
+}
+
+_set_wget_githubRelease-detect-parallel() {
+	export githubRelease_retriesMax=25
+	export githubRelease_retriesWait=18
+}
+
+_set_curl_github_retry() {
+	export curl_retries_args=( --retry 5 --retry-delay 90 --connect-timeout 45 --max-time 600 )
+}
+#_set_wget_githubRelease
+#unset curl_retries_args
+
+
+_if_gh() {
+	if type -p gh > /dev/null 2>&1 && [[ "$GH_TOKEN" != "" ]]
+	then
+		( _messagePlain_probe '_if_gh: gh' >&2 ) > /dev/null
+		return 0
+	fi
+	( _messagePlain_probe '_if_gh: NOT gh' >&2 ) > /dev/null
+	return 1
+}
+
+
+#_wget_githubRelease-URL "owner/repo" "" "file.ext"
+#_wget_githubRelease-URL "owner/repo" "latest" "file.ext"
+#_wget_githubRelease-URL "owner/repo" "internal" "file.ext"
+_wget_githubRelease-URL() {
+	( _messagePlain_nominal "$currentStream"'\/\/\/\/\/ init: _wget_githubRelease-URL' >&2 ) > /dev/null
+	if _if_gh
+	then
+		( _messagePlain_probe_safe _wget_githubRelease-URL-gh "$@" >&2 ) > /dev/null
+		_wget_githubRelease-URL-gh "$@"
+		return
+	else
+		( _messagePlain_probe_safe _wget_githubRelease-URL-curl "$@" >&2 ) > /dev/null
+		_wget_githubRelease-URL-curl "$@"
+		return
+	fi
+}
+#_wget_githubRelease-URL "owner/repo" "file.ext"
+_wget_githubRelease_internal-URL() {
+	_wget_githubRelease-URL "$1" "internal" "$2"
+}
+#_wget_githubRelease-address "owner/repo" "" "file.ext"
+#_wget_githubRelease-address "owner/repo" "latest" "file.ext"
+#_wget_githubRelease-address "owner/repo" "internal" "file.ext"
+_wget_githubRelease-address() {
+	( _messagePlain_nominal "$currentStream"'\/\/\/\/\/ init: _wget_githubRelease-address' >&2 ) > /dev/null
+	if _if_gh
+	then
+		( _messagePlain_probe_safe _wget_githubRelease-address-gh "$@" >&2 ) > /dev/null
+		_wget_githubRelease-address-gh "$@"
+		return
+	else
+		( _messagePlain_probe_safe _wget_githubRelease-address-curl "$@" >&2 ) > /dev/null
+		_wget_githubRelease-address-curl "$@"
+		return
+	fi
+}
+
+#"$api_address_type" == "tagName" || "$api_address_type" == "url"
+# ATTENTION: WARNING: Unusually, api_address_type , is a monolithic variable NEVER exported . Keep local, and do NOT use for any other purpose.
+_jq_github_browser_download_address() {
+	( _messagePlain_probe 'init: _jq_github_browser_download_address' >&2 ) > /dev/null
+	local currentReleaseLabel="$2"
+	local currentFile="$3"
+
+	# 'latest'
+	#  or alternatively (untested, apparently incompatible), for all tags from the 'currentData' regardless of 'currentReleaseLabel'
+	if [[ "$currentReleaseLabel" == "latest" ]] || [[ "$currentReleaseLabel" == "" ]]
+	then
+		if [[ "$api_address_type" == "" ]] || [[ "$api_address_type" == "url" ]]
+        then
+            #jq -r ".assets[] | select(.name == "'"$currentFile"'") | .browser_download_url"
+			jq --arg filename "$currentFile" --arg releaseLabel "$currentReleaseLabel" -r '.assets[] | select(.name == $filename) | .browser_download_url'
+            return
+        fi
+		if [[ "$api_address_type" == "tagName" ]]
+        then
+            #jq -r ".tag_name"
+			jq --arg filename "$currentFile" --arg releaseLabel "$currentReleaseLabel" -r '.tag_name'
+            return
+        fi
+		if [[ "$api_address_type" == "api_url" ]]
+		then
+			#jq -r ".assets[] | select(.name == "'"$currentFile"'") | .url"
+			jq --arg filename "$currentFile" --arg releaseLabel "$currentReleaseLabel" -r '.assets[] | select(.name == $filename) | .url'
+			return
+		fi
+	# eg. 'internal', 'build', etc
+	else
+		if [[ "$api_address_type" == "" ]] || [[ "$api_address_type" == "url" ]]
+        then
+            #jq -r "sort_by(.published_at) | reverse | .[] | select(.name == "'"$currentReleaseLabel"'") | .assets[] | select(.name == "'"$currentFile"'") | .browser_download_url"
+			jq --arg filename "$currentFile" --arg releaseLabel "$currentReleaseLabel" -r 'sort_by(.published_at) | reverse | .[] | select(.name == $releaseLabel) | .assets[] | select(.name == $filename) | .browser_download_url'
+            return
+        fi
+		if [[ "$api_address_type" == "tagName" ]]
+        then
+            #jq -r "sort_by(.published_at) | reverse | .[] | select(.name == "'"$currentReleaseLabel"'") | .tag_name"
+			jq --arg filename "$currentFile" --arg releaseLabel "$currentReleaseLabel" -r 'sort_by(.published_at) | reverse | .[] | select(.name == $releaseLabel) | .tag_name'
+            return
+        fi
+		if [[ "$api_address_type" == "api_url" ]]
+		then
+			#jq -r "sort_by(.published_at) | reverse | .[] | select(.name == "'"$currentReleaseLabel"'") | .assets[] | select(.name == "'"$currentFile"'") | .url"
+			jq --arg filename "$currentFile" --arg releaseLabel "$currentReleaseLabel" -r 'sort_by(.published_at) | reverse | .[] | select(.name == $releaseLabel) | .assets[] | select(.name == $filename) | .url'
+			return
+		fi
+	fi
+}
+_curl_githubAPI_releases_page() {
+	( _messagePlain_nominal "$currentStream"'\/\/\/ init: _curl_githubAPI_releases_page' >&2 ) > /dev/null
+	local currentAbsoluteRepo="$1"
+	local currentReleaseLabel="$2"
+	local currentFile="$3"
+
+	[[ "$currentAbsoluteRepo" == "" ]] && return 1
+	[[ "$currentReleaseLabel" == "" ]] && currentReleaseLabel="latest"
+	[[ "$currentFile" == "" ]] && return 1
+
+	local currentPageNum="$4"
+	[[ "$currentPageNum" == "" ]] && currentPageNum="1"
+	_messagePlain_probe_var currentPageNum >&2 | cat /dev/null
+
+	local current_API_page_URL
+	current_API_page_URL="https://api.github.com/repos/""$currentAbsoluteRepo""/releases?per_page=100&page=""$currentPageNum"
+	[[ "$currentReleaseLabel" == "latest" ]] && current_API_page_URL="https://api.github.com/repos/""$currentAbsoluteRepo""/releases""/latest"
+	_messagePlain_probe_safe "current_API_page_URL= ""$current_API_page_URL" >&2 | cat /dev/null
+
+	local current_curl_args
+	current_curl_args=()
+	[[ "$GH_TOKEN" != "" ]] && current_curl_args+=( -H "Authorization: Bearer $GH_TOKEN" )
+	#current_curl_args+=( -H "Accept: application/octet-stream" )
+	current_curl_args+=( -S )
+	current_curl_args+=( -s )
+
+    local currentFailParam="$5"
+    [[ "$currentFailParam" != "--no-fail" ]] && currentFailParam="--fail"
+	current_curl_args+=( "$currentFailParam" )
+	shift ; shift ; shift ; shift ; shift
+	# CAUTION: Discouraged unless proven necessary. Causes delays and latency beyond "$githubRelease_retriesWait"*"$githubRelease_retriesMax" , possibly exceeding prebuffering on a single error.
+	#--retry 5 --retry-delay 90 --connect-timeout 45 --max-time 600
+	#_set_curl_github_retry
+	#"${curl_retries_args[@]}"
+	current_curl_args+=( "$@" )
+
+	local currentPage
+	currentPage=""
+
+	local currentExitStatus_ipv4=1
+	local currentExitStatus_ipv6=1
+
+	( _messagePlain_probe '_curl_githubAPI_releases_page: IPv6 (false)' >&2 ) > /dev/null
+	# ATTENTION: IPv6 is NOT offered by GitHub API, and so usually only wastes time at best.
+	#currentPage=$(curl -6 "${current_curl_args[@]}" "$current_API_page_URL")
+	false
+	currentExitStatus_ipv6="$?"
+	if [[ "$currentExitStatus_ipv6" != "0" ]]
+	then
+		( _messagePlain_probe '_curl_githubAPI_releases_page: IPv4' >&2 ) > /dev/null
+		[[ "$currentPage" == "" ]] && currentPage=$(curl -4 "${current_curl_args[@]}" "$current_API_page_URL")
+		currentExitStatus_ipv4="$?"
+	fi
+
+	_safeEcho_newline "$currentPage"
+
+	if [[ "$currentExitStatus_ipv6" != "0" ]] && [[ "$currentExitStatus_ipv4" != "0" ]]
+	then
+		( _messagePlain_bad 'bad: FAIL: _curl_githubAPI_releases_page' >&2 ) > /dev/null
+		[[ "$currentExitStatus_ipv4" != "1" ]] && [[ "$currentExitStatus_ipv4" != "0" ]] && return "$currentExitStatus_ipv4"
+		[[ "$currentExitStatus_ipv6" != "1" ]] && [[ "$currentExitStatus_ipv6" != "0" ]] && return "$currentExitStatus_ipv6"
+		return "$currentExitStatus_ipv4"
+	fi
+
+	[[ "$currentPage" == "" ]] && return 1
+	return 0
+}
+# WARNING: No production use. May be untested.
+#  Rapidly skips part files which are not upstream, using only a single page from the GitHub API, saving time and API calls.
+# Not guaranteed reliable. Structure of this non-essential function is provider-specific, code is written ad-hoc.
+# Duplicates much code from other functions:
+#  '_wget_githubRelease_procedure-address-curl'
+#  '_wget_githubRelease_procedure-address_fromTag-curl'
+#  '_wget_githubRelease-address-backend-curl'
+#env maxCurrentPart=63 ./ubiquitous_bash.sh _curl_githubAPI_releases_join-skip soaringDistributions/ubDistBuild spring package_image.tar.flx
+#env maxCurrentPart=63 ./ubiquitous_bash.sh _curl_githubAPI_releases_join-skip soaringDistributions/ubDistBuild latest package_image.tar.flx
+_curl_githubAPI_releases_join-skip() {
+	# Similar retry logic for all similar functions: _wget_githubRelease-URL-curl, _wget_githubRelease-URL-gh .
+	( _messagePlain_nominal "$currentStream"'\/\/\/\/ init: _curl_githubAPI_releases_join-skip' >&2 ) > /dev/null
+	( _messagePlain_probe_safe _curl_githubAPI_releases_join-skip "$@" >&2 ) > /dev/null
+
+    # ATTENTION: WARNING: Unusually, api_address_type , is a monolithic variable NEVER exported . Keep local, and do NOT use for any other purpose.
+    [[ "$GH_TOKEN" != "" ]] && local api_address_type="api_url"
+	[[ "$GH_TOKEN" == "" ]] && local api_address_type="url"
+
+	local currentPartDownload
+	currentPartDownload=""
+
+	local currentExitStatus=1
+
+	local currentIteration=0
+
+	#[[ "$currentPartDownload" == "" ]] ||
+	while ( [[ "$currentExitStatus" != "0" ]] ) && [[ "$currentIteration" -lt "$githubRelease_retriesMax" ]]
+	do
+		currentPartDownload=""
+
+		if [[ "$currentIteration" != "0" ]]
+		then
+			( _messagePlain_warn 'warn: BAD: RETRY: _curl_githubAPI_releases_join-skip: _curl_githubAPI_releases_join_procedure-skip: currentIteration != 0' >&2 ) > /dev/null
+			sleep "$githubRelease_retriesWait"
+		fi
+
+		( _messagePlain_probe _curl_githubAPI_releases_join_procedure-skip >&2 ) > /dev/null
+		currentPartDownload=$(_curl_githubAPI_releases_join_procedure-skip "$@")
+		currentExitStatus="$?"
+
+		let currentIteration=currentIteration+1
+	done
+
+	_safeEcho_newline "$currentPartDownload"
+
+	[[ "$currentIteration" -ge "$githubRelease_retriesMax" ]] && ( _messagePlain_bad 'bad: FAIL: _curl_githubAPI_releases_join-skip: maxRetries' >&2 ) > /dev/null && return 1
+
+	return 0
+}
+#env maxCurrentPart=63 ./ubiquitous_bash.sh _curl_githubAPI_releases_join_procedure-skip soaringDistributions/ubDistBuild spring package_image.tar.flx
+#env maxCurrentPart=63 ./ubiquitous_bash.sh _curl_githubAPI_releases_join_procedure-skip soaringDistributions/ubDistBuild latest package_image.tar.flx
+_curl_githubAPI_releases_join_procedure-skip() {
+	local currentAbsoluteRepo="$1"
+	local currentReleaseLabel="$2"
+	local currentFile="$3"
+
+	[[ "$currentAbsoluteRepo" == "" ]] && return 1
+	[[ "$currentReleaseLabel" == "" ]] && currentReleaseLabel="latest"
+	[[ "$currentFile" == "" ]] && return 1
+
+
+	local currentExitStatus_tmp=0
+	local currentExitStatus=0
+
+
+	local currentPart
+	local currentAddress
+
+
+	if [[ "$currentReleaseLabel" == "latest" ]]
+	then
+		local currentData
+		local currentData_page

+		#(set -o pipefail ; _curl_githubAPI_releases_page "$currentAbsoluteRepo" "$currentReleaseLabel" "$currentFile" | _jq_github_browser_download_address "" "$currentReleaseLabel" "$currentFile")
+		#return
+
+		currentData_page=$(set -o pipefail ; _curl_githubAPI_releases_page "$currentAbsoluteRepo" "$currentReleaseLabel" "$currentFile")
+		currentExitStatus="$?"
+
+		currentData="$currentData_page"
+
+		[[ "$currentExitStatus" != "0" ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease_procedure-address-curl: currentExitStatus' >&2 ) > /dev/null && return "$currentExitStatus"

+		[[ "$currentData" == "" ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease_procedure-address-curl: empty: currentData' >&2 ) > /dev/null && return 1
+
+		#( set -o pipefail ; _safeEcho_newline "$currentData" | _jq_github_browser_download_address "" "$currentReleaseLabel" "$currentFile" | head -n 1 )
+		#currentExitStatus_tmp="$?"
+
+		# ###
+		for currentPart in $(seq -f "%02g" 0 "$maxCurrentPart" | sort -r)
+		do
+			currentAddress=$(set -o pipefail ; _safeEcho_newline "$currentData" | _jq_github_browser_download_address "" "$currentReleaseLabel" "$currentFile".part"$currentPart" | head -n 1)
+			currentExitStatus_tmp="$?"
+
+			[[ "$currentExitStatus_tmp" != "0" ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease_procedure-address-curl: pipefail: _jq_github_browser_download_address: currentExitStatus_tmp' >&2 ) > /dev/null && return "$currentExitStatus_tmp"
+
+			[[ "$currentAddress" != "" ]] && echo "$currentPart" && return 0
+		done
+

-		_cells_begin-terminal() {
-			local currentWidth
-			currentWidth="0%"
-			[[ "$1" != "" ]] && currentWidth="$1"
-
-			local currentWidthParameter
-			currentWidthParameter=""
-			[[ "$currentWidth" != "" ]] && currentWidthParameter='width="'"$currentWidth"'" '
-
-			_safeEcho_quoteAddSingle "$currentFunctionName" "$@"
-			_safeEcho_newline
-
-
-			#echo "$interpret__terminal_NOT_shell__begin"
-
-			#_safeEcho_newline '<table '"$currentWidthParameter"'style="empty-cells: show; border-spacing: 0px; border: 1px solid black; margin-top: 0px; vertical-align: top;">' | cat
-
-			#echo "$interpret__terminal_NOT_shell__end"
-		}
-		_cells_end-terminal() {
-			_safeEcho_quoteAddSingle "$currentFunctionName" "$@"
-			_safeEcho_newline
-
-
-			#echo "$interpret__terminal_NOT_shell__begin"
-
-			#_safeEcho_newline '</table>' | cat
-
-			#echo "$interpret__terminal_NOT_shell__end"
-		}
-		_cells_row_begin-terminal() {
-			_safeEcho_quoteAddSingle "$currentFunctionName" "$@"
-			_safeEcho_newline
-
-
-			#echo "$interpret__terminal_NOT_shell__begin"
-
-			#_safeEcho_newline '<tr>' | cat
-
-			#echo "$interpret__terminal_NOT_shell__end"
-		}
-		_cells_row_end-terminal() {
-			_safeEcho_quoteAddSingle "$currentFunctionName" "$@"
-			_safeEcho_newline
-
-
-			#echo "$interpret__terminal_NOT_shell__begin"
-
-			#_safeEcho_newline '</tr>' | cat
-
-			#echo "$interpret__terminal_NOT_shell__end"
-		}
-		_cells_speck_begin-terminal() {
-			local currentWidth
-			currentWidth="0%"
-			[[ "$1" != "" ]] && currentWidth="$1"
-
-			local currentWidthParameter
-			currentWidthParameter=""
-			[[ "$currentWidth" != "" ]] && currentWidthParameter='width="'"$currentWidth"'" '
-
-
-			local currentColspan
-			currentColspan="1"
-			[[ "$2" != "" ]] && currentColspan="$2"
-
-			local currentColspanParameter
-			currentColspanParameter=""
-			[[ "$currentColspan" != "" ]] && currentColspanParameter='colspan="'"$currentColspan"'" '
-
-
-			_safeEcho_quoteAddSingle "$currentFunctionName" "$@"
-			_safeEcho_newline
-
-
-			#echo "$interpret__terminal_NOT_shell__begin"
-
-			#_safeEcho_newline '<td '"$currentWidthParameter"''"$currentColspanParameter"'style="border-spacing: 0px; border: 1px solid black; margin-top: 0px; vertical-align: top;">' | cat
-
-			#echo "$interpret__terminal_NOT_shell__end"
-		}
-		_cells_speck_end-terminal() {
-			_safeEcho_quoteAddSingle "$currentFunctionName" "$@"
-			_safeEcho_newline
-
-
-			#echo "$interpret__terminal_NOT_shell__begin"
-
-			#_safeEcho_newline '</td>' | cat
-
-			#echo "$interpret__terminal_NOT_shell__end"
-		}
+		# ### ATTENTION: No part files found is not 'skip' but FAIL .
+		[[ "$currentAddress" == "" ]] && ( _messagePlain_bad 'bad: FAIL: _curl_githubAPI_releases_join-skip: empty: _safeEcho_newline | _jq_github_browser_download_address' >&2 ) > /dev/null && return 1

+		return 0
+	else
+		local currentData
+		currentData=""

+		local currentData_page
+		currentData_page="doNotMatch"

-		_markup_asciidoc_disable_begin-terminal() {
-			true
-		}
-		_markup_asciidoc_disable_end-terminal() {
-			true
-		}
+		local currentIteration
+		currentIteration=1

+		# ATTRIBUTION-AI: Many-Chat 2025-03-23
+		# Alternative detection of empty array, as suggested by AI LLM .
+		#[[ $(jq 'length' <<< "$currentData_page") -gt 0 ]]
+		while ( [[ "$currentData_page" != "" ]] && [[ $(_safeEcho_newline "$currentData_page" | tr -dc 'a-zA-Z\[\]' | sed '/^$/d') != $(echo 'WwoKXQo=' | base64 -d | tr -dc 'a-zA-Z\[\]') ]] ) && ( [[ "$currentIteration" -le "1" ]] || ( [[ "$GH_TOKEN" != "" ]] && [[ "$currentIteration" -le "3" ]] ) )
+		do
+			currentData_page=$(set -o pipefail ; _curl_githubAPI_releases_page "$currentAbsoluteRepo" "$currentReleaseLabel" "$currentFile" "$currentIteration")
+			currentExitStatus_tmp="$?"
+			[[ "$currentIteration" == "1" ]] && currentExitStatus="$currentExitStatus_tmp"
+			currentData="$currentData"'
+'"$currentData_page"
+
+            ( _messagePlain_probe "_wget_githubRelease_procedure-address-curl: ""$currentIteration" >&2 ) > /dev/null
+            #( _safeEcho_newline "$currentData" | _jq_github_browser_download_address "" "$currentReleaseLabel" "$currentFile" | head -n 1 >&2 ) > /dev/null
+            [[ "$currentIteration" -ge 4 ]] && ( _safeEcho_newline "$currentData_page" >&2 ) > /dev/null
+
+			let currentIteration=currentIteration+1
+		done
+
+		#( set -o pipefail ; _safeEcho_newline "$currentData" | _jq_github_browser_download_address "" "$currentReleaseLabel" "$currentFile" | head -n 1 )
+		#currentExitStatus_tmp="$?"
+
+		# ###
+		for currentPart in $(seq -f "%02g" 0 "$maxCurrentPart" | sort -r)
+		do
+			currentAddress=$( set -o pipefail ; _safeEcho_newline "$currentData" | _jq_github_browser_download_address "" "$currentReleaseLabel" "$currentFile".part"$currentPart" | head -n 1 )
+			currentExitStatus_tmp="$?"
+
+			[[ "$currentExitStatus" != "0" ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease_procedure-address-curl: _curl_githubAPI_releases_page: currentExitStatus' >&2 ) > /dev/null && return "$currentExitStatus"
+			[[ "$currentExitStatus_tmp" != "0" ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease_procedure-address-curl: pipefail: _jq_github_browser_download_address: currentExitStatus_tmp' >&2 ) > /dev/null && return "$currentExitStatus_tmp"
+			[[ "$currentData" == "" ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease_procedure-address-curl: empty: currentData' >&2 ) > /dev/null && return 1
+
+			[[ "$currentAddress" != "" ]] && echo "$currentPart" && return 0
+		done
+

+		# ### ATTENTION: No part files found is not 'skip' but FAIL .
+		[[ "$currentAddress" == "" ]] && ( _messagePlain_bad 'bad: FAIL: _curl_githubAPI_releases_join-skip: empty: _safeEcho_newline | _jq_github_browser_download_address' >&2 ) > /dev/null && return 1

+        return 0
+	fi
+}
+_wget_githubRelease_procedure-address-curl() {
+	local currentAbsoluteRepo="$1"
+	local currentReleaseLabel="$2"
+	local currentFile="$3"
+
+	[[ "$currentAbsoluteRepo" == "" ]] && return 1
+	[[ "$currentReleaseLabel" == "" ]] && currentReleaseLabel="latest"
+	[[ "$currentFile" == "" ]] && return 1
+
+
+	local currentExitStatus_tmp=0
+	local currentExitStatus=0
+
+	if [[ "$currentReleaseLabel" == "latest" ]]
+	then
+		local currentData
+		local currentData_page

-		_fold-terminal() {
-			#if [[ "$markup_terminal_fold" != "" ]]
-			#then
-				#fold -w "$markup_terminal_fold" -s
-				#return
-			#fi
-			cat
-		}
+		#(set -o pipefail ; _curl_githubAPI_releases_page "$currentAbsoluteRepo" "$currentReleaseLabel" "$currentFile" | _jq_github_browser_download_address "" "$currentReleaseLabel" "$currentFile")
+		#return
+
+		currentData_page=$(set -o pipefail ; _curl_githubAPI_releases_page "$currentAbsoluteRepo" "$currentReleaseLabel" "$currentFile")
+		currentExitStatus="$?"
+
+		currentData="$currentData_page"
+
+		[[ "$currentExitStatus" != "0" ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease_procedure-address-curl: currentExitStatus' >&2 ) > /dev/null && return "$currentExitStatus"

+		[[ "$currentData" == "" ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease_procedure-address-curl: empty: currentData' >&2 ) > /dev/null && return 1
+
+		( set -o pipefail ; _safeEcho_newline "$currentData" | _jq_github_browser_download_address "" "$currentReleaseLabel" "$currentFile" | head -n 1 )
+		currentExitStatus_tmp="$?"
+
+		[[ "$currentExitStatus_tmp" != "0" ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease_procedure-address-curl: pipefail: _jq_github_browser_download_address: currentExitStatus_tmp' >&2 ) > /dev/null && return "$currentExitStatus_tmp"
+
+		# ATTENTION: Part file does NOT exist upstream. Page did NOT match 'Not Found', page NOT empty, and data NOT empty, implying repo, releaseLabel , indeed EXISTS upstream.
+		# Retries/wait must NOT continue in that case - calling function must detect and either fail or skip file on empty address if appropriate.
+		#[[ "$(_safeEcho_newline "$currentData" | _jq_github_browser_download_address "" "$currentReleaseLabel" "$currentFile" | head -n 1 | wc -c )" -le 0 ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease_procedure-address-curl: empty: _safeEcho_newline | _jq_github_browser_download_address' >&2 ) > /dev/null  && return 1

+		return 0
+	else
+		local currentData
+		currentData=""

-		_workaround_preformattedCharacters-terminal() {
-			#sed 's/\&#35;/#/g'
-			#sed 's/\&#35;/#/g' | sed "s/\\\x27/\&#39;/g" | sed "s/\\\047/\&#39;/g" | sed "s/%27/\&#39;/g" | sed "s/\&#39;/\&#39;/g"
-
-			#sed "s/\\\x27/\&#39;/g" | sed "s/\\\047/\&#39;/g" | sed "s/%27/\&#39;/g" | sed "s/\&#39;/\&#39;/g"
-			#sed "s/\\\x3c/\&lt;;/g" | sed "s/\\\060/\&lt;;/g" | sed "s/%3c/\&lt;;/g" | sed "s/\&lt;;/\&lt;;/g"
-
-			#sed 's/\&#35;/#/g' | sed "s/\\\x27/\&#39;/g" | sed "s/\\\047/\&#39;/g" | sed "s/%27/\&#39;/g" | sed "s/\&#39;/\&#39;/g" | sed "s/\\\x3c/\&lt;;/g" | sed "s/\\\060/\&lt;;/g" | sed "s/%3c/\&lt;;/g" | sed "s/\&lt;;/\&lt;;/g"
-
-			cat
-
-
-			#| sed "s/\&#92;/\\\/"
-		}
+		local currentData_page
+		currentData_page="doNotMatch"

+		local currentIteration
+		currentIteration=1

-		_markup_terminal_cmd() {
-			local currentString
-
-			while read -r currentString
-			do
-				[ "$currentString" ] && printf '%b' "$markup_terminal_cmd_begin""$currentString""$markup_terminal_cmd_end"
-				echo
-			done
-		}
-	fi
-
-	if [[ "$current_scriptedIllustrator_markup" == "" ]] && [[ "$current_scriptedIllustrator_markup_markdown" == "" ]] && [[ "$workaround_noInterpret_begin" == "" ]] && [[ "$workaround_noInterpret_end" == "" ]] && [[ "$workaround_comment_shell_line" == "" ]]
-	then
-		_shellCommentLines() {
-			local currentString
-
-			while read -r currentString
-			do
-				[ "$currentString" ] && printf '%b' "$comment_shell_line $currentString"
-				echo
-			done
-
-			#echo -n "$comment_shell_line"' '
-			##LANG=C IFS=
-			#while LANG=C IFS= read -r -d '' -n 1 currentString
-			#do
-				#[ "$currentString" ] && printf '%b' "$currentString"
-				#[[ "$currentString" == $'\n' ]] && echo -n "$comment_shell_line"' '
-			#done
-		}
+		# ATTRIBUTION-AI: Many-Chat 2025-03-23
+		# Alternative detection of empty array, as suggested by AI LLM .
+		#[[ $(jq 'length' <<< "$currentData_page") -gt 0 ]]
+		while ( [[ "$currentData_page" != "" ]] && [[ $(_safeEcho_newline "$currentData_page" | tr -dc 'a-zA-Z\[\]' | sed '/^$/d') != $(echo 'WwoKXQo=' | base64 -d | tr -dc 'a-zA-Z\[\]') ]] ) && ( [[ "$currentIteration" -le "1" ]] || ( [[ "$GH_TOKEN" != "" ]] && [[ "$currentIteration" -le "3" ]] ) )
+		do
+			currentData_page=$(set -o pipefail ; _curl_githubAPI_releases_page "$currentAbsoluteRepo" "$currentReleaseLabel" "$currentFile" "$currentIteration")
+			currentExitStatus_tmp="$?"
+			[[ "$currentIteration" == "1" ]] && currentExitStatus="$currentExitStatus_tmp"
+			currentData="$currentData"'
+'"$currentData_page"
+
+            ( _messagePlain_probe "_wget_githubRelease_procedure-address-curl: ""$currentIteration" >&2 ) > /dev/null
+            #( _safeEcho_newline "$currentData" | _jq_github_browser_download_address "" "$currentReleaseLabel" "$currentFile" | head -n 1 >&2 ) > /dev/null
+            [[ "$currentIteration" -ge 4 ]] && ( _safeEcho_newline "$currentData_page" >&2 ) > /dev/null
+
+			let currentIteration=currentIteration+1
+		done
+
+		( set -o pipefail ; _safeEcho_newline "$currentData" | _jq_github_browser_download_address "" "$currentReleaseLabel" "$currentFile" | head -n 1 )
+		currentExitStatus_tmp="$?"
+
+		[[ "$currentExitStatus" != "0" ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease_procedure-address-curl: _curl_githubAPI_releases_page: currentExitStatus' >&2 ) > /dev/null && return "$currentExitStatus"
+		[[ "$currentExitStatus_tmp" != "0" ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease_procedure-address-curl: pipefail: _jq_github_browser_download_address: currentExitStatus_tmp' >&2 ) > /dev/null && return "$currentExitStatus_tmp"
+		[[ "$currentData" == "" ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease_procedure-address-curl: empty: currentData' >&2 ) > /dev/null && return 1
+
+		# ATTENTION: Part file does NOT exist upstream. Page did NOT match 'Not Found', page NOT empty, and data NOT empty, implying repo, releaseLabel , indeed EXISTS upstream.
+		# Retries/wait must NOT continue in that case - calling function must detect and either fail or skip file on empty address if appropriate.
+		#[[ "$(_safeEcho_newline "$currentData" | _jq_github_browser_download_address "" "$currentReleaseLabel" "$currentFile" | head -n 1 | wc -c )" -le 0 ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease_procedure-address-curl: empty: _safeEcho_newline | _jq_github_browser_download_address' >&2 ) > /dev/null  && return 1

-		# WARNING: Affects accurate prevention of '_r' and '_t' inaccurately accumulating or removing newlines.
-		_filter__scriptedIllustrator_markup() {
-			# Inherently add newline if not already present.
-			grep -v "$flag__NOT_shell"
-
-			# Add newline if already present.
-			#grep -v $(_uid) | grep -v "$flag__NOT_shell"
-
-			# Do not add newline if not already present.
-			#sed 's/^.*'"$flag__NOT_shell"'.*$//g'
-		}
+        return 0
 	fi
-
 }
-_set_markup_terminal
+_wget_githubRelease-address-backend-curl() {
+	local currentAddress
+	currentAddress=""

+	local currentExitStatus=1

-_set_markup_terminal_exportFunctions() {
-	_set_markup_terminal "$@"
-
-	#export current_scriptedIllustrator_markup='terminal'
-	export current_scriptedIllustrator_markup=''
-
-	export -f _e
-
-	export -f _e_
-
-	export -f _o
-
-	export -f _o_
-
-	export -f _i
-
-	export -f _v
-
-	export -f _t
-
-	export -f _r
-
-	export -f _
-	export -f _h
-
-
-
-	export -f _heading1
-	export -f _heading2
-	export -f _heading3
-	export -f _heading4
-	export -f _heading5
-	export -f _heading6
-
-	export -f _page
-
-	export -f _paragraph_begin
-	export -f _paragraph_end
+	local currentIteration=0
+
+	#[[ "$currentAddress" == "" ]] ||
+	while ( [[ "$currentExitStatus" != "0" ]] ) && [[ "$currentIteration" -lt "$githubRelease_retriesMax" ]]
+	do
+		currentAddress=""
+
+		if [[ "$currentIteration" != "0" ]]
+		then
+			( _messagePlain_warn 'warn: BAD: RETRY: _wget_githubRelease-URL-curl: _wget_githubRelease_procedure-address-curl: currentIteration != 0' >&2 ) > /dev/null
+			sleep "$githubRelease_retriesWait"
+		fi
+
+		( _messagePlain_probe _wget_githubRelease_procedure-address-curl >&2 ) > /dev/null
+		currentAddress=$(_wget_githubRelease_procedure-address-curl "$@")
+		currentExitStatus="$?"
+
+		let currentIteration=currentIteration+1
+	done

+	_safeEcho_newline "$currentAddress"
+
+	[[ "$currentIteration" -ge "$githubRelease_retriesMax" ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease-URL-curl: maxRetries' >&2 ) > /dev/null && return 1
+
+	return 0
+}
+_wget_githubRelease-address-curl() {
+	# Similar retry logic for all similar functions: _wget_githubRelease-URL-curl, _wget_githubRelease-URL-gh .
+	( _messagePlain_nominal "$currentStream"'\/\/\/\/ init: _wget_githubRelease-address-curl' >&2 ) > /dev/null
+	( _messagePlain_probe_safe _wget_githubRelease-URL-curl "$@" >&2 ) > /dev/null
+
+    # ATTENTION: WARNING: Unusually, api_address_type , is a monolithic variable NEVER exported . Keep local, and do NOT use for any other purpose.
+    local api_address_type="tagName"
+
+    _wget_githubRelease-address-backend-curl "$@"
+    return
+}
+_wget_githubRelease-URL-curl() {
+	# Similar retry logic for all similar functions: _wget_githubRelease-URL-curl, _wget_githubRelease-URL-gh .
+	( _messagePlain_nominal "$currentStream"'\/\/\/\/ init: _wget_githubRelease-URL-curl' >&2 ) > /dev/null
+	( _messagePlain_probe_safe _wget_githubRelease-URL-curl "$@" >&2 ) > /dev/null
+
+    # ATTENTION: WARNING: Unusually, api_address_type , is a monolithic variable NEVER exported . Keep local, and do NOT use for any other purpose.
+    local api_address_type="url"
+
+	local currentAddress
+
+	local currentExitStatus=1
+
+    #_wget_githubRelease-address-backend-curl "$@"
+	currentAddress=$(_wget_githubRelease-address-backend-curl "$@")
+	currentExitStatus="$?"

-	export -f _picture
-	export -f _image
+	_safeEcho_newline "$currentAddress"
+
+	[[ "$currentAddress" == "" ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease-URL-curl: empty: currentAddress' >&2 ) > /dev/null && return 1
+
+    return "$currentExitStatus"
+}
+
+# Calling functions MUST attempt download unless skip function conclusively determines BOTH that releaseLabel exists in upstream repo, AND file does NOT exist upstream. Functions may use such skip to skip high-numbered part files that do not exist.
+_wget_githubRelease-skip-URL-curl() {
+	# Similar retry logic for all similar functions: _wget_githubRelease-skip-URL-curl, _wget_githubRelease-URL-gh .
+	( _messagePlain_nominal "$currentStream"'\/\/\/\/ init: _wget_githubRelease-skip-URL-curl' >&2 ) > /dev/null
+	( _messagePlain_probe_safe _wget_githubRelease-skip-URL-curl "$@" >&2 ) > /dev/null
+
+    # ATTENTION: WARNING: Unusually, api_address_type , is a monolithic variable NEVER exported . Keep local, and do NOT use for any other purpose.
+    local api_address_type="url"
+
+	local currentAddress
+
+	local currentExitStatus=1
+
+    #_wget_githubRelease-address-backend-curl "$@"
+	currentAddress=$(_wget_githubRelease-address-backend-curl "$@")
+	currentExitStatus="$?"

+	( _safeEcho_newline "$currentAddress" >&2 ) > /dev/null
+	[[ "$currentExitStatus" != "0" ]] && return "$currentExitStatus"
+
+	if [[ "$currentAddress" == "" ]]
+	then
+		echo skip
+		( _messagePlain_good 'good: _wget_githubRelease-skip-URL-curl: empty: currentAddress: PRESUME skip' >&2 ) > /dev/null
+		return 0
+	fi
+
+	if [[ "$currentAddress" != "" ]]
+	then
+		echo download
+		( _messagePlain_good 'good: _wget_githubRelease-skip-URL-curl: found: currentAddress: PRESUME download' >&2 ) > /dev/null
+		return 0
+	fi
+
+	return 1
+}
+_wget_githubRelease-detect-URL-curl() {
+	_wget_githubRelease-skip-URL-curl "$@"
+}
+
+# WARNING: May be untested.
+_wget_githubRelease-API_URL-curl() {
+	# Similar retry logic for all similar functions: _wget_githubRelease-URL-curl, _wget_githubRelease-URL-gh .
+	( _messagePlain_nominal "$currentStream"'\/\/\/\/ init: _wget_githubRelease-API_URL-curl' >&2 ) > /dev/null
+	( _messagePlain_probe_safe _wget_githubRelease-API_URL-curl "$@" >&2 ) > /dev/null
+
+    # ATTENTION: WARNING: Unusually, api_address_type , is a monolithic variable NEVER exported . Keep local, and do NOT use for any other purpose.
+    local api_address_type="api_url"
+
+	local currentAddress
+
+	local currentExitStatus=1
+
+    #_wget_githubRelease-address-backend-curl "$@"
+	currentAddress=$(_wget_githubRelease-address-backend-curl "$@")
+	currentExitStatus="$?"

-	export -f _cells_begin
-	export -f _cells_end
-	export -f _cells_row_begin
-	export -f _cells_row_end
-	export -f _cells_speck_begin
-	export -f _cells_speck_end
+	_safeEcho_newline "$currentAddress"
+
+	[[ "$currentAddress" == "" ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease-API_URL-curl: empty: currentAddress' >&2 ) > /dev/null && return 1
+
+    return "$currentExitStatus"
+}
+
+# WARNING: May be untested.
+# Calling functions MUST attempt download unless skip function conclusively determines BOTH that releaseLabel exists in upstream repo, AND file does NOT exist upstream. Functions may use such skip to skip high-numbered part files that do not exist.
+_wget_githubRelease-skip-API_URL-curl() {
+	# Similar retry logic for all similar functions: _wget_githubRelease-skip-URL-curl, _wget_githubRelease-URL-gh .
+	( _messagePlain_nominal "$currentStream"'\/\/\/\/ init: _wget_githubRelease-skip-API_URL-curl' >&2 ) > /dev/null
+	( _messagePlain_probe_safe _wget_githubRelease-skip-API_URL-curl "$@" >&2 ) > /dev/null
+
+    # ATTENTION: WARNING: Unusually, api_address_type , is a monolithic variable NEVER exported . Keep local, and do NOT use for any other purpose.
+    local api_address_type="api_url"
+
+	local currentAddress
+
+	local currentExitStatus=1
+
+    #_wget_githubRelease-address-backend-curl "$@"
+	currentAddress=$(_wget_githubRelease-address-backend-curl "$@")
+	currentExitStatus="$?"

-	export -f _markup_asciidoc_disable_begin
-	export -f _markup_asciidoc_disable_end
+	( _safeEcho_newline "$currentAddress" >&2 ) > /dev/null
+	[[ "$currentExitStatus" != "0" ]] && return "$currentExitStatus"
+
+	if [[ "$currentAddress" == "" ]]
+	then
+		echo skip
+		( _messagePlain_good 'good: _wget_githubRelease-skip-API_URL-curl: empty: currentAddress: PRESUME skip' >&2 ) > /dev/null
+		return 0
+	fi
+
+	if [[ "$currentAddress" != "" ]]
+	then
+		echo download
+		( _messagePlain_good 'good: _wget_githubRelease-skip-API_URL-curl: found: currentAddress: PRESUME download' >&2 ) > /dev/null
+		return 0
+	fi
+
+	return 1
+}
+_wget_githubRelease-detect-API_URL-curl() {
+	_wget_githubRelease-skip-API_URL-curl "$@"
 }

-_declareFunctions_markup_terminal() {
-	declare -f _set_markup_terminal
-	declare -f _set_markup_terminal_exportFunctions
+_wget_githubRelease_procedure-address-gh-awk() {
+	#( _messagePlain_probe 'init: _wget_githubRelease_procedure-address-gh-awk' >&2 ) > /dev/null
+	( _messagePlain_probe_safe _wget_githubRelease_procedure-address-gh-awk "$@" >&2 ) > /dev/null
+    local currentReleaseLabel="$2"
+    #( _messagePlain_probe_var currentReleaseLabel >&2 ) > /dev/null
+
+    # WARNING: Use of complex 'awk' scripts historically has seemed less resilient, less portable, less reliable.
+    # ATTRIBUTION-AI: ChatGPT o1 2025-01-22 , 2025-01-27 .
+	if [[ "$currentReleaseLabel" == "latest" ]]
+	then
+		#gh release list -L 1
+		# In theory, simply accepting single line output from gh release list (ie. -L 1) should provide the same result (in case this awk script ever breaks).
+		awk '
+			# Skip a header line if it appears first:
+			NR == 1 && $1 == "TITLE" && $2 == "TYPE" {
+				# Just move on to the next line and do nothing else
+				next
+			}
+
+			# The real match: find the line whose second column is "Latest"
+			$2 == "Latest" {
+				# Print the third column (TAG NAME) and exit
+				print $3
+				exit
+			}
+		'
+	else
+		awk -v label="$currentReleaseLabel" '
+		# For each line where the first column equals the label we are looking for...
+		$1 == label {
+			# If the second column is one of the known “types,” shift fields left so
+			# the *real* tag moves into $2. Repeat until no more known types remain.
+			while ($2 == "Latest" || $2 == "draft" || $2 == "pre-release" || $2 == "prerelease") {
+			for (i=2; i<NF; i++) {
+				$i = $(i+1)
+			}
+			NF--
+			}
+			# At this point, $2 is guaranteed to be the actual tag.
+			print $2
+		}
+		'
+	fi
+}
+# Requires "$GH_TOKEN" .
+_wget_githubRelease_procedure-address-gh() {
+	( _messagePlain_nominal "$currentStream"'\/\/\/ init: _wget_githubRelease_procedure-address-gh' >&2 ) > /dev/null
+	( _messagePlain_probe_safe _wget_githubRelease_procedure-address-gh "$@" >&2 ) > /dev/null
+    ! _if_gh && return 1

+	local currentAbsoluteRepo="$1"
+	local currentReleaseLabel="$2"
+	local currentFile="$3"
+
+	[[ "$currentAbsoluteRepo" == "" ]] && return 1
+	[[ "$currentReleaseLabel" == "" ]] && currentReleaseLabel="latest"
+	[[ "$currentFile" == "" ]] && return 1
+
+    local currentTag
+
+	local currentExitStatus=0
+	local currentExitStatus_tmp=0
+
+    local currentIteration
+    currentIteration=1
+
+    while [[ "$currentTag" == "" ]] && ( [[ "$currentIteration" -le "1" ]] || ( [[ "$GH_TOKEN" != "" ]] && [[ "$currentIteration" -le "3" ]] ) )
+    do
+        #currentTag=$(gh release list -L 100 -R "$currentAbsoluteRepo" | sed 's/Latest//' | grep '^'"$currentReleaseLabel" | awk '{ print $2 }' | head -n 1)
+
+        currentTag=$(set -o pipefail ; gh release list -L $(( $currentIteration * 100 )) -R "$currentAbsoluteRepo" | _wget_githubRelease_procedure-address-gh-awk "" "$currentReleaseLabel" "" | head -n 1)    # or pick whichever match you want
+        currentExitStatus_tmp="$?"
+		[[ "$currentIteration" == "1" ]] && currentExitStatus="$currentExitStatus_tmp"
+
+        let currentIteration++
+    done
+
+    _safeEcho_newline "$currentTag"
+    #_safeEcho_newline "https://github.com/""$currentAbsoluteRepo""/releases/download/""$currentTag""/""$currentFile"
+
+	[[ "$currentExitStatus" != "0" ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease_procedure-address-gh: pipefail: currentExitStatus' >&2 ) > /dev/null && return "$currentExitStatus"
+    [[ "$currentTag" == "" ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease_procedure-address-gh: empty: currentTag' >&2 ) > /dev/null && return 1
+
+    return 0
+}
+_wget_githubRelease-address-gh() {
+	# Similar retry logic for all similar functions: _wget_githubRelease-URL-curl, _wget_githubRelease-address-gh .
+	( _messagePlain_nominal "$currentStream"'\/\/\/\/ init: _wget_githubRelease-address-gh' >&2 ) > /dev/null
+	( _messagePlain_probe_safe _wget_githubRelease-address-gh "$@" >&2 ) > /dev/null
+    ! _if_gh && return 1
+
+	#local currentURL
+	#currentURL=""
+	local currentTag
+	currentTag=""
+
+	local currentExitStatus=1
+
+	local currentIteration=0
+
+	#while ( [[ "$currentURL" == "" ]] || [[ "$currentExitStatus" != "0" ]] ) && [[ "$currentIteration" -lt "$githubRelease_retriesMax" ]]
+	while ( [[ "$currentTag" == "" ]] || [[ "$currentExitStatus" != "0" ]] ) && [[ "$currentIteration" -lt "$githubRelease_retriesMax" ]]
+	do
+		#currentURL=""
+		currentTag=""
+
+		if [[ "$currentIteration" != "0" ]]
+		then
+			( _messagePlain_warn 'warn: BAD: RETRY: _wget_githubRelease-address-gh: _wget_githubRelease_procedure-address-gh: currentIteration != 0' >&2 ) > /dev/null
+			sleep "$githubRelease_retriesWait"
+		fi
+
+		( _messagePlain_probe _wget_githubRelease_procedure-address-gh >&2 ) > /dev/null
+		#currentURL=$(_wget_githubRelease_procedure-address-gh "$@")
+		currentTag=$(_wget_githubRelease_procedure-address-gh "$@")
+		currentExitStatus="$?"
+
+		let currentIteration=currentIteration+1
+	done

-	# WARNING: Most functions would be declared twice, substantially increasing 'current_internal_CompressedFunctions_bytes' .
+	#_safeEcho_newline "$currentURL"
+	_safeEcho_newline "$currentTag"
+
+	[[ "$currentIteration" -ge "$githubRelease_retriesMax" ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease-address-gh: maxRetries' >&2 ) > /dev/null && return 1
+
 	return 0
+}
+_wget_githubRelease-URL-gh() {
+	( _messagePlain_nominal "$currentStream"'\/\/\/\/ init: _wget_githubRelease-URL-gh' >&2 ) > /dev/null
+	( _messagePlain_probe_safe _wget_githubRelease-URL-gh "$@" >&2 ) > /dev/null
+    ! _if_gh && return 1

-	declare -f _e
-	declare -f _e-terminal
-
-	declare -f _e_
-	declare -f _e_-terminal
-
-	declare -f _o
-	declare -f _o-terminal
-
-	declare -f _o_
-	declare -f _o_-terminal
-
-	declare -f _i
-	declare -f _i-terminal
-
-	declare -f _v
-	declare -f _v-terminal
-
-	declare -f _t
-	declare -f _t-terminal
-
-	declare -f _r
-	declare -f _r-terminal
-
-	declare -f _
-	declare -f _h
-	declare -f _h-terminal
-
-
-
-
-
-
-	declare -f _heading1
-	declare -f _heading1-terminal
-	declare -f _heading2
-	declare -f _heading2-terminal
-	declare -f _heading3
-	declare -f _heading3-terminal
-	declare -f _heading4
-	declare -f _heading4-terminal
-	declare -f _heading5
-	declare -f _heading5-terminal
-	declare -f _heading6
-	declare -f _heading6-terminal
-
-	declare -f _page
-	declare -f _page-terminal
-
-	declare -f _paragraph_begin
-	declare -f _paragraph_begin-terminal
-	declare -f _paragraph_end
-	declare -f _paragraph_end-terminal
-
-	declare -f _picture
-	declare -f _picture-terminal
-	declare -f _image
-	declare -f _image-terminal
-
-	declare -f _cells_begin
-	declare -f _cells_begin-terminal
-	declare -f _cells_end
-	declare -f _cells_end-terminal
-	declare -f _cells_row_begin
-	declare -f _cells_row_begin-terminal
-	declare -f _cells_row_end
-	declare -f _cells_row_end-terminal
-	declare -f _cells_speck_begin
-	declare -f _cells_speck_begin-terminal
-	declare -f _cells_speck_end
-	declare -f _cells_speck_end-terminal
-
+	local currentAbsoluteRepo="$1"
+	local currentReleaseLabel="$2"
+	local currentFile="$3"
+
+	[[ "$currentAbsoluteRepo" == "" ]] && return 1
+	[[ "$currentReleaseLabel" == "" ]] && currentReleaseLabel="latest"
+	[[ "$currentFile" == "" ]] && return 1
+
+    local currentTag
+
+	local currentExitStatus=1
+
+	currentTag=$(_wget_githubRelease-address-gh "$@")
+	currentExitStatus="$?"

-	declare -f _markup_asciidoc_disable_begin
-	declare -f _markup_asciidoc_disable_begin-terminal
-	declare -f _markup_asciidoc_disable_end
-	declare -f _markup_asciidoc_disable_end-terminal
+
+	#echo "$currentTag"
+    _safeEcho_newline "https://github.com/""$currentAbsoluteRepo""/releases/download/""$currentTag""/""$currentFile"
+
+	[[ "$currentExitStatus" != "0" ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease-URL-gh: currentExitStatus' >&2 ) > /dev/null && return "$currentExitStatus"
+	[[ "$currentTag" == "" ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease-URL-gh: empty: currentTag' >&2 ) > /dev/null && return 1

+	return 0
+}
+
+
+
+
+
+# _gh_download "$currentAbsoluteRepo" "$currentTagName" "$currentFile" -O "$currentOutFile"
+# Requires "$GH_TOKEN" .
+_gh_download() {
+	# Similar retry logic for all similar functions: _gh_download , _wget_githubRelease_loop-curl .
+	( _messagePlain_nominal "$currentStream"'\/\/\/\/\/ init: _gh_download' >&2 ) > /dev/null

-	declare -f _fold-terminal
+	! _if_gh && return 1

+	local currentAbsoluteRepo="$1"
+	local currentTagName="$2"
+	local currentFile="$3"
+
+	local currentOutParameter="$4"
+	local currentOutFileParameter="$5"
+
+	local currentOutFile="$currentFile"
+
+	shift
+	shift
+	shift
+	[[ "$currentOutParameter" == "--output" ]] && currentOutParameter="-O"
+	[[ "$currentOutParameter" == "-O" ]] && currentOutFile="$currentOutFileParameter" && shift && shift
+
+	[[ "$currentOutParameter" == "-O" ]] && [[ "$currentOutFile" == "" ]] && _messagePlain_bad 'bad: fail: unexpected: unspecified: currentOutFile' && return 1
+
+	#[[ "$currentOutFile" != "-" ]] && rm -f "$currentOutFile" > /dev/null 2>&1
+	[[ "$currentOutFile" != "-" ]] && _destroy_lock "$currentOutFile"
+
+	# CAUTION: Assumed 'false' by 'rotten' !
+	# (ie. 'rotten' does NOT support Cygwin/MSW)
+	local currentOutFile_translated_cygwinMSW=""
+	( _if_cygwin && type -p cygpath > /dev/null 2>&1 ) && ( [[ "$currentOutFile" != "" ]] && [[ "$currentOutFile" != "-" ]] ) && currentOutFile_translated_cygwinMSW=$(cygpath -w $(_getAbsoluteLocation "$currentOutFile"))
+
+	local currentExitStatus=1
+
+	local currentIteration
+	currentIteration=0
+	# && ( [[ "$currentIteration" != "0" ]] && sleep "$githubRelease_retriesWait" )
+	while ( [[ "$currentExitStatus" != "0" ]] || ( ! [[ -e "$currentOutFile" ]] && [[ "$currentOutFile" != "-" ]] ) ) && [[ "$currentIteration" -lt "$githubRelease_retriesMax" ]]
+	do
+		if [[ "$currentIteration" != "0" ]]
+		then
+			( _messagePlain_warn 'warn: BAD: RETRY: _gh_download: gh release download: currentIteration != 0' >&2 ) > /dev/null
+			sleep "$githubRelease_retriesWait"
+		fi
+
+		# CAUTION: Assumed 'false' by 'rotten' !
+		# (ie. 'rotten' does NOT support Cygwin/MSW)
+		if [[ "$currentOutFile_translated_cygwinMSW" != "" ]]
+		then
+			# WARNING: Apparently, 'gh release download' will throw an error with filename '/cygdrive'...'.m_axelTmp__'"$(_uid14)" .
+			( _messagePlain_probe_safe gh release download --clobber "$currentTagName" -R "$currentAbsoluteRepo" -p "$currentFile" -O "$currentOutFile_translated_cygwinMSW" "$@" >&2 ) > /dev/null
+			( set -o pipefail ; gh release download --clobber "$currentTagName" -R "$currentAbsoluteRepo" -p "$currentFile" -O "$currentOutFile_translated_cygwinMSW" "$@" 2> >(tail -n 30 >&2) )
+			currentExitStatus="$?"
+		else
+			( _messagePlain_probe_safe gh release download --clobber "$currentTagName" -R "$currentAbsoluteRepo" -p "$currentFile" -O "$currentOutFile" "$@" >&2 ) > /dev/null
+			( set -o pipefail ; gh release download --clobber "$currentTagName" -R "$currentAbsoluteRepo" -p "$currentFile" -O "$currentOutFile" "$@" 2> >(tail -n 30 >&2) )
+			currentExitStatus="$?"
+		fi
+
+		let currentIteration=currentIteration+1
+	done

-	declare -f _workaround_preformattedCharacters-terminal
+	[[ "$currentExitStatus" != "0" ]] && ( _messagePlain_bad 'bad: FAIL: _gh_download: gh release download: currentExitStatus' >&2 ) > /dev/null && return "$currentExitStatus"
+	! [[ -e "$currentOutFile" ]] && [[ "$currentOutFile" != "-" ]] && ( _messagePlain_bad 'bad: FAIL: missing: currentOutFile' >&2 ) > /dev/null && return 1
+
+	return 0
 }
+#_gh_downloadURL "https://github.com/""$currentAbsoluteRepo""/releases/download/""$currentTagName""/""$currentFile" "$currentOutFile"
+# Requires "$GH_TOKEN" .
+_gh_downloadURL() {
+	( _messagePlain_nominal "$currentStream"'\/\/\/\/\/ init: _gh_downloadURL' >&2 ) > /dev/null
+
+	! _if_gh && return 1
+
+	# ATTRIBUTION-AI: ChatGPT GPT-4 2023-11-04 ... refactored 2025-01-22 ... .
+
+	local currentURL="$1"
+	local currentOutParameter="$2"
+	local currentOutFileParameter="$3"
+
+	[[ "$currentURL" == "" ]] && return 1

+	# Use `sed` to extract the parts of the URL
+	local currentAbsoluteRepo=$(echo "$currentURL" | sed -n 's|https://github.com/\([^/]*\)/\([^/]*\)/.*|\1/\2|p')
+	[[ "$?" != "0" ]] && return 1
+	local currentTagName=$(echo "$currentURL" | sed -n 's|https://github.com/[^/]*/[^/]*/releases/download/\([^/]*\)/.*|\1|p')
+	[[ "$?" != "0" ]] && return 1
+	local currentFile=$(echo "$currentURL" | sed -n 's|https://github.com/[^/]*/[^/]*/releases/download/[^/]*/\(.*\)|\1|p')
+	[[ "$?" != "0" ]] && return 1

-_test_devemacs() {
-	_wantGetDep emacs
+	local currentOutFile="$currentFile"
+
+	shift
+	[[ "$currentOutParameter" == "--output" ]] && currentOutParameter="-O"
+	[[ "$currentOutParameter" == "-O" ]] && currentOutFile="$currentOutFileParameter" && shift && shift
+
+	[[ "$currentOutParameter" == "-O" ]] && [[ "$currentOutFile" == "" ]] && _messagePlain_bad 'bad: fail: unexpected: unspecified: currentOutFile' && return 1
+
+	#[[ "$currentOutFile" != "-" ]] && rm -f "$currentOutFile"
+	##[[ "$currentOutFile" != "-" ]] && _destroy_lock "$currentOutFile"
+
+	local currentExitStatus=1
+	#currentExitStatus=1
+
+	#local currentIteration
+	#currentIteration=0
+	# && ( [[ "$currentIteration" != "0" ]] && sleep "$githubRelease_retriesWait" )
+	#while ( [[ "$currentExitStatus" != "0" ]] || ( ! [[ -e "$currentOutFile" ]] && [[ "$currentOutFile" != "-" ]] ) ) && [[ "$currentIteration" -lt "$githubRelease_retriesMax" ]]
+	#do
+		#if [[ "$currentIteration" != "0" ]]
+		#then
+			#( _messagePlain_warn 'warn: BAD: RETRY: _gh_downloadURL: _gh_download: currentIteration != 0' >&2 ) > /dev/null
+			#sleep "$githubRelease_retriesWait"
+		#fi
+
+		# CAUTION: Do NOT translate file parameter (ie. for Cygwin/MSW) for an underlying backend function (ie. '_gh_download') - that will be done by underlying backend function if at all. Similarly, also do NOT state '--clobber' or similar parameters to backend function.
+		#[[ "$currentOutFile" != "-" ]] && rm -f "$currentOutFile"
+		##[[ "$currentOutFile" != "-" ]] && _destroy_lock "$currentOutFile"
+		( _messagePlain_probe_safe _gh_download "$currentAbsoluteRepo" "$currentTagName" "$currentFile" -O "$currentOutFile" "$@" >&2 ) > /dev/null
+		_gh_download "$currentAbsoluteRepo" "$currentTagName" "$currentFile" -O "$currentOutFile" "$@"
+		currentExitStatus="$?"
+
+		#let currentIteration=currentIteration+1
+	#done
+
+	[[ "$currentExitStatus" != "0" ]] && ( _messagePlain_bad 'bad: FAIL: _gh_downloadURL: _gh_download: currentExitStatus' >&2 ) > /dev/null && return "$currentExitStatus"
+	! [[ -e "$currentOutFile" ]] && [[ "$currentOutFile" != "-" ]] && ( _messagePlain_bad 'bad: FAIL: missing: currentOutFile' >&2 ) > /dev/null && return 1

-	#_if_cygwin && return 0
-
-	if type -p emacs > /dev/null 2>&1
-	then
-		echo 'warn: missing: emacs'
-		return 0
-	else
-		local emacsDetectedVersion=$(emacs --version | head -n 1 | cut -f 3 -d\ | cut -d\. -f1)
-		! [[ "$emacsDetectedVersion" -ge "24" ]] && echo 'warn: obsolete: emacs' && return 1
-	fi
-
 	return 0
 }

-_set_emacsFakeHomeSource() {
-	#if [[ ! -e "$scriptLib"/app/emacs/home ]]
-	#then
-		#_messageError 'missing: '"$scriptLib"'/app/emacs/home'
-		#_messageFAIL
-		#_stop 1
-	#fi
-
-	if [[ ! -e "$scriptBundle"/app/emacs/home ]]
-	then
-		_messageError 'missing: '"$scriptBundle"'/app/emacs/home'
-		_messageFAIL
-		_stop 1
-	fi
-
-	#export emacsFakeHomeSource="$scriptLib"/app/emacs/home
-	export emacsFakeHomeSource="$scriptBundle"/app/emacs/home
-	if ! [[ -e "$emacsFakeHomeSource" ]]
-	then
-		#export emacsFakeHomeSource="$scriptLib"/ubiquitous_bash/_lib/app/emacs/home
-		export emacsFakeHomeSource="$scriptLib"/ubiquitous_bash/_bundle/app/emacs/home
-	fi
-}

-_install_fakeHome_emacs() {
-	_link_fakeHome "$emacsFakeHomeSource"/.emacs .emacs
-	_link_fakeHome "$emacsFakeHomeSource"/.emacs.d .emacs.d
-}

-_emacs_edit_procedure() {
-	_set_emacsFakeHomeSource
-
-	export actualFakeHome="$instancedFakeHome"
-	#export actualFakeHome="$globalFakeHome"
-	export fakeHomeEditLib="true"
-	export keepFakeHome="false"
-
-	_install_fakeHome_emacs
-
-	#echo -n "$@" >> "$HOME"/.emacs
-
-	_fakeHome emacs "$@"
-}

-_emacs_edit_sequence() {
-	_start
-
-	_emacs_edit_procedure "$@"
-
-	_stop $?
-}

-_emacs_edit() {
-	"$scriptAbsoluteLocation" _emacs_edit_sequence "$@"
-}

-_emacs_user_procedure() {
-	_set_emacsFakeHomeSource
-
-	export actualFakeHome="$instancedFakeHome"
-	#export actualFakeHome="$globalFakeHome"
-	export fakeHomeEditLib="false"
-	export keepFakeHome="false"
-
-	_install_fakeHome_emacs
-
-	#echo -n "$@" >> "$HOME"/.emacs
-
-	_fakeHome emacs "$@"
-}
+#_wget_githubRelease-stdout

-_emacs_user_sequence() {
-	_start
-
-	_emacs_user_procedure "$@"
-
-	_stop $?
-}
+#_wget_githubRelease

-_emacs_user() {
-	"$scriptAbsoluteLocation" _emacs_user_sequence "$@"
-}

-_emacs() {
-	_emacs_user "$@"
-}

-_bashdb_procedure() {
-	_set_emacsFakeHomeSource
-
-	export actualFakeHome="$instancedFakeHome"
-	export fakeHomeEditLib="false"
-	export keepFakeHome="false"
-
-	_install_fakeHome_emacs
-
-	#echo -n '(bashdb "bash --debugger' >> "$actualFakeHome"/.emacs
-	echo -n '(bashdb-large "bash --debugger' >> "$actualFakeHome"/.emacs
-
-	local currentArg
-
-	for currentArg in "$@"
-	do
-		echo -n ' ' >> "$actualFakeHome"/.emacs
-		echo -n '\"' >> "$actualFakeHome"/.emacs
-		echo -n "$currentArg" >> "$actualFakeHome"/.emacs
-		echo -n '\"' >> "$actualFakeHome"/.emacs
-	done
-
-	echo '")' >> "$actualFakeHome"/.emacs
+_wget_githubRelease-stdout() {
+	( _messagePlain_nominal "$currentStream"'\/\/\/\/\/ \/\/\/\/\/ init: _wget_githubRelease-stdout' >&2 ) > /dev/null
+	local currentAxelTmpFileRelative=.m_axelTmp_"$currentStream"_$(_uid 14)
+	local currentAxelTmpFile="$scriptAbsoluteFolder"/"$currentAxelTmpFileRelative"

-	_fakeHome emacs
-}
+	local currentExitStatus

-_bashdb_sequence() {
-	_start
-
-	_bashdb_procedure "$@"
-
-	_stop $?
-}
+	# WARNING: Very strongly discouraged. Any retry/continue of any interruption will nevertheless unavoidably result in a corrupted output stream.
+	[[ "$FORCE_DIRECT" == "true" ]] && _wget_githubRelease_procedure-stdout "$@"

-_bashdb() {
-	"$scriptAbsoluteLocation" _bashdb_sequence "$@"
-}
+	# ATTENTION: /dev/null assures that stdout is not corrupted by any unexpected output that should have been sent to stderr
+	[[ "$FORCE_DIRECT" != "true" ]] && _wget_githubRelease_procedure-stdout "$@" > /dev/null

-_ubdb() {
-	_bashdb "$scriptAbsoluteLocation" "$@"
+	if ! [[ -e "$currentAxelTmpFile".PASS ]]
+	then
+		currentExitStatus=$(cat "$currentAxelTmpFile".FAIL)
+		( [[ "$currentExitStatus" == "" ]] || [[ "$currentExitStatus" = "0" ]] || [[ "$currentExitStatus" = "0"* ]] ) && currentExitStatus=1
+		#rm -f "$currentAxelTmpFile".PASS > /dev/null 2>&1
+		_destroy_lock "$currentAxelTmpFile".PASS
+		#rm -f "$currentAxelTmpFile".FAIL > /dev/null 2>&1
+		_destroy_lock "$currentAxelTmpFile".FAIL
+		#rm -f "$currentAxelTmpFile" > /dev/null 2>&1
+		_destroy_lock "$currentAxelTmpFile"
+		return "$currentExitStatus"
+		#return 1
+	fi
+	[[ "$FORCE_DIRECT" != "true" ]] && cat "$currentAxelTmpFile"
+	#rm -f "$currentAxelTmpFile" > /dev/null 2>&1
+	_destroy_lock "$currentAxelTmpFile"
+	#rm -f "$currentAxelTmpFile".PASS > /dev/null 2>&1
+	_destroy_lock "$currentAxelTmpFile".PASS
+	#rm -f "$currentAxelTmpFile".FAIL > /dev/null 2>&1
+	_destroy_lock "$currentAxelTmpFile".FAIL
+	return 0
 }
+_wget_githubRelease_procedure-stdout() {
+	( _messagePlain_probe_safe _wget_githubRelease_procedure-stdout "$@" >&2 ) > /dev/null

-_set_java__eclipse() {
-	_set_java_openjdk "$@"
-}
+	local currentAbsoluteRepo="$1"
+	local currentReleaseLabel="$2"
+	local currentFile="$3"

+	local currentOutParameter="$4"
+	local currentOutFile="$5"

-_eclipse_binary() {
-	eclipse "$@"
-}
+	shift
+	shift
+	shift
+	if [[ "$currentOutParameter" == "-O" ]]
+	then
+		if [[ "$currentOutFile" != "-" ]]
+		then
+			( _messagePlain_bad 'bad: fail: unexpected: currentOutFile: NOT stdout' >&2 ) > /dev/null
+			echo "1" > "$currentAxelTmpFile".FAIL
+			return 1
+		fi
+		shift
+		shift
+	fi

-# ATTENTION: Override with 'core.sh', 'ops', or similar.
-# Static parameters. Must be accepted if function overridden to point script contained installation.
-_eclipse_param() {
-	_eclipse_example_binary -vm "$ubJava" -data "$ub_eclipse_workspace" -configuration "$ub_eclipse_configuration" "$@"
-}
+	#local currentAxelTmpFileRelative=.m_axelTmp_"$currentStream"_$(_uid 14)
+	#local currentAxelTmpFile="$scriptAbsoluteFolder"/"$currentAxelTmpFileRelative"

+	local currentExitStatus

+	# WARNING: Very strongly discouraged. Any retry/continue of any interruption will nevertheless unavoidably result in a corrupted output stream.
+	if [[ "$FORCE_DIRECT" == "true" ]]
+	then
+		_wget_githubRelease_procedure "$currentAbsoluteRepo" "$currentReleaseLabel" "$currentFile" -O - "$@"
+		currentExitStatus="$?"
+		if [[ "$currentExitStatus" != "0" ]]
+		then
+			echo > "$currentAxelTmpFile".FAIL
+			return "$currentExitStatus"
+		fi
+		echo > "$currentAxelTmpFile".PASS
+		return 0
+	fi

+	_wget_githubRelease_procedure "$currentAbsoluteRepo" "$currentReleaseLabel" "$currentFile" -O "$currentAxelTmpFile" "$@"
+	currentExitStatus="$?"
+	if [[ "$currentExitStatus" != "0" ]]
+	then
+		echo "$currentExitStatus" > "$currentAxelTmpFile".FAIL
+		return "$currentExitStatus"
+	fi
+	echo > "$currentAxelTmpFile".PASS
+	return 0
+}




-

+#! "$scriptAbsoluteLocation" _wget_githubRelease_join "owner/repo" "internal" "file.ext" -O "file.ext"
+#! _wget_githubRelease "owner/repo" "" "file.ext" -O "file.ext"
+# ATTENTION: WARNING: Warn messages correspond to inability to assuredly, effectively, use GH_TOKEN .
+_wget_githubRelease() {
+	( _messagePlain_nominal "$currentStream"'\/\/\/\/\/ \/\/\/\/\/ init: _wget_githubRelease' >&2 ) > /dev/null
+	( _messagePlain_probe_safe _wget_githubRelease "$@" >&2 ) > /dev/null

-_prepare_example_ConfigurationLookupDirectory_eclipse() {
-	#_prepare_abstractfs_appdir_none "$@"
-
-	#_prepare_abstractfs_appdir_independent "$@"
-
-	# DANGER: Strongly discouraged. May break use of "project.afs" with alternative layouts and vice versa.
-	#_prepare_abstractfs_appdir_shared "$@"
-
-	_prepare_abstractfs_appdir_export "$@"
-
-	#_probe_prepare_abstractfs_appdir_AbstractSourceDirectory
-	#_probe_prepare_abstractfs_appdir_AbstractSourceDirectory_prior
-	#_probe_prepare_abstractfs_appdir_post
-	_probe_prepare_abstractfs_appdir
-
-	export ub_eclipse_workspace="$ubAFS_CLD"/_eclipse-workspace
-	export ub_eclipse_configuration="$ubAFS_CLD"/_eclipse-configuration/_eclipse_configuration
-
-	mkdir -p "$ubASD_PRJ"
-	mkdir -p "$ubASD_CLD"
+	_wget_githubRelease_procedure "$@"
+}
+_wget_githubRelease_internal() {
+	_wget_githubRelease "$1" "internal" "$2"
 }
+_wget_githubRelease_procedure() {
+	# ATTENTION: Distinction nominally between '_wget_githubRelease' and '_wget_githubRelease_procedure' should only be necessary if a while loop retries the procedure .
+	# ATTENTION: Potentially more specialized logic within download procedures should remain delegated with the responsibility to attempt retries , for now.
+	# NOTICE: Several functions should already have retry logic: '_gh_download' , '_gh_downloadURL' , '_wget_githubRelease-address' , '_wget_githubRelease_procedure-curl' , '_wget_githubRelease-URL-curl' , etc .
+	#( _messagePlain_nominal "$currentStream"'\/\/\/\/\/ \/\/\/\/ init: _wget_githubRelease_procedure' >&2 ) > /dev/null
+	#( _messagePlain_probe_safe _wget_githubRelease_procedure "$@" >&2 ) > /dev/null

+    local currentAbsoluteRepo="$1"
+	local currentReleaseLabel="$2"
+	local currentFile="$3"

+	local currentOutParameter="$4"
+	local currentOutFile="$5"

-_eclipse_example_binary() {
-	eclipse "$@"
-	#sleep 9
-}
+	shift
+	shift
+	shift
+	[[ "$currentOutParameter" != "-O" ]] && currentOutFile="$currentFile"
+	#[[ "$currentOutParameter" == "-O" ]] && currentOutFile="$currentOutFile"

+	#[[ "$currentOutParameter" == "-O" ]] && [[ "$currentOutFile" == "" ]] && currentOutFile="$currentFile"
+	[[ "$currentOutParameter" == "-O" ]] && [[ "$currentOutFile" == "" ]] && ( _messagePlain_bad 'bad: fail: unexpected: unspecified: currentOutFile' >&2 ) > /dev/null && return 1

-# ATTENTION: Override with 'core.sh', 'ops', or similar.
-# Static parameters. Must be accepted if function overridden to point script contained installation.
-_eclipse_example-static() {
-	mkdir -p "$ub_eclipse_workspace"
-	mkdir -p "$ub_eclipse_configuration"
-	_eclipse_example_binary -vm "$ubJava" -data "$ub_eclipse_workspace" -configuration "$ub_eclipse_configuration" "$@"
-}
+	#[[ "$currentOutFile" != "-" ]] && rm -f "$currentOutFile" > /dev/null 2>&1
+	[[ "$currentOutFile" != "-" ]] && _destroy_lock "$currentOutFile"

+    local currentExitStatus=1

+    # Discouraged .
+    if [[ "$FORCE_WGET" == "true" ]]
+    then
+		local currentURL_typeSelected=""
+        _warn_githubRelease_FORCE_WGET
+        #local currentURL=$(_wget_githubRelease-URL-curl "$currentAbsoluteRepo" "$currentReleaseLabel" "$currentFile")
+		local currentURL
+		[[ "$GH_TOKEN" != "" ]] && currentURL_typeSelected="api_url" && currentURL=$(_wget_githubRelease-API_URL-curl "$currentAbsoluteRepo" "$currentReleaseLabel" "$currentFile")
+		[[ "$GH_TOKEN" == "" ]] && currentURL_typeSelected="url" && currentURL=$(_wget_githubRelease-URL-curl "$currentAbsoluteRepo" "$currentReleaseLabel" "$currentFile")

-_eclipse_example_procedure() {
-	! _set_java__eclipse && _stop 1
-
-	# Scope will by default... cd "$ub_specimen" ...
-	#... abstractfs... consistent directory name... '_eclipse_executable'
-	mkdir -p ./project
-	cd ./project
-
-
-	# Configuration Lookup Directory
-	_prepare_example_ConfigurationLookupDirectory_eclipse _eclipse_example-static "$@"
-
-
-	#... fakeHome... preparation... disable ?
-
-
-	# Example only.
-	[[ "$specialGCC" != '' ]] && _messagePlain_request 'request: special GCC bin='"$specialGCC"
-
-	#echo "$ub_specimen"
-
-
-
-	_messagePlain_request 'request: abstractfs: project:  '"$ubAFS_PRJ"
-
-
-	#_abstractfs bash
-	#eclipse -vm "$ubJava"  "$@"
-
-
-	# DANGER: Current directory WILL be included in directory chosen by "_abstractfs" !
-	_abstractfs _eclipse_example-static "$@"
-}
+        #"$GH_TOKEN"
+        #"$currentAbsoluteRepo" "$currentReleaseLabel" "$currentFile" "$currentOutFile"
+        #_wget_githubRelease_procedure-curl
+		_wget_githubRelease_loop-curl
+        return "$?"
+    fi

+	# Discouraged . Benefits of multi-part-per-file downloading are less essential given that files are split into <2GB chunks.
+	if [[ "$FORCE_AXEL" != "" ]] # && [[ "$MANDATORY_HASH" == "true" ]]
+    then
+		local currentURL_typeSelected=""
+        ( _messagePlain_warn 'warn: WARNING: FORCE_AXEL not empty' >&2 ; echo 'FORCE_AXEL may have similar effects to FORCE_WGET and should not be necessary.' >&2  ) > /dev/null
+        #local currentURL=$(_wget_githubRelease-URL-curl "$currentAbsoluteRepo" "$currentReleaseLabel" "$currentFile")
+		local currentURL
+		[[ "$GH_TOKEN" != "" ]] && currentURL_typeSelected="api_url" && currentURL=$(_wget_githubRelease-API_URL-curl "$currentAbsoluteRepo" "$currentReleaseLabel" "$currentFile")
+		[[ "$GH_TOKEN" == "" ]] && currentURL_typeSelected="url" && currentURL=$(_wget_githubRelease-URL-curl "$currentAbsoluteRepo" "$currentReleaseLabel" "$currentFile")

-_eclipse_example() {
-	#_fakeHome "$scriptAbsoluteLocation" _eclipse_example_procedure "$@"
-	"$scriptAbsoluteLocation" _eclipse_example_procedure "$@"
-}
+		[[ "$FORCE_DIRECT" == "true" ]] && ( _messagePlain_bad 'bad: fail: FORCE_AXEL==true is NOT compatible with FORCE_DIRECT==true' >&2 ) > /dev/null && return 1

+        #"$GH_TOKEN"
+        #"$currentAbsoluteRepo" "$currentReleaseLabel" "$currentFile" "$currentOutFile"
+        #_wget_githubRelease_procedure-axel
+		_wget_githubRelease_loop-axel
+        return "$?"
+    fi

-#Simulated client/server discussion testing.
+    if _if_gh
+    then
+        #_wget_githubRelease-address-gh
+        local currentTag=$(_wget_githubRelease-address "$currentAbsoluteRepo" "$currentReleaseLabel" "$currentFile")

-_log_query() {
-	[[ "$1" == "" ]] && return 1
-
-	tee "$1"
-
-	return 0
-}
+        ( _messagePlain_probe _gh_download "$currentAbsoluteRepo" "$currentTag" "$currentFile" "$@" >&2 ) > /dev/null
+        _gh_download "$currentAbsoluteRepo" "$currentTag" "$currentFile" "$@"
+        currentExitStatus="$?"

-_report_query_stdout() {
-	[[ "$1" == "" ]] && return 1
-
-	_messagePlain_probe 'stdout: strings'
-	strings "$1"
-
-	_messagePlain_probe 'stdout: hex'
-	xxd -p "$1" | tr -d '\n'
-	echo
-
-	return 0
-}
+        [[ "$currentExitStatus" != "0" ]] && _bad_fail_githubRelease_currentExitStatus && return "$currentExitStatus"
+        [[ ! -e "$currentOutFile" ]] && [[ "$currentOutFile" != "-" ]] && _bad_fail_githubRelease_missing && return 1
+        return 0
+    fi

-# ATTENTION: Overload with "core.sh" or similar.
-_prepare_query_prog() {
-	true
-}
+    if ! _if_gh
+    then
+		local currentURL_typeSelected=""
+        ( _messagePlain_warn 'warn: WARNING: FALLBACK: wget/curl' >&2 ) > /dev/null
+        #local currentURL=$(_wget_githubRelease-URL-curl "$currentAbsoluteRepo" "$currentReleaseLabel" "$currentFile")
+		local currentURL
+		[[ "$GH_TOKEN" != "" ]] && currentURL_typeSelected="api_url" && currentURL=$(_wget_githubRelease-API_URL-curl "$currentAbsoluteRepo" "$currentReleaseLabel" "$currentFile")
+		[[ "$GH_TOKEN" == "" ]] && currentURL_typeSelected="url" && currentURL=$(_wget_githubRelease-URL-curl "$currentAbsoluteRepo" "$currentReleaseLabel" "$currentFile")

-_prepare_query() {
-	export ub_queryclientdir="$queryTmp"/client
-	export qc="$ub_queryclientdir"
-
-	export ub_queryclient="$ub_queryclientdir"/script
-	export qce="$ub_queryclient"
-
-	export ub_queryserverdir="$queryTmp"/server
-	export qs="$ub_queryserverdir"
-
-	export ub_queryserver="$ub_queryserverdir"/script
-	export qse="$ub_queryserver"
-
-	mkdir -p "$ub_queryclientdir"
-	mkdir -p "$ub_queryserverdir"
-
-	! [[ -e "$ub_queryclient" ]] && cp "$scriptAbsoluteLocation" "$ub_queryclient"
-	! [[ -e "$ub_queryserver" ]] && cp "$scriptAbsoluteLocation" "$ub_queryserver"
-
-	_prepare_query_prog "$@"
-
-	_safe_declare_uid
+        #"$GH_TOKEN"
+        #"$currentAbsoluteRepo" "$currentReleaseLabel" "$currentFile" "$currentOutFile"
+        #_wget_githubRelease_procedure-curl
+		_wget_githubRelease_loop-curl
+        return "$?"
+    fi
+
+    return 1
 }
+_wget_githubRelease_procedure-curl() {
+	( _messagePlain_nominal "$currentStream"'\/\/\/\/\/ \/\/\/ init: _wget_githubRelease_procedure-curl' >&2 ) > /dev/null
+    ( _messagePlain_probe_safe "currentURL= ""$currentURL" >&2 ) > /dev/null
+    ( _messagePlain_probe_safe "currentOutFile= ""$currentOutFile" >&2 ) > /dev/null

-_queryServer_sequence() {
-	_start
-
-	_safe_declare_uid
-
-	local currentExitStatus
-
-	export queryType="server"
-	"$ub_queryserver" "$@"
-	currentExitStatus="$?"
-
-	env > env_$(_uid)
-
-	_stop "$currentExitStatus"
-}
-_queryServer() {
-	"$scriptAbsoluteLocation" _queryServer_sequence "$@"
-}
-_qs() {
-	_queryServer "$@"
-}
+	# ATTENTION: Better if the loop does this only once. Resume may be possible.
+	##[[ "$currentOutFile" != "-" ]] && rm -f "$currentOutFile" > /dev/null 2>&1
+	#[[ "$currentOutFile" != "-" ]] && _destroy_lock "$currentOutFile"

-_queryClient_sequence() {
-	_start
-
-	_safe_declare_uid
-
-	local currentExitStatus
-
-	export queryType="client"
-	"$ub_queryclient" "$@"
-	currentExitStatus="$?"
-
-	env > env_$(_uid)
+    local current_curl_args
+	current_curl_args=()
+	[[ "$GH_TOKEN" != "" ]] && current_curl_args+=( -H "Authorization: Bearer $GH_TOKEN" )
+	current_curl_args+=( -H "Accept: application/octet-stream" )
+	current_curl_args+=( -S )
+	current_curl_args+=( -s )
+	#current_curl_args+=( --clobber )
+	current_curl_args+=( --continue-at - )
+
+    local currentFailParam="$1"
+    [[ "$currentFailParam" != "--no-fail" ]] && currentFailParam="--fail"
+	current_curl_args+=( "$currentFailParam" )
+	shift
+	# ATTENTION: Usually '_wget_githubRelease_procedure-curl' is used ONLY through '_wget_githubRelease_loop-curl' - the total timeout is similar but the latency is much safer.
+	# CAUTION: Discouraged unless proven necessary. Causes delays and latency beyond "$githubRelease_retriesWait"*"$githubRelease_retriesMax" , possibly exceeding prebuffering on a single error.
+	#--retry 5 --retry-delay 90 --connect-timeout 45 --max-time 600
+	#_set_curl_github_retry
+	#"${curl_retries_args[@]}"
+	current_curl_args+=( "$@" )

-	_stop "$currentExitStatus"
-}
-_queryClient() {
-	"$scriptAbsoluteLocation" _queryClient_sequence "$@"
-}
-_qc() {
-	_queryClient "$@"
-}
+	local currentExitStatus_ipv4=1
+	local currentExitStatus_ipv6=1
+
+	( _messagePlain_probe '_wget_githubRelease_procedure-curl: IPv6 (false)' >&2 ) > /dev/null
+	# ATTENTION: IPv6 is NOT offered by GitHub API, and so usually only wastes time at best.
+	#curl -6 "${current_curl_args[@]}" -L -o "$currentOutFile" "$currentURL"
+	false
+	# WARNING: May be untested.
+	#( set -o pipefail ; curl -6 "${current_curl_args[@]}" -L -o "$currentOutFile" "$currentURL" 2> >(tail -n 30 >&2) )
+	currentExitStatus_ipv6="$?"
+	if [[ "$currentExitStatus_ipv6" != "0" ]]
+	then
+		( _messagePlain_probe '_wget_githubRelease_procedure-curl: IPv4' >&2 ) > /dev/null
+		curl -4 "${current_curl_args[@]}" -L -o "$currentOutFile" "$currentURL"
+		# WARNING: May be untested.
+		#( set -o pipefail ; curl -4 "${current_curl_args[@]}" -L -o "$currentOutFile" "$currentURL" 2> >(tail -n 30 >&2) )
+		currentExitStatus_ipv4="$?"
+	fi
+
+	if [[ "$currentExitStatus_ipv6" != "0" ]] && [[ "$currentExitStatus_ipv4" != "0" ]]
+	then
+		#( _messagePlain_bad 'bad: FAIL: _wget_githubRelease_procedure-curl' >&2 ) > /dev/null
+        _bad_fail_githubRelease_currentExitStatus
+		[[ "$currentExitStatus_ipv4" != "1" ]] && [[ "$currentExitStatus_ipv4" != "0" ]] && return "$currentExitStatus_ipv4"
+		[[ "$currentExitStatus_ipv6" != "1" ]] && [[ "$currentExitStatus_ipv6" != "0" ]] && return "$currentExitStatus_ipv6"
+		return "$currentExitStatus_ipv4"
+	fi

-_query_diag() {
-	echo test | _query "$@"
-	local currentExitStatus="$?"
-
-	_messagePlain_nominal 'diag: tx.log'
-	_report_query_stdout "$queryTmp"/tx.log
-
-	_messagePlain_nominal 'diag: xc.log'
-	_report_query_stdout "$queryTmp"/xc.log
-
-	_messagePlain_nominal 'diag: rx.log'
-	_report_query_stdout "$queryTmp"/rx.log
-
-	return "$currentExitStatus"
-}
+    [[ ! -e "$currentOutFile" ]] && [[ "$currentOutFile" != "-" ]] && _bad_fail_githubRelease_missing && return 1

-# ATTENTION: Overload with "core.sh" or similar.
-_query() {
-	_prepare_query
-
-	( cd "$qc" ; _queryClient _bin cat | _log_query "$queryTmp"/tx.log | ( cd "$qs" ; _queryServer _bin cat | _log_query "$queryTmp"/xc.log | ( cd "$qc" ; _queryClient _bin cat | _log_query "$queryTmp"/rx.log ; return "${PIPESTATUS[0]}" )))
+    return 0
 }
+_wget_githubRelease_loop-curl() {
+	# Similar retry logic for all similar functions: _gh_download , _wget_githubRelease_loop-curl .
+	( _messagePlain_nominal "$currentStream"'\/\/\/\/\/ \/\/\/\/ init: _wget_githubRelease_loop-curl' >&2 ) > /dev/null
+	( _messagePlain_probe_safe _wget_githubRelease_loop-curl "$@" >&2 ) > /dev/null

-_scope_attach_prog() {
-	true
-}
+	#[[ "$currentOutFile" != "-" ]] && rm -f "$currentOutFile" > /dev/null 2>&1
+	[[ "$currentOutFile" != "-" ]] && _destroy_lock "$currentOutFile"

-# No known production use.
-_scope_attach_compile() {
-	#_scope_command_write _compile
-	#_scope_command_external_here _compile
-	true
-}
+	local currentExitStatus=1

-_scope_attach_query() {
-	_scope_command_write _query
-	_scope_command_write _qs
-	_scope_command_write _qc
-}
+	local currentIteration=0

-# ATTENTION: Overload with "core.sh" or similar!
-_scope_attach() {
-	_messagePlain_nominal '_scope_attach'
-
-	_scope_here > "$ub_scope"/.devenv
-	chmod u+x "$ub_scope"/.devenv
-	_scope_readme_here > "$ub_scope"/README
-
-	_scope_command_write _scope_terminal_procedure
-
-	_scope_command_write _scope_konsole_procedure
-	_scope_command_write _scope_dolphin_procedure
-	_scope_command_write _scope_eclipse_procedure
-	_scope_command_write _scope_atom_procedure
-
-	_scope_attach_query "$@"
-
-	_scope_attach_compile "$@"
-
-	_scope_attach_prog "$@"
-}
+	while ( [[ "$currentExitStatus" != "0" ]] || ( ! [[ -e "$currentOutFile" ]] && [[ "$currentOutFile" != "-" ]] ) ) && [[ "$currentIteration" -lt "$githubRelease_retriesMax" ]]
+	do
+		if [[ "$currentIteration" != "0" ]]
+		then
+			( _messagePlain_warn 'warn: BAD: RETRY: _wget_githubRelease_procedure-curl: currentIteration != 0' >&2 ) > /dev/null
+			sleep "$githubRelease_retriesWait"
+		fi

-_prepare_scope() {
-	#mkdir -p "$safeTmp"/scope
-	mkdir -p "$scopeTmp"
-	#true
-}
+		( _messagePlain_probe_safe _wget_githubRelease_procedure-curl >&2 ) > /dev/null
+		_wget_githubRelease_procedure-curl
+		# WARNING: May be untested.
+		#( set -o pipefail ; _wget_githubRelease_procedure-curl 2> >(tail -n 100 >&2) )
+		currentExitStatus="$?"

-_relink_scope() {
-	#_relink "$safeTmp"/scope "$ub_scope"
-	_relink "$scopeTmp" "$ub_scope"
-	#_relink "$safeTmp" "$ub_scope"
-
-	_relink "$safeTmp" "$ub_scope"/safeTmp
-	_relink "$shortTmp" "$ub_scope"/shortTmp
+		let currentIteration=currentIteration+1
+	done

-	# DANGER: Creates infinitely recursive symlinks.
-	#[[ -e "$abstractfs_projectafs" ]] && _relink "$abstractfs_projectafs" "$ub_scope"/project.afs
-	#[[ -d "$abstractfs" ]] && _relink "$abstractfs" "$ub_scope"/afs
-}
+	[[ "$currentExitStatus" != "0" ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease_loop-curl: _wget_githubRelease_procedure-curl: currentExitStatus' >&2 ) > /dev/null && return "$currentExitStatus"
+	! [[ -e "$currentOutFile" ]] && [[ "$currentOutFile" != "-" ]] && ( _messagePlain_bad 'bad: FAIL: missing: currentOutFile' >&2 ) > /dev/null && return 1

-_ops_scope() {
-	_messagePlain_nominal '_ops_scope'
-
-	#Find/run ops file in project dir.
-	[[ -e "$ub_specimen"/ops ]] && _messagePlain_good 'aU: found: sketch ops: ops' && . "$ub_specimen"/ops
-	[[ -e "$ub_specimen"/ops.sh ]] && _messagePlain_good 'aU: found: sketch ops: ops.sh' && . "$ub_specimen"/ops.sh
-
-	! [[ -e "$ub_specimen"/ops ]] && ! [[ -e "$ub_specimen"/ops.sh ]] && _messagePlain_warn 'aU: undef: sketch ops' && return 1
-
 	return 0
 }
+_wget_githubRelease_procedure-axel() {
+	( _messagePlain_nominal "$currentStream"'\/\/\/\/\/ \/\/\/ init: _wget_githubRelease_procedure-axel' >&2 ) > /dev/null
+    ( _messagePlain_probe_safe "currentURL= ""$currentURL" >&2 ) > /dev/null
+    ( _messagePlain_probe_safe "currentOutFile= ""$currentOutFile" >&2 ) > /dev/null

-#"$1" == ub_specimen
-#"$ub_scope_name" (default "scope")
-# WARNING Multiple instances of same scope on a single specimen strictly forbidden. Launch multiple applications within a scope, not multiple scopes.
-_start_scope() {
-	_messagePlain_nominal '_start_scope'
-
-	export ub_specimen=$(_getAbsoluteLocation "$1")
-	export specimen="$ub_specimen"
-	export ub_specimen_basename=$(basename "$ub_specimen")
-	export basename="$ub_specimen_basename"
-	[[ ! -d "$ub_specimen" ]] && _messagePlain_bad 'missing: specimen= '"$ub_specimen" && _stop 1
-	[[ ! -e "$ub_specimen" ]] && _messagePlain_bad 'missing: specimen= '"$ub_specimen" && _stop 1
-
-	[[ "$ub_scope_name" == "" ]] && export ub_scope_name='scope'
-
-	export ub_scope="$ub_specimen"/.s_"$ub_scope_name"
-	export scope="$ub_scope"
-	[[ -e "$ub_scope" ]] && _messagePlain_bad 'fail: safety: multiple scopes && single specimen' && _stop 1
-	[[ -L "$ub_scope" ]] && _messagePlain_bad 'fail: safety: multiple scopes && single specimen' && _stop 1
-
-	#[[ -e "$ub_specimen"/.e_* ]] && _messagePlain_bad 'fail: safety: engine root scope strongly discouraged' && _stop 1
-
-	#export ub_scope_tmp="$ub_scope"/s_"$sessionid"
-
-	_prepare_scope "$@"
-	_relink_scope "$@"
-	[[ ! -d "$ub_scope" ]] && _messagePlain_bad 'fail: link scope= '"$ub_scope" && _stop 1
-	#[[ ! -d "$ub_scope_tmp" ]] && _messagePlain_bad 'fail: create ub_scope_tmp= '"$ub_scope_tmp" && _stop 1
-	[[ ! -d "$ub_scope"/safeTmp ]] && _messagePlain_bad 'fail: link' && _stop 1
-	[[ ! -d "$ub_scope"/shortTmp ]] && _messagePlain_bad 'fail: link' && _stop 1
-
-	[[ ! -e "$ub_scope"/.pid ]] && echo $$ > "$ub_scope"/.pid
-
-	_messagePlain_good 'pass: prepare, relink'
-
-	return 0
-}
+    # ATTENTION: Quirk of aria2c , default dir is "$PWD" , is prepended to absolute paths , and the resulting '//' does not direct the absolute path to root.
+    local currentOutFile_relative=$(basename "$currentOutFile")
+    local currentOutDir=$(_getAbsoluteFolder "$currentOutFile")
+    ( _messagePlain_probe_safe "currentOutFile_relative= ""$currentOutFile_relative" >&2 ) > /dev/null
+    ( _messagePlain_probe_safe "currentOutDir= ""$currentOutFile" >&2 ) > /dev/null

-#Defaults, bash terminal, wait for kill signal, wait for EOF, etc. Override with "core.sh" . May run file manager, terminal, etc.
-# WARNING: Scope should only be terminated by process or user managing this interaction (eg. by closing file manager). Manager must be aware of any inter-scope dependencies.
-#"$@" <commands>
-_scope_interact() {
-	_messagePlain_nominal '_scope_interact'
-	#read > /dev/null 2>&1
-
-	_scopePrompt
-
-	_safe_declare_uid
+    ( _messagePlain_probe_safe "FORCE_AXEL= ""$FORCE_AXEL" >&2 ) > /dev/null
+
+	# ATTENTION: Better if the loop does this only once. Resume may be possible.
+	##[[ "$currentOutFile" != "-" ]] && rm -f "$currentOutFile" > /dev/null 2>&1
+	#[[ "$currentOutFile" != "-" ]] && _destroy_lock "$currentOutFile"
+
+	#aria2c --timeout=180 --max-tries=25 --retry-wait=15 "$@"
+    ##_messagePlain_probe _aria2c_bin_githubRelease -x "$currentForceAxel" --async-dns=false -o "$currentAxelTmpFileRelative".tmp1 --disable-ipv6=false "${currentURL_array_reversed[$currentIteration]}" >&2
+    ##_aria2c_bin_githubRelease --log=- --log-level=info -x "$currentForceAxel" --async-dns=false -o "$currentAxelTmpFileRelative".tmp1 --disable-ipv6=false "${currentURL_array_reversed[$currentIteration]}" | grep --color -i -E "Name resolution|$" >&2 &
+    ##messagePlain_probe _aria2c_bin_githubRelease -x "$currentForceAxel" --async-dns=false -o "$currentAxelTmpFileRelative".tmp2 --disable-ipv6=true "${currentURL_array_reversed[$currentIterationNext1]}" >&2
+    ##_aria2c_bin_githubRelease --log=- --log-level=info -x "$currentForceAxel" --async-dns=false -o "$currentAxelTmpFileRelative".tmp2 --disable-ipv6=true "${currentURL_array_reversed[$currentIterationNext1]}" | grep --color -i -E "Name resolution|$" >&2 &
+    local current_axel_args
+	current_axel_args=()
+	##[[ "$GH_TOKEN" != "" ]] && current_axel_args+=( -H "Authorization: Bearer $GH_TOKEN" )
+	[[ "$GH_TOKEN" != "" ]] && current_axel_args+=( --header="Authorization: token $GH_TOKEN" )
+	current_axel_args+=( --header="Accept: application/octet-stream" )
+	#current_axel_args+=( --quiet=true )
+	#current_axel_args+=( --timeout=180 --max-tries=25 --retry-wait=15 )
+    current_axel_args+=( --stderr=true --summary-interval=0 --console-log-level=error --async-dns=false )
+    [[ "$FORCE_AXEL" != "" ]] && current_axel_args+=( -x "$FORCE_AXEL" )

-	if [[ "$@" == "" ]]
+	local currentExitStatus_ipv4=1
+	local currentExitStatus_ipv6=1
+
+	#( _messagePlain_probe '_wget_githubRelease_procedure-axel: IPv6' >&2 ) > /dev/null
+	( _messagePlain_probe '_wget_githubRelease_procedure-axel: IPv6 (false)' >&2 ) > /dev/null
+    #( _messagePlain_probe_safe aria2c --disable-ipv6=false "${current_axel_args[@]}" -d "$currentOutDir" -o "$currentOutFile_relative" "$currentURL" >&2 ) > /dev/null
+	##aria2c --disable-ipv6=false "${current_axel_args[@]}" -d "$currentOutDir" -o "$currentOutFile_relative" "$currentURL"
+	## WARNING: May be untested.
+	##( set -o pipefail ; aria2c --disable-ipv6=false "${current_axel_args[@]}" -d "$currentOutDir" -o "$currentOutFile_relative" "$currentURL" 2> >(tail -n 40 >&2) )
+	#( set -o pipefail ; aria2c --disable-ipv6=false "${current_axel_args[@]}" -d "$currentOutDir" -o "$currentOutFile_relative" "$currentURL" > "$currentOutFile".log 2>&1 )
+	#currentExitStatus_ipv6="$?"
+	#( tail -n 40 "$currentOutFile".log >&2 )
+	#rm -f "$currentOutFile".log > /dev/null 2>&1
+	false
+    if [[ "$currentExitStatus_ipv6" != "0" ]]
+    then
+        ( _messagePlain_probe '_wget_githubRelease_procedure-axel: IPv4' >&2 ) > /dev/null
+        ( _messagePlain_probe_safe aria2c --disable-ipv6=true "${current_axel_args[@]}" -d "$currentOutDir" -o "$currentOutFile_relative" "$currentURL" >&2 ) > /dev/null
+        #aria2c --disable-ipv6=true "${current_axel_args[@]}" -d "$currentOutDir" -o "$currentOutFile_relative" "$currentURL"
+        #( set -o pipefail ; aria2c --disable-ipv6=true "${current_axel_args[@]}" -d "$currentOutDir" -o "$currentOutFile_relative" "$currentURL" 2> >(tail -n 40 >&2) )
+		( set -o pipefail ; aria2c --disable-ipv6=true "${current_axel_args[@]}" -d "$currentOutDir" -o "$currentOutFile_relative" "$currentURL" > "$currentOutFile".log 2>&1 )
+        currentExitStatus_ipv4="$?"
+		( tail -n 40 "$currentOutFile".log >&2 )
+		rm -f "$currentOutFile".log > /dev/null 2>&1
+    fi
+
+	if [[ "$currentExitStatus_ipv6" != "0" ]] && [[ "$currentExitStatus_ipv4" != "0" ]]
 	then
-		_scope_terminal_procedure
-		#_scope_eclipse_procedure
-		#eclipse
-# 		return
+		#( _messagePlain_bad 'bad: FAIL: _wget_githubRelease_procedure-axel' >&2 ) > /dev/null
+        _bad_fail_githubRelease_currentExitStatus
+		[[ "$currentExitStatus_ipv4" != "1" ]] && [[ "$currentExitStatus_ipv4" != "0" ]] && return "$currentExitStatus_ipv4"
+		[[ "$currentExitStatus_ipv6" != "1" ]] && [[ "$currentExitStatus_ipv6" != "0" ]] && return "$currentExitStatus_ipv6"
+		return "$currentExitStatus_ipv4"
 	fi
-
-	_safe_declare_uid
-
-	"$@"
-}

-# ATTENTION: Overload with "core.sh" or similar!
-_scope_prog_procedure() {
-	# WARNING: Not necessarily wise for all applications. However, applications needing a different working directory should get there from an environment variable relative to script or specimen directory.
-	# WARNING: Disabling this may cause inconsistencies with programs which require "_abstractfs" (eg. Arduino, Eclipse).
-	cd "$ub_specimen"
-
-	#true
-}
+    [[ ! -e "$currentOutFile" ]] && [[ "$currentOutFile" != "-" ]] && _bad_fail_githubRelease_missing && return 1

+	# WARNING: Partial download is FAIL, but aria2c may set exit status '0' (ie. true). Return FALSE in this case.
+	#if ls -1 "$scriptAbsoluteFolder"/$(_axelTmp).aria2* > /dev/null 2>&1
+	#if ls -1 "$currentAxelTmpFile".aria2* > /dev/null 2>&1
+	#if ls -1 "$scriptAbsoluteFolder"/.m_axelTmp_"$currentStream"_"$currentAxelTmpFileUID".aria2* > /dev/null 2>&1
+	if ls -1 "$currentOutFile".aria2* > /dev/null 2>&1
+	then
+		return 1
+	fi

-_scope_sequence() {
-	_messagePlain_nominal 'init: scope: '"$ub_scope_name"
-	_messagePlain_probe 'HOME= '"$HOME"
-
-	_start
-	_start_scope "$@"
-	_ops_scope
-
-	_scope_prog_procedure "$@"
-
-	_scope_attach "$@"
-
-	#User interaction.
-	shift
-	_scope_interact "$@"
-
-	_stop
-}
+	# Disabled (commented out). Contradictory state of PASS with part files remaining should terminate script with FAIL , _stop , exit , etc .
+	# ie.
+	##  _messagePlain_bad 'bad: FAIL: currentAxelTmpFile*: EXISTS !'
+	##  _messageError 'FAIL'
+	##_destroy_lock "$scriptAbsoluteFolder"/$(_axelTmp).part*
+	#_destroy_lock "$scriptAbsoluteFolder"/.m_axelTmp_"$currentStream"_"$currentAxelTmpFileUID".part*
+	##_destroy_lock "$scriptAbsoluteFolder"/$(_axelTmp).aria2*
+	#_destroy_lock "$scriptAbsoluteFolder"/.m_axelTmp_"$currentStream"_"$currentAxelTmpFileUID".aria2*

-# ATTENTION: Overload with "core.sh" or similar!
-_scope_prog() {
-	[[ "$ub_scope_name" == "" ]] && export ub_scope_name='scope'
+    return 0
 }
+_wget_githubRelease_loop-axel() {
+	# Similar retry logic for all similar functions: _gh_download , _wget_githubRelease_loop-axel .
+	( _messagePlain_nominal "$currentStream"'\/\/\/\/\/ \/\/\/\/ init: _wget_githubRelease_loop-axel' >&2 ) > /dev/null
+	( _messagePlain_probe_safe _wget_githubRelease_loop-axel "$@" >&2 ) > /dev/null

-_scope() {
-	_scope_prog "$@"
-	[[ "$ub_scope_name" == "" ]] && export ub_scope_name='scope'
-	"$scriptAbsoluteLocation" _scope_sequence "$@"
-}
+	#[[ "$currentOutFile" != "-" ]] && rm -f "$currentOutFile" > /dev/null 2>&1
+	[[ "$currentOutFile" != "-" ]] && _destroy_lock "$currentOutFile"

-_scope_readme_here() {
-	cat << CZXWXcRMTo8EmM8i4d
-Ubiquitous Bash scope.
-CZXWXcRMTo8EmM8i4d
-}
+	local currentExitStatus=1

-#Example, override with "core.sh" .
-_scope_var_here_prog() {
-	cat << CZXWXcRMTo8EmM8i4d
-CZXWXcRMTo8EmM8i4d
-}
+	local currentIteration=0

-_scope_var_here() {
-	cat << CZXWXcRMTo8EmM8i4d
-export ub_specimen="$ub_specimen"
-export specimen="$specimen"
-export ub_specimen_basename="$ub_specimen_basename"
-export basename="$basename"
-export ub_scope_name="$ub_scope_name"
-export ub_scope="$ub_scope"
-export scope="$scope"
+	while ( [[ "$currentExitStatus" != "0" ]] || ( ! [[ -e "$currentOutFile" ]] && [[ "$currentOutFile" != "-" ]] ) ) && [[ "$currentIteration" -lt "$githubRelease_retriesMax" ]]
+	do
+		if [[ "$currentIteration" != "0" ]]
+		then
+			( _messagePlain_warn 'warn: BAD: RETRY: _wget_githubRelease_procedure-axel: currentIteration != 0' >&2 ) > /dev/null
+			sleep "$githubRelease_retriesWait"
+		fi

-CZXWXcRMTo8EmM8i4d
+		( _messagePlain_probe_safe _wget_githubRelease_procedure-axel >&2 ) > /dev/null
+		_wget_githubRelease_procedure-axel
+		# WARNING: May be untested.
+		#( set -o pipefail ; _wget_githubRelease_procedure-axel 2> >(tail -n 100 >&2) )
+		currentExitStatus="$?"
+
+		let currentIteration=currentIteration+1
+	done

-	_scope_var_here_prog "$@"
+	[[ "$currentExitStatus" != "0" ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease_loop-axel: _wget_githubRelease_procedure-axel: currentExitStatus' >&2 ) > /dev/null && return "$currentExitStatus"
+	! [[ -e "$currentOutFile" ]] && [[ "$currentOutFile" != "-" ]] && ( _messagePlain_bad 'bad: FAIL: missing: currentOutFile' >&2 ) > /dev/null && return 1
+
+	return 0
 }

-_scope_here() {
-	cat << CZXWXcRMTo8EmM8i4d
-#!/usr/bin/env bash

-CZXWXcRMTo8EmM8i4d

-	_scope_var_here

-	cat << CZXWXcRMTo8EmM8i4d

-export scriptAbsoluteLocation="$scriptAbsoluteLocation"
-export scriptAbsoluteFolder="$scriptAbsoluteFolder"
-export sessionid="$sessionid"
-. "$scriptAbsoluteLocation" --devenv "\$@"
-CZXWXcRMTo8EmM8i4d
-}

-_scope_command_here() {
-	cat << CZXWXcRMTo8EmM8i4d
-#!/usr/bin/env bash

-CZXWXcRMTo8EmM8i4d

-	_scope_var_here

-	cat << CZXWXcRMTo8EmM8i4d

-export scriptAbsoluteLocation="$scriptAbsoluteLocation"
-export scriptAbsoluteFolder="$scriptAbsoluteFolder"
-export sessionid="$sessionid"
-. "$scriptAbsoluteLocation" --devenv "$1" "\$@"
-CZXWXcRMTo8EmM8i4d
-}

-_scope_command_external_here() {
-	cat << CZXWXcRMTo8EmM8i4d
-#!/usr/bin/env bash

-CZXWXcRMTo8EmM8i4d

-	_scope_var_here

-	cat << CZXWXcRMTo8EmM8i4d

-export importScriptLocation="$scriptAbsoluteLocation"
-export importScriptFolder="$scriptAbsoluteFolder"
-. "$scriptAbsoluteLocation" --script "$1" "\$@"
-CZXWXcRMTo8EmM8i4d
-}
+_wget_githubRelease_join() {
+    local currentAbsoluteRepo="$1"
+	local currentReleaseLabel="$2"
+	local currentFile="$3"

-_scope_command_write() {
-	_scope_command_here "$@" > "$ub_scope"/"$1"
-	chmod u+x "$ub_scope"/"$1"
-}
+	local currentOutParameter="$4"
+	local currentOutFile="$5"

-_scope_command_external_write() {
-	_scope_command_external_here "$@" > "$ub_scope"/"$1"
-	chmod u+x "$ub_scope"/"$1"
-}
+	shift
+	shift
+	shift
+	[[ "$currentOutParameter" != "-O" ]] && currentOutFile="$currentFile"
+	#[[ "$currentOutParameter" == "-O" ]] && currentOutFile="$currentOutFile"

-_scopePrompt() {
-	[[ "$ub_scope_name" == "" ]] && return 0
-
-	#export PS1='\[\033[01;40m\]\[\033[01;36m\]+\[\033[01;34m\]-|\[\033[01;31m\]${?}:${debian_chroot:+($debian_chroot)}\[\033[01;33m\]\u\[\033[01;32m\]@\h\[\033[01;36m\]\[\033[01;34m\])-\[\033[01;36m\]------------------------\[\033[01;34m\]-(\[\033[01;35m\]$(date +%H:%M:%S\ .%d)\[\033[01;34m\])-\[\033[01;36m\]- -|\[\033[00m\]\n\[\033[01;40m\]\[\033[01;36m\]+\[\033[01;34m\]-|\[\033[37m\][\w]\[\033[00m\]\n\[\033[01;36m\]+\[\033[01;34m\]-|\#) \[\033[36m\]'"$ub_scope_name"'>\[\033[00m\] '
-
-
-	_visualPrompt
-
-	if ! _if_cygwin
+	#[[ "$currentOutParameter" == "-O" ]] && [[ "$currentOutFile" == "" ]] && currentOutFile="$currentFile"
+	[[ "$currentOutParameter" == "-O" ]] && [[ "$currentOutFile" == "" ]] && ( _messagePlain_bad 'bad: fail: unexpected: unspecified: currentOutFile' >&2 ) > /dev/null && return 1
+
+	if [[ "$currentOutParameter" == "-O" ]]
 	then
-		export PS1='\[\033[01;40m\]\[\033[01;36m\]\[\033[01;34m\]|\[\033[01;31m\]${?}:${debian_chroot:+($debian_chroot)}\[\033[01;33m\]\u\[\033[01;32m\]@\h\[\033[01;36m\]\[\033[01;34m\])\[\033[01;36m\]\[\033[01;34m\]-(\[\033[01;35m\]$(date +%H:%M:%S\.%d)\[\033[01;34m\])\[\033[01;36m\]|\[\033[00m\]\n\[\033[01;40m\]\[\033[01;36m\]\[\033[01;34m\]|\[\033[37m\][\w]\[\033[00m\]\n\[\033[01;36m\]\[\033[01;34m\]|$PS1_lineNumberText\[\033[01;34m\]) \[\033[36m\]'"$ub_scope_name"'>\[\033[00m\] '
-	else
-		export PS1='\[\033[01;40m\]\[\033[01;36m\]\[\033[01;34m\]|\[\033[01;31m\]${?}:${debian_chroot:+($debian_chroot)}\[\033[01;33m\]\u\[\033[01;32m\]@\h\[\033[01;36m\]\[\033[01;34m\])\[\033[01;36m\]\[\033[01;34m\]-(\[\033[01;35m\]$(date +%H:%M:%S\.%d)\[\033[01;34m\])\[\033[01;36m\]|\[\033[00m\]\n\[\033[01;40m\]\[\033[01;36m\]\[\033[01;34m\]\[\033[37m\]\w\n\[\033[01;36m\]\[\033[01;34m\]|$PS1_lineNumberText\[\033[01;34m\]) \[\033[36m\]'"$ub_scope_name"'>\[\033[00m\] '
+		shift
+		shift
 	fi
-}

-_scope_terminal_procedure() {
-	_tryExec '_scopePrompt'
-	#_tryExec '_visualPrompt'
-
-	_safe_declare_uid
-
-	export PATH="$PATH":"$ub_scope"
-	echo
-	/usr/bin/env bash --norc
-	echo
-}
+	#[[ "$currentOutFile" != "-" ]] && rm -f "$currentOutFile" > /dev/null 2>&1
+	[[ "$currentOutFile" != "-" ]] && _destroy_lock "$currentOutFile"

-_scope_terminal() {
-	_safe_declare_uid
-
-	local shiftParam1
-	shiftParam1="$1"
-	shift
-
-	_scope_prog "$@"
-	_scope "$shiftParam1" "_scope_terminal_procedure" "$@"
-}

-_scope_eclipse_procedure() {
-	_safe_declare_uid
-
-	_eclipse "$@"
-}
+	# ATTENTION
+	currentFile=$(basename "$currentFile")

-_scope_eclipse() {
-	_safe_declare_uid
-
-	local shiftParam1
-	shiftParam1="$1"
-	shift
-
-	_scope_prog "$@"
-	_scope "$shiftParam1" "_scope_eclipse_procedure" "$@"
-}

-_scope_atom_procedure() {
-	_safe_declare_uid
-
-	"$scriptAbsoluteLocation" _atom_tmp_sequence "$ub_specimen" "$@"  > /dev/null 2>&1
-}

-# WARNING: No production use. Not to be relied upon. May be removed.
-_scope_atom() {
-	_safe_declare_uid
-
-	local shiftParam1
-	shiftParam1="$1"
-	shift
-
-	_scope_prog "$@"
-	_scope "$shiftParam1" "_scope_atom_procedure" "$@"
-}

-_scope_konsole_procedure() {
-	_safe_declare_uid
-
-	_messagePlain_probe konsole --workdir "$ub_specimen" "$@"
-	konsole --workdir "$ub_specimen" "$@"
-}
+	( _messagePlain_probe_safe _wget_githubRelease_join "$@" >&2 ) > /dev/null

-_scope_konsole() {
-	_safe_declare_uid
-
-	local shiftParam1
-	shiftParam1="$1"
-	shift
-
-	_scope_prog "$@"
-	_scope "$shiftParam1" "_scope_konsole_procedure" -p tabtitle="$ub_scope_name" "$@"
+	_messagePlain_probe_safe _wget_githubRelease_join-stdout "$currentAbsoluteRepo" "$currentReleaseLabel" "$currentFile" "$@" '>' "$currentOutFile" >&2
+	_wget_githubRelease_join-stdout "$currentAbsoluteRepo" "$currentReleaseLabel" "$currentFile" "$@" > "$currentOutFile"
+
+	[[ ! -e "$currentOutFile" ]] && _messagePlain_bad 'missing: '"$1"' '"$2"' '"$3" && return 1
+
+	return 0
 }

-_scope_dolphin_procedure() {
-	_safe_declare_uid
-
-	dolphin "$ub_specimen" "$@"
+
+
+
+_wget_githubRelease_join-stdout() {
+	"$scriptAbsoluteLocation" _wget_githubRelease_join_sequence-stdout "$@"
 }
+_wget_githubRelease_join_sequence-stdout() {
+	( _messagePlain_nominal '\/\/\/\/\/ \/\/\/\/\/ init: _wget_githubRelease_join-stdout' >&2 ) > /dev/null
+	( _messagePlain_probe_safe _wget_githubRelease_join-stdout "$@" >&2 ) > /dev/null
+
+	local currentAbsoluteRepo="$1"
+	local currentReleaseLabel="$2"
+	local currentFile="$3"
+
+	local currentOutParameter="$4"
+	local currentOutFile="$5"

-_scope_dolphin() {
-	_safe_declare_uid
-
-	local shiftParam1
-	shiftParam1="$1"
 	shift
-
-	_scope_prog "$@"
-	_scope "$shiftParam1" "_scope_dolphin_procedure" "$@"
-}
+	shift
+	shift
+	if [[ "$currentOutParameter" == "-O" ]]
+	then
+		if [[ "$currentOutFile" != "-" ]]
+		then
+			( _messagePlain_bad 'bad: fail: unexpected: currentOutFile: NOT stdout' >&2 ) > /dev/null
+			#echo "1" > "$currentAxelTmpFile".FAIL
+			return 1
+		fi
+		shift
+		shift
+	fi


-_github_removeActionsHTTPS-filter() {
-    _messagePlain_probe '_github_removeActionsHTTPS-filter: '"$1"
-
-    sed -i 's/^\sextraheader.*$//g' "$1"
-    sed -i 's/^\sinsteadOf = git@github.com:.*$//g' "$1"
-    sed -i 's/^\sinsteadOf = org.*@github.com:.*$//g' "$1"
-}
+    _set_wget_githubRelease "$@"

-_github_removeActionsHTTPS() {
-    if [[ "$1" != *".git"* ]] && [[ "$1" != *".git" ]]
-    then
-        _messagePlain_bad 'warn: missing: .git: '"$1"
-        _messageFAIL
-        _stop 1
-        return 1
-    fi

-    find "$1" -type f -name 'config' -exec "$scriptAbsoluteLocation" _github_removeActionsHTTPS-filter {} \;
-
+    local currentPart
+    local currentSkip
+    local currentStream
+	local currentStream_wait
+	local currentBusyStatus

-}
+	# CAUTION: Any greater than 50 is not expected to serve any purpose, may exhaust expected API rate limits, may greatly delay download, and may disrupt subsequent API requests. Any less than 50 may fall below the ~100GB capacity that is both expected necessary for some complete toolchains and at the limit of ~100GB archival quality optical disc (ie. M-Disc) .
+	#local maxCurrentPart=50

+	# ATTENTION: Graceful degradation to a maximum part count of 49 can be achieved by reducing API calls using the _curl_githubAPI_releases_join-skip function. That single API call can get 100 results, leaving 49 unused API calls remaining to get API_URL addresses to download 49 parts. Files larger than ~200GB are likely rare, specialized.
+	#local maxCurrentPart=98

+	# ATTENTION: In practice, 128GB storage media - reputable brand BD-XL near-archival quality optical disc, SSDs, etc - is the maximum file size that is convenient.
+	# '1997537280' bytes truncate/tail
+	# https://en.wikipedia.org/wiki/Blu-ray
+	#  '128,001,769,472' ... 'Bytes'
+	# https://fy.chalmers.se/~appro/linux/DVD+RW/Blu-ray/
+	#  'only inner spare area of 256MB'
+	local maxCurrentPart=63


+    local currentExitStatus=1



-# "$1" == build-${{ github.run_id }}-${{ github.run_attempt }}
-#shift
-# "$@" == ./_local/package_image_beforeBoot.tar.flx.part*
-_gh_release_upload_parts-multiple() {
-    "$scriptAbsoluteLocation" _gh_release_upload_parts-multiple_sequence "$@"
-}
-_gh_release_upload_parts-multiple_sequence() {
-    _messageNormal '_gh_release_upload_parts: '"$@"
-    local currentTag="$1"
-    shift
+    (( [[ "$FORCE_BUFFER" == "true" ]] && [[ "$FORCE_DIRECT" == "true" ]] ) || ( [[ "$FORCE_BUFFER" == "false" ]] && [[ "$FORCE_DIRECT" == "false" ]] )) && ( _messagePlain_bad 'bad: fail: FORCE_BUFFER , FORCE_DIRECT: conflict' >&2 ) > /dev/null && ( _messageError 'FAIL' >&2 ) > /dev/null && exit 1

-    local currentStream_max=12
+	[[ "$FORCE_PARALLEL" == "1" ]] && ( _messagePlain_bad 'bad: fail: FORCE_PARALLEL: sanity' >&2 ) > /dev/null && ( _messageError 'FAIL' >&2 ) > /dev/null && exit 1
+	[[ "$FORCE_PARALLEL" == "0" ]] && ( _messagePlain_bad 'bad: fail: FORCE_PARALLEL: sanity' >&2 ) > /dev/null && ( _messageError 'FAIL' >&2 ) > /dev/null && exit 1
+
+    [[ "$FORCE_AXEL" != "" ]] && [[ "$FORCE_DIRECT" == "true" ]] && ( _messagePlain_bad 'bad: fail: FORCE_AXEL is NOT compatible with FORCE_DIRECT==true' >&2 ) > /dev/null && ( _messageError 'FAIL' >&2 ) > /dev/null && exit 1

-    local currentStreamNum=0
+    [[ "$FORCE_AXEL" != "" ]] && ( _messagePlain_warn 'warn: WARNING: FORCE_AXEL not empty' >&2 ; echo 'FORCE_AXEL may have similar effects to FORCE_WGET and should not be necessary.' >&2  ) > /dev/null

-    for currentFile in "$@"
-    do
-        let currentStreamNum++

-        "$scriptAbsoluteLocation" _gh_release_upload_part-single_sequence "$currentTag" "$currentFile" &
-        eval local currentStream_${currentStreamNum}_PID="$!"
-        _messagePlain_probe_var currentStream_${currentStreamNum}_PID
-
-        while [[ $(jobs | wc -l) -ge "$currentStream_max" ]]
-        do
-            echo
-            jobs
-            echo
-            sleep 2
-            true
-        done
-    done

-    local currentStreamPause
-    for currentStreamPause in $(seq "1" "$currentStreamNum")
-	do
-        _messagePlain_probe currentStream_${currentStreamPause}_PID= $(eval "echo \$currentStream_${currentStreamPause}_PID")
-		if eval "[[ \$currentStream_${currentStreamPause}_PID != '' ]]"
+    _if_buffer() {
+        if ( [[ "$FORCE_BUFFER" == "true" ]] || [[ "$FORCE_DIRECT" == "false" ]] ) || [[ "$FORCE_BUFFER" == "" ]]
         then
-           _messagePlain_probe _pauseForProcess $(eval "echo \$currentStream_${currentStreamPause}_PID")
-           _pauseForProcess $(eval "echo \$currentStream_${currentStreamPause}_PID")
+            true
+            return
+        else
+            false
+            return
         fi
-	done
-
-    while [[ $(jobs | wc -l) -ge 1 ]]
-    do
-        echo
-        jobs
-        echo
-        sleep 2
         true
-    done
+        return
+    }
+
+

-    wait
-}
-_gh_release_upload_part-single_sequence() {
-    _messagePlain_nominal '_gh_release_upload: '"$1"' '"$2"
-    local currentTag="$1"
-    local currentFile="$2"
+    # WARNING: FORCE_DIRECT="true" , "FORCE_BUFFER="false" very strongly discouraged. Any retry/continue of any interruption will nevertheless unavoidably result in a corrupted output stream.
+    if ! _if_buffer
+    then
+        #export FORCE_DIRECT="true"

-    #local currentPID
-    #"$scriptAbsoluteLocation" _stopwatch gh release upload "$currentTag" "$currentFile" &
-    #currentPID="$!"
+        _set_wget_githubRelease-detect "$@"
+        currentSkip="skip"

-    #_pauseForProcess "$currentPID"
-    #wait
+        currentStream="noBuf"
+        #local currentAxelTmpFileRelative=.m_axelTmp_"$currentStream"_$(_uid 14)
+	    #local currentAxelTmpFile="$scriptAbsoluteFolder"/"$currentAxelTmpFileRelative"

-    #while ! "$scriptAbsoluteLocation" _stopwatch _timeout 10 dd if="$currentFile" bs=1M status=progress > /dev/null
-    #do
-        #sleep 7
-    #done
-    #return 0
+		maxCurrentPart=$(_curl_githubAPI_releases_join-skip "$currentAbsoluteRepo" "$currentReleaseLabel" "$currentFile")

-    # Maximum file size is 2GigaBytes .
-    local currentIteration=0
-    while ! "$scriptAbsoluteLocation" _stopwatch _timeout 600 gh release upload --clobber "$currentTag" "$currentFile" && [[ "$currentIteration" -lt 30 ]]
-    do
-        sleep 7
-        let currentIteration++
-    done
-    return 0
-}
+        currentPart=""
+        for currentPart in $(seq -f "%02g" 0 "$maxCurrentPart" | sort -r)
+        do
+            if [[ "$currentSkip" == "skip" ]]
+            then
+				# ATTENTION: Could expect to use the 'API_URL' function in both cases, since we are not using the resulting URL except to 'skip'/'download' .
+				#currentSkip=$(_wget_githubRelease-skip-API_URL-curl "$currentAbsoluteRepo" "$currentReleaseLabel" "$currentFile".part"$currentPart")
+				if [[ "$GH_TOKEN" != "" ]]
+				then
+					currentSkip=$(_wget_githubRelease-skip-API_URL-curl "$currentAbsoluteRepo" "$currentReleaseLabel" "$currentFile".part"$currentPart")
+					#[[ "$?" != "0" ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease-skip-API_URL-curl' >&2 ) > /dev/null && ( _messageError 'FAIL' >&2 ) > /dev/null && exit 1
+					#[[ "$?" != "0" ]] && currentSkip="skip"
+					[[ "$?" != "0" ]] && ( _messagePlain_warn 'bad: FAIL: _wget_githubRelease-skip-API_URL-curl' >&2 ) > /dev/null
+				else
+					currentSkip=$(_wget_githubRelease-skip-URL-curl "$currentAbsoluteRepo" "$currentReleaseLabel" "$currentFile".part"$currentPart")
+					#[[ "$?" != "0" ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease-skip-API_URL-curl' >&2 ) > /dev/null && ( _messageError 'FAIL' >&2 ) > /dev/null && exit 1
+					#[[ "$?" != "0" ]] && currentSkip="skip"
+					[[ "$?" != "0" ]] && ( _messagePlain_warn 'bad: FAIL: _wget_githubRelease-skip-API_URL-curl' >&2 ) > /dev/null
+				fi
+            fi
+
+            [[ "$currentSkip" == "skip" ]] && continue

+
+            if [[ "$currentExitStatus" == "0" ]] || [[ "$currentSkip" != "skip" ]]
+            then
+                _set_wget_githubRelease "$@"
+                currentSkip="download"
+            fi


-_testGit() {
-	_wantGetDep git
-}
+            _wget_githubRelease_procedure "$currentAbsoluteRepo" "$currentReleaseLabel" "$currentFile".part"$currentPart" -O - "$@"
+            currentExitStatus="$?"
+            #[[ "$currentExitStatus" != "0" ]] && break
+        done

-#Ignores file modes, suitable for use with possibly broken filesystems like NTFS.
-_gitCompatible() {
-	git -c core.fileMode=false "$@"
-}
+        return "$currentExitStatus"
+    fi

-_gitInfo() {
-	#Git Repository Information
-	export repoDir="$PWD"

-	export repoName=$(basename "$repoDir")
-	export bareRepoDir=../."$repoName".git
-	export bareRepoAbsoluteDir=$(_getAbsoluteLocation "$bareRepoDir")

-	#Set $repoHostName in user ".bashrc" or similar. May also set $repoPort including colon prefix.
-	[[ "$repoHostname" == "" ]] && export repoHostname=$(hostname -f)
-
-	true
-}

-_gitRemote() {
-	_gitInfo
-
-	if [[ -e "$bareRepoDir" ]]
-	then
-		_showGitRepoURI
-		return 0
-	fi
-
-	if ! [[ -e "$repoDir"/.git ]]
-	then
-		return 1
-	fi
-
-	if git config --get remote.origin.url > /dev/null 2>&1
-	then
-		echo -n "git clone --recursive "
-		git config --get remote.origin.url
-		return 0
-	fi
-	_gitBare
-}

-_gitNew() {
-	git init
-	git add .
-	git commit -a -m "first commit"
-	git branch -M main
-}
+	# ### ATTENTION: _if_buffer (IMPLICIT)

-_gitImport() {
-	cd "$scriptFolder"
-
-	mkdir -p "$1"
-	cd "$1"
-	shift
-	git clone "$@"
-
-	cd "$scriptFolder"
-}
+	# NOTICE: Parallel downloads may, if necessary, be adapted to first cache a list of addresses (ie. URLs) to download. API rate limits could then have as much time as possible to recover before subsequent commands (eg. analysis of builds). Such a cache must be filled with addresses BEFORE the download loop.
+	#  However, at best, this can only be used with non-ephemeral 'browser_download_url' addresses .

-_findGit_procedure() {
-	cd "$1"
-	shift
-
-	if [[ -e "./.git" ]]
-	then
-		"$@"
-		return 0
-	fi
-
-	find -L . -mindepth 1 -maxdepth 1 -not \( -path \*_arc\* -prune \) -not \( -path \*/_local/ubcp/\* -prune \) -type d -exec "$scriptAbsoluteLocation" _findGit_procedure '{}' "$@" \;
-}

-#Recursively searches for directories containing ".git".
-_findGit() {
-	if [[ -e "./.git" ]]
-	then
-		"$@"
-		return 0
-	fi
-
-	find -L . -mindepth 1 -maxdepth 1 -not \( -path \*_arc\* -prune \) -not \( -path \*/_local/ubcp/\* -prune \) -type d -exec "$scriptAbsoluteLocation" _findGit_procedure '{}' "$@" \;
-}
+	export currentAxelTmpFileUID="$(_uid 14)"
+	_axelTmp() {
+		echo .m_axelTmp_"$currentStream"_"$currentAxelTmpFileUID"
+	}
+	local currentAxelTmpFile
+	#currentAxelTmpFile="$scriptAbsoluteFolder"/$(_axelTmp)

-_gitPull() {
-	git pull
-	git submodule update --recursive
-}
+	local currentStream_min=1
+	local currentStream_max=3
+	[[ "$FORCE_PARALLEL" != "" ]] && currentStream_max="$FORCE_PARALLEL"

-_gitCheck_sequence() {
-	echo '-----'
-
-	local checkRealpath
-	checkRealpath=$(realpath .)
-	local checkBasename
-	checkBasename=$(basename "$checkRealpath")
-
-	echo "$checkBasename"
-
-	git status
-}
+	currentStream="$currentStream_min"

-_gitCheck() {
-	_findGit "$scriptAbsoluteLocation" _gitCheck_sequence
-}

-_gitPullRecursive_sequence() {
-	echo '-----'
-
-	local checkRealpath
-	checkRealpath=$(realpath .)
-	local checkBasename
-	checkBasename=$(basename "$checkRealpath")
-
-	echo "$checkBasename"
-
-	"$scriptAbsoluteLocation" _gitPull
-}
+	currentPart="$maxCurrentPart"

-# DANGER
-#Updates all git repositories recursively.
-_gitPullRecursive() {
-	_findGit "$scriptAbsoluteLocation" _gitPullRecursive_sequence
-}

-# DANGER
-# Pushes all changes as a commit described as "Upstream."
-_gitUpstream() {
-	git add -A . ; git commit -a -m "Upstream." ; git push
-}
-_gitUp() {
-	_gitUpstream
-}
+	_set_wget_githubRelease-detect "$@"
+	currentSkip="skip"

-# DANGER
-#Removes all but the .git folder from the working directory.
-#_gitFresh() {
-#	find . -not -path '\.\/\.git*' -delete
-#}
+	maxCurrentPart=$(_curl_githubAPI_releases_join-skip "$currentAbsoluteRepo" "$currentReleaseLabel" "$currentFile")
+
+	currentPart=""
+	for currentPart in $(seq -f "%02g" 0 "$maxCurrentPart" | sort -r)
+	do
+		if [[ "$currentSkip" == "skip" ]]
+		then
+			# ATTENTION: EXPERIMENT
+			# ATTENTION: Could expect to use the 'API_URL' function in both cases, since we are not using the resulting URL except to 'skip'/'download' .
+			#currentSkip=$(_wget_githubRelease-skip-API_URL-curl "$currentAbsoluteRepo" "$currentReleaseLabel" "$currentFile".part"$currentPart")
+			##currentSkip=$([[ "$currentPart" -gt "17" ]] && echo 'skip' ; true)
+			if [[ "$GH_TOKEN" != "" ]]
+			then
+				currentSkip=$(_wget_githubRelease-skip-API_URL-curl "$currentAbsoluteRepo" "$currentReleaseLabel" "$currentFile".part"$currentPart")
+				#[[ "$?" != "0" ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease-skip-API_URL-curl' >&2 ) > /dev/null && ( _messageError 'FAIL' >&2 ) > /dev/null && exit 1
+				#[[ "$?" != "0" ]] && currentSkip="skip"
+				[[ "$?" != "0" ]] && ( _messagePlain_warn 'bad: FAIL: _wget_githubRelease-skip-API_URL-curl' >&2 ) > /dev/null
+			else
+				currentSkip=$(_wget_githubRelease-skip-URL-curl "$currentAbsoluteRepo" "$currentReleaseLabel" "$currentFile".part"$currentPart")
+				#[[ "$?" != "0" ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease-skip-API_URL-curl' >&2 ) > /dev/null && ( _messageError 'FAIL' >&2 ) > /dev/null && exit 1
+				#[[ "$?" != "0" ]] && currentSkip="skip"
+				[[ "$?" != "0" ]] && ( _messagePlain_warn 'bad: FAIL: _wget_githubRelease-skip-API_URL-curl' >&2 ) > /dev/null
+			fi
+		fi
+
+		[[ "$currentSkip" == "skip" ]] && continue
+
+
+		#[[ "$currentExitStatus" == "0" ]] ||
+		if [[ "$currentSkip" != "skip" ]]
+		then
+			_set_wget_githubRelease "$@"
+			currentSkip="download"
+			break
+		fi
+	done

+	export currentSkipPart="$currentPart"
+	[[ "$currentStream_max" -gt "$currentSkipPart" ]] && currentStream_max=$(( "$currentSkipPart" + 1 ))

+	"$scriptAbsoluteLocation" _wget_githubRelease_join_sequence-parallel "$currentAbsoluteRepo" "$currentReleaseLabel" "$currentFile" &


+	# Prebuffer .
+	( _messagePlain_nominal '\/\/\/\/\/ \/\/\/\/  preBUFFER: WAIT  ...  currentPart='"$currentPart" >&2 ) > /dev/null
+	if [[ "$currentPart" -ge "01" ]] && [[ "$currentStream_max" -ge "2" ]]
+	then
+		#currentStream="2"
+		for currentStream in $(seq "$currentStream_min" "$currentStream_max" | sort -r)
+		do
+			( _messagePlain_probe 'prebuffer: currentStream= '"$currentStream" >&2 ) > /dev/null
+			while ( ! [[ -e "$scriptAbsoluteFolder"/$(_axelTmp).PASS ]] && ! [[ -e "$scriptAbsoluteFolder"/$(_axelTmp).FAIL ]] )
+			do
+				sleep 3
+			done
+		done
+	fi
+	currentStream="$currentStream_min"


+	for currentPart in $(seq -f "%02g" 0 "$currentSkipPart" | sort -r)
+	do
+	( _messagePlain_nominal '\/\/\/\/\/ \/\/\/\/  outputLOOP  ...  currentPart='"$currentPart"' currentStream='"$currentStream" >&2 ) > /dev/null
+	#( _messagePlain_probe_var currentPart >&2 ) > /dev/null
+	#( _messagePlain_probe_var currentStream >&2 ) > /dev/null

+		# Stream must have written PASS/FAIL file .
+		local currentDiagnosticIteration_outputLOOP_wait=0
+		( _messagePlain_nominal '\/\/\/\/\/ \/\/\/  outputLOOP: WAIT:  P_A_S_S/F_A_I_L  ... currentPart='"$currentPart"' currentStream='"$currentStream" >&2 ) > /dev/null
+		while ! [[ -e "$scriptAbsoluteFolder"/$(_axelTmp).busy ]] || ( ! [[ -e "$scriptAbsoluteFolder"/$(_axelTmp).PASS ]] && ! [[ -e "$scriptAbsoluteFolder"/$(_axelTmp).FAIL ]] )
+		do
+			sleep 1

-# DANGER: CAUTION: WARNING: Calls '_git_shallow'.
-_git_shallow-ubiquitous() {
-	[[ "$1" != "true" ]] && exit 1
-
-	_git_shallow 'git@github.com:mirage335/ubiquitous_bash.git' '_lib/ubiquitous_bash'
+			let currentDiagnosticIteration_outputLOOP_wait=currentDiagnosticIteration_outputLOOP_wait+1
+			if [[ "$currentDiagnosticIteration_outputLOOP_wait" -gt 15 ]]
+			then
+				currentDiagnosticIteration_outputLOOP_wait=0
+				( _messagePlain_probe "diagnostic_outputLOOP_wait: pid: ""$!" >&2 ) > /dev/null
+				# ATTRIBUTION-AI: ChatGPT 4.5-preview 2025-03-29
+				#( echo "diagnostic_outputLOOP_wait: checking filenames exactly as seen by script: |$scriptAbsoluteFolder/$(_axelTmp).busy| and |$scriptAbsoluteFolder/$(_axelTmp).PASS|" >&2 ) > /dev/null
+				#( ls -l "$scriptAbsoluteFolder"/$(_axelTmp).* >&2 )
+				#stat "$scriptAbsoluteFolder"/$(_axelTmp).busy >&2 || ( echo 'diagnostic_outputLOOP_wait: '"stat busy - file truly doesn't exist at this name!" >&2 )
+				#stat "$scriptAbsoluteFolder"/$(_axelTmp).PASS >&2 || ( echo 'diagnostic_outputLOOP_wait: '"stat PASS - file truly doesn't exist at this name!" >&2 )
+			fi
+		done
+
+		( _messagePlain_nominal '\/\/\/\/\/ \/\/\/  outputLOOP: OUTPUT  ...  currentPart='"$currentPart"' currentStream='"$currentStream" >&2 ) > /dev/null
+		# ATTENTION: EXPERIMENT
+		#status=none
+		dd if="$scriptAbsoluteFolder"/$(_axelTmp) bs=1M
+		#cat "$scriptAbsoluteFolder"/$(_axelTmp)
+		#dd if="$scriptAbsoluteFolder"/$(_axelTmp) bs=1M | pv --rate-limit 100M 2>/dev/null
+		[[ -e "$scriptAbsoluteFolder"/$(_axelTmp).PASS ]] && currentSkip="download"
+		[[ -e "$scriptAbsoluteFolder"/$(_axelTmp).FAIL ]] && [[ "$currentSkip" != "skip" ]] && ( _messageError 'FAIL' >&2 ) > /dev/null && return 1
+
+		( _messagePlain_nominal '\/\/\/\/\/ \/\/\/  outputLOOP: DELETE  ...  currentPart='"$currentPart"' currentStream='"$currentStream" >&2 ) > /dev/null
+		#rm -f "$scriptAbsoluteFolder"/$(_axelTmp) > /dev/null 2>&1
+		_destroy_lock "$scriptAbsoluteFolder"/$(_axelTmp)
+		#rm -f "$scriptAbsoluteFolder"/$(_axelTmp).busy > /dev/null 2>&1
+		_destroy_lock "$scriptAbsoluteFolder"/$(_axelTmp).busy
+
+		#_destroy_lock "$scriptAbsoluteFolder"/$(_axelTmp).*
+		#_destroy_lock "$scriptAbsoluteFolder"/.m_axelTmp_"$currentStream"_"$currentAxelTmpFileUID".*
+
+		let currentStream=currentStream+1
+		[[ "$currentStream" -gt "$currentStream_max" ]] && currentStream="$currentStream_min"
+	done
+
+	true
 }
+_wget_githubRelease_join_sequence-parallel() {
+	local currentAbsoluteRepo="$1"
+	local currentReleaseLabel="$2"
+	local currentFile="$3"

-# DANGER: Not robust. May damage repository and/or submodules, as well as any history not remotely available, causing *severe* data loss.
-# CAUTION: Intended only for developers to correct a rare mistake of adding a non-shallow git submodule. No production use.
-# WARNING: Submodule path must NOT have trailing or preceeding slash!
-# "$1" == uri (eg. git@github.com:mirage335/ubiquitous_bash.git)
-# "$2" == path/to/submodule (eg. '_lib/ubiquitous_bash')
-_git_shallow() {
-	[[ "$1" == "" ]] && exit 1
-	[[ "$2" == "" ]] && exit 1
-	! [[ -e "$2" ]] && exit 1
-	! [[ -e "$scriptAbsoluteFolder"/"$2" ]] && exit 1
-	cd "$scriptAbsoluteFolder"
-	! [[ -e "$2" ]] && exit 1
-	! [[ -e "$scriptAbsoluteFolder"/"$2" ]] && exit 1
-
-
-	! [[ -e "$scriptAbsoluteFolder"/.gitmodules ]] && exit 1
-	! [[ -e "$scriptAbsoluteFolder"/.git/config ]] && exit 1
-
-	_start
-
-	# https://gist.github.com/myusuf3/7f645819ded92bda6677
-
-	# Remove the submodule entry from .git/config
-	git submodule deinit -f "$2"
+	local currentOutParameter="$4"
+	local currentOutFile="$5"

-	# Remove the submodule directory from the superproject's .git/modules directory
-	#rm -rf .git/modules/"$2"
-	export safeToDeleteGit="true"
-	_safeRMR "$scriptAbsoluteFolder"/.git/modules/"$2"
+	shift
+	shift
+	shift
+	if [[ "$currentOutParameter" == "-O" ]]
+	then
+		if [[ "$currentOutFile" != "-" ]]
+		then
+			( _messagePlain_bad 'bad: fail: unexpected: currentOutFile: NOT stdout' >&2 ) > /dev/null
+			#echo "1" > "$currentAxelTmpFile".FAIL
+			return 1
+		fi
+		shift
+		shift
+	fi

-	# Remove the entry in .gitmodules and remove the submodule directory located at path/to/submodule
-	git rm -f "$2"
-
-	git commit -m "WIP."
-
-
-	# https://stackoverflow.com/questions/2144406/how-to-make-shallow-git-submodules
-
-	git submodule add --depth 1 "$1" "$2"
-
-	git config -f .gitmodules submodule."$2".shallow true
+
+	#export currentAxelTmpFileUID="$(_uid 14)"
+	_axelTmp() {
+		echo .m_axelTmp_"$currentStream"_"$currentAxelTmpFileUID"
+	}
+	#local currentAxelTmpFile
+	#currentAxelTmpFile="$scriptAbsoluteFolder"/$(_axelTmp)
+
+	# Due to parallelism , only API rate limits, NOT download speeds, are a concern with larger number of retries.
+	_set_wget_githubRelease "$@"
+	#_set_wget_githubRelease-detect "$@"
+	#_set_wget_githubRelease-detect-parallel "$@"
+	local currentSkip="skip"

-	_messagePlain_request git commit -a -m "Draft."
-	_messagePlain_request git push
+	local currentStream_min=1
+	local currentStream_max=3
+	[[ "$FORCE_PARALLEL" != "" ]] && currentStream_max="$FORCE_PARALLEL"
+	[[ "$currentStream_max" -gt "$currentSkipPart" ]] && currentStream_max=$(( "$currentSkipPart" + 1 ))

-	_stop
-}
+	currentStream="$currentStream_min"
+	for currentPart in $(seq -f "%02g" 0 "$currentSkipPart" | sort -r)
+	do
+	( _messagePlain_nominal '\/\/\/\/\/ \/\/\/\/  downloadLOOP  ...  currentPart='"$currentPart"' currentStream='"$currentStream" >&2 ) > /dev/null
+	#( _messagePlain_probe_var currentPart >&2 ) > /dev/null
+	#( _messagePlain_probe_var currentStream >&2 ) > /dev/null

+		# Slot in use. Downloaded  "$scriptAbsoluteFolder"/$(_axelTmp)  file will be DELETED after use by calling process.
+		( _messagePlain_nominal '\/\/\/\/\/ \/\/\/  downloadLOOP: WAIT: BUSY  ...  currentPart='"$currentPart"' currentStream='"$currentStream" >&2 ) > /dev/null
+		while ( ls -1 "$scriptAbsoluteFolder"/$(_axelTmp) > /dev/null 2>&1 ) || ( ls -1 "$scriptAbsoluteFolder"/$(_axelTmp).busy > /dev/null 2>&1 )
+		do
+		( _messagePlain_nominal '\/\/\/\/\/ \/\/\/  downloadLOOP: WAIT: BUSY  ...  currentPart='"$currentPart"' currentStream='"$currentStream" >&2 ) > /dev/null
+			sleep 1
+		done

+		( _messagePlain_nominal '\/\/\/\/\/ \/\/\/  downloadLOOP: detect skip  ...  currentPart='"$currentPart"' currentStream='"$currentStream" >&2 ) > /dev/null
+		[[ -e "$scriptAbsoluteFolder"/$(_axelTmp).PASS ]] && _set_wget_githubRelease "$@" && currentSkip="download"
+		[[ -e "$scriptAbsoluteFolder"/$(_axelTmp).FAIL ]] && [[ "$currentSkip" != "skip" ]] && ( _messageError 'FAIL' >&2 ) > /dev/null && return 1

+		( _messagePlain_nominal '\/\/\/\/\/ \/\/\/  downloadLOOP: DELETE  ...  currentPart='"$currentPart"' currentStream='"$currentStream" >&2 ) > /dev/null
+		#rm -f "$scriptAbsoluteFolder"/$(_axelTmp).PASS > /dev/null 2>&1
+		_destroy_lock "$scriptAbsoluteFolder"/$(_axelTmp).PASS
+		#rm -f "$scriptAbsoluteFolder"/$(_axelTmp).FAIL > /dev/null 2>&1
+		_destroy_lock "$scriptAbsoluteFolder"/$(_axelTmp).FAIL

+		( _messagePlain_nominal '\/\/\/\/\/ \/\/\/  downloadLOOP: DELAY: stagger, Inter-Process Communication, _stop  ...  currentPart='"$currentPart"' currentStream='"$currentStream" >&2 ) > /dev/null
+		# Staggered Delay.
+		[[ "$currentPart" == "$currentSkipPart" ]] && sleep 2
+		[[ "$currentPart" != "$currentSkipPart" ]] && sleep 6
+		# Inter-Process Communication Delay.
+		# Prevents new download from starting before previous download process has done  rm -f "$currentAxelTmpFile"*  .
+		#  Beware that  rm  is inevitable or at least desirable - called by _stop() through trap, etc.
+		sleep 7
+
+		( _messagePlain_nominal '\/\/\/\/\/ \/\/\/  downloadLOOP: DOWNLOAD  ...  currentPart='"$currentPart"' currentStream='"$currentStream" >&2 ) > /dev/null
+		export currentAxelTmpFile="$scriptAbsoluteFolder"/$(_axelTmp)
+		if ls -1 "$currentAxelTmpFile"* > /dev/null 2>&1
+		then
+			( _messagePlain_bad 'bad: FAIL: currentAxelTmpFile*: EXISTS !' >&2 ) > /dev/null
+			echo "1" > "$currentAxelTmpFile".FAIL
+			_messageError 'FAIL' >&2
+			exit 1
+			return 1
+		fi
+		"$scriptAbsoluteLocation" _wget_githubRelease_procedure-join "$currentAbsoluteRepo" "$currentReleaseLabel" "$currentFile".part$(printf "%02g" "$currentPart") &
+		echo "$!" > "$scriptAbsoluteFolder"/$(_axelTmp).pid

-#####Program
+		# Stream must have written either in-progress download or PASS/FAIL file .
+		( _messagePlain_nominal '\/\/\/\/\/ \/\/\/  downloadLOOP: WAIT: BEGIN  ...  currentPart='"$currentPart"' currentStream='"$currentStream" >&2 ) > /dev/null
+		while ! ( ls -1 "$scriptAbsoluteFolder"/$(_axelTmp)* > /dev/null 2>&1 )
+		do
+		( _messagePlain_nominal '\/\/\/\/\/ \/\/\/  downloadLOOP: WAIT: BEGIN  ...  currentPart='"$currentPart"' currentStream='"$currentStream" >&2 ) > /dev/null
+			sleep 0.6
+		done

-_createBareGitRepo() {
-	mkdir -p "$bareRepoDir"
-	cd $bareRepoDir
-
-	git --bare init
-	git branch -M main
-
-	echo "-----"
-}
+		let currentStream=currentStream+1
+		[[ "$currentStream" -gt "$currentStream_max" ]] && currentStream="$currentStream_min"
+	done

+	( _messagePlain_nominal '\/\/\/\/\/ \/\/\/\/  download: DELETE' >&2 ) > /dev/null
+	for currentStream in $(seq "$currentStream_min" "$currentStream_max")
+	do
+		( _messagePlain_nominal '\/\/\/\/\/ \/\/\/  download: WAIT: BUSY  ...  currentStream='"$currentStream" >&2 ) > /dev/null
+		while ( ls -1 "$scriptAbsoluteFolder"/$(_axelTmp) > /dev/null 2>&1 ) || ( ls -1 "$scriptAbsoluteFolder"/$(_axelTmp).busy > /dev/null 2>&1 )
+		do
+		( _messagePlain_nominal '\/\/\/\/\/ \/\/\/  download: WAIT: BUSY  ...  currentStream='"$currentStream" >&2 ) > /dev/null
+			sleep 1
+		done

-_setBareGitRepo() {
-	cd "$repoDir"
-
-	git remote rm origin
-	git remote add origin "$bareRepoDir"
-	git push --set-upstream origin master
-
-	# WARNING: TODO: Experimental, requires further testing. Use branch 'main' if extant.
-	git push --set-upstream origin main
-
-	echo "-----"
-}
+		( _messagePlain_nominal '\/\/\/\/\/ \/\/\/  download: DELETE ...  currentStream='"$currentStream" >&2 ) > /dev/null
+		#rm -f "$scriptAbsoluteFolder"/$(_axelTmp).PASS > /dev/null 2>&1
+		_destroy_lock "$scriptAbsoluteFolder"/$(_axelTmp).PASS
+		#rm -f "$scriptAbsoluteFolder"/$(_axelTmp).FAIL > /dev/null 2>&1
+		_destroy_lock "$scriptAbsoluteFolder"/$(_axelTmp).FAIL
+	done

-_showGitRepoURI() {
-	echo git clone --recursive "$bareRepoAbsoluteDir" "$repoName"
-	echo git clone --recursive ssh://"$USER"@"$repoHostname""$repoPort""$bareRepoAbsoluteDir" "$repoName"
-
-
-	#if [[ "$repoHostname" != "" ]]
-	#then
-	#	clear
-	#	echo ssh://"$USER"@"$repoHostname""$repoPort""$bareRepoAbsoluteDir"
-	#	sleep 15
-	#fi
+	( _messagePlain_nominal '\/\/\/\/\/ \/\/\/\/  download: WAIT PID  ...  currentPart='"$currentPart"' currentStream='"$currentStream" >&2 ) > /dev/null
+	for currentStream in $(seq "$currentStream_min" "$currentStream_max")
+	do
+		[[ -e "$scriptAbsoluteFolder"/$(_axelTmp).pid ]] && _pauseForProcess $(cat "$scriptAbsoluteFolder"/$(_axelTmp).pid) > /dev/null
+	done
+	wait >&2
+
+	true
 }
+_wget_githubRelease_procedure-join() {
+	( _messagePlain_probe_safe _wget_githubRelease_procedure-join "$@" >&2 ) > /dev/null

-_gitBareSequence() {
-	_gitInfo
-
-	if [[ -e "$bareRepoDir" ]]
+	local currentAbsoluteRepo="$1"
+	local currentReleaseLabel="$2"
+	local currentFile="$3"
+
+	local currentOutParameter="$4"
+	local currentOutFile="$5"
+
+	shift
+	shift
+	shift
+	if [[ "$currentOutParameter" == "-O" ]]
 	then
-		_showGitRepoURI
-		return 2
+		if [[ "$currentOutFile" != "-" ]]
+		then
+			( _messagePlain_bad 'bad: fail: unexpected: currentOutFile: NOT stdout' >&2 ) > /dev/null
+			echo "1" > "$currentAxelTmpFile".FAIL
+			return 1
+		fi
+		shift
+		shift
 	fi
-
-	if ! [[ -e "$repoDir"/.git ]]
+
+	#local currentAxelTmpFileRelative=.m_axelTmp_"$currentStream"_$(_uid 14)
+	#local currentAxelTmpFile="$scriptAbsoluteFolder"/"$currentAxelTmpFileRelative"
+
+	local currentExitStatus
+
+	echo -n > "$currentAxelTmpFile".busy
+
+	# ATTENTION: EXPERIMENT
+	_wget_githubRelease_procedure "$currentAbsoluteRepo" "$currentReleaseLabel" "$currentFile" -O "$currentAxelTmpFile" "$@"
+    #dd if=/dev/zero bs=1M count=1500 > "$currentAxelTmpFile"
+	#echo "$currentFile" >> "$currentAxelTmpFile"
+    #dd if=/dev/urandom bs=1M count=1500 | pv --rate-limit 300M 2>/dev/null > "$currentAxelTmpFile"
+	currentExitStatus="$?"
+
+	# Inter-Process Communication Delay
+	# Essentially a 'minimum download time' .
+	sleep 7
+
+	[[ "$currentExitStatus" == "0" ]] && echo "$currentExitStatus" > "$currentAxelTmpFile".PASS
+	if [[ "$currentExitStatus" != "0" ]]
 	then
-		return 1
+		echo -n > "$currentAxelTmpFile"
+		echo "$currentExitStatus" > "$currentAxelTmpFile".FAIL
 	fi
-
-	_createBareGitRepo
-
-	_setBareGitRepo
-
-	_showGitRepoURI
-
-}

-_gitBare() {
-
-	"$scriptAbsoluteLocation" _gitBareSequence
-
+    while [[ -e "$currentAxelTmpFile" ]] || [[ -e "$currentAxelTmpFile".busy ]] || [[ -e "$currentAxelTmpFile".PASS ]] || [[ -e "$currentAxelTmpFile".FAIL ]]
+    do
+        sleep 1
+    done
+
+	# WARNING: Already inevitable (due to _stop , etc).
+    #[[ "$currentAxelTmpFile" != "" ]] && rm -f "$currentAxelTmpFile".*
+	[[ "$currentAxelTmpFile" != "" ]] && _destroy_lock "$currentAxelTmpFile".*
+
+    #unset currentAxelTmpFile
+
+    [[ "$currentExitStatus" == "0" ]] && return 0
+    return "$currentExitStatus"
 }




-_self_gitMad_procedure() {
-	local functionEntryPWD
-	functionEntryPWD="$PWD"

-	cd "$scriptAbsoluteFolder"
-	_gitMad
-
-	cd "$functionEntryPWD"
-}
-_self_gitMad() {
-	"$scriptAbsoluteLocation" _self_gitMad_procedure "$@"
-}
-# https://stackoverflow.com/questions/1580596/how-do-i-make-git-ignore-file-mode-chmod-changes
-_gitMad() {
-	git config core.fileMode false
-	git submodule foreach git config core.fileMode false
-	git submodule foreach git submodule foreach git config core.fileMode false
-	git submodule foreach git submodule foreach git submodule foreach git config core.fileMode false
-	git submodule foreach git submodule foreach git submodule foreach git submodule foreach git config core.fileMode false
-	git submodule foreach git submodule foreach git submodule foreach git submodule foreach git submodule foreach git config core.fileMode false
-	git submodule foreach git submodule foreach git submodule foreach git submodule foreach git submodule foreach git submodule foreach git config core.fileMode false
-	git submodule foreach git submodule foreach git submodule foreach git submodule foreach git submodule foreach git submodule foreach git submodule foreach git config core.fileMode false
-	git submodule foreach git submodule foreach git submodule foreach git submodule foreach git submodule foreach git submodule foreach git submodule foreach git submodule foreach git config core.fileMode false
-	git submodule foreach git submodule foreach git submodule foreach git submodule foreach git submodule foreach git submodule foreach git submodule foreach git submodule foreach git submodule foreach git config core.fileMode false
-	git submodule foreach git submodule foreach git submodule foreach git submodule foreach git submodule foreach git submodule foreach git submodule foreach git submodule foreach git submodule foreach git submodule foreach git config core.fileMode false
-}


-_gitBest_detect_github_procedure() {
-	[[ "$current_gitBest_source_GitHub" == "FAIL" ]] && export current_gitBest_source_GitHub=""
-	[[ "$current_gitBest_source_GitHub" != "" ]] && return
-
-	_messagePlain_nominal 'init: _gitBest_detect_github_procedure'
-
-	if [[ "$current_gitBest_source_GitHub" == "" ]]
-	then
-		_messagePlain_request 'performance: export current_gitBest_source_GitHub=$("'"$scriptAbsoluteLocation"'" _gitBest_detect_github_sequence | tail -n1)'
-
-		if [[ -e "$HOME"/core ]] && [[ "$gitBestNoCore" != "true" ]]
-		then
-			export current_gitBest_source_GitHub="github_core"
-		fi
-
-		local currentSSHoutput
-		if ( [[ -e "$HOME"/.ssh/id_rsa ]] || [[ -e "$HOME"/.ssh/config ]] || ( [[ ! -e "$HOME"/.ssh/id_ed25519_sk ]] && [[ ! -e "$HOME"/.ssh/ecdsa-sk ]] ) ) && currentSSHoutput=$(ssh -o StrictHostKeyChecking=no -o Compression=yes -o ConnectionAttempts=3 -o ServerAliveInterval=6 -o ServerAliveCountMax=9 -o ConnectTimeout="$netTimeout" -o PubkeyAuthentication=yes -o PasswordAuthentication=no git@github.com 2>&1 ; true) && _safeEcho_newline "$currentSSHoutput" | grep 'successfully authenticated'
-		then
-			export current_gitBest_source_GitHub="github_ssh"
-			return
-		fi
-		_safeEcho_newline "$currentSSHoutput"
-
-		#if _checkPort github.com 443
-		if wget -qO- https://github.com > /dev/null
-		then
-			export current_gitBest_source_GitHub="github_https"
-			return
-		fi
-
-
-		[[ "$current_gitBest_source_GitHub" == "" ]] && export current_gitBest_source_GitHub="FAIL"
-		return 1
-	fi
-	return 0
-}
-_gitBest_detect_github_sequence() {
-	_gitBest_detect_github_procedure "$@"
-	_messagePlain_probe_var current_gitBest_source_GitHub
-	echo "$current_gitBest_source_GitHub"
-}
-_gitBest_detect_github() {
-	local currentOutput
-	currentOutput=$("$scriptAbsoluteLocation" _gitBest_detect_github_sequence "$@")
-	_safeEcho_newline "$currentOutput"
-	export current_gitBest_source_GitHub=$(_safeEcho_newline "$currentOutput" | tail -n 1)
-	[[ "$current_gitBest_source_GitHub" != "github_"* ]] && export current_gitBest_source_GitHub="FAIL"
-
-	return 0
-}
-_gitBest_detect() {
-	_gitBest_detect_github "$@"
-}



-_gitBest_override_config_insteadOf-core() {
-	git config --global url."file://""$realHome""/core/infrastructure/""$1".insteadOf git@github.com:mirage335/"$1".git git@github.com:mirage335/"$1"
-}
-_gitBest_override_config_insteadOf-core--colossus() {
-	git config --global url."file://""$realHome""/core/infrastructure/""$1".insteadOf git@github.com:mirage335-colossus/"$1".git git@github.com:mirage335-colossus/"$1"
+_warn_githubRelease_FORCE_WGET() {
+    ( _messagePlain_warn 'warn: WARNING: FORCE_WGET=true' >&2 ; echo 'FORCE_WGET is a workaround. Only expected FORCE_WGET uses: low RAM , cloud testing/diagnostics .' >&2  ) > /dev/null
+    return 0
 }
-_gitBest_override_config_insteadOf-core--gizmos() {
-	git config --global url."file://""$realHome""/core/infrastructure/""$1".insteadOf git@github.com:mirage335-gizmos/"$1".git git@github.com:mirage335-gizmos/"$1"
+_bad_fail_githubRelease_currentExitStatus() {
+    ( _messagePlain_bad 'fail: wget_githubRelease: currentExitStatus: '"$currentAbsoluteRepo"' '"$currentReleaseLabel"' '"$currentFile" >&2 ) > /dev/null
+    return 0
 }
-_gitBest_override_config_insteadOf-core--distllc() {
-	git config --global url."file://""$realHome""/core/infrastructure/""$1".insteadOf git@github.com:soaringDistributions/"$1".git git@github.com:soaringDistributions/"$1"
+_bad_fail_githubRelease_missing() {
+    ( _messagePlain_bad 'fail: wget_githubRelease: missing: '"$currentAbsoluteRepo"' '"$currentReleaseLabel"' '"$currentFile" >&2 ) > /dev/null
+    return 0
 }


-_gitBest_override_github-github_core() {
-	_gitBest_override_config_insteadOf-core--colossus ubiquitous_bash
-	_gitBest_override_config_insteadOf-core--colossus extendedInterface
-
-	_gitBest_override_config_insteadOf-core--gizmos flightDeck
-	_gitBest_override_config_insteadOf-core--gizmos kinematicBase-large

-	_gitBest_override_config_insteadOf-core--distllc ubDistBuild
-	_gitBest_override_config_insteadOf-core--distllc ubDistFetch
-
-	_gitBest_override_config_insteadOf-core mirage335_documents
-	_gitBest_override_config_insteadOf-core mirage335GizmoScience

-	_gitBest_override_config_insteadOf-core scriptedIllustrator
-	_gitBest_override_config_insteadOf-core arduinoUbiquitous
-
-	_gitBest_override_config_insteadOf-core BOM_designer
-	_gitBest_override_config_insteadOf-core CoreAutoSSH
-	_gitBest_override_config_insteadOf-core coreoracle
-	_gitBest_override_config_insteadOf-core flipKey
-	_gitBest_override_config_insteadOf-core freecad-assembly2
-	_gitBest_override_config_insteadOf-core Freerouting
-	_gitBest_override_config_insteadOf-core gEDA_designer
-	_gitBest_override_config_insteadOf-core metaBus
-	_gitBest_override_config_insteadOf-core PanelBoard
-	_gitBest_override_config_insteadOf-core PatchRap
-	_gitBest_override_config_insteadOf-core PatchRap_LulzBot
-	_gitBest_override_config_insteadOf-core PatchRap_to_CNC
-	_gitBest_override_config_insteadOf-core pcb-ioAutorouter
-	_gitBest_override_config_insteadOf-core RigidTable
-	_gitBest_override_config_insteadOf-core SigBlockly-mod
-	_gitBest_override_config_insteadOf-core stepperTester
-	_gitBest_override_config_insteadOf-core TazIntermediate
-	_gitBest_override_config_insteadOf-core translate2geda
-	_gitBest_override_config_insteadOf-core webClient
-	_gitBest_override_config_insteadOf-core zipTiePanel
-}
-_gitBest_override_github-github_https() {
-	# && [[ "$1" == "push" ]]
-	if [[ "$INPUT_GITHUB_TOKEN" == "" ]]
-	then
-		git config --global url."https://github.com/".insteadOf git@github.com:
-	elif [[ "$INPUT_GITHUB_TOKEN" != "" ]]
-	then
-		git config --global url."https://""$INPUT_GITHUB_TOKEN""@github.com/".insteadOf git@github.com:
-	fi
-}


+_vector_wget_githubRelease-URL-gh() {
+    local currentReleaseLabel="build"
+
+    [[ $(
+cat <<'CZXWXcRMTo8EmM8i4d' | _wget_githubRelease_procedure-address-gh-awk "" "$currentReleaseLabel" "" 2> /dev/null
+TITLE  TYPE    TAG NAME             PUBLISHED
+build  Latest  build-1002-1  about 1 days ago
+build          build-1001-1  about 2 days ago
+CZXWXcRMTo8EmM8i4d
+) == "build-1002-1
+build-1001-1" ]] || ( _messagePlain_bad 'fail: bad: _wget_githubRelease_procedure-address-gh-awk' && _messageFAIL )

-_gitBest_override_github() {
-	_messagePlain_nominal 'init: _gitBest_override_github'
-
-	cat "$realHome"/.gitconfig >> "$HOME"/.gitconfig
-
-	if [[ "$current_gitBest_source_GitHub" == "github_core" ]]
-	then
-		_gitBest_override_github-github_core
-	fi
-
-	if [[ "$current_gitBest_source_GitHub" == "github_https" ]]
-	then
-		_gitBest_override_github-github_https "$@"
-	fi
-
-	if [[ "$current_gitBest_source_GitHub" == "github_ssh" ]]
-	then
-		_messagePlain_good 'good: preferred: github_ssh'
-	fi
-
-	if [[ "$current_gitBest_source_GitHub" == "FAIL" ]]
-	then
-		_messageError 'FAIL: missing: GitHub'
-		_stop 1
-	fi
 	return 0
 }

@@ -27651,196 +34046,185 @@ _gitBest_override_github() {



-_gitBest_sequence() {
-	_messagePlain_nominal 'init: _gitBest_sequence'
-
-	_start scriptLocal_mkdir_disable
-
-	export realHome="$HOME"
-	export HOME="$safeTmp"/special_fakeHome
-	mkdir -p "$HOME"
-
-	_messagePlain_probe_var current_gitBest_source_GitHub
-	_messagePlain_probe_var HOME
-
-
-	_gitBest_override_github "$@"
-
-	if ! [[ -e "$HOME"/.gitconfig ]]
-	then
-		_messagePlain_good 'good: write: overrides: none'
-	else
-		echo
-		echo
-		cat "$HOME"/.gitconfig
-		echo
-		echo
-	fi
-
-
-	_messagePlain_nominal 'init: git'
-
-	git "$@"
-
-
-	_stop "$?"
-}
-
-_gitBest() {
-	_messageNormal 'init: _gitBest'
-
-	_gitBest_detect "$@"
-
-	"$scriptAbsoluteLocation" _gitBest_sequence "$@"
-}


-_test_gitBest() {
-	_wantGetDep stty
-	_wantGetDep ssh
-
-	_wantGetDep git
-
-	#_wantGetDep nmap
-	#_wantGetDep curl
-	#_wantGetDep wget
-}





+# WARNING: No production use. Non-essential.
+# May be used nearly interchangeably in place of 'wget_githubRelease_internal' as an alternative to 'releaseLabel' downloads within 'build.yml, 'zCustom.yml', 'zUpgrade.yml', etc, GitHub Actions workflow builds (ie. internally downloading the ingredient, beforeBoot, etc, disk image, specifically for the currentTag, rather than the latest matching the 'build' label). Not regarded as production use since non-concurrent use of the 'releaseLabel' download functions is considered the production functions, as these have commonality with the functions tested by end-users over the vagarities of internet connections, and are the first functions maintained with any workarounds, etc, as needed.
+#  ATTENTION: This definition of 'no production use', is consistent with the use of that phrase throughout 'ubiquitous_bash'. Production use of these functions, can be tolerated, but is NOT guaranteed. Best practice when using such 'no production use' functions in production scripting, is to leave a commented out, but adequately tested, alternative use of a function that is guaranteed, to quickly change this back if needed.
+#
+# Downloads single files through GitHub API by unique tag (instead of label).
+#
+# Only necessary for 'analysis' - downloading currentTag log files, comparing to log files from tags of previous releases.

-# CAUTION: This file is very necessarily part of 'rotten' . Do NOT move functions or rename to other files without updating the build shellcode for 'rotten' !
+# CAUTION: NOT included in 'rotten' .
+# May depend on functions from 'wget_githubRelease_internal.sh', NOT vice-versa .

-# Refactored from code which was very robust with fast ISP, however often failed with slower ISP, as explained by ChatGPT due to AWS S3 temporary link expiration.
-# See "_ref/wget_githubRelease_internal-OBSOLETE.sh" for original code, which due to the more iterative development process at the time, may be more reliable in untested cases.

-# WARNING: May be untested.

-# CAUTION: WARNING: Unusually, inheritance of local variables in procedure functions is relied upon. Theoretically, this has been long tested by 'ubiquitous_bash.sh _test' .
-#"$api_address_type"
-#"$currentStream"
-#"$currentAxelTmpFileRelative" "$currentAxelTmpFile"
-#
-#"$currentAbsoluteRepo"' '"$currentReleaseLabel"' '"$currentFile"
-#"$currentOutFile"

-# WARNING: CAUTION: Many functions rely on emitting to standard output . Experiment/diagnose by copying code to override with 'ops.sh' . CAUTION: Be very careful enabling or using diagnostic output to stderr, as stderr may also be redirected by calling functions, terminal may not be present, etc.
-#( echo x >&2 ) > /dev/null
-#_messagePlain_probe_var page >&2 | cat /dev/null
-#_messagePlain_probe_safe "currentAPI_URL= ""$currentAPI_URL" >&2 | cat /dev/null
-# WARNING: Limit stderr pollution for log (including CI logs) and terminal readability , using 'tail' .
-#( cat ubiquitous_bash.sh >&2 ) 2> >(tail -n 10 >&2) | tail -n 10
-#( set -o pipefail ; false | cat ubiquitous_bash.sh >&2 ) 2> >(tail -n 10 >&2) | cat > /dev/null
-#( set -o pipefail ; false 2> >(tail -n 10 >&2) | cat > /dev/null )

-# DANGER: Use _messagePlain_probe_safe , _safeEcho , _safeEcho_newline , etc .

-# CAUTION: ATTENTION: Uncommented lines add to ALL 'compiled' bash shell scripts - INCLUDING rotten_compressed.sh !
-# Thus, it may be preferable to keep example code as a separate line commented at the beginning of that line, rather than a comment character after code on the same line .



+#env currentRepository='soaringDistributions/ubDistBuild' currentReleaseTag='build-13932580400-9999' ./ubiquitous_bash.sh _wget_githubRelease-fromTag-analysisReport-fetch 20 lsmodReport binReport coreReport dpkg
+#env currentRepository='mirage335-colossus/ubiquitous_bash' currentReleaseTag='build-13917942290-9999' ./ubiquitous_bash.sh _wget_githubRelease-fromTag-analysisReport-fetch 20 'ubcp-binReport-UNIX_Linux'
+#env:
+#  currentRepository: ${{ github.repository }}
+#  currentReleaseTag: build-${{ github.run_id }}-9999
+#  GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
+_wget_githubRelease-fromTag-analysisReport-fetch() {
+    local currentLimit
+    currentLimit="$1"
+    shift

+    mkdir -p "$scriptLocal"/analysisTmp

-# ATTENTION: 'MANDATORY_HASH == true' claim requirement can be imposed without any important effect on reliability or performance.
-# In practice, such multi-part-per-file download programs as 'aria2c' may or may not have any worse integrity safety concerns than other download programs.
-# NOTICE: Track record from historically imposing MANDATORY_HASH has been long enough to establish excellent confidence for imposing the requirement for this safety claim again without serious issue if necessary.
-# https://www.cvedetails.com/vulnerability-list/vendor_id-12682/Haxx.html
-#  'Haxx'
-# https://www.cvedetails.com/vulnerability-list/vendor_id-3385/Wget.html
-# https://www.cvedetails.com/vulnerability-list/vendor_id-19755/product_id-53327/Aria2-Project-Aria2.html
-# https://www.cvedetails.com/vulnerability-list/vendor_id-2842/Axel.html
-# ATTENTION: DANGER: Client downloading function explicitly sets 'MANDATORY_HASH == true' to claim resulting file EITHER will be checked by external hash before production use OR file is downloaded within an internal safer network (ie. GitHub Actions) using integrity guarded computers (ie. GitHub Runners). Potentially less integrity-safe downloading as multi-part-per-file parallel 'axel' 'download accelerator' style downloading can be limited to require a safety check for the MANDATORY_HASH claim.
-# NOTICE: Imposing safety check for MANDATORY_HASH claim has long track record and no known use cases combine BOTH the jittery contentious internet connections over which multi-part-per-file downloading may or may not be more reliable, AND cannot test build steps without download large files to cycle the entire build completely. That is to say, ONLY CI environments would be usefully faster from not requiring a MANDATORY_HASH claim, yet CI environments can already make an integrity claim relevant for MANDATORY_HASH, and CI environments usually have high-quality internet connections not needing complex trickery to improve download reliability/speed.
-#[[ "$FORCE_AXEL" != "" ]] && ( [[ "$MANDATORY_HASH" == "true" ]] )
+    local current_reportFiles_list
+    current_reportFiles_list=()

+    current_reportFiles_list=( "$@" )

+    local current_reportFile

-#export FORCE_DIRECT="true"
-#export FORCE_WGET="true"
-#export FORCE_AXEL="4"
+    #for current_reportFile in "${current_reportFiles_list[@]}"; do
+        #_wget_githubRelease-fromTag-fetchReport "$currentRepository" "$currentReleaseTag" "$current_reportFile" > "$scriptLocal"/analysisTmp/"$current_reportFile"
+    #done

-# Actually buffers files in progress behind completed files, in addition to downloading over multiple connections. Streaming without buffer underrun (ie. directly to packetDisc, ie. directly to optical disc) regardless of internet connection quality may require such buffer.
-#export FORCE_PARALLEL="3"
+    ! _wget_githubRelease-releasesTags "$currentRepository" "$currentLimit" | tr -dc 'a-zA-Z0-9\-_.:\n' > "$scriptLocal"/analysisTmp/releasesTags && _messageFAIL
+
+    for current_reportFile in "${current_reportFiles_list[@]}"; do
+        for current_reviewReleaseTag in $(cat "$scriptLocal"/analysisTmp/releasesTags); do
+            # Download the (eg. binReport) report file for this release
+            _wget_githubRelease-fromTag-fetchReport "$currentRepository" "$current_reviewReleaseTag" "$current_reportFile" --no-fail > "$scriptLocal"/analysisTmp/"$current_reportFile"-"$current_reviewReleaseTag"
+        done
+    done

-# Already default. FORCE_BUFFER="true" implies FORCE_PARALLEL=3 or similar and sets FORCE_DIRECT="false". FORCE_BUFFER="false" implies and sets FORCE_DIRECT="true" .
-#FORCE_BUFFER="true"
+    if [[ "$currentReleaseTag" != "" ]]
+    then
+        _wget_githubRelease-fromTag-analysisReport-select "${current_reportFiles_list[@]}"
+        return
+    fi
+    return 0
+}

-#export GH_TOKEN="..."
+#./ubiquitous_bash.sh _wget_githubRelease-fromTag-analysisReport-select 'ubcp-binReport-UNIX_Linux'
+#env:
+#  currentReleaseTag: build-${{ github.run_id }}-9999
+_wget_githubRelease-fromTag-analysisReport-select() {
+    mkdir -p "$scriptLocal"/analysisTmp

+    local current_reportFiles_list
+    current_reportFiles_list=()

+    current_reportFiles_list=( "$@" )

+    local current_reportFile

+    if [[ "$currentReleaseTag" == "" ]]
+    then
+        ( echo 'FAIL: missing: currentReleaseTag' >&2 ) > /dev/null
+        _messageFAIL
+    fi
+
+    for current_reportFile in "${current_reportFiles_list[@]}"; do
+        ( _messagePlain_probe cat "$scriptLocal"/analysisTmp/"$current_reportFile"-"$currentReleaseTag" > "$scriptLocal"/analysisTmp/"$current_reportFile" >&2 ) > /dev/null
+        if ! cat "$scriptLocal"/analysisTmp/"$current_reportFile"-"$currentReleaseTag" > "$scriptLocal"/analysisTmp/"$current_reportFile"
+        then
+            _messageFAIL
+        fi
+    done
+    return 0
+}

-#_get_vmImg_ubDistBuild_sequence
-#export MANDATORY_HASH="true"
-# write file
-#_wget_githubRelease_join-stdout "soaringDistributions/ubDistBuild" "$releaseLabel" "package_image.tar.flx" | _get_extract_ubDistBuild-tar xv --overwrite
-# write disk (eg. '/dev/sda')
-#_wget_githubRelease_join-stdout "soaringDistributions/ubDistBuild" "$releaseLabel" "package_image.tar.flx" | _get_extract_ubDistBuild-tar --extract ./vm.img --to-stdout | sudo -n dd of="$3" bs=1M status=progress
-#
-#export MANDATORY_HASH=
-#unset MANDATORY_HASH
-#_wget_githubRelease-stdout "soaringDistributions/ubDistBuild" "$releaseLabel" "_hash-ubdist.txt"

+#env currentRepository='mirage335-colossus/ubiquitous_bash' currentReleaseTag='build-13917942290-9999' ./ubiquitous_bash.sh _wget_githubRelease-fromTag-analysisReport-analysis 65 lsmodReport binReport coreReport dpkg
+#env currentRepository='mirage335-colossus/ubiquitous_bash' currentReleaseTag='build-13917942290-9999' ./ubiquitous_bash.sh _wget_githubRelease-fromTag-analysisReport-analysis 65 'ubcp-binReport-UNIX_Linux'
+#env:
+#  currentReleaseTag: build-${{ github.run_id }}-9999
+_wget_githubRelease-fromTag-analysisReport-analysis() {
+    local currentLimit
+    currentLimit="$1"
+    shift

-#_get_vmImg_beforeBoot_ubDistBuild_sequence
-#export MANDATORY_HASH="true"
-# write file
-#_wget_githubRelease_join-stdout "soaringDistributions/ubDistBuild" "$releaseLabel" "package_image_beforeBoot.tar.flx" | _get_extract_ubDistBuild-tar xv --overwrite
-# write disk (eg. '/dev/sda')
-#_wget_githubRelease_join-stdout "soaringDistributions/ubDistBuild" "$releaseLabel" "package_image_beforeBoot.tar.flx" | _get_extract_ubDistBuild-tar --extract ./vm.img --to-stdout | sudo -n dd of="$3" bs=1M status=progress
-#
-#export MANDATORY_HASH=
-#unset MANDATORY_HASH
-#_wget_githubRelease-stdout "soaringDistributions/ubDistBuild" "$releaseLabel" "_hash-ubdist_beforeBoot.txt"
+    mkdir -p "$scriptLocal"/analysisTmp

+    local current_reportFiles_list
+    current_reportFiles_list=()

-#_get_vmImg_ubDistBuild-live_sequence
-#export MANDATORY_HASH="true"
-# write file
-#_wget_githubRelease_join "soaringDistributions/ubDistBuild" "$releaseLabel" "vm-live.iso"
-#currentHash_bytes=$(_wget_githubRelease-stdout "soaringDistributions/ubDistBuild" "$releaseLabel" "_hash-ubdist.txt" | head -n 14 | tail -n 1 | sed 's/^.*count=$(bc <<< '"'"'//' | cut -f1 -d\  )
-# write packetDisc (eg. '/dev/sr0', '/dev/dvd'*, '/dev/cdrom'*)
-#_wget_githubRelease_join-stdout "soaringDistributions/ubDistBuild" "$releaseLabel" "vm-live.iso" | tee >(openssl dgst -whirlpool -binary | xxd -p -c 256 >> "$scriptLocal"/hash-download.txt) ; dd if=/dev/zero bs=2048 count=$(bc <<< '1000000000000 / 2048' ) ) | sudo -n growisofs -speed=3 -dvd-compat -Z "$3"=/dev/stdin -use-the-force-luke=notray -use-the-force-luke=spare:min -use-the-force-luke=bufsize:128m
-# write disk (eg. '/dev/sda')
-#_wget_githubRelease_join-stdout "soaringDistributions/ubDistBuild" "$releaseLabel" "vm-live.iso" | tee >(openssl dgst -whirlpool -binary | xxd -p -c 256 >> "$scriptLocal"/hash-download.txt) ; dd if=/dev/zero bs=2048 count=$(bc <<< '1000000000000 / 2048' ) ) | sudo -n dd of="$3" bs=1M status=progress
-#
-#export MANDATORY_HASH=
-#unset MANDATORY_HASH
-#_wget_githubRelease-stdout "soaringDistributions/ubDistBuild" "$releaseLabel" "_hash-ubdist.txt"
+    current_reportFiles_list=( "$@" )

+    local current_reportFile
+
+	# Analysis - for each report file, compare for all tags.
+    #for current_reportFile in "${current_reportFiles_list[@]}"; do
+        #rm -f "$scriptLocal"/analysisTmp/missing-"$current_reportFile"
+        #for current_reviewReleaseTag in $(cat "$scriptLocal"/analysisTmp/releasesTags); do
+            ## Compare the list of binaries, etc, in this release to the current release
+            #if [ "$current_reviewReleaseTag" != "$currentReleaseTag" ]; then
+                #echo | tee -a "$scriptLocal"/analysisTmp/missing-"$current_reportFile"
+                #echo 'Items (ie. '"$current_reportFile"') in '"$current_reviewReleaseTag"' but not in currentRelease '"$currentReleaseTag"':' | tee -a "$scriptLocal"/analysisTmp/missing-"$current_reportFile"
+                ##| tee -a "$scriptLocal"/analysisTmp/missing-"$current_reportFile"
+                #comm -23 <(sort "$scriptLocal"/analysisTmp/"$current_reportFile"-"$current_reviewReleaseTag") <(sort "$scriptLocal"/analysisTmp/"$current_reportFile") > "$scriptLocal"/analysisTmp/missing-"$current_reportFile".tmp
+                #cat "$scriptLocal"/analysisTmp/missing-"$current_reportFile".tmp | head -n "$currentLimit"
+                #cat "$scriptLocal"/analysisTmp/missing-"$current_reportFile".tmp >> "$scriptLocal"/analysisTmp/missing-"$current_reportFile"
+                #rm -f "$scriptLocal"/analysisTmp/missing-"$current_reportFile".tmp
+            #fi
+        #done
+    #done

-#_get_vmImg_ubDistBuild-rootfs_sequence
-#export MANDATORY_HASH="true"
-#_wget_githubRelease_join-stdout "soaringDistributions/ubDistBuild" "$releaseLabel" "package_rootfs.tar.flx" | lz4 -d -c > ./package_rootfs.tar
-#
-#export MANDATORY_HASH=
-#unset MANDATORY_HASH
-#_wget_githubRelease-stdout "soaringDistributions/ubDistBuild" "$releaseLabel" "_hash-ubdist.txt"

+	# Analysis - for each tag, compare all report files.
+	#  More human readable stdout - shows all differences between current version and other tagged version , one tagged version at a time.
+	# WARNING: Selected "$scriptLocal"/analysisTmp/"$current_reportFile" file is used directly, rather than "$scriptLocal"/analysisTmp/"$current_reportFile"-"$currentReleaseTag" , for compatibility with analysis solely for more rapid diagnostics which will not be uploaded (ie. 'ubDistBuild' 'build-analysis-beforeBoot').
+	for current_reportFile in "${current_reportFiles_list[@]}"; do
+		rm -f "$scriptLocal"/analysisTmp/missing-"$current_reportFile"
+	done
+    for current_reviewReleaseTag in $(cat "$scriptLocal"/analysisTmp/releasesTags); do
+    	for current_reportFile in "${current_reportFiles_list[@]}"; do
+			 if [ "$current_reviewReleaseTag" != "$currentReleaseTag" ]; then

+			 	echo | tee -a "$scriptLocal"/analysisTmp/missing-"$current_reportFile"
+				echo 'Items (ie. '"$current_reportFile"') in '"$current_reviewReleaseTag"' but not in currentRelease '"$currentReleaseTag"':' | tee -a "$scriptLocal"/analysisTmp/missing-"$current_reportFile"
+
+                #| tee -a "$scriptLocal"/analysisTmp/missing-"$current_reportFile"
+                comm -23 <(sort "$scriptLocal"/analysisTmp/"$current_reportFile"-"$current_reviewReleaseTag") <(sort "$scriptLocal"/analysisTmp/"$current_reportFile") > "$scriptLocal"/analysisTmp/missing-"$current_reportFile".tmp
+                cat "$scriptLocal"/analysisTmp/missing-"$current_reportFile".tmp | head -n "$currentLimit"
+                cat "$scriptLocal"/analysisTmp/missing-"$current_reportFile".tmp >> "$scriptLocal"/analysisTmp/missing-"$current_reportFile"
+                rm -f "$scriptLocal"/analysisTmp/missing-"$current_reportFile".tmp

-#! "$scriptAbsoluteLocation" _wget_githubRelease_join "owner/repo" "internal" "file.ext"
-#! _wget_githubRelease "owner/repo" "" "file.ext"
+			fi
+		done
+	done


-#_wget_githubRelease_join "soaringDistributions/Llama-augment_bundle" "" "llama-3.1-8b-instruct-abliterated.Q4_K_M.gguf"



-#_wget_githubRelease-stdout
-#export MANDATORY_HASH="true"
-#export MANDATORY_HASH=""
+    return 0
+}

-#_wget_githubRelease_join
-#export MANDATORY_HASH="true"
-#export MANDATORY_HASH=""
+_safeRMR-analysisTmp() {
+    [[ -e "$scriptLocal"/analysisTmp ]] && _safeRMR "$scriptLocal"/analysisTmp
+}

-#_wget_githubRelease_join-stdout
-#export MANDATORY_HASH="true"
+#env currentRepository='mirage335-colossus/ubiquitous_bash' currentReleaseTag='build-13917942290-9999' ./ubiquitous_bash.sh _wget_githubRelease-fromTag-analysisReport 'ubcp-binReport-UNIX_Linux'
+#env:
+#  currentRepository: ${{ github.repository }}
+#  currentReleaseTag: build-${{ github.run_id }}-9999
+#  GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
+# No production use.
+_wget_githubRelease-fromTag-analysisReport() {
+    _wget_githubRelease-fromTag-analysisReport-fetch 20 "$@"
+    _wget_githubRelease-fromTag-analysisReport-select "$@"
+    _wget_githubRelease-fromTag-analysisReport-analysis 65 "$@"
+    _safeRMR-analysisTmp
+}



@@ -27848,267 +34232,304 @@ _test_gitBest() {



-#type -p gh > /dev/null 2>&1

+#./ubiquitous_bash.sh _wget_githubRelease-fromTag-fetchReport 'soaringDistributions/ubDistBuild' 'build_upgrade-13945231768-9999' 'binReport'
+#./ubiquitous_bash.sh _wget_githubRelease-fromTag-fetchReport 'soaringDistributions/ubDistBuild' 'build_upgrade-13945231768-9999' 'binReportX'
+#"$GH_TOKEN"
+_wget_githubRelease-fromTag-fetchReport() {
+    ( _messagePlain_nominal '\/\/\/\/\/ init: _wget_githubRelease-fromTag-fetchReport' >&2 ) > /dev/null

-#_wget_githubRelease_internal
+    if [[ "$GH_TOKEN" == "" ]]
+    then
+        ( _messagePlain_bad 'bad: FAIL: GH_TOKEN not set' >&2 ) > /dev/null
+        return 1
+    fi
+
+    local currentAbsoluteRepo="$1"
+    local currentTag="$2"
+    local currentFile="$3"
+    local currentFailParam="$4"
+    [[ "$currentFailParam" != "--no-fail" ]] && currentFailParam="--fail"
+    shift ; shift ; shift ; shift

-#curl --no-progress-meter
-#gh release download "$current_tagName" -R "$current_repo" -p "$current_file" "$@" 2> >(tail -n 10 >&2) | tail -n 10
+    local current

-## Use variables to construct the gh release download command
-#local currentIteration
-#currentIteration=0
-#while ! [[ -e "$current_fileOut" ]] && [[ "$currentIteration" -lt 3 ]]
-#do
-	##gh release download "$current_tagName" -R "$current_repo" -p "$current_file" "$@"
-	#gh release download "$current_tagName" -R "$current_repo" -p "$current_file" "$@" 2> >(tail -n 10 >&2) | tail -n 10
-	#! [[ -e "$current_fileOut" ]] && sleep 7
-	#let currentIteration=currentIteration+1
-#done
-#[[ -e "$current_fileOut" ]]
-#return "$?"
+    # ATTRIBUTION-AI: 2025-03-23
+    #_set_curl_github_retry
+    #curl "$currentFailParam" "${curl_retries_args[@]}" -s -S -L -H "Authorization: token $GH_TOKEN" -H "Accept: application/octet-stream" "$(curl "$currentFailParam" "${curl_retries_args[@]}" -s -S -H "Authorization: token $GH_TOKEN" "https://api.github.com/repos/""$currentAbsoluteRepo""/releases/tags/""$currentTag"  | jq -r '.assets[] | select(.name=="'"$currentFile"'") | .url')" -o -


+    export githubRelease_retriesMax=2
+	export githubRelease_retriesWait=4
+    _set_curl_github_retry
+
+    local currentExitStatus=0

-# ATTENTION: Override with 'ops.sh' or similar. Do NOT attempt to override with exported variables: do indeed override the function.
+    #local currentSkip
+    #currentSkip=$(_wget_githubRelease-skip-URL_fromTag-curl "$currentAbsoluteRepo" "$currentTag" "$currentFile" "$currentFailParam")
+    #currentExitStatus="$?"
+    #[[ "$currentExitStatus" != "0" ]] && [[ "$currentFailParam" != "--no-fail" ]] && return "$currentExitStatus"
+    #[[ "$currentSkip" == "skip" ]] && [[ "$currentFailParam" == "--no-fail" ]] && return 0
+    #[[ "$currentSkip" != 'download' ]] && [[ "$currentFailParam" != "--no-fail" ]] && return 1

-_set_wget_githubRelease() {
-	export githubRelease_retriesMax=25
-	export githubRelease_retriesWait=18
-}
-_set_wget_githubRelease
+    #curl "$currentFailParam" "${curl_retries_args[@]}" -s -S -L -H "Authorization: token $GH_TOKEN" -H "Accept: application/octet-stream" "$(_wget_githubRelease-API_URL_fromTag-curl "$currentAbsoluteRepo" "$currentTag" "$currentFile" "$currentFailParam")" -o -
+    #currentExitStatus="$?"

-_set_wget_githubRelease-detect() {
-	export githubRelease_retriesMax=2
-	export githubRelease_retriesWait=4
-}
+    local current_API_URL
+    current_API_URL=$(_wget_githubRelease-API_URL_fromTag-curl "$currentAbsoluteRepo" "$currentTag" "$currentFile" "$currentFailParam")
+    currentExitStatus="$?"
+    [[ "$currentExitStatus" != "0" ]] && [[ "$currentFailParam" != "--no-fail" ]] && return "$currentExitStatus"
+    [[ "$current_API_URL" == "" ]] && [[ "$currentFailParam" == "--no-fail" ]] && return 0
+    [[ "$current_API_URL" == '' ]] && [[ "$currentFailParam" != "--no-fail" ]] && return 1

-_set_wget_githubRelease-detect-parallel() {
-	export githubRelease_retriesMax=25
-	export githubRelease_retriesWait=18
+    curl "$currentFailParam" "${curl_retries_args[@]}" -s -S -L -H "Authorization: token $GH_TOKEN" -H "Accept: application/octet-stream" "$current_API_URL" -o -
+
+    _set_wget_githubRelease
+    unset curl_retries_args
+
+    return "$currentExitStatus"
 }



-_if_gh() {
-	if type -p gh > /dev/null 2>&1 && [[ "$GH_TOKEN" != "" ]]
-	then
-		( _messagePlain_probe '_if_gh: gh' >&2 ) > /dev/null
-		return 0
-	fi
-	( _messagePlain_probe '_if_gh: NOT gh' >&2 ) > /dev/null
-	return 1
-}


-#_wget_githubRelease-URL "owner/repo" "" "file.ext"
-#_wget_githubRelease-URL "owner/repo" "latest" "file.ext"
-#_wget_githubRelease-URL "owner/repo" "internal" "file.ext"
-_wget_githubRelease-URL() {
-	( _messagePlain_nominal "$currentStream"'\/\/\/\/\/ init: _wget_githubRelease-URL' >&2 ) > /dev/null
-	if _if_gh
-	then
-		( _messagePlain_probe_safe _wget_githubRelease-URL-gh "$@" >&2 ) > /dev/null
-		_wget_githubRelease-URL-gh "$@"
-		return
-	else
-		( _messagePlain_probe_safe _wget_githubRelease-URL-curl "$@" >&2 ) > /dev/null
-		_wget_githubRelease-URL-curl "$@"
-		return
-	fi
-}
-#_wget_githubRelease-URL "owner/repo" "file.ext"
-_wget_githubRelease_internal-URL() {
-	_wget_githubRelease-URL "$1" "internal" "$2"
-}
-#_wget_githubRelease-address "owner/repo" "" "file.ext"
-#_wget_githubRelease-address "owner/repo" "latest" "file.ext"
-#_wget_githubRelease-address "owner/repo" "internal" "file.ext"
-_wget_githubRelease-address() {
-	( _messagePlain_nominal "$currentStream"'\/\/\/\/\/ init: _wget_githubRelease-address' >&2 ) > /dev/null
-	if _if_gh
-	then
-		( _messagePlain_probe_safe _wget_githubRelease-address-gh "$@" >&2 ) > /dev/null
-		_wget_githubRelease-address-gh "$@"
-		return
-	else
-		( _messagePlain_probe_safe _wget_githubRelease-address-curl "$@" >&2 ) > /dev/null
-		_wget_githubRelease-address-curl "$@"
-		return
-	fi
-}
+

 #"$api_address_type" == "tagName" || "$api_address_type" == "url"
 # ATTENTION: WARNING: Unusually, api_address_type , is a monolithic variable NEVER exported . Keep local, and do NOT use for any other purpose.
-_jq_github_browser_download_address() {
-	( _messagePlain_probe 'init: _jq_github_browser_download_address' >&2 ) > /dev/null
-	local currentReleaseLabel="$2"
+# ATTRIBUTION-AI: Many-Chat 2025-03-23
+_jq_github_browser_download_address_fromTag() {
+	( _messagePlain_probe 'init: _jq_github_browser_download_address_fromTag' >&2 ) > /dev/null
+	#local currentReleaseLabel="$2"
+    local currentTag="$2"
 	local currentFile="$3"

-	# 'latest'
-	if [[ "$currentReleaseLabel" == "latest" ]] || [[ "$currentReleaseLabel" == "" ]]
-	then
-		if [[ "$api_address_type" == "" ]] || [[ "$api_address_type" == "url" ]]
-        then
-            #jq -r ".assets[] | select(.name == \"""$3""\") | .browser_download_url"
-            jq -r ".assets[] | select(.name == \"""$currentFile""\") | .browser_download_url"
-            return
-        fi
-		if [[ "$api_address_type" == "tagName" ]]
-        then
-            jq -r ".tag_name"
-            return
-        fi
-	# eg. 'internal', 'build', etc
-	else
-		if [[ "$api_address_type" == "" ]] || [[ "$api_address_type" == "url" ]]
-        then
-            #jq -r ".[] | select(.name == \"""$2""\") | .assets[] | select(.name == \"""$3""\") | .browser_download_url" | sort -n -r | head -n 1
-            jq -r "sort_by(.published_at) | reverse | .[] | select(.name == \"""$currentReleaseLabel""\") | .assets[] | select(.name == \"""$currentFile""\") | .browser_download_url"
-            return
-        fi
-		if [[ "$api_address_type" == "tagName" ]]
-        then
-            jq -r "sort_by(.published_at) | reverse | .[] | select(.name == \"""$currentReleaseLabel""\") | .tag_name"
-            return
-        fi
-
-	fi
+
+    if [[ "$api_address_type" == "" ]] || [[ "$api_address_type" == "url" ]]
+    then
+        #jq -r ".assets[] | select(.name == "'"$currentFile"'") | .browser_download_url"
+        #jq -r ".assets | sort_by(.published_at) | reverse | .[] | select(.name == "'"$currentFile"'") | .browser_download_url"
+
+        #jq -r '.[] | select(.tag_name == "'"$currentTag"'") | .assets[] | select(.name == "'"$currentFile"'") | .browser_download_url'
+        jq --arg shellFile "$currentFile" --arg shellTag "$currentTag" -r '.[] | select(.tag_name == $shellTag) | .assets[] | select(.name == $shellFile) | .browser_download_url'
+
+        return
+    fi
+    if [[ "$api_address_type" == "tagName" ]]
+    then
+        #jq -r ".tag_name"
+
+        # ATTRIBUTION-AI: ChatGPT 4.5-preview 2025-03-23
+        #jq -r '.[] | select(.tag_name == "'"$currentTag"'") | select(.assets[].name == "'"$currentFile"'") | .tag_name'
+        jq --arg shellFile "$currentFile" --arg shellTag "$currentTag" -r '.[] | select(.tag_name == $shellTag) | select(.assets[].name == $shellFile) | .tag_name'
+
+        return
+    fi
+    if [[ "$api_address_type" == "api_url" ]]
+    then
+        #jq -r ".assets[] | select(.name == "'"$currentFile"'") | .url"
+        #jq -r ".assets | sort_by(.published_at) | reverse | .[] | select(.name == \"$currentFile\") | .url"
+
+        #jq -r ".[] | select(.tag_name == \"$currentTag\") | .assets[] | select(.name == \"$currentFile\") | .url"
+        #jq -r '.[] | select(.tag_name == "'"$currentTag"'") | .assets[] | select(.name == "'"$currentFile"'") | .url'
+        jq --arg shellFile "$currentFile" --arg shellTag "$currentTag" -r '.[] | select(.tag_name == $shellTag) | .assets[] | select(.name == $shellFile) | .url'
+
+        return
+    fi
 }
-_curl_githubAPI_releases_page() {
-	( _messagePlain_nominal "$currentStream"'\/\/\/ init: _curl_githubAPI_releases_page' >&2 ) > /dev/null
-	local currentAbsoluteRepo="$1"
-	local currentReleaseLabel="$2"
-	local currentFile="$3"

-	[[ "$currentAbsoluteRepo" == "" ]] && return 1
-	[[ "$currentReleaseLabel" == "" ]] && currentReleaseLabel="latest"
-	[[ "$currentFile" == "" ]] && return 1

-	local currentPageNum="$4"
-	[[ "$currentPageNum" == "" ]] && currentPageNum="1"
-	_messagePlain_probe_var page >&2 | cat /dev/null
-
-	local currentAPI_URL
-	currentAPI_URL="https://api.github.com/repos/""$currentAbsoluteRepo""/releases?per_page=100&page=""$currentPageNum"
-	[[ "$currentReleaseLabel" == "latest" ]] && currentAPI_URL="https://api.github.com/repos/""$currentAbsoluteRepo""/releases""/latest"
-	_messagePlain_probe_safe "currentAPI_URL= ""$currentAPI_URL" >&2 | cat /dev/null

-	local current_curl_args
-	current_curl_args=()
-	[[ "$GH_TOKEN" != "" ]] && current_curl_args+=( -H "Authorization: Bearer $GH_TOKEN" )
-	current_curl_args+=( -S )
-	current_curl_args+=( -s )
+# WARNING: No production use. May be untested.
+#  Rapidly skips part files which are not upstream, using only a single page from the GitHub API, saving time and API calls.
+# Not guaranteed reliable. Structure of this non-essential function is provider-specific, code is written ad-hoc.
+# Duplicates much code from other functions:
+#  '_wget_githubRelease_procedure-address-curl'
+#  '_wget_githubRelease_procedure-address_fromTag-curl'
+#  '_wget_githubRelease-address-backend-curl'
+#env maxCurrentPart=63 ./ubiquitous_bash.sh _curl_githubAPI_releases_fromTag_join-skip soaringDistributions/ubDistBuild build-14095557231-9999 package_image.tar.flx
+#env maxCurrentPart=63 ./ubiquitous_bash.sh _curl_githubAPI_releases_fromTag_join-skip soaringDistributions/ubDistBuild build-13347565825-1 vm-ingredient.img.flx
+_curl_githubAPI_releases_fromTag_join-skip() {
+	# Similar retry logic for all similar functions: _wget_githubRelease-URL-curl, _wget_githubRelease-URL-gh .
+	( _messagePlain_nominal "$currentStream"'\/\/\/\/ init: _curl_githubAPI_releases_fromTag_join-skip' >&2 ) > /dev/null
+	( _messagePlain_probe_safe _curl_githubAPI_releases_fromTag_join-skip "$@" >&2 ) > /dev/null

-	local currentPage
-	currentPage=""
+    # ATTENTION: WARNING: Unusually, api_address_type , is a monolithic variable NEVER exported . Keep local, and do NOT use for any other purpose.
+    [[ "$GH_TOKEN" != "" ]] && local api_address_type="api_url"
+	[[ "$GH_TOKEN" == "" ]] && local api_address_type="url"

-	local currentExitStatus_ipv4=1
-	local currentExitStatus_ipv6=1
+	local currentPartDownload
+	currentPartDownload=""

-	( _messagePlain_probe '_curl_githubAPI_releases_page: IPv6 (false)' >&2 ) > /dev/null
-	# ATTENTION: IPv6 is NOT offered by GitHub API, and so usually only wastes time at best.
-	#currentPage=$(curl -6 "${current_curl_args[@]}" "$currentAPI_URL")
-	false
-	currentExitStatus_ipv6="$?"
-	if [[ "$currentExitStatus_ipv6" != "0" ]]
-	then
-		( _messagePlain_probe '_curl_githubAPI_releases_page: IPv4' >&2 ) > /dev/null
-		[[ "$currentPage" == "" ]] && currentPage=$(curl -4 "${current_curl_args[@]}" "$currentAPI_URL")
-		currentExitStatus_ipv4="$?"
-	fi
+	local currentExitStatus=1
+
+	local currentIteration=0
+
+	#[[ "$currentPartDownload" == "" ]] ||
+	while ( [[ "$currentExitStatus" != "0" ]] ) && [[ "$currentIteration" -lt "$githubRelease_retriesMax" ]]
+	do
+		currentPartDownload=""
+
+		if [[ "$currentIteration" != "0" ]]
+		then
+			( _messagePlain_warn 'warn: BAD: RETRY: _curl_githubAPI_releases_fromTag_join-skip: _curl_githubAPI_releases_fromTag_join_procedure-skip: currentIteration != 0' >&2 ) > /dev/null
+			sleep "$githubRelease_retriesWait"
+		fi
+
+		( _messagePlain_probe _curl_githubAPI_releases_fromTag_join_procedure-skip >&2 ) > /dev/null
+		currentPartDownload=$(_curl_githubAPI_releases_fromTag_join_procedure-skip "$@")
+		currentExitStatus="$?"
+
+		let currentIteration=currentIteration+1
+	done

-	_safeEcho_newline "$currentPage"
+	_safeEcho_newline "$currentPartDownload"

-	if [[ "$currentExitStatus_ipv6" != "0" ]] && [[ "$currentExitStatus_ipv4" != "0" ]]
-	then
-		( _messagePlain_bad 'bad: FAIL: _curl_githubAPI_releases_page' >&2 ) > /dev/null
-		[[ "$currentExitStatus_ipv4" != "1" ]] && [[ "$currentExitStatus_ipv4" != "0" ]] && return "$currentExitStatus_ipv4"
-		[[ "$currentExitStatus_ipv6" != "1" ]] && [[ "$currentExitStatus_ipv6" != "0" ]] && return "$currentExitStatus_ipv6"
-		return "$currentExitStatus_ipv4"
-	fi
+	[[ "$currentIteration" -ge "$githubRelease_retriesMax" ]] && ( _messagePlain_bad 'bad: FAIL: _curl_githubAPI_releases_fromTag_join-skip: maxRetries' >&2 ) > /dev/null && return 1

-	[[ "$currentPage" == "" ]] && return 1
 	return 0
 }
-_wget_githubRelease_procedure-address-curl() {
+#env maxCurrentPart=63 ./ubiquitous_bash.sh _curl_githubAPI_releases_fromTag_join_procedure-skip soaringDistributions/ubDistBuild spring package_image.tar.flx
+#env maxCurrentPart=63 ./ubiquitous_bash.sh _curl_githubAPI_releases_fromTag_join_procedure-skip soaringDistributions/ubDistBuild latest package_image.tar.flx
+_curl_githubAPI_releases_fromTag_join_procedure-skip() {
 	local currentAbsoluteRepo="$1"
-	local currentReleaseLabel="$2"
+	local currentTag="$2"
 	local currentFile="$3"

 	[[ "$currentAbsoluteRepo" == "" ]] && return 1
-	[[ "$currentReleaseLabel" == "" ]] && currentReleaseLabel="latest"
 	[[ "$currentFile" == "" ]] && return 1


 	local currentExitStatus_tmp=0
 	local currentExitStatus=0

-	if [[ "$currentReleaseLabel" == "latest" ]]
-	then
-		#(set -o pipefail ; _curl_githubAPI_releases_page "$currentAbsoluteRepo" "$currentReleaseLabel" "$currentFile" | _jq_github_browser_download_address "" "$currentReleaseLabel" "$currentFile")
-		#return

-		currentData_page=$(set -o pipefail ; _curl_githubAPI_releases_page "$currentAbsoluteRepo" "$currentReleaseLabel" "$currentFile")
-		currentExitStatus="$?"
+	local currentPart
+	local currentAddress

-		currentData="$currentData_page"

-		[[ "$currentExitStatus" != "0" ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease_procedure-address-curl: currentExitStatus' >&2 ) > /dev/null && return "$currentExitStatus"
-
-		[[ "$currentData" == "" ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease_procedure-address-curl: empty: currentData' >&2 ) > /dev/null && return 1

-		( set -o pipefail ; _safeEcho_newline "$currentData" | _jq_github_browser_download_address "" "$currentReleaseLabel" "$currentFile" | head -n 1 )
+	local currentData
+	currentData=""
+
+	local currentData_page
+	currentData_page="doNotMatch"
+
+	local currentIteration
+	currentIteration=1
+
+	# ATTRIBUTION-AI: Many-Chat 2025-03-23
+	# Alternative detection of empty array, as suggested by AI LLM .
+	#[[ $(jq 'length' <<< "$currentData_page") -gt 0 ]]
+	while ( [[ "$currentData_page" != "" ]] && [[ $(_safeEcho_newline "$currentData_page" | tr -dc 'a-zA-Z\[\]' | sed '/^$/d') != $(echo 'WwoKXQo=' | base64 -d | tr -dc 'a-zA-Z\[\]') ]] ) && ( [[ "$currentIteration" -le "1" ]] || ( [[ "$GH_TOKEN" != "" ]] && [[ "$currentIteration" -le "3" ]] ) )
+	do
+		currentData_page=$(set -o pipefail ; _curl_githubAPI_releases_page "$currentAbsoluteRepo" "$currentTag" "$currentFile" "$currentIteration")
 		currentExitStatus_tmp="$?"
-
-		[[ "$currentExitStatus_tmp" != "0" ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease_procedure-address-curl: pipefail: _jq_github_browser_download_address: currentExitStatus_tmp' >&2 ) > /dev/null && return "$currentExitStatus_tmp"
-
-		# ATTENTION: Part file does NOT exist upstream. Page did NOT match 'Not Found', page NOT empty, and data NOT empty, implying repo, releaseLabel , indeed EXISTS upstream.
-		# Retries/wait must NOT continue in that case - calling function must detect and either fail or skip file on empty address if appropriate.
-		#[[ "$(_safeEcho_newline "$currentData" | _jq_github_browser_download_address "" "$currentReleaseLabel" "$currentFile" | head -n 1 | wc -c )" -le 0 ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease_procedure-address-curl: empty: _safeEcho_newline | _jq_github_browser_download_address' >&2 ) > /dev/null  && return 1
-
-		return 0
-	else
-		local currentData
-		currentData=""
-
-		local currentData_page
-		currentData_page="doNotMatch"
-
-		local currentIteration
-		currentIteration=1
-
-		while ( [[ "$currentData_page" != "" ]] && [[ "$currentData_page" != *$(echo 'WwoKXQo=' | base64 -d)* ]] ) && [[ "$currentIteration" -le "3" ]]
-		do
-			currentData_page=$(_curl_githubAPI_releases_page "$currentAbsoluteRepo" "$currentReleaseLabel" "$currentFile" "$currentIteration")
-			currentExitStatus_tmp="$?"
-			[[ "$currentIteration" == "1" ]] && currentExitStatus="$currentExitStatus_tmp"
-			currentData="$currentData"'
+		[[ "$currentIteration" == "1" ]] && currentExitStatus="$currentExitStatus_tmp"
+		currentData="$currentData"'
 '"$currentData_page"

-            ( _messagePlain_probe "_wget_githubRelease_procedure-address-curl: ""$currentIteration" >&2 ) > /dev/null
-            #( _safeEcho_newline "$currentData" | _jq_github_browser_download_address "" "$currentReleaseLabel" "$currentFile" | head -n 1 >&2 ) > /dev/null
-            [[ "$currentIteration" -ge 4 ]] && ( _safeEcho_newline "$currentData_page" >&2 ) > /dev/null
+		( _messagePlain_probe "_wget_githubRelease_procedure-address-curl: ""$currentIteration" >&2 ) > /dev/null
+		#( _safeEcho_newline "$currentData" | _jq_github_browser_download_address "" "$currentTag" "$currentFile" | head -n 1 >&2 ) > /dev/null
+		[[ "$currentIteration" -ge 4 ]] && ( _safeEcho_newline "$currentData_page" >&2 ) > /dev/null

-			let currentIteration=currentIteration+1
-		done
+		let currentIteration=currentIteration+1
+	done

-		( set -o pipefail ; _safeEcho_newline "$currentData" | _jq_github_browser_download_address "" "$currentReleaseLabel" "$currentFile" | head -n 1 )
+	#( set -o pipefail ; _safeEcho_newline "$currentData" | _jq_github_browser_download_address "" "$currentTag" "$currentFile" | head -n 1 )
+	#currentExitStatus_tmp="$?"
+
+	# ###
+	for currentPart in $(seq -f "%02g" 0 "$maxCurrentPart" | sort -r)
+	do
+		currentAddress=$( set -o pipefail ; _safeEcho_newline "$currentData" | _jq_github_browser_download_address_fromTag "" "$currentTag" "$currentFile".part"$currentPart" | head -n 1 )
 		currentExitStatus_tmp="$?"

-		[[ "$currentExitStatus" != "0" ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease_procedure-address-curl: _curl_githubAPI_releases_page: currentExitStatus' >&2 ) > /dev/null && return "$currentExitStatus"
+		[[ "$currentExitStatus" != "0" ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease_procedure-address-curl: _curl_githubAPI_releases_fromTag_page: currentExitStatus' >&2 ) > /dev/null && return "$currentExitStatus"
 		[[ "$currentExitStatus_tmp" != "0" ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease_procedure-address-curl: pipefail: _jq_github_browser_download_address: currentExitStatus_tmp' >&2 ) > /dev/null && return "$currentExitStatus_tmp"
 		[[ "$currentData" == "" ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease_procedure-address-curl: empty: currentData' >&2 ) > /dev/null && return 1

-		# ATTENTION: Part file does NOT exist upstream. Page did NOT match 'Not Found', page NOT empty, and data NOT empty, implying repo, releaseLabel , indeed EXISTS upstream.
-		# Retries/wait must NOT continue in that case - calling function must detect and either fail or skip file on empty address if appropriate.
-		#[[ "$(_safeEcho_newline "$currentData" | _jq_github_browser_download_address "" "$currentReleaseLabel" "$currentFile" | head -n 1 | wc -c )" -le 0 ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease_procedure-address-curl: empty: _safeEcho_newline | _jq_github_browser_download_address' >&2 ) > /dev/null  && return 1
-
-        return 0
-	fi
+		[[ "$currentAddress" != "" ]] && echo "$currentPart" && return 0
+	done
+
+
+	# ### ATTENTION: No part files found is not 'skip' but FAIL .
+	[[ "$currentAddress" == "" ]] && ( _messagePlain_bad 'bad: FAIL: _curl_githubAPI_releases_fromTag_join-skip: empty: _safeEcho_newline | _jq_github_browser_download_address' >&2 ) > /dev/null && return 1
+
+	return 0
+
 }
-_wget_githubRelease-address-backend-curl() {
+
+
+
+
+
+
+
+
+
+#./ubiquitous_bash.sh _wget_githubRelease-API_URL_fromTag-curl 'soaringDistributions/ubDistBuild' 'build_upgrade-13945231768-9999' 'binReport' --fail | head
+
+_wget_githubRelease_procedure-address_fromTag-curl() {
+	local currentAbsoluteRepo="$1"
+    local currentTag="$2"
+    local currentFile="$3"
+    local currentFailParam="$4"
+    [[ "$currentFailParam" != "--no-fail" ]] && currentFailParam="--fail"
+
+	#local currentReleaseLabel="$2"
+	#local currentFile="$3"
+
+	[[ "$currentAbsoluteRepo" == "" ]] && return 1
+	#[[ "$currentReleaseLabel" == "" ]] && currentReleaseLabel="latest"
+	[[ "$currentFile" == "" ]] && return 1
+
+
+	local currentExitStatus_tmp=0
+	local currentExitStatus=0
+
+
+    local currentData
+    currentData=""
+
+    local currentData_page
+    currentData_page="doNotMatch"
+
+    local currentIteration
+    currentIteration=1
+
+    # ATTRIBUTION-AI: Many-Chat 2025-03-23
+    # Alternative detection of empty array, as suggested by AI LLM .
+    #[[ $(jq 'length' <<< "$currentData_page") -gt 0 ]]
+    while ( [[ "$currentData_page" != "" ]] && [[ $(_safeEcho_newline "$currentData_page" | tr -dc 'a-zA-Z\[\]' | sed '/^$/d') != $(echo 'WwoKXQo=' | base64 -d | tr -dc 'a-zA-Z\[\]') ]] ) && ( [[ "$currentIteration" -le "1" ]] || ( [[ "$GH_TOKEN" != "" ]] && [[ "$currentIteration" -le "3" ]] ) )
+    do
+        #currentData_page=$(set -o pipefail ; _curl_githubAPI_releases_page "$currentAbsoluteRepo" "$currentReleaseLabel" "$currentFile")
+        #_set_curl_github_retry
+        currentData_page=$(set -o pipefail ; _curl_githubAPI_releases_page "$currentAbsoluteRepo" "doNotMatch" "$currentFile" "$currentIteration" "$currentFailParam" "${curl_retries_args[@]}")
+        unset curl_retries_args
+        currentExitStatus_tmp="$?"
+        [[ "$currentIteration" == "1" ]] && currentExitStatus="$currentExitStatus_tmp"
+        currentData="$currentData"'
+'"$currentData_page"
+
+        ( _messagePlain_probe "_wget_githubRelease_procedure-address_fromTag-curl: ""$currentIteration" >&2 ) > /dev/null
+        [[ "$currentIteration" -ge 4 ]] && ( _safeEcho_newline "$currentData_page" >&2 ) > /dev/null
+
+        let currentIteration=currentIteration+1
+    done
+
+    #( set -o pipefail ; _safeEcho_newline "$currentData" | _jq_github_browser_download_address "" "$currentReleaseLabel" "$currentFile" | head -n 1 )
+    ( set -o pipefail ; _safeEcho_newline "$currentData" | _jq_github_browser_download_address_fromTag "" "$currentTag" "$currentFile" | head -n 1 )
+    currentExitStatus_tmp="$?"
+
+    [[ "$currentExitStatus" != "0" ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease_procedure-address_fromTag-curl: _curl_githubAPI_releases_page: currentExitStatus' >&2 ) > /dev/null && return "$currentExitStatus"
+    [[ "$currentExitStatus_tmp" != "0" ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease_procedure-address_fromTag-curl: pipefail: _jq_github_browser_download_address_fromTag: currentExitStatus_tmp' >&2 ) > /dev/null && return "$currentExitStatus_tmp"
+    [[ "$currentData" == "" ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease_procedure-address_fromTag-curl: empty: currentData' >&2 ) > /dev/null && return 1
+
+    return 0
+}
+_wget_githubRelease-address_fromTag-backend-curl() {
 	local currentAddress
 	currentAddress=""

@@ -28116,6 +34537,8 @@ _wget_githubRelease-address-backend-curl() {

 	local currentIteration=0

+    #export githubRelease_retriesMax=2
+	#export githubRelease_retriesWait=4
 	#[[ "$currentAddress" == "" ]] ||
 	while ( [[ "$currentExitStatus" != "0" ]] ) && [[ "$currentIteration" -lt "$githubRelease_retriesMax" ]]
 	do
@@ -28123,38 +34546,39 @@ _wget_githubRelease-address-backend-curl() {

 		if [[ "$currentIteration" != "0" ]]
 		then
-			( _messagePlain_warn 'warn: BAD: RETRY: _wget_githubRelease-URL-curl: _wget_githubRelease_procedure-address-curl: currentIteration != 0' >&2 ) > /dev/null
+			( _messagePlain_warn 'warn: BAD: RETRY: _wget_githubRelease-URL_fromTag-curl: _wget_githubRelease_procedure-address_fromTag-curl: currentIteration != 0' >&2 ) > /dev/null
 			sleep "$githubRelease_retriesWait"
 		fi

-		( _messagePlain_probe _wget_githubRelease_procedure-address-curl >&2 ) > /dev/null
-		currentAddress=$(_wget_githubRelease_procedure-address-curl "$@")
+		( _messagePlain_probe _wget_githubRelease_procedure-address_fromTag-curl >&2 ) > /dev/null
+		currentAddress=$(_wget_githubRelease_procedure-address_fromTag-curl "$@")
 		currentExitStatus="$?"

 		let currentIteration=currentIteration+1
 	done
+    #_set_wget_githubRelease

 	_safeEcho_newline "$currentAddress"

-	[[ "$currentIteration" -ge "$githubRelease_retriesMax" ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease-URL-curl: maxRetries' >&2 ) > /dev/null && return 1
+	[[ "$currentIteration" -ge "$githubRelease_retriesMax" ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease-URL_fromTag-curl: maxRetries' >&2 ) > /dev/null && return 1

 	return 0
 }
-_wget_githubRelease-address-curl() {
+_wget_githubRelease-address_fromTag-curl() {
 	# Similar retry logic for all similar functions: _wget_githubRelease-URL-curl, _wget_githubRelease-URL-gh .
-	( _messagePlain_nominal "$currentStream"'\/\/\/\/ init: _wget_githubRelease-address-curl' >&2 ) > /dev/null
-	( _messagePlain_probe_safe _wget_githubRelease-URL-curl "$@" >&2 ) > /dev/null
+	( _messagePlain_nominal "$currentStream"'\/\/\/\/ init: _wget_githubRelease-address_fromTag-curl' >&2 ) > /dev/null
+	( _messagePlain_probe_safe _wget_githubRelease-URL_fromTag-curl "$@" >&2 ) > /dev/null

     # ATTENTION: WARNING: Unusually, api_address_type , is a monolithic variable NEVER exported . Keep local, and do NOT use for any other purpose.
     local api_address_type="tagName"

-    _wget_githubRelease-address-backend-curl "$@"
+    _wget_githubRelease-address_fromTag-backend-curl "$@"
     return
 }
-_wget_githubRelease-URL-curl() {
+_wget_githubRelease-URL_fromTag-curl() {
 	# Similar retry logic for all similar functions: _wget_githubRelease-URL-curl, _wget_githubRelease-URL-gh .
-	( _messagePlain_nominal "$currentStream"'\/\/\/\/ init: _wget_githubRelease-URL-curl' >&2 ) > /dev/null
-	( _messagePlain_probe_safe _wget_githubRelease-URL-curl "$@" >&2 ) > /dev/null
+	( _messagePlain_nominal "$currentStream"'\/\/\/\/ init: _wget_githubRelease-URL_fromTag-curl' >&2 ) > /dev/null
+	( _messagePlain_probe_safe _wget_githubRelease-URL_fromTag-curl "$@" >&2 ) > /dev/null

     # ATTENTION: WARNING: Unusually, api_address_type , is a monolithic variable NEVER exported . Keep local, and do NOT use for any other purpose.
     local api_address_type="url"
@@ -28163,22 +34587,38 @@ _wget_githubRelease-URL-curl() {

 	local currentExitStatus=1

-    #_wget_githubRelease-address-backend-curl "$@"
-	currentAddress=$(_wget_githubRelease-address-backend-curl "$@")
+	currentAddress=$(_wget_githubRelease-address_fromTag-backend-curl "$@")
 	currentExitStatus="$?"

 	_safeEcho_newline "$currentAddress"

-	[[ "$currentAddress" == "" ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease-URL-curl: empty: currentAddress' >&2 ) > /dev/null && return 1
+	[[ "$currentAddress" == "" ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease-URL_fromTag-curl: empty: currentAddress' >&2 ) > /dev/null && return 1

     return "$currentExitStatus"
 }
+_wget_githubRelease-address_fromTag() {
+	local currentTag="$2"
+
+    ( _messagePlain_nominal "$currentStream"'\/\/\/\/\/ init: _wget_githubRelease-address_fromTag' >&2 ) > /dev/null
+	if _if_gh
+	then
+		##( _messagePlain_probe_safe _wget_githubRelease-address_fromTag-gh "$@" >&2 ) > /dev/null
+		##_wget_githubRelease-address_fromTag-gh "$@"
+        _safeEcho_newline "$currentTag"
+		return
+	else
+		#( _messagePlain_probe_safe _wget_githubRelease-address_fromTag-curl "$@" >&2 ) > /dev/null
+		#_wget_githubRelease-address_fromTag-curl "$@"
+        _safeEcho_newline "$currentTag"
+		return
+	fi
+}

 # Calling functions MUST attempt download unless skip function conclusively determines BOTH that releaseLabel exists in upstream repo, AND file does NOT exist upstream. Functions may use such skip to skip high-numbered part files that do not exist.
-_wget_githubRelease-skip-URL-curl() {
+_wget_githubRelease-skip-URL_fromTag-curl() {
 	# Similar retry logic for all similar functions: _wget_githubRelease-skip-URL-curl, _wget_githubRelease-URL-gh .
-	( _messagePlain_nominal "$currentStream"'\/\/\/\/ init: _wget_githubRelease-skip-URL-curl' >&2 ) > /dev/null
-	( _messagePlain_probe_safe _wget_githubRelease-skip-URL-curl "$@" >&2 ) > /dev/null
+	( _messagePlain_nominal "$currentStream"'\/\/\/\/ init: _wget_githubRelease-skip-URL_fromTag-curl' >&2 ) > /dev/null
+	( _messagePlain_probe_safe _wget_githubRelease-skip-URL_fromTag-curl "$@" >&2 ) > /dev/null

     # ATTENTION: WARNING: Unusually, api_address_type , is a monolithic variable NEVER exported . Keep local, and do NOT use for any other purpose.
     local api_address_type="url"
@@ -28187,8 +34627,7 @@ _wget_githubRelease-skip-URL-curl() {

 	local currentExitStatus=1

-    #_wget_githubRelease-address-backend-curl "$@"
-	currentAddress=$(_wget_githubRelease-address-backend-curl "$@")
+	currentAddress=$(_wget_githubRelease-address_fromTag-backend-curl "$@")
 	currentExitStatus="$?"

 	( _safeEcho_newline "$currentAddress" >&2 ) > /dev/null
@@ -28197,358 +34636,754 @@ _wget_githubRelease-skip-URL-curl() {
 	if [[ "$currentAddress" == "" ]]
 	then
 		echo skip
-		( _messagePlain_good 'good: _wget_githubRelease-skip-URL-curl: empty: currentAddress: PRESUME skip' >&2 ) > /dev/null
+		( _messagePlain_good 'good: _wget_githubRelease-skip-URL_fromTag-curl: empty: currentAddress: PRESUME skip' >&2 ) > /dev/null
 		return 0
 	fi

 	if [[ "$currentAddress" != "" ]]
 	then
 		echo download
-		( _messagePlain_good 'good: _wget_githubRelease-skip-URL-curl: found: currentAddress: PRESUME download' >&2 ) > /dev/null
+		( _messagePlain_good 'good: _wget_githubRelease-skip-URL_fromTag-curl: found: currentAddress: PRESUME download' >&2 ) > /dev/null
 		return 0
 	fi

 	return 1
 }
-_wget_githubRelease-detect-URL-curl() {
-	_wget_githubRelease-skip-URL-curl "$@"
+_wget_githubRelease-detect-URL_fromTag-curl() {
+	_wget_githubRelease-skip-URL_fromTag-curl "$@"
 }

-_wget_githubRelease_procedure-address-gh-awk() {
-	#( _messagePlain_probe 'init: _wget_githubRelease_procedure-address-gh-awk' >&2 ) > /dev/null
-	( _messagePlain_probe_safe _wget_githubRelease_procedure-address-gh-awk "$@" >&2 ) > /dev/null
-    local currentReleaseLabel="$2"
-    #( _messagePlain_probe_var currentReleaseLabel >&2 ) > /dev/null
-
-    # WARNING: Use of complex 'awk' scripts historically has seemed less resilient, less portable, less reliable.
-    # ATTRIBUTION-AI: ChatGPT o1 2025-01-22 , 2025-01-27 .
-	if [[ "$currentReleaseLabel" == "latest" ]]
+# WARNING: May be untested.
+_wget_githubRelease-API_URL_fromTag-curl() {
+	# Similar retry logic for all similar functions: _wget_githubRelease-URL-curl, _wget_githubRelease-URL-gh .
+	( _messagePlain_nominal "$currentStream"'\/\/\/\/ init: _wget_githubRelease-API_URL_fromTag-curl' >&2 ) > /dev/null
+	( _messagePlain_probe_safe _wget_githubRelease-API_URL_fromTag-curl "$@" >&2 ) > /dev/null
+
+    # ATTENTION: WARNING: Unusually, api_address_type , is a monolithic variable NEVER exported . Keep local, and do NOT use for any other purpose.
+    local api_address_type="api_url"
+
+	local currentAddress
+
+	local currentExitStatus=1
+
+	currentAddress=$(_wget_githubRelease-address_fromTag-backend-curl "$@")
+	currentExitStatus="$?"
+
+	_safeEcho_newline "$currentAddress"
+
+	[[ "$currentAddress" == "" ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease-API_URL_fromTag-curl: empty: currentAddress' >&2 ) > /dev/null && return 1
+
+    return "$currentExitStatus"
+}
+
+# WARNING: May be untested.
+# Calling functions MUST attempt download unless skip function conclusively determines BOTH that releaseLabel exists in upstream repo, AND file does NOT exist upstream. Functions may use such skip to skip high-numbered part files that do not exist.
+_wget_githubRelease-skip-API_URL_fromTag-curl() {
+	# Similar retry logic for all similar functions: _wget_githubRelease-skip-URL-curl, _wget_githubRelease-URL-gh .
+	( _messagePlain_nominal "$currentStream"'\/\/\/\/ init: _wget_githubRelease-skip-API_URL_fromTag-curl' >&2 ) > /dev/null
+	( _messagePlain_probe_safe _wget_githubRelease-skip-API_URL_fromTag-curl "$@" >&2 ) > /dev/null
+
+    # ATTENTION: WARNING: Unusually, api_address_type , is a monolithic variable NEVER exported . Keep local, and do NOT use for any other purpose.
+    local api_address_type="api_url"
+
+	local currentAddress
+
+	local currentExitStatus=1
+
+	currentAddress=$(_wget_githubRelease-address_fromTag-backend-curl "$@")
+	currentExitStatus="$?"
+
+	( _safeEcho_newline "$currentAddress" >&2 ) > /dev/null
+	[[ "$currentExitStatus" != "0" ]] && return "$currentExitStatus"
+
+	if [[ "$currentAddress" == "" ]]
 	then
-		#gh release list -L 1
-		# In theory, simply accepting single line output from gh release list (ie. -L 1) should provide the same result (in case this awk script ever breaks).
-		awk '
-			# Skip a header line if it appears first:
-			NR == 1 && $1 == "TITLE" && $2 == "TYPE" {
-				# Just move on to the next line and do nothing else
-				next
-			}
-
-			# The real match: find the line whose second column is "Latest"
-			$2 == "Latest" {
-				# Print the third column (TAG NAME) and exit
-				print $3
-				exit
-			}
-		'
-	else
-		awk -v label="$currentReleaseLabel" '
-		# For each line where the first column equals the label we are looking for...
-		$1 == label {
-			# If the second column is one of the known “types,” shift fields left so
-			# the *real* tag moves into $2. Repeat until no more known types remain.
-			while ($2 == "Latest" || $2 == "draft" || $2 == "pre-release" || $2 == "prerelease") {
-			for (i=2; i<NF; i++) {
-				$i = $(i+1)
-			}
-			NF--
-			}
-			# At this point, $2 is guaranteed to be the actual tag.
-			print $2
-		}
-		'
+		echo skip
+		( _messagePlain_good 'good: _wget_githubRelease-skip-API_URL_fromTag-curl: empty: currentAddress: PRESUME skip' >&2 ) > /dev/null
+		return 0
+	fi
+
+	if [[ "$currentAddress" != "" ]]
+	then
+		echo download
+		( _messagePlain_good 'good: _wget_githubRelease-skip-API_URL_fromTag-curl: found: currentAddress: PRESUME download' >&2 ) > /dev/null
+		return 0
+	fi
+
+	return 1
+}
+_wget_githubRelease-detect-API_URL_fromTag-curl() {
+	_wget_githubRelease-skip-API_URL_fromTag-curl "$@"
+}
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+#_wget_githubRelease-fromTag-stdout
+
+#_wget_githubRelease-fromTag
+
+
+
+_wget_githubRelease-fromTag-stdout() {
+	( _messagePlain_nominal "$currentStream"'\/\/\/\/\/ \/\/\/\/\/ init: _wget_githubRelease-fromTag-stdout' >&2 ) > /dev/null
+	local currentAxelTmpFileRelative=.m_axelTmp_"$currentStream"_$(_uid 14)
+	local currentAxelTmpFile="$scriptAbsoluteFolder"/"$currentAxelTmpFileRelative"
+
+	local currentExitStatus
+
+	# WARNING: Very strongly discouraged. Any retry/continue of any interruption will nevertheless unavoidably result in a corrupted output stream.
+	[[ "$FORCE_DIRECT" == "true" ]] && _wget_githubRelease-fromTag_procedure-stdout "$@"
+
+	# ATTENTION: /dev/null assures that stdout is not corrupted by any unexpected output that should have been sent to stderr
+	[[ "$FORCE_DIRECT" != "true" ]] && _wget_githubRelease-fromTag_procedure-stdout "$@" > /dev/null
+
+	if ! [[ -e "$currentAxelTmpFile".PASS ]]
+	then
+		currentExitStatus=$(cat "$currentAxelTmpFile".FAIL)
+		( [[ "$currentExitStatus" == "" ]] || [[ "$currentExitStatus" = "0" ]] || [[ "$currentExitStatus" = "0"* ]] ) && currentExitStatus=1
+		rm -f "$currentAxelTmpFile".PASS > /dev/null 2>&1
+		rm -f "$currentAxelTmpFile".FAIL > /dev/null 2>&1
+		rm -f "$currentAxelTmpFile" > /dev/null 2>&1
+		return "$currentExitStatus"
+		#return 1
+	fi
+	[[ "$FORCE_DIRECT" != "true" ]] && cat "$currentAxelTmpFile"
+	rm -f "$currentAxelTmpFile" > /dev/null 2>&1
+	rm -f "$currentAxelTmpFile".PASS > /dev/null 2>&1
+	rm -f "$currentAxelTmpFile".FAIL > /dev/null 2>&1
+	return 0
+}
+_wget_githubRelease-fromTag_procedure-stdout() {
+	( _messagePlain_probe_safe _wget_githubRelease-fromTag_procedure-stdout "$@" >&2 ) > /dev/null
+
+	local currentAbsoluteRepo="$1"
+	local currentReleaseTag="$2"
+	local currentFile="$3"
+
+	local currentOutParameter="$4"
+	local currentOutFile="$5"
+
+	shift
+	shift
+	shift
+	if [[ "$currentOutParameter" == "-O" ]]
+	then
+		if [[ "$currentOutFile" != "-" ]]
+		then
+			( _messagePlain_bad 'bad: fail: unexpected: currentOutFile: NOT stdout' >&2 ) > /dev/null
+			echo "1" > "$currentAxelTmpFile".FAIL
+			return 1
+		fi
+		shift
+		shift
+	fi
+
+	#local currentAxelTmpFileRelative=.m_axelTmp_"$currentStream"_$(_uid 14)
+	#local currentAxelTmpFile="$scriptAbsoluteFolder"/"$currentAxelTmpFileRelative"
+
+	local currentExitStatus
+
+	# WARNING: Very strongly discouraged. Any retry/continue of any interruption will nevertheless unavoidably result in a corrupted output stream.
+	if [[ "$FORCE_DIRECT" == "true" ]]
+	then
+		_wget_githubRelease-fromTag_procedure "$currentAbsoluteRepo" "$currentReleaseTag" "$currentFile" -O - "$@"
+		currentExitStatus="$?"
+		if [[ "$currentExitStatus" != "0" ]]
+		then
+			echo > "$currentAxelTmpFile".FAIL
+			return "$currentExitStatus"
+		fi
+		echo > "$currentAxelTmpFile".PASS
+		return 0
+	fi
+
+	_wget_githubRelease-fromTag_procedure "$currentAbsoluteRepo" "$currentReleaseTag" "$currentFile" -O "$currentAxelTmpFile" "$@"
+	currentExitStatus="$?"
+	if [[ "$currentExitStatus" != "0" ]]
+	then
+		echo "$currentExitStatus" > "$currentAxelTmpFile".FAIL
+		return "$currentExitStatus"
 	fi
+	echo > "$currentAxelTmpFile".PASS
+	return 0
+}
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+#! "$scriptAbsoluteLocation" _wget_githubRelease-fromTag_join "owner/repo" "tag_name" "file.ext" -O "file.ext"
+#! _wget_githubRelease "owner/repo" "" "file.ext" -O "file.ext"
+# ATTENTION: WARNING: Warn messages correspond to inability to assuredly, effectively, use GH_TOKEN .
+_wget_githubRelease-fromTag() {
+	( _messagePlain_nominal "$currentStream"'\/\/\/\/\/ \/\/\/\/\/ init: _wget_githubRelease-fromTag' >&2 ) > /dev/null
+	( _messagePlain_probe_safe _wget_githubRelease-fromTag "$@" >&2 ) > /dev/null
+
+	_wget_githubRelease-fromTag_procedure "$@"
+}
+_wget_githubRelease-fromTag_procedure() {
+    # Should be very similar to '_wget_githubRelease_procedure' , but we will already have the tag , and in the case of curl/axel, we will need to generate the API_URL, in the case of 'gh' we will simply proceed to download.
+    #
+	# ATTENTION: Distinction nominally between '_wget_githubRelease' and '_wget_githubRelease_procedure' should only be necessary if a while loop retries the procedure .
+	# ATTENTION: Potentially more specialized logic within download procedures should remain delegated with the responsibility to attempt retries , for now.
+	# NOTICE: Several functions should already have retry logic: '_gh_download' , '_gh_downloadURL' , '_wget_githubRelease-address' , '_wget_githubRelease_procedure-curl' , '_wget_githubRelease-URL-curl' , etc .
+	#( _messagePlain_nominal "$currentStream"'\/\/\/\/\/ \/\/\/\/ init: _wget_githubRelease_procedure' >&2 ) > /dev/null
+	#( _messagePlain_probe_safe _wget_githubRelease_procedure "$@" >&2 ) > /dev/null
+
+    local currentAbsoluteRepo="$1"
+	#local currentReleaseLabel="$2"
+    local currentTag="$2"
+	local currentFile="$3"
+
+	local currentOutParameter="$4"
+	local currentOutFile="$5"
+
+	shift
+	shift
+	shift
+	[[ "$currentOutParameter" != "-O" ]] && currentOutFile="$currentFile"
+	#[[ "$currentOutParameter" == "-O" ]] && currentOutFile="$currentOutFile"
+
+	#[[ "$currentOutParameter" == "-O" ]] && [[ "$currentOutFile" == "" ]] && currentOutFile="$currentFile"
+	[[ "$currentOutParameter" == "-O" ]] && [[ "$currentOutFile" == "" ]] && ( _messagePlain_bad 'bad: fail: unexpected: unspecified: currentOutFile' >&2 ) > /dev/null && return 1
+
+	[[ "$currentOutFile" != "-" ]] && rm -f "$currentOutFile" > /dev/null 2>&1
+
+    local currentExitStatus=1
+
+    # Discouraged .
+    if [[ "$FORCE_WGET" == "true" ]]
+    then
+        _warn_githubRelease_FORCE_WGET
+        #local currentURL=$(_wget_githubRelease-URL-curl "$currentAbsoluteRepo" "$currentTag" "$currentFile")
+		local currentURL
+		[[ "$GH_TOKEN" != "" ]] && currentURL=$(_wget_githubRelease-API_URL_fromTag-curl "$currentAbsoluteRepo" "$currentTag" "$currentFile")
+		[[ "$GH_TOKEN" == "" ]] && currentURL=$(_wget_githubRelease-URL_fromTag-curl "$currentAbsoluteRepo" "$currentTag" "$currentFile")
+
+		_wget_githubRelease_loop-curl
+        return "$?"
+    fi
+
+	# Discouraged . Benefits of multi-part-per-file downloading are less essential given that files are split into <2GB chunks.
+	if [[ "$FORCE_AXEL" != "" ]] # && [[ "$MANDATORY_HASH" == "true" ]]
+    then
+        ( _messagePlain_warn 'warn: WARNING: FORCE_AXEL not empty' >&2 ; echo 'FORCE_AXEL may have similar effects to FORCE_WGET and should not be necessary.' >&2  ) > /dev/null
+        #local currentURL=$(_wget_githubRelease-URL-curl "$currentAbsoluteRepo" "$currentTag" "$currentFile")
+		local currentURL
+		[[ "$GH_TOKEN" != "" ]] && currentURL=$(_wget_githubRelease-API_URL_fromTag-curl "$currentAbsoluteRepo" "$currentTag" "$currentFile")
+		[[ "$GH_TOKEN" == "" ]] && currentURL=$(_wget_githubRelease-URL_fromTag-curl "$currentAbsoluteRepo" "$currentTag" "$currentFile")
+
+		[[ "$FORCE_DIRECT" == "true" ]] && ( _messagePlain_bad 'bad: fail: FORCE_AXEL==true is NOT compatible with FORCE_DIRECT==true' >&2 ) > /dev/null && return 1
+
+		_wget_githubRelease_loop-axel
+        return "$?"
+    fi
+
+    if _if_gh
+    then
+        #_wget_githubRelease-address_fromTag-gh
+        #local currentTag
+        #currentTag=$(_wget_githubRelease-address_fromTag "$currentAbsoluteRepo" "$currentTag" "$currentFile")
+
+        ( _messagePlain_probe _gh_download "$currentAbsoluteRepo" "$currentTag" "$currentFile" "$@" >&2 ) > /dev/null
+        _gh_download "$currentAbsoluteRepo" "$currentTag" "$currentFile" "$@"
+        currentExitStatus="$?"
+
+        [[ "$currentExitStatus" != "0" ]] && _bad_fail_githubRelease_currentExitStatus && return "$currentExitStatus"
+        [[ ! -e "$currentOutFile" ]] && [[ "$currentOutFile" != "-" ]] && _bad_fail_githubRelease_missing && return 1
+        return 0
+    fi
+
+    if ! _if_gh
+    then
+        ( _messagePlain_warn 'warn: WARNING: FALLBACK: wget/curl' >&2 ) > /dev/null
+        #local currentURL=$(_wget_githubRelease-URL-curl "$currentAbsoluteRepo" "$currentTag" "$currentFile")
+		local currentURL
+		[[ "$GH_TOKEN" != "" ]] && currentURL=$(_wget_githubRelease-API_URL_fromTag-curl "$currentAbsoluteRepo" "$currentTag" "$currentFile")
+		[[ "$GH_TOKEN" == "" ]] && currentURL=$(_wget_githubRelease-URL_fromTag-curl "$currentAbsoluteRepo" "$currentTag" "$currentFile")
+
+		_wget_githubRelease_loop-curl
+        return "$?"
+    fi
+
+    return 1
 }
-# Requires "$GH_TOKEN" .
-_wget_githubRelease_procedure-address-gh() {
-	( _messagePlain_nominal "$currentStream"'\/\/\/ init: _wget_githubRelease_procedure-address-gh' >&2 ) > /dev/null
-	( _messagePlain_probe_safe _wget_githubRelease_procedure-address-gh "$@" >&2 ) > /dev/null
-    ! _if_gh && return 1
-
-	local currentAbsoluteRepo="$1"
-	local currentReleaseLabel="$2"
-	local currentFile="$3"

-	[[ "$currentAbsoluteRepo" == "" ]] && return 1
-	[[ "$currentReleaseLabel" == "" ]] && currentReleaseLabel="latest"
-	[[ "$currentFile" == "" ]] && return 1

-    local currentTag

-	local currentExitStatus=0
-	local currentExitStatus_tmp=0

-    local currentIteration
-    currentIteration=1

-    while [[ "$currentTag" == "" ]] && [[ "$currentIteration" -le 3 ]]
-    do
-        #currentTag=$(gh release list -L 100 -R "$currentAbsoluteRepo" | sed 's/Latest//' | grep '^'"$currentReleaseLabel" | awk '{ print $2 }' | head -n 1)
-
-        currentTag=$(set -o pipefail ; gh release list -L $(( $currentIteration * 100 )) -R "$currentAbsoluteRepo" | _wget_githubRelease_procedure-address-gh-awk "" "$currentReleaseLabel" "" | head -n 1)    # or pick whichever match you want
-        currentExitStatus_tmp="$?"
-		[[ "$currentIteration" == "1" ]] && currentExitStatus="$currentExitStatus_tmp"
-
-        let currentIteration++
-    done

-    _safeEcho_newline "$currentTag"
-    #_safeEcho_newline "https://github.com/""$currentAbsoluteRepo""/releases/download/""$currentTag""/""$currentFile"

-	[[ "$currentExitStatus" != "0" ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease_procedure-address-gh: pipefail: currentExitStatus' >&2 ) > /dev/null && return "$currentExitStatus"
-    [[ "$currentTag" == "" ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease_procedure-address-gh: empty: currentTag' >&2 ) > /dev/null && return 1

-    return 0
-}
-_wget_githubRelease-address-gh() {
-	# Similar retry logic for all similar functions: _wget_githubRelease-URL-curl, _wget_githubRelease-address-gh .
-	( _messagePlain_nominal "$currentStream"'\/\/\/\/ init: _wget_githubRelease-address-gh' >&2 ) > /dev/null
-	( _messagePlain_probe_safe _wget_githubRelease-address-gh "$@" >&2 ) > /dev/null
-    ! _if_gh && return 1

-	#local currentURL
-	#currentURL=""
-	local currentTag
-	currentTag=""

-	local currentExitStatus=1

-	local currentIteration=0

-	#while ( [[ "$currentURL" == "" ]] || [[ "$currentExitStatus" != "0" ]] ) && [[ "$currentIteration" -lt "$githubRelease_retriesMax" ]]
-	while ( [[ "$currentTag" == "" ]] || [[ "$currentExitStatus" != "0" ]] ) && [[ "$currentIteration" -lt "$githubRelease_retriesMax" ]]
-	do
-		#currentURL=""
-		currentTag=""

-		if [[ "$currentIteration" != "0" ]]
-		then
-			( _messagePlain_warn 'warn: BAD: RETRY: _wget_githubRelease-address-gh: _wget_githubRelease_procedure-address-gh: currentIteration != 0' >&2 ) > /dev/null
-			sleep "$githubRelease_retriesWait"
-		fi

-		( _messagePlain_probe _wget_githubRelease_procedure-address-gh >&2 ) > /dev/null
-		#currentURL=$(_wget_githubRelease_procedure-address-gh "$@")
-		currentTag=$(_wget_githubRelease_procedure-address-gh "$@")
-		currentExitStatus="$?"

-		let currentIteration=currentIteration+1
-	done
-
-	#_safeEcho_newline "$currentURL"
-	_safeEcho_newline "$currentTag"

-	[[ "$currentIteration" -ge "$githubRelease_retriesMax" ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease-address-gh: maxRetries' >&2 ) > /dev/null && return 1

-	return 0
-}
-_wget_githubRelease-URL-gh() {
-	( _messagePlain_nominal "$currentStream"'\/\/\/\/ init: _wget_githubRelease-URL-gh' >&2 ) > /dev/null
-	( _messagePlain_probe_safe _wget_githubRelease-URL-gh "$@" >&2 ) > /dev/null
-    ! _if_gh && return 1
-
-	local currentAbsoluteRepo="$1"
-	local currentReleaseLabel="$2"
-	local currentFile="$3"

-	[[ "$currentAbsoluteRepo" == "" ]] && return 1
-	[[ "$currentReleaseLabel" == "" ]] && currentReleaseLabel="latest"
-	[[ "$currentFile" == "" ]] && return 1

-    local currentTag

-	local currentExitStatus=1

-	currentTag=$(_wget_githubRelease-address-gh "$@")
-	currentExitStatus="$?"
-

-	#echo "$currentTag"
-    _safeEcho_newline "https://github.com/""$currentAbsoluteRepo""/releases/download/""$currentTag""/""$currentFile"

-	[[ "$currentExitStatus" != "0" ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease-URL-gh: currentExitStatus' >&2 ) > /dev/null && return "$currentExitStatus"
-	[[ "$currentTag" == "" ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease-URL-gh: empty: currentTag' >&2 ) > /dev/null && return 1
-
-	return 0
-}





-# _gh_download "$currentAbsoluteRepo" "$currentTagName" "$currentFile" -O "$currentOutFile"
-# Requires "$GH_TOKEN" .
-_gh_download() {
-	# Similar retry logic for all similar functions: _gh_download , _wget_githubRelease_loop-curl .
-	( _messagePlain_nominal "$currentStream"'\/\/\/\/\/ init: _gh_download' >&2 ) > /dev/null
-
-	! _if_gh && return 1
-
-	local currentAbsoluteRepo="$1"
-	local currentTagName="$2"
+
+
+
+
+
+_wget_githubRelease-fromTag_join() {
+    local currentAbsoluteRepo="$1"
+	local currentReleaseTag="$2"
 	local currentFile="$3"

 	local currentOutParameter="$4"
-	local currentOutFileParameter="$5"
-
-	local currentOutFile="$currentFile"
+	local currentOutFile="$5"

 	shift
 	shift
 	shift
-	[[ "$currentOutParameter" == "--output" ]] && currentOutParameter="-O"
-	[[ "$currentOutParameter" == "-O" ]] && currentOutFile="$currentOutFileParameter" && shift && shift
+	[[ "$currentOutParameter" != "-O" ]] && currentOutFile="$currentFile"
+	#[[ "$currentOutParameter" == "-O" ]] && currentOutFile="$currentOutFile"

-	[[ "$currentOutParameter" == "-O" ]] && [[ "$currentOutFile" == "" ]] && _messagePlain_bad 'bad: fail: unexpected: unspecified: currentOutFile' && return 1
+	#[[ "$currentOutParameter" == "-O" ]] && [[ "$currentOutFile" == "" ]] && currentOutFile="$currentFile"
+	[[ "$currentOutParameter" == "-O" ]] && [[ "$currentOutFile" == "" ]] && ( _messagePlain_bad 'bad: fail: unexpected: unspecified: currentOutFile' >&2 ) > /dev/null && return 1
+
+	if [[ "$currentOutParameter" == "-O" ]]
+	then
+		shift
+		shift
+	fi

 	[[ "$currentOutFile" != "-" ]] && rm -f "$currentOutFile" > /dev/null 2>&1

-	# CAUTION: Assumed 'false' by 'rotten' !
-	# (ie. 'rotten' does NOT support Cygwin/MSW)
-	local currentOutFile_translated_cygwinMSW=""
-	( _if_cygwin && type -p cygpath > /dev/null 2>&1 ) && ( [[ "$currentOutFile" != "" ]] && [[ "$currentOutFile" != "-" ]] ) && currentOutFile_translated_cygwinMSW=$(cygpath -w $(_getAbsoluteLocation "$currentOutFile"))

-	local currentExitStatus=1
+	# ATTENTION
+	currentFile=$(basename "$currentFile")

-	local currentIteration
-	currentIteration=0
-	# && ( [[ "$currentIteration" != "0" ]] && sleep "$githubRelease_retriesWait" )
-	while ( [[ "$currentExitStatus" != "0" ]] || ( ! [[ -e "$currentOutFile" ]] && [[ "$currentOutFile" != "-" ]] ) ) && [[ "$currentIteration" -lt "$githubRelease_retriesMax" ]]
-	do
-		if [[ "$currentIteration" != "0" ]]
-		then
-			( _messagePlain_warn 'warn: BAD: RETRY: _gh_download: gh release download: currentIteration != 0' >&2 ) > /dev/null
-			sleep "$githubRelease_retriesWait"
-		fi

-		# CAUTION: Assumed 'false' by 'rotten' !
-		# (ie. 'rotten' does NOT support Cygwin/MSW)
-		if [[ "$currentOutFile_translated_cygwinMSW" != "" ]]
-		then
-			# WARNING: Apparently, 'gh release download' will throw an error with filename '/cygdrive'...'.m_axelTmp__'"$(_uid14)" .
-			( _messagePlain_probe_safe gh release download --clobber "$currentTagName" -R "$currentAbsoluteRepo" -p "$currentFile" -O "$currentOutFile_translated_cygwinMSW" "$@" >&2 ) > /dev/null
-			( set -o pipefail ; gh release download --clobber "$currentTagName" -R "$currentAbsoluteRepo" -p "$currentFile" -O "$currentOutFile_translated_cygwinMSW" "$@" 2> >(tail -n 30 >&2) )
-			currentExitStatus="$?"
-		else
-			( _messagePlain_probe_safe gh release download --clobber "$currentTagName" -R "$currentAbsoluteRepo" -p "$currentFile" -O "$currentOutFile" "$@" >&2 ) > /dev/null
-			( set -o pipefail ; gh release download --clobber "$currentTagName" -R "$currentAbsoluteRepo" -p "$currentFile" -O "$currentOutFile" "$@" 2> >(tail -n 30 >&2) )
-			currentExitStatus="$?"
-		fi

-		let currentIteration=currentIteration+1
-	done
-
-	[[ "$currentExitStatus" != "0" ]] && ( _messagePlain_bad 'bad: FAIL: _gh_download: gh release download: currentExitStatus' >&2 ) > /dev/null && return "$currentExitStatus"
-	! [[ -e "$currentOutFile" ]] && [[ "$currentOutFile" != "-" ]] && ( _messagePlain_bad 'bad: FAIL: missing: currentOutFile' >&2 ) > /dev/null && return 1
+
+	( _messagePlain_probe_safe _wget_githubRelease-fromTag_join "$@" >&2 ) > /dev/null
+
+	_messagePlain_probe_safe _wget_githubRelease-fromTag_join-stdout "$currentAbsoluteRepo" "$currentReleaseTag" "$currentFile" "$@" '>' "$currentOutFile" >&2
+	_wget_githubRelease-fromTag_join-stdout "$currentAbsoluteRepo" "$currentReleaseTag" "$currentFile" "$@" > "$currentOutFile"
+
+	[[ ! -e "$currentOutFile" ]] && _messagePlain_bad 'missing: '"$1"' '"$2"' '"$3" && return 1

 	return 0
 }
-#_gh_downloadURL "https://github.com/""$currentAbsoluteRepo""/releases/download/""$currentTagName""/""$currentFile" "$currentOutFile"
-# Requires "$GH_TOKEN" .
-_gh_downloadURL() {
-	( _messagePlain_nominal "$currentStream"'\/\/\/\/\/ init: _gh_downloadURL' >&2 ) > /dev/null
-
-	! _if_gh && return 1

-	# ATTRIBUTION-AI: ChatGPT GPT-4 2023-11-04 ... refactored 2025-01-22 ... .

-	local currentURL="$1"
-	local currentOutParameter="$2"
-	local currentOutFileParameter="$3"

-	[[ "$currentURL" == "" ]] && return 1

-	# Use `sed` to extract the parts of the URL
-	local currentAbsoluteRepo=$(echo "$currentURL" | sed -n 's|https://github.com/\([^/]*\)/\([^/]*\)/.*|\1/\2|p')
-	[[ "$?" != "0" ]] && return 1
-	local currentTagName=$(echo "$currentURL" | sed -n 's|https://github.com/[^/]*/[^/]*/releases/download/\([^/]*\)/.*|\1|p')
-	[[ "$?" != "0" ]] && return 1
-	local currentFile=$(echo "$currentURL" | sed -n 's|https://github.com/[^/]*/[^/]*/releases/download/[^/]*/\(.*\)|\1|p')
-	[[ "$?" != "0" ]] && return 1
+_wget_githubRelease-fromTag_join-stdout() {
+	"$scriptAbsoluteLocation" _wget_githubRelease-fromTag_join_sequence-stdout "$@"
+}
+_wget_githubRelease-fromTag_join_sequence-stdout() {
+	( _messagePlain_nominal '\/\/\/\/\/ \/\/\/\/\/ init: _wget_githubRelease-fromTag_join-stdout' >&2 ) > /dev/null
+	( _messagePlain_probe_safe _wget_githubRelease-fromTag_join-stdout "$@" >&2 ) > /dev/null

-	local currentOutFile="$currentFile"
+	local currentAbsoluteRepo="$1"
+	local currentReleaseTag="$2"
+	local currentFile="$3"
+
+	local currentOutParameter="$4"
+	local currentOutFile="$5"

 	shift
-	[[ "$currentOutParameter" == "--output" ]] && currentOutParameter="-O"
-	[[ "$currentOutParameter" == "-O" ]] && currentOutFile="$currentOutFileParameter" && shift && shift
+	shift
+	shift
+	if [[ "$currentOutParameter" == "-O" ]]
+	then
+		if [[ "$currentOutFile" != "-" ]]
+		then
+			( _messagePlain_bad 'bad: fail: unexpected: currentOutFile: NOT stdout' >&2 ) > /dev/null
+			#echo "1" > "$currentAxelTmpFile".FAIL
+			return 1
+		fi
+		shift
+		shift
+	fi

-	[[ "$currentOutParameter" == "-O" ]] && [[ "$currentOutFile" == "" ]] && _messagePlain_bad 'bad: fail: unexpected: unspecified: currentOutFile' && return 1

-	#[[ "$currentOutFile" != "-" ]] && rm -f "$currentOutFile"
+    _set_wget_githubRelease "$@"

-	local currentExitStatus=1
-	#currentExitStatus=1

-	#local currentIteration
-	#currentIteration=0
-	# && ( [[ "$currentIteration" != "0" ]] && sleep "$githubRelease_retriesWait" )
-	#while ( [[ "$currentExitStatus" != "0" ]] || ( ! [[ -e "$currentOutFile" ]] && [[ "$currentOutFile" != "-" ]] ) ) && [[ "$currentIteration" -lt "$githubRelease_retriesMax" ]]
-	#do
-		#if [[ "$currentIteration" != "0" ]]
-		#then
-			#( _messagePlain_warn 'warn: BAD: RETRY: _gh_downloadURL: _gh_download: currentIteration != 0' >&2 ) > /dev/null
-			#sleep "$githubRelease_retriesWait"
-		#fi
+    local currentPart
+    local currentSkip
+    local currentStream
+	local currentStream_wait
+	local currentBusyStatus

-		# CAUTION: Do NOT translate file parameter (ie. for Cygwin/MSW) for an underlying backend function (ie. '_gh_download') - that will be done by underlying backend function if at all. Similarly, also do NOT state '--clobber' or similar parameters to backend function.
-		#[[ "$currentOutFile" != "-" ]] && rm -f "$currentOutFile"
-		( _messagePlain_probe_safe _gh_download "$currentAbsoluteRepo" "$currentTagName" "$currentFile" -O "$currentOutFile" "$@" >&2 ) > /dev/null
-		_gh_download "$currentAbsoluteRepo" "$currentTagName" "$currentFile" -O "$currentOutFile" "$@"
-		currentExitStatus="$?"
+	# CAUTION: Any greater than 50 is not expected to serve any purpose, may exhaust expected API rate limits, may greatly delay download, and may disrupt subsequent API requests. Any less than 50 may fall below the ~100GB capacity that is both expected necessary for some complete toolchains and at the limit of ~100GB archival quality optical disc (ie. M-Disc) .
+	#local maxCurrentPart=50

-		#let currentIteration=currentIteration+1
-	#done
+	# ATTENTION: Graceful degradation to a maximum part count of 49 can be achieved by reducing API calls using the _curl_githubAPI_releases_join-skip function. That single API call can get 100 results, leaving 49 unused API calls remaining to get API_URL addresses to download 49 parts. Files larger than ~200GB are likely rare, specialized.
+	#local maxCurrentPart=98

-	[[ "$currentExitStatus" != "0" ]] && ( _messagePlain_bad 'bad: FAIL: _gh_downloadURL: _gh_download: currentExitStatus' >&2 ) > /dev/null && return "$currentExitStatus"
-	! [[ -e "$currentOutFile" ]] && [[ "$currentOutFile" != "-" ]] && ( _messagePlain_bad 'bad: FAIL: missing: currentOutFile' >&2 ) > /dev/null && return 1
+	# ATTENTION: In practice, 128GB storage media - reputable brand BD-XL near-archival quality optical disc, SSDs, etc - is the maximum file size that is convenient.
+	# '1997537280' bytes truncate/tail
+	# https://en.wikipedia.org/wiki/Blu-ray
+	#  '128,001,769,472' ... 'Bytes'
+	# https://fy.chalmers.se/~appro/linux/DVD+RW/Blu-ray/
+	#  'only inner spare area of 256MB'
+	local maxCurrentPart=63

-	return 0
-}

+    local currentExitStatus=1



+    (( [[ "$FORCE_BUFFER" == "true" ]] && [[ "$FORCE_DIRECT" == "true" ]] ) || ( [[ "$FORCE_BUFFER" == "false" ]] && [[ "$FORCE_DIRECT" == "false" ]] )) && ( _messagePlain_bad 'bad: fail: FORCE_BUFFER , FORCE_DIRECT: conflict' >&2 ) > /dev/null && ( _messageError 'FAIL' >&2 ) > /dev/null && exit 1

+	[[ "$FORCE_PARALLEL" == "1" ]] && ( _messagePlain_bad 'bad: fail: FORCE_PARALLEL: sanity' >&2 ) > /dev/null && ( _messageError 'FAIL' >&2 ) > /dev/null && exit 1
+	[[ "$FORCE_PARALLEL" == "0" ]] && ( _messagePlain_bad 'bad: fail: FORCE_PARALLEL: sanity' >&2 ) > /dev/null && ( _messageError 'FAIL' >&2 ) > /dev/null && exit 1
+
+    [[ "$FORCE_AXEL" != "" ]] && [[ "$FORCE_DIRECT" == "true" ]] && ( _messagePlain_bad 'bad: fail: FORCE_AXEL is NOT compatible with FORCE_DIRECT==true' >&2 ) > /dev/null && ( _messageError 'FAIL' >&2 ) > /dev/null && exit 1

-#_wget_githubRelease-stdout
+    [[ "$FORCE_AXEL" != "" ]] && ( _messagePlain_warn 'warn: WARNING: FORCE_AXEL not empty' >&2 ; echo 'FORCE_AXEL may have similar effects to FORCE_WGET and should not be necessary.' >&2  ) > /dev/null

-#_wget_githubRelease


+    _if_buffer() {
+        if ( [[ "$FORCE_BUFFER" == "true" ]] || [[ "$FORCE_DIRECT" == "false" ]] ) || [[ "$FORCE_BUFFER" == "" ]]
+        then
+            true
+            return
+        else
+            false
+            return
+        fi
+        true
+        return
+    }

-_wget_githubRelease-stdout() {
-	( _messagePlain_nominal "$currentStream"'\/\/\/\/\/ \/\/\/\/\/ init: _wget_githubRelease-stdout' >&2 ) > /dev/null
-	local currentAxelTmpFileRelative=.m_axelTmp_"$currentStream"_$(_uid 14)
-	local currentAxelTmpFile="$scriptAbsoluteFolder"/"$currentAxelTmpFileRelative"
-
-	local currentExitStatus

-	# WARNING: Very strongly discouraged. Any retry/continue of any interruption will nevertheless unavoidably result in a corrupted output stream.
-	[[ "$FORCE_DIRECT" == "true" ]] && _wget_githubRelease_procedure-stdout "$@"
+
+    # WARNING: FORCE_DIRECT="true" , "FORCE_BUFFER="false" very strongly discouraged. Any retry/continue of any interruption will nevertheless unavoidably result in a corrupted output stream.
+    if ! _if_buffer
+    then
+        #export FORCE_DIRECT="true"

-	# ATTENTION: /dev/null assures that stdout is not corrupted by any unexpected output that should have been sent to stderr
-	[[ "$FORCE_DIRECT" != "true" ]] && _wget_githubRelease_procedure-stdout "$@" > /dev/null
+        _set_wget_githubRelease-detect "$@"
+        currentSkip="skip"

-	if ! [[ -e "$currentAxelTmpFile".PASS ]]
+        currentStream="noBuf"
+        #local currentAxelTmpFileRelative=.m_axelTmp_"$currentStream"_$(_uid 14)
+	    #local currentAxelTmpFile="$scriptAbsoluteFolder"/"$currentAxelTmpFileRelative"
+
+		maxCurrentPart=$(_curl_githubAPI_releases_fromTag_join-skip "$currentAbsoluteRepo" "$currentReleaseTag" "$currentFile")
+
+        currentPart=""
+        for currentPart in $(seq -f "%02g" 0 "$maxCurrentPart" | sort -r)
+        do
+            if [[ "$currentSkip" == "skip" ]]
+            then
+				# ATTENTION: Could expect to use the 'API_URL' function in both cases, since we are not using the resulting URL except to 'skip'/'download' .
+				#currentSkip=$(_wget_githubRelease-skip-API_URL-curl "$currentAbsoluteRepo" "$currentReleaseTag" "$currentFile".part"$currentPart")
+				[[ "$GH_TOKEN" != "" ]] && currentSkip=$(_wget_githubRelease-skip-API_URL_fromTag-curl "$currentAbsoluteRepo" "$currentReleaseTag" "$currentFile".part"$currentPart")
+				[[ "$GH_TOKEN" == "" ]] && currentSkip=$(_wget_githubRelease-skip-URL_fromTag-curl "$currentAbsoluteRepo" "$currentReleaseTag" "$currentFile".part"$currentPart")
+                #[[ "$?" != "0" ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease-skip-API_URL-curl' >&2 ) > /dev/null && ( _messageError 'FAIL' >&2 ) > /dev/null && exit 1
+                #[[ "$?" != "0" ]] && currentSkip="skip"
+                [[ "$?" != "0" ]] && ( _messagePlain_warn 'bad: FAIL: _wget_githubRelease-skip-API_URL_fromTag-curl' >&2 ) > /dev/null
+            fi
+
+            [[ "$currentSkip" == "skip" ]] && continue
+
+
+            if [[ "$currentExitStatus" == "0" ]] || [[ "$currentSkip" != "skip" ]]
+            then
+                _set_wget_githubRelease "$@"
+                currentSkip="download"
+            fi
+
+
+            _wget_githubRelease-fromTag_procedure "$currentAbsoluteRepo" "$currentReleaseTag" "$currentFile".part"$currentPart" -O - "$@"
+            currentExitStatus="$?"
+            #[[ "$currentExitStatus" != "0" ]] && break
+        done
+
+        return "$currentExitStatus"
+    fi
+
+
+
+
+
+	# ### ATTENTION: _if_buffer (IMPLICIT)
+
+	# NOTICE: Parallel downloads may, if necessary, be adapted to first cache a list of addresses (ie. URLs) to download. API rate limits could then have as much time as possible to recover before subsequent commands (eg. analysis of builds). Such a cache must be filled with addresses BEFORE the download loop.
+
+
+	export currentAxelTmpFileUID="$(_uid 14)"
+	_axelTmp() {
+		echo .m_axelTmp_"$currentStream"_"$currentAxelTmpFileUID"
+	}
+	local currentAxelTmpFile
+	#currentAxelTmpFile="$scriptAbsoluteFolder"/$(_axelTmp)
+
+	local currentStream_min=1
+	local currentStream_max=3
+	[[ "$FORCE_PARALLEL" != "" ]] && currentStream_max="$FORCE_PARALLEL"
+
+	currentStream="$currentStream_min"
+
+
+	currentPart="$maxCurrentPart"
+
+
+	_set_wget_githubRelease-detect "$@"
+	currentSkip="skip"
+
+	maxCurrentPart=$(_curl_githubAPI_releases_fromTag_join-skip "$currentAbsoluteRepo" "$currentReleaseTag" "$currentFile")
+
+	currentPart=""
+	for currentPart in $(seq -f "%02g" 0 "$maxCurrentPart" | sort -r)
+	do
+		if [[ "$currentSkip" == "skip" ]]
+		then
+			# ATTENTION: EXPERIMENT
+			# ATTENTION: Could expect to use the 'API_URL' function in both cases, since we are not using the resulting URL except to 'skip'/'download' .
+			#currentSkip=$(_wget_githubRelease-skip-API_URL-curl "$currentAbsoluteRepo" "$currentReleaseTag" "$currentFile".part"$currentPart")
+			##currentSkip=$([[ "$currentPart" -gt "17" ]] && echo 'skip' ; true)
+			[[ "$GH_TOKEN" != "" ]] && currentSkip=$(_wget_githubRelease-skip-API_URL_fromTag-curl "$currentAbsoluteRepo" "$currentReleaseTag" "$currentFile".part"$currentPart")
+			[[ "$GH_TOKEN" == "" ]] && currentSkip=$(_wget_githubRelease-skip-URL_fromTag-curl "$currentAbsoluteRepo" "$currentReleaseTag" "$currentFile".part"$currentPart")
+
+			#[[ "$?" != "0" ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease-skip-API_URL-curl' >&2 ) > /dev/null && ( _messageError 'FAIL' >&2 ) > /dev/null && exit 1
+			#[[ "$?" != "0" ]] && currentSkip="skip"
+			[[ "$?" != "0" ]] && ( _messagePlain_warn 'bad: FAIL: _wget_githubRelease-skip-API_URL_fromTag-curl' >&2 ) > /dev/null
+		fi
+
+		[[ "$currentSkip" == "skip" ]] && continue
+
+		#[[ "$currentExitStatus" == "0" ]] ||
+		if [[ "$currentSkip" != "skip" ]]
+		then
+			_set_wget_githubRelease "$@"
+			currentSkip="download"
+			break
+		fi
+	done
+
+	export currentSkipPart="$currentPart"
+	[[ "$currentStream_max" -gt "$currentSkipPart" ]] && currentStream_max=$(( "$currentSkipPart" + 1 ))
+
+	"$scriptAbsoluteLocation" _wget_githubRelease-fromTag_join_sequence-parallel "$currentAbsoluteRepo" "$currentReleaseTag" "$currentFile" &
+
+
+	# Prebuffer .
+	( _messagePlain_nominal '\/\/\/\/\/ \/\/\/\/  preBUFFER: WAIT  ...  currentPart='"$currentPart" >&2 ) > /dev/null
+	if [[ "$currentPart" -ge "01" ]] && [[ "$currentStream_max" -ge "2" ]]
 	then
-		currentExitStatus=$(cat "$currentAxelTmpFile".FAIL)
-		( [[ "$currentExitStatus" == "" ]] || [[ "$currentExitStatus" = "0" ]] || [[ "$currentExitStatus" = "0"* ]] ) && currentExitStatus=1
-		rm -f "$currentAxelTmpFile".PASS > /dev/null 2>&1
-		rm -f "$currentAxelTmpFile".FAIL > /dev/null 2>&1
-		rm -f "$currentAxelTmpFile" > /dev/null 2>&1
-		return "$currentExitStatus"
-		#return 1
+		#currentStream="2"
+		for currentStream in $(seq "$currentStream_min" "$currentStream_max" | sort -r)
+		do
+			( _messagePlain_probe 'prebuffer: currentStream= '"$currentStream" >&2 ) > /dev/null
+			while ( ! [[ -e "$scriptAbsoluteFolder"/$(_axelTmp).PASS ]] && ! [[ -e "$scriptAbsoluteFolder"/$(_axelTmp).FAIL ]] )
+			do
+				sleep 3
+			done
+		done
 	fi
-	[[ "$FORCE_DIRECT" != "true" ]] && cat "$currentAxelTmpFile"
-	rm -f "$currentAxelTmpFile" > /dev/null 2>&1
-	rm -f "$currentAxelTmpFile".PASS > /dev/null 2>&1
-	rm -f "$currentAxelTmpFile".FAIL > /dev/null 2>&1
-	return 0
+	currentStream="$currentStream_min"
+
+
+	for currentPart in $(seq -f "%02g" 0 "$currentSkipPart" | sort -r)
+	do
+	( _messagePlain_nominal '\/\/\/\/\/ \/\/\/\/  outputLOOP  ...  currentPart='"$currentPart"' currentStream='"$currentStream" >&2 ) > /dev/null
+	#( _messagePlain_probe_var currentPart >&2 ) > /dev/null
+	#( _messagePlain_probe_var currentStream >&2 ) > /dev/null
+
+		# Stream must have written PASS/FAIL file .
+		( _messagePlain_nominal '\/\/\/\/\/ \/\/\/  outputLOOP: WAIT: PASS/FAIL ... currentPart='"$currentPart"' currentStream='"$currentStream" >&2 ) > /dev/null
+		while ! [[ -e "$scriptAbsoluteFolder"/$(_axelTmp).busy ]] || ( ! [[ -e "$scriptAbsoluteFolder"/$(_axelTmp).PASS ]] && ! [[ -e "$scriptAbsoluteFolder"/$(_axelTmp).FAIL ]] )
+		do
+			sleep 1
+		done
+
+		( _messagePlain_nominal '\/\/\/\/\/ \/\/\/  outputLOOP: OUTPUT  ...  currentPart='"$currentPart"' currentStream='"$currentStream" >&2 ) > /dev/null
+		# ATTENTION: EXPERIMENT
+		#status=none
+		dd if="$scriptAbsoluteFolder"/$(_axelTmp) bs=1M
+		#cat "$scriptAbsoluteFolder"/$(_axelTmp)
+		#dd if="$scriptAbsoluteFolder"/$(_axelTmp) bs=1M | pv --rate-limit 100M 2>/dev/null
+		[[ -e "$scriptAbsoluteFolder"/$(_axelTmp).PASS ]] && currentSkip="download"
+		[[ -e "$scriptAbsoluteFolder"/$(_axelTmp).FAIL ]] && [[ "$currentSkip" != "skip" ]] && ( _messageError 'FAIL' >&2 ) > /dev/null && return 1
+
+		( _messagePlain_nominal '\/\/\/\/\/ \/\/\/  outputLOOP: DELETE  ...  currentPart='"$currentPart"' currentStream='"$currentStream" >&2 ) > /dev/null
+		rm -f "$scriptAbsoluteFolder"/$(_axelTmp) > /dev/null 2>&1
+		rm -f "$scriptAbsoluteFolder"/$(_axelTmp).busy > /dev/null 2>&1
+
+		let currentStream=currentStream+1
+		[[ "$currentStream" -gt "$currentStream_max" ]] && currentStream="$currentStream_min"
+	done
+
+	true
+}
+_wget_githubRelease-fromTag_join_sequence-parallel() {
+	local currentAbsoluteRepo="$1"
+	local currentReleaseTag="$2"
+	local currentFile="$3"
+
+	local currentOutParameter="$4"
+	local currentOutFile="$5"
+
+	shift
+	shift
+	shift
+	if [[ "$currentOutParameter" == "-O" ]]
+	then
+		if [[ "$currentOutFile" != "-" ]]
+		then
+			( _messagePlain_bad 'bad: fail: unexpected: currentOutFile: NOT stdout' >&2 ) > /dev/null
+			#echo "1" > "$currentAxelTmpFile".FAIL
+			return 1
+		fi
+		shift
+		shift
+	fi
+
+
+	#export currentAxelTmpFileUID="$(_uid 14)"
+	_axelTmp() {
+		echo .m_axelTmp_"$currentStream"_"$currentAxelTmpFileUID"
+	}
+	#local currentAxelTmpFile
+	#currentAxelTmpFile="$scriptAbsoluteFolder"/$(_axelTmp)
+
+	# Due to parallelism , only API rate limits, NOT download speeds, are a concern with larger number of retries.
+	_set_wget_githubRelease "$@"
+	#_set_wget_githubRelease-detect "$@"
+	#_set_wget_githubRelease-detect-parallel "$@"
+	local currentSkip="skip"
+
+	local currentStream_min=1
+	local currentStream_max=3
+	[[ "$FORCE_PARALLEL" != "" ]] && currentStream_max="$FORCE_PARALLEL"
+	[[ "$currentStream_max" -gt "$currentSkipPart" ]] && currentStream_max=$(( "$currentSkipPart" + 1 ))
+
+	currentStream="$currentStream_min"
+	for currentPart in $(seq -f "%02g" 0 "$currentSkipPart" | sort -r)
+	do
+	( _messagePlain_nominal '\/\/\/\/\/ \/\/\/\/  downloadLOOP  ...  currentPart='"$currentPart"' currentStream='"$currentStream" >&2 ) > /dev/null
+	#( _messagePlain_probe_var currentPart >&2 ) > /dev/null
+	#( _messagePlain_probe_var currentStream >&2 ) > /dev/null
+
+		# Slot in use. Downloaded  "$scriptAbsoluteFolder"/$(_axelTmp)  file will be DELETED after use by calling process.
+		( _messagePlain_nominal '\/\/\/\/\/ \/\/\/  downloadLOOP: WAIT: BUSY  ...  currentPart='"$currentPart"' currentStream='"$currentStream" >&2 ) > /dev/null
+		while ( ls -1 "$scriptAbsoluteFolder"/$(_axelTmp) > /dev/null 2>&1 ) || ( ls -1 "$scriptAbsoluteFolder"/$(_axelTmp).busy > /dev/null 2>&1 )
+		do
+		( _messagePlain_nominal '\/\/\/\/\/ \/\/\/  downloadLOOP: WAIT: BUSY  ...  currentPart='"$currentPart"' currentStream='"$currentStream" >&2 ) > /dev/null
+			sleep 1
+		done
+
+		( _messagePlain_nominal '\/\/\/\/\/ \/\/\/  downloadLOOP: detect skip  ...  currentPart='"$currentPart"' currentStream='"$currentStream" >&2 ) > /dev/null
+		[[ -e "$scriptAbsoluteFolder"/$(_axelTmp).PASS ]] && _set_wget_githubRelease "$@" && currentSkip="download"
+		[[ -e "$scriptAbsoluteFolder"/$(_axelTmp).FAIL ]] && [[ "$currentSkip" != "skip" ]] && ( _messageError 'FAIL' >&2 ) > /dev/null && return 1
+
+		( _messagePlain_nominal '\/\/\/\/\/ \/\/\/  downloadLOOP: DELETE  ...  currentPart='"$currentPart"' currentStream='"$currentStream" >&2 ) > /dev/null
+		rm -f "$scriptAbsoluteFolder"/$(_axelTmp).PASS > /dev/null 2>&1
+		rm -f "$scriptAbsoluteFolder"/$(_axelTmp).FAIL > /dev/null 2>&1
+
+		( _messagePlain_nominal '\/\/\/\/\/ \/\/\/  downloadLOOP: DELAY: stagger, Inter-Process Communication, _stop  ...  currentPart='"$currentPart"' currentStream='"$currentStream" >&2 ) > /dev/null
+		# Staggered Delay.
+		[[ "$currentPart" == "$currentSkipPart" ]] && sleep 2
+		[[ "$currentPart" != "$currentSkipPart" ]] && sleep 6
+		# Inter-Process Communication Delay.
+		# Prevents new download from starting before previous download process has done  rm -f "$currentAxelTmpFile"*  .
+		#  Beware that  rm  is inevitable or at least desirable - called by _stop() through trap, etc.
+		sleep 7
+
+		( _messagePlain_nominal '\/\/\/\/\/ \/\/\/  downloadLOOP: DOWNLOAD  ...  currentPart='"$currentPart"' currentStream='"$currentStream" >&2 ) > /dev/null
+		export currentAxelTmpFile="$scriptAbsoluteFolder"/$(_axelTmp)
+		"$scriptAbsoluteLocation" _wget_githubRelease-fromTag_procedure-join "$currentAbsoluteRepo" "$currentReleaseTag" "$currentFile".part$(printf "%02g" "$currentPart") &
+		echo "$!" > "$scriptAbsoluteFolder"/$(_axelTmp).pid
+
+		# Stream must have written either in-progress download or PASS/FAIL file .
+		( _messagePlain_nominal '\/\/\/\/\/ \/\/\/  downloadLOOP: WAIT: BEGIN  ...  currentPart='"$currentPart"' currentStream='"$currentStream" >&2 ) > /dev/null
+		while ! ( ls -1 "$scriptAbsoluteFolder"/$(_axelTmp)* > /dev/null 2>&1 )
+		do
+		( _messagePlain_nominal '\/\/\/\/\/ \/\/\/  downloadLOOP: WAIT: BEGIN  ...  currentPart='"$currentPart"' currentStream='"$currentStream" >&2 ) > /dev/null
+			sleep 0.6
+		done
+
+		let currentStream=currentStream+1
+		[[ "$currentStream" -gt "$currentStream_max" ]] && currentStream="$currentStream_min"
+	done
+
+	( _messagePlain_nominal '\/\/\/\/\/ \/\/\/\/  download: DELETE' >&2 ) > /dev/null
+	for currentStream in $(seq "$currentStream_min" "$currentStream_max")
+	do
+		( _messagePlain_nominal '\/\/\/\/\/ \/\/\/  download: WAIT: BUSY  ...  currentStream='"$currentStream" >&2 ) > /dev/null
+		while ( ls -1 "$scriptAbsoluteFolder"/$(_axelTmp) > /dev/null 2>&1 ) || ( ls -1 "$scriptAbsoluteFolder"/$(_axelTmp).busy > /dev/null 2>&1 )
+		do
+		( _messagePlain_nominal '\/\/\/\/\/ \/\/\/  download: WAIT: BUSY  ...  currentStream='"$currentStream" >&2 ) > /dev/null
+			sleep 1
+		done
+
+		( _messagePlain_nominal '\/\/\/\/\/ \/\/\/  download: DELETE ...  currentStream='"$currentStream" >&2 ) > /dev/null
+		rm -f "$scriptAbsoluteFolder"/$(_axelTmp).PASS > /dev/null 2>&1
+		rm -f "$scriptAbsoluteFolder"/$(_axelTmp).FAIL > /dev/null 2>&1
+	done
+
+	( _messagePlain_nominal '\/\/\/\/\/ \/\/\/\/  download: WAIT PID  ...  currentPart='"$currentPart"' currentStream='"$currentStream" >&2 ) > /dev/null
+	for currentStream in $(seq "$currentStream_min" "$currentStream_max")
+	do
+		[[ -e "$scriptAbsoluteFolder"/$(_axelTmp).pid ]] && _pauseForProcess $(cat "$scriptAbsoluteFolder"/$(_axelTmp).pid) > /dev/null
+	done
+	wait >&2
+
+	true
 }
-_wget_githubRelease_procedure-stdout() {
-	( _messagePlain_probe_safe _wget_githubRelease_procedure-stdout "$@" >&2 ) > /dev/null
+_wget_githubRelease-fromTag_procedure-join() {
+	( _messagePlain_probe_safe _wget_githubRelease-fromTag_procedure-join "$@" >&2 ) > /dev/null

 	local currentAbsoluteRepo="$1"
-	local currentReleaseLabel="$2"
+	local currentReleaseTag="$2"
 	local currentFile="$3"

 	local currentOutParameter="$4"
@@ -28574,304 +35409,88 @@ _wget_githubRelease_procedure-stdout() {

 	local currentExitStatus

-	# WARNING: Very strongly discouraged. Any retry/continue of any interruption will nevertheless unavoidably result in a corrupted output stream.
-	if [[ "$FORCE_DIRECT" == "true" ]]
-	then
-		_wget_githubRelease_procedure "$currentAbsoluteRepo" "$currentReleaseLabel" "$currentFile" -O - "$@"
-		currentExitStatus="$?"
-		if [[ "$currentExitStatus" != "0" ]]
-		then
-			echo > "$currentAxelTmpFile".FAIL
-			return "$currentExitStatus"
-		fi
-		echo > "$currentAxelTmpFile".PASS
-		return 0
-	fi
+	echo -n > "$currentAxelTmpFile".busy

-	_wget_githubRelease_procedure "$currentAbsoluteRepo" "$currentReleaseLabel" "$currentFile" -O "$currentAxelTmpFile" "$@"
+	# ATTENTION: EXPERIMENT
+	_wget_githubRelease-fromTag_procedure "$currentAbsoluteRepo" "$currentReleaseTag" "$currentFile" -O "$currentAxelTmpFile" "$@"
+    #dd if=/dev/zero bs=1M count=1500 > "$currentAxelTmpFile"
+	#echo "$currentFile" >> "$currentAxelTmpFile"
+    #dd if=/dev/urandom bs=1M count=1500 | pv --rate-limit 300M 2>/dev/null > "$currentAxelTmpFile"
 	currentExitStatus="$?"
+
+	# Inter-Process Communication Delay
+	# Essentially a 'minimum download time' .
+	sleep 7
+
+	[[ "$currentExitStatus" == "0" ]] && echo "$currentExitStatus" > "$currentAxelTmpFile".PASS
 	if [[ "$currentExitStatus" != "0" ]]
 	then
+		echo -n > "$currentAxelTmpFile"
 		echo "$currentExitStatus" > "$currentAxelTmpFile".FAIL
-		return "$currentExitStatus"
 	fi
-	echo > "$currentAxelTmpFile".PASS
-	return 0
+
+    while [[ -e "$currentAxelTmpFile" ]] || [[ -e "$currentAxelTmpFile".busy ]] || [[ -e "$currentAxelTmpFile".PASS ]] || [[ -e "$currentAxelTmpFile".FAIL ]]
+    do
+        sleep 1
+    done
+
+    [[ "$currentAxelTmpFile" != "" ]] && rm -f "$currentAxelTmpFile".*
+
+    #unset currentAxelTmpFile
+
+    [[ "$currentExitStatus" == "0" ]] && return 0
+    return "$currentExitStatus"
 }





-#! "$scriptAbsoluteLocation" _wget_githubRelease_join "owner/repo" "internal" "file.ext" -O "file.ext"
-#! _wget_githubRelease "owner/repo" "" "file.ext" -O "file.ext"
-# ATTENTION: WARNING: Warn messages correspond to inability to assuredly, effectively, use GH_TOKEN .
-_wget_githubRelease() {
-	( _messagePlain_nominal "$currentStream"'\/\/\/\/\/ \/\/\/\/\/ init: _wget_githubRelease' >&2 ) > /dev/null
-	( _messagePlain_probe_safe _wget_githubRelease "$@" >&2 ) > /dev/null

-	_wget_githubRelease_procedure "$@"
-}
-_wget_githubRelease_internal() {
-	_wget_githubRelease "$1" "internal" "$2"
-}
-_wget_githubRelease_procedure() {
-	# ATTENTION: Distinction nominally between '_wget_githubRelease' and '_wget_githubRelease_procedure' should only be necessary if a while loop retries the procedure .
-	# ATTENTION: Potentially more specialized logic within download procedures should remain delegated with the responsibility to attempt retries , for now.
-	# NOTICE: Several functions should already have retry logic: '_gh_download' , '_gh_downloadURL' , '_wget_githubRelease-address' , '_wget_githubRelease_procedure-curl' , '_wget_githubRelease-URL-curl' , etc .
-	#( _messagePlain_nominal "$currentStream"'\/\/\/\/\/ \/\/\/\/ init: _wget_githubRelease_procedure' >&2 ) > /dev/null
-	#( _messagePlain_probe_safe _wget_githubRelease_procedure "$@" >&2 ) > /dev/null

-    local currentAbsoluteRepo="$1"
-	local currentReleaseLabel="$2"
-	local currentFile="$3"

-	local currentOutParameter="$4"
-	local currentOutFile="$5"

-	shift
-	shift
-	shift
-	[[ "$currentOutParameter" != "-O" ]] && currentOutFile="$currentFile"
-	#[[ "$currentOutParameter" == "-O" ]] && currentOutFile="$currentOutFile"

-	#[[ "$currentOutParameter" == "-O" ]] && [[ "$currentOutFile" == "" ]] && currentOutFile="$currentFile"
-	[[ "$currentOutParameter" == "-O" ]] && [[ "$currentOutFile" == "" ]] && ( _messagePlain_bad 'bad: fail: unexpected: unspecified: currentOutFile' >&2 ) > /dev/null && return 1

-	[[ "$currentOutFile" != "-" ]] && rm -f "$currentOutFile" > /dev/null 2>&1

-    local currentExitStatus=1

-    # Discouraged .
-    if [[ "$FORCE_WGET" == "true" ]]
-    then
-        _warn_githubRelease_FORCE_WGET
-        local currentURL=$(_wget_githubRelease-URL-curl "$currentAbsoluteRepo" "$currentReleaseLabel" "$currentFile")

-        #"$GH_TOKEN"
-        #"$currentAbsoluteRepo" "$currentReleaseLabel" "$currentFile" "$currentOutFile"
-        #_wget_githubRelease_procedure-curl
-		_wget_githubRelease_loop-curl
-        return "$?"
-    fi

-	# Discouraged . Benefits of multi-part-per-file downloading are less essential given that files are split into <2GB chunks.
-	if [[ "$FORCE_AXEL" != "" ]] # && [[ "$MANDATORY_HASH" == "true" ]]
-    then
-        ( _messagePlain_warn 'warn: WARNING: FORCE_AXEL not empty' >&2 ; echo 'FORCE_AXEL may have similar effects to FORCE_WGET and should not be necessary.' >&2  ) > /dev/null
-        local currentURL=$(_wget_githubRelease-URL-curl "$currentAbsoluteRepo" "$currentReleaseLabel" "$currentFile")

-		[[ "$FORCE_DIRECT" == "true" ]] && ( _messagePlain_bad 'bad: fail: FORCE_AXEL==true is NOT compatible with FORCE_DIRECT==true' >&2 ) > /dev/null && return 1

-        #"$GH_TOKEN"
-        #"$currentAbsoluteRepo" "$currentReleaseLabel" "$currentFile" "$currentOutFile"
-        #_wget_githubRelease_procedure-axel
-		_wget_githubRelease_loop-axel
-        return "$?"
-    fi

-    if _if_gh
-    then
-        #_wget_githubRelease-address-gh
-        local currentTag=$(_wget_githubRelease-address "$currentAbsoluteRepo" "$currentReleaseLabel" "$currentFile")

-        ( _messagePlain_probe _gh_download "$currentAbsoluteRepo" "$currentTag" "$currentFile" "$@" >&2 ) > /dev/null
-        _gh_download "$currentAbsoluteRepo" "$currentTag" "$currentFile" "$@"
-        currentExitStatus="$?"

-        [[ "$currentExitStatus" != "0" ]] && _bad_fail_githubRelease_currentExitStatus && return "$currentExitStatus"
-        [[ ! -e "$currentOutFile" ]] && [[ "$currentOutFile" != "-" ]] && _bad_fail_githubRelease_missing && return 1
-        return 0
-    fi

-    if ! _if_gh
-    then
-        ( _messagePlain_warn 'warn: WARNING: FALLBACK: wget/curl' >&2 ) > /dev/null
-        local currentURL=$(_wget_githubRelease-URL-curl "$currentAbsoluteRepo" "$currentReleaseLabel" "$currentFile")

-        #"$GH_TOKEN"
-        #"$currentAbsoluteRepo" "$currentReleaseLabel" "$currentFile" "$currentOutFile"
-        #_wget_githubRelease_procedure-curl
-		_wget_githubRelease_loop-curl
-        return "$?"
-    fi
-
-    return 1
-}
-_wget_githubRelease_procedure-curl() {
-	( _messagePlain_nominal "$currentStream"'\/\/\/\/\/ \/\/\/ init: _wget_githubRelease_procedure-curl' >&2 ) > /dev/null
-    ( _messagePlain_probe_safe "currentURL= ""$currentURL" >&2 ) > /dev/null
-    ( _messagePlain_probe_safe "currentOutFile= ""$currentOutFile" >&2 ) > /dev/null

-	# ATTENTION: Better if the loop does this only once. Resume may be possible.
-	#[[ "$currentOutFile" != "-" ]] && rm -f "$currentOutFile" > /dev/null 2>&1

-    local current_curl_args
-	current_curl_args=()
-	[[ "$GH_TOKEN" != "" ]] && current_curl_args+=( -H "Authorization: Bearer $GH_TOKEN" )
-	current_curl_args+=( -S )
-	current_curl_args+=( -s )
-	#current_curl_args+=( --clobber )
-	current_curl_args+=( --continue-at - )
-
-	local currentExitStatus_ipv4=1
-	local currentExitStatus_ipv6=1

-	( _messagePlain_probe '_wget_githubRelease_procedure-curl: IPv6 (false)' >&2 ) > /dev/null
-	# ATTENTION: IPv6 is NOT offered by GitHub API, and so usually only wastes time at best.
-	#curl -6 "${current_curl_args[@]}" -L -o "$currentOutFile" "$currentURL"
-	false
-	# WARNING: May be untested.
-	#( set -o pipefail ; curl -6 "${current_curl_args[@]}" -L -o "$currentOutFile" "$currentURL" 2> >(tail -n 30 >&2) )
-	currentExitStatus_ipv6="$?"
-	if [[ "$currentExitStatus_ipv6" != "0" ]]
-	then
-		( _messagePlain_probe '_wget_githubRelease_procedure-curl: IPv4' >&2 ) > /dev/null
-		curl -4 "${current_curl_args[@]}" -L -o "$currentOutFile" "$currentURL"
-		# WARNING: May be untested.
-		#( set -o pipefail ; curl -4 "${current_curl_args[@]}" -L -o "$currentOutFile" "$currentURL" 2> >(tail -n 30 >&2) )
-		currentExitStatus_ipv4="$?"
-	fi

-	if [[ "$currentExitStatus_ipv6" != "0" ]] && [[ "$currentExitStatus_ipv4" != "0" ]]
-	then
-		#( _messagePlain_bad 'bad: FAIL: _wget_githubRelease_procedure-curl' >&2 ) > /dev/null
-        _bad_fail_githubRelease_currentExitStatus
-		[[ "$currentExitStatus_ipv4" != "1" ]] && [[ "$currentExitStatus_ipv4" != "0" ]] && return "$currentExitStatus_ipv4"
-		[[ "$currentExitStatus_ipv6" != "1" ]] && [[ "$currentExitStatus_ipv6" != "0" ]] && return "$currentExitStatus_ipv6"
-		return "$currentExitStatus_ipv4"
-	fi

-    [[ ! -e "$currentOutFile" ]] && [[ "$currentOutFile" != "-" ]] && _bad_fail_githubRelease_missing && return 1

-    return 0
-}
-_wget_githubRelease_loop-curl() {
-	# Similar retry logic for all similar functions: _gh_download , _wget_githubRelease_loop-curl .
-	( _messagePlain_nominal "$currentStream"'\/\/\/\/\/ \/\/\/\/ init: _wget_githubRelease_loop-curl' >&2 ) > /dev/null
-	( _messagePlain_probe_safe _wget_githubRelease_loop-curl "$@" >&2 ) > /dev/null

-	[[ "$currentOutFile" != "-" ]] && rm -f "$currentOutFile" > /dev/null 2>&1

-	local currentExitStatus=1

-	local currentIteration=0

-	while ( [[ "$currentExitStatus" != "0" ]] || ( ! [[ -e "$currentOutFile" ]] && [[ "$currentOutFile" != "-" ]] ) ) && [[ "$currentIteration" -lt "$githubRelease_retriesMax" ]]
-	do
-		if [[ "$currentIteration" != "0" ]]
-		then
-			( _messagePlain_warn 'warn: BAD: RETRY: _wget_githubRelease_procedure-curl: currentIteration != 0' >&2 ) > /dev/null
-			sleep "$githubRelease_retriesWait"
-		fi

-		( _messagePlain_probe_safe _wget_githubRelease_procedure-curl >&2 ) > /dev/null
-		_wget_githubRelease_procedure-curl
-		# WARNING: May be untested.
-		#( set -o pipefail ; _wget_githubRelease_procedure-curl 2> >(tail -n 100 >&2) )
-		currentExitStatus="$?"

-		let currentIteration=currentIteration+1
-	done
-
-	[[ "$currentExitStatus" != "0" ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease_loop-curl: _wget_githubRelease_procedure-curl: currentExitStatus' >&2 ) > /dev/null && return "$currentExitStatus"
-	! [[ -e "$currentOutFile" ]] && [[ "$currentOutFile" != "-" ]] && ( _messagePlain_bad 'bad: FAIL: missing: currentOutFile' >&2 ) > /dev/null && return 1

-	return 0
-}
-_wget_githubRelease_procedure-axel() {
-	( _messagePlain_nominal "$currentStream"'\/\/\/\/\/ \/\/\/ init: _wget_githubRelease_procedure-axel' >&2 ) > /dev/null
-    ( _messagePlain_probe_safe "currentURL= ""$currentURL" >&2 ) > /dev/null
-    ( _messagePlain_probe_safe "currentOutFile= ""$currentOutFile" >&2 ) > /dev/null

-    # ATTENTION: Quirk of aria2c , default dir is "$PWD" , is prepended to absolute paths , and the resulting '//' does not direct the absolute path to root.
-    local currentOutFile_relative=$(basename "$currentOutFile")
-    local currentOutDir=$(_getAbsoluteFolder "$currentOutFile")
-    ( _messagePlain_probe_safe "currentOutFile_relative= ""$currentOutFile_relative" >&2 ) > /dev/null
-    ( _messagePlain_probe_safe "currentOutDir= ""$currentOutFile" >&2 ) > /dev/null

-    ( _messagePlain_probe_safe "FORCE_AXEL= ""$FORCE_AXEL" >&2 ) > /dev/null

-	# ATTENTION: Better if the loop does this only once. Resume may be possible.
-	#[[ "$currentOutFile" != "-" ]] && rm -f "$currentOutFile" > /dev/null 2>&1

-	#aria2c --timeout=180 --max-tries=25 --retry-wait=15 "$@"
-    ##_messagePlain_probe _aria2c_bin_githubRelease -x "$currentForceAxel" --async-dns=false -o "$currentAxelTmpFileRelative".tmp1 --disable-ipv6=false "${currentURL_array_reversed[$currentIteration]}" >&2
-    ##_aria2c_bin_githubRelease --log=- --log-level=info -x "$currentForceAxel" --async-dns=false -o "$currentAxelTmpFileRelative".tmp1 --disable-ipv6=false "${currentURL_array_reversed[$currentIteration]}" | grep --color -i -E "Name resolution|$" >&2 &
-    ##messagePlain_probe _aria2c_bin_githubRelease -x "$currentForceAxel" --async-dns=false -o "$currentAxelTmpFileRelative".tmp2 --disable-ipv6=true "${currentURL_array_reversed[$currentIterationNext1]}" >&2
-    ##_aria2c_bin_githubRelease --log=- --log-level=info -x "$currentForceAxel" --async-dns=false -o "$currentAxelTmpFileRelative".tmp2 --disable-ipv6=true "${currentURL_array_reversed[$currentIterationNext1]}" | grep --color -i -E "Name resolution|$" >&2 &
-    local current_axel_args
-	current_axel_args=()
-	##[[ "$GH_TOKEN" != "" ]] && current_axel_args+=( -H "Authorization: Bearer $GH_TOKEN" )
-	#current_axel_args+=( --quiet=true )
-	#current_axel_args+=( --timeout=180 --max-tries=25 --retry-wait=15 )
-    current_axel_args+=( --stderr=true --summary-interval=0 --console-log-level=error --async-dns=false )
-    [[ "$FORCE_AXEL" != "" ]] && current_axel_args+=( -x "$FORCE_AXEL" )
-
-	local currentExitStatus_ipv4=1
-	local currentExitStatus_ipv6=1

-	( _messagePlain_probe '_wget_githubRelease_procedure-axel: IPv6' >&2 ) > /dev/null
-    ( _messagePlain_probe_safe aria2c --disable-ipv6=false "${current_axel_args[@]}" -d "$currentOutDir" -o "$currentOutFile_relative" "$currentURL" >&2 ) > /dev/null
-	#aria2c --disable-ipv6=false "${current_axel_args[@]}" -d "$currentOutDir" -o "$currentOutFile_relative" "$currentURL"
-	# WARNING: May be untested.
-	( set -o pipefail ; aria2c --disable-ipv6=false "${current_axel_args[@]}" -d "$currentOutDir" -o "$currentOutFile_relative" "$currentURL" 2> >(tail -n 40 >&2) )
-	currentExitStatus_ipv6="$?"
-    if [[ "$currentExitStatus_ipv6" != "0" ]]
-    then
-        ( _messagePlain_probe '_wget_githubRelease_procedure-axel: IPv4' >&2 ) > /dev/null
-        ( _messagePlain_probe_safe aria2c --disable-ipv6=true "${current_axel_args[@]}" -d "$currentOutDir" -o "$currentOutFile_relative" "$currentURL" >&2 ) > /dev/null
-        #aria2c --disable-ipv6=true "${current_axel_args[@]}" -d "$currentOutDir" -o "$currentOutFile_relative" "$currentURL"
-        ( set -o pipefail ; aria2c --disable-ipv6=true "${current_axel_args[@]}" -d "$currentOutDir" -o "$currentOutFile_relative" "$currentURL" 2> >(tail -n 40 >&2) )
-        currentExitStatus_ipv4="$?"
-    fi

-	if [[ "$currentExitStatus_ipv6" != "0" ]] && [[ "$currentExitStatus_ipv4" != "0" ]]
-	then
-		#( _messagePlain_bad 'bad: FAIL: _wget_githubRelease_procedure-axel' >&2 ) > /dev/null
-        _bad_fail_githubRelease_currentExitStatus
-		[[ "$currentExitStatus_ipv4" != "1" ]] && [[ "$currentExitStatus_ipv4" != "0" ]] && return "$currentExitStatus_ipv4"
-		[[ "$currentExitStatus_ipv6" != "1" ]] && [[ "$currentExitStatus_ipv6" != "0" ]] && return "$currentExitStatus_ipv6"
-		return "$currentExitStatus_ipv4"
-	fi

-    [[ ! -e "$currentOutFile" ]] && [[ "$currentOutFile" != "-" ]] && _bad_fail_githubRelease_missing && return 1

-    return 0
-}
-_wget_githubRelease_loop-axel() {
-	# Similar retry logic for all similar functions: _gh_download , _wget_githubRelease_loop-axel .
-	( _messagePlain_nominal "$currentStream"'\/\/\/\/\/ \/\/\/\/ init: _wget_githubRelease_loop-axel' >&2 ) > /dev/null
-	( _messagePlain_probe_safe _wget_githubRelease_loop-axel "$@" >&2 ) > /dev/null

-	[[ "$currentOutFile" != "-" ]] && rm -f "$currentOutFile" > /dev/null 2>&1

-	local currentExitStatus=1

-	local currentIteration=0

-	while ( [[ "$currentExitStatus" != "0" ]] || ( ! [[ -e "$currentOutFile" ]] && [[ "$currentOutFile" != "-" ]] ) ) && [[ "$currentIteration" -lt "$githubRelease_retriesMax" ]]
-	do
-		if [[ "$currentIteration" != "0" ]]
-		then
-			( _messagePlain_warn 'warn: BAD: RETRY: _wget_githubRelease_procedure-axel: currentIteration != 0' >&2 ) > /dev/null
-			sleep "$githubRelease_retriesWait"
-		fi

-		( _messagePlain_probe_safe _wget_githubRelease_procedure-axel >&2 ) > /dev/null
-		_wget_githubRelease_procedure-axel
-		# WARNING: May be untested.
-		#( set -o pipefail ; _wget_githubRelease_procedure-axel 2> >(tail -n 100 >&2) )
-		currentExitStatus="$?"

-		let currentIteration=currentIteration+1
-	done
-
-	[[ "$currentExitStatus" != "0" ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease_loop-axel: _wget_githubRelease_procedure-axel: currentExitStatus' >&2 ) > /dev/null && return "$currentExitStatus"
-	! [[ -e "$currentOutFile" ]] && [[ "$currentOutFile" != "-" ]] && ( _messagePlain_bad 'bad: FAIL: missing: currentOutFile' >&2 ) > /dev/null && return 1

-	return 0
-}



@@ -28887,473 +35506,572 @@ _wget_githubRelease_loop-axel() {



-_wget_githubRelease_join() {
-    local currentAbsoluteRepo="$1"
-	local currentReleaseLabel="$2"
-	local currentFile="$3"

-	local currentOutParameter="$4"
-	local currentOutFile="$5"

-	shift
-	shift
-	shift
-	[[ "$currentOutParameter" != "-O" ]] && currentOutFile="$currentFile"
-	#[[ "$currentOutParameter" == "-O" ]] && currentOutFile="$currentOutFile"

-	#[[ "$currentOutParameter" == "-O" ]] && [[ "$currentOutFile" == "" ]] && currentOutFile="$currentFile"
-	[[ "$currentOutParameter" == "-O" ]] && [[ "$currentOutFile" == "" ]] && ( _messagePlain_bad 'bad: fail: unexpected: unspecified: currentOutFile' >&2 ) > /dev/null && return 1

-	if [[ "$currentOutParameter" == "-O" ]]
-	then
-		shift
-		shift
-	fi

-	[[ "$currentOutFile" != "-" ]] && rm -f "$currentOutFile" > /dev/null 2>&1


-	# ATTENTION
-	currentFile=$(basename "$currentFile")




-	( _messagePlain_probe_safe _wget_githubRelease_join "$@" >&2 ) > /dev/null

-	_messagePlain_probe_safe _wget_githubRelease_join-stdout "$currentAbsoluteRepo" "$currentReleaseLabel" "$currentFile" "$@" '>' "$currentOutFile" >&2
-	_wget_githubRelease_join-stdout "$currentAbsoluteRepo" "$currentReleaseLabel" "$currentFile" "$@" > "$currentOutFile"

-	[[ ! -e "$currentOutFile" ]] && _messagePlain_bad 'missing: '"$1"' '"$2"' '"$3" && return 1

-	return 0
-}




-_wget_githubRelease_join-stdout() {
-	"$scriptAbsoluteLocation" _wget_githubRelease_join_sequence-stdout "$@"
-}
-_wget_githubRelease_join_sequence-stdout() {
-	( _messagePlain_nominal '\/\/\/\/\/ \/\/\/\/\/ init: _wget_githubRelease_join-stdout' >&2 ) > /dev/null
-	( _messagePlain_probe_safe _wget_githubRelease_join-stdout "$@" >&2 ) > /dev/null

+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+#./ubiquitous_bash.sh _wget_githubRelease-releasesTags soaringDistributions/ubDistBuild 20
+#./ubiquitous_bash.sh _wget_githubRelease_procedure-releasesTags-curl soaringDistributions/ubDistBuild 20
+#./ubiquitous_bash.sh _wget_githubRelease_procedure-releasesTags-gh soaringDistributions/ubDistBuild 20
+_wget_githubRelease_procedure-releasesTags-curl() {
 	local currentAbsoluteRepo="$1"
-	local currentReleaseLabel="$2"
-	local currentFile="$3"
+    local currentQuantity="$2"
+    [[ "$currentQuantity" == "0" ]] && currentQuantity=20

-	local currentOutParameter="$4"
-	local currentOutFile="$5"
+	#local currentReleaseLabel="$2"
+	#local currentFile="$3"

-	shift
-	shift
-	shift
-	if [[ "$currentOutParameter" == "-O" ]]
-	then
-		if [[ "$currentOutFile" != "-" ]]
+	[[ "$currentAbsoluteRepo" == "" ]] && return 1
+	#[[ "$currentReleaseLabel" == "" ]] && currentReleaseLabel="latest"
+	#[[ "$currentFile" == "" ]] && return 1
+
+
+	local currentExitStatus_tmp=0
+	local currentExitStatus=0
+
+
+    local currentData
+    currentData=""
+
+    local currentData_page
+    currentData_page="doNotMatch"
+
+    local currentIteration
+    currentIteration=1
+
+    # ATTRIBUTION-AI: Many-Chat 2025-03-23
+    # Alternative detection of empty array, as suggested by AI LLM .
+    #[[ $(jq 'length' <<< "$currentData_page") -gt 0 ]]
+    while ( [[ "$currentData_page" != "" ]] && [[ $(_safeEcho_newline "$currentData_page" | tr -dc 'a-zA-Z\[\]' | sed '/^$/d') != $(echo 'WwoKXQo=' | base64 -d | tr -dc 'a-zA-Z\[\]') ]] ) && ( [[ "$currentIteration" -le "1" ]] || ( [[ "$GH_TOKEN" != "" ]] && [[ "$currentIteration" -le "3" ]] ) )
+    do
+        #currentData_page=$(_curl_githubAPI_releases_page "$currentAbsoluteRepo" "$currentReleaseLabel" "$currentFile" "$currentIteration")
+        # ATTENTION: FORCE curl retry , since we will not be doing prebuffering (or downloading any files) directly with 'releasesTags' .
+        _set_curl_github_retry
+        currentData_page=$(_curl_githubAPI_releases_page "$currentAbsoluteRepo" "doNotMatch" "doNotMatch" "$currentIteration" "$currentFailParam" "${curl_retries_args[@]}")
+        unset curl_retries_args
+        currentExitStatus_tmp="$?"
+        [[ "$currentIteration" == "1" ]] && currentExitStatus="$currentExitStatus_tmp"
+        currentData="$currentData"'
+'"$currentData_page"
+
+        ( _messagePlain_probe "_wget_githubRelease_procedure-releasesTags-curl: ""$currentIteration" >&2 ) > /dev/null
+        [[ "$currentIteration" -ge 4 ]] && ( _safeEcho_newline "$currentData_page" >&2 ) > /dev/null
+
+        let currentIteration=currentIteration+1
+    done
+
+    #( set -o pipefail ; _safeEcho_newline "$currentData" | _jq_github_browser_download_releasesTags "" "$currentReleaseLabel" "$currentFile" | head -n 1 )
+    ( set -o pipefail ; _safeEcho_newline "$currentData" | jq -r 'sort_by(.published_at) | reverse | .[].tag_name' | tr -dc 'a-zA-Z0-9\-_.:\n' | sed '/^$/d' | head -n "$currentQuantity" )
+    currentExitStatus_tmp="$?"
+
+    [[ "$currentExitStatus" != "0" ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease_procedure-releasesTags-curl: _curl_githubAPI_releases_page: currentExitStatus' >&2 ) > /dev/null && return "$currentExitStatus"
+    [[ "$currentExitStatus_tmp" != "0" ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease_procedure-releasesTags-curl: pipefail: jq: currentExitStatus_tmp' >&2 ) > /dev/null && return "$currentExitStatus_tmp"
+    [[ "$currentData" == "" ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease_procedure-releasesTags-curl: empty: currentData' >&2 ) > /dev/null && return 1
+
+    return 0
+}
+_wget_githubRelease-releasesTags-backend-curl() {
+	local currentReleasesTags
+	currentReleasesTags=""
+
+	local currentExitStatus=1
+
+	local currentIteration=0
+
+	#export githubRelease_retriesMax=2
+	#export githubRelease_retriesWait=4
+	#[[ "$currentReleasesTags" == "" ]] ||
+	while ( [[ "$currentExitStatus" != "0" ]] ) && [[ "$currentIteration" -lt "$githubRelease_retriesMax" ]]
+	do
+		currentReleasesTags=""
+
+		if [[ "$currentIteration" != "0" ]]
 		then
-			( _messagePlain_bad 'bad: fail: unexpected: currentOutFile: NOT stdout' >&2 ) > /dev/null
-			#echo "1" > "$currentAxelTmpFile".FAIL
-			return 1
+			( _messagePlain_warn 'warn: BAD: RETRY: _wget_githubRelease-URL-curl: _wget_githubRelease_procedure-releasesTags-curl: currentIteration != 0' >&2 ) > /dev/null
+			sleep "$githubRelease_retriesWait"
 		fi
-		shift
-		shift
-	fi

+		( _messagePlain_probe _wget_githubRelease_procedure-releasesTags-curl >&2 ) > /dev/null
+		currentReleasesTags=$(_wget_githubRelease_procedure-releasesTags-curl "$@")
+		currentExitStatus="$?"

-    _set_wget_githubRelease "$@"
+		let currentIteration=currentIteration+1
+	done
+    #_set_wget_githubRelease
+
+	_safeEcho_newline "$currentReleasesTags"

+	[[ "$currentIteration" -ge "$githubRelease_retriesMax" ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease-URL-curl: maxRetries' >&2 ) > /dev/null && return 1

-    local currentPart
-    local currentSkip
-    local currentStream
-	local currentStream_wait
-	local currentBusyStatus
+	return 0
+}
+_wget_githubRelease-releasesTags-curl() {
+	# Similar retry logic for all similar functions: _wget_githubRelease-URL-curl, _wget_githubRelease-URL-gh .
+	( _messagePlain_nominal "$currentStream"'\/\/\/\/ init: _wget_githubRelease-releasesTags-curl' >&2 ) > /dev/null
+	( _messagePlain_probe_safe _wget_githubRelease-releasesTags-curl "$@" >&2 ) > /dev/null

-	# CAUTION: Any greater than 50 is not expected to serve any purpose, may exhaust expected API rate limits, may greatly delay download, and may disrupt subsequent API requests. Any less than 50 may fall below the ~100GB capacity that is both expected necessary for some complete toolchains and at the limit of ~100GB archival quality optical disc .
-	local maxCurrentPart=50
+    _wget_githubRelease-releasesTags-backend-curl "$@"
+    return
+}

+_wget_githubRelease_procedure-releasesTags-gh-awk() {
+	awk '
+        # Skip a header line if it appears first:
+        NR == 1 && $1 == "TITLE" && $2 == "TYPE" {
+            # Just move on to the next line and do nothing else
+            next
+        }
+
+        {
+            # If the second column is one of the known “types,” shift fields left so
+            # the *real* tag moves into $2. Repeat until no more known types remain.
+            while ($2 == "Latest" || $2 == "draft" || $2 == "pre-release" || $2 == "prerelease") {
+            for (i=2; i<NF; i++) {
+                $i = $(i+1)
+            }
+            NF--
+            }
+            # At this point, $2 is guaranteed to be the actual tag.
+            print $2
+		}
+		'
+}
+# Requires "$GH_TOKEN" .
+_wget_githubRelease_procedure-releasesTags-gh() {
+	( _messagePlain_nominal "$currentStream"'\/\/\/ init: _wget_githubRelease_procedure-releasesTags-gh' >&2 ) > /dev/null
+	( _messagePlain_probe_safe _wget_githubRelease_procedure-releasesTags-gh "$@" >&2 ) > /dev/null
+    ! _if_gh && return 1
+
+	local currentAbsoluteRepo="$1"
+    local currentQuantity="$2"
+    [[ "$currentQuantity" == "0" ]] && currentQuantity=20
+
+	#local currentReleaseLabel="$2"
+	#local currentFile="$3"

-    local currentExitStatus=1
+	[[ "$currentAbsoluteRepo" == "" ]] && return 1
+	#[[ "$currentReleaseLabel" == "" ]] && currentReleaseLabel="latest"
+	#[[ "$currentFile" == "" ]] && return 1


+	local currentExitStatus_tmp=0
+	local currentExitStatus=0

-    (( [[ "$FORCE_BUFFER" == "true" ]] && [[ "$FORCE_DIRECT" == "true" ]] ) || ( [[ "$FORCE_BUFFER" == "false" ]] && [[ "$FORCE_DIRECT" == "false" ]] )) && ( _messagePlain_bad 'bad: fail: FORCE_BUFFER , FORCE_DIRECT: conflict' >&2 ) > /dev/null && ( _messageError 'FAIL' >&2 ) > /dev/null && exit 1

-	[[ "$FORCE_PARALLEL" == "1" ]] && ( _messagePlain_bad 'bad: fail: FORCE_PARALLEL: sanity' >&2 ) > /dev/null && ( _messageError 'FAIL' >&2 ) > /dev/null && exit 1
-	[[ "$FORCE_PARALLEL" == "0" ]] && ( _messagePlain_bad 'bad: fail: FORCE_PARALLEL: sanity' >&2 ) > /dev/null && ( _messageError 'FAIL' >&2 ) > /dev/null && exit 1
+    local currentData
+    currentData=""

-    [[ "$FORCE_AXEL" != "" ]] && [[ "$FORCE_DIRECT" == "true" ]] && ( _messagePlain_bad 'bad: fail: FORCE_AXEL is NOT compatible with FORCE_DIRECT==true' >&2 ) > /dev/null && ( _messageError 'FAIL' >&2 ) > /dev/null && exit 1
+    local currentData_page
+    currentData_page="doNotMatch"
+
+    local currentIteration
+    currentIteration=1
+
+    while ( [[ "$currentData_page" != "" ]] && ( [[ "$currentIteration" -le "1" ]] || ( [[ "$GH_TOKEN" != "" ]] && [[ "$currentIteration" -le "3" ]] ) ) )
+    do
+        currentData_page=$(set -o pipefail ; gh release list -L $(( $currentIteration * 100 )) -R "$currentAbsoluteRepo" | _wget_githubRelease_procedure-releasesTags-gh-awk | tr -dc 'a-zA-Z0-9\-_.:\n' | tail -n +$(( $currentIteration * 100 - 100 + 1 )))
+        currentExitStatus_tmp="$?"
+        [[ "$currentIteration" == "1" ]] && currentExitStatus="$currentExitStatus_tmp"
+        currentData="$currentData"'
+'"$currentData_page"

-    [[ "$FORCE_AXEL" != "" ]] && ( _messagePlain_warn 'warn: WARNING: FORCE_AXEL not empty' >&2 ; echo 'FORCE_AXEL may have similar effects to FORCE_WGET and should not be necessary.' >&2  ) > /dev/null
+        ( _messagePlain_probe "_wget_githubRelease_procedure-releasesTags-gh: ""$currentIteration" >&2 ) > /dev/null
+        [[ "$currentIteration" -ge 4 ]] && ( _safeEcho_newline "$currentData_page" >&2 ) > /dev/null

+        let currentIteration=currentIteration+1
+    done

+    #( set -o pipefail ; _safeEcho_newline "$currentData" | _jq_github_browser_download_releasesTags "" "$currentReleaseLabel" "$currentFile" | head -n 1 )
+    #( set -o pipefail ; _safeEcho_newline "$currentData" | jq -r 'sort_by(.published_at) | reverse | .[].tag_name' | head -n "$currentQuantity" | tr -dc 'a-zA-Z0-9\-_.:\n' )
+    ( set -o pipefail ; _safeEcho_newline "$currentData" | tr -dc 'a-zA-Z0-9\-_.:\n' | sed '/^$/d' | head -n "$currentQuantity" )
+    currentExitStatus_tmp="$?"

-    _if_buffer() {
-        if ( [[ "$FORCE_BUFFER" == "true" ]] || [[ "$FORCE_DIRECT" == "false" ]] ) || [[ "$FORCE_BUFFER" == "" ]]
-        then
-            true
-            return
-        else
-            false
-            return
-        fi
-        true
-        return
-    }
+    [[ "$currentExitStatus" != "0" ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease_procedure-releasesTags-gh: gh: currentExitStatus' >&2 ) > /dev/null && return "$currentExitStatus"
+    [[ "$currentExitStatus_tmp" != "0" ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease_procedure-releasesTags-gh: pipefail: head: currentExitStatus_tmp' >&2 ) > /dev/null && return "$currentExitStatus_tmp"
+    [[ "$currentData" == "" ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease_procedure-releasesTags-gh: empty: currentData' >&2 ) > /dev/null && return 1

+    return 0
+}
+_wget_githubRelease-releasesTags-gh() {
+	# Similar retry logic for all similar functions: _wget_githubRelease-URL-curl, _wget_githubRelease-releasesTags-gh .
+	( _messagePlain_nominal "$currentStream"'\/\/\/\/ init: _wget_githubRelease-releasesTags-gh' >&2 ) > /dev/null
+	( _messagePlain_probe_safe _wget_githubRelease-releasesTags-gh "$@" >&2 ) > /dev/null
+    ! _if_gh && return 1

-
-    # WARNING: FORCE_DIRECT="true" , "FORCE_BUFFER="false" very strongly discouraged. Any retry/continue of any interruption will nevertheless unavoidably result in a corrupted output stream.
-    if ! _if_buffer
-    then
-        #export FORCE_DIRECT="true"
+	local currentTag
+	currentTag=""

-        _set_wget_githubRelease-detect "$@"
-        currentSkip="skip"
+	local currentExitStatus=1

-        currentStream="noBuf"
-        #local currentAxelTmpFileRelative=.m_axelTmp_"$currentStream"_$(_uid 14)
-	    #local currentAxelTmpFile="$scriptAbsoluteFolder"/"$currentAxelTmpFileRelative"
+	local currentIteration=0

-        currentPart=""
-        for currentPart in $(seq -f "%02g" 0 "$maxCurrentPart" | sort -r)
-        do
-            if [[ "$currentSkip" == "skip" ]]
-            then
-                currentSkip=$(_wget_githubRelease-skip-URL-curl "$currentAbsoluteRepo" "$currentReleaseLabel" "$currentFile".part"$currentPart")
-                #[[ "$?" != "0" ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease-skip-URL-curl' >&2 ) > /dev/null && ( _messageError 'FAIL' >&2 ) > /dev/null && exit 1
-                #[[ "$?" != "0" ]] && currentSkip="skip"
-                [[ "$?" != "0" ]] && ( _messagePlain_warn 'bad: FAIL: _wget_githubRelease-skip-URL-curl' >&2 ) > /dev/null
-            fi
-
-            [[ "$currentSkip" == "skip" ]] && continue
+	while ( [[ "$currentTag" == "" ]] || [[ "$currentExitStatus" != "0" ]] ) && [[ "$currentIteration" -lt "$githubRelease_retriesMax" ]]
+	do
+		currentTag=""

-
-            if [[ "$currentExitStatus" == "0" ]] || [[ "$currentSkip" != "skip" ]]
-            then
-                _set_wget_githubRelease "$@"
-                currentSkip="download"
-            fi
+		if [[ "$currentIteration" != "0" ]]
+		then
+			( _messagePlain_warn 'warn: BAD: RETRY: _wget_githubRelease-releasesTags-gh: _wget_githubRelease_procedure-releasesTags-gh: currentIteration != 0' >&2 ) > /dev/null
+			sleep "$githubRelease_retriesWait"
+		fi
+
+		( _messagePlain_probe _wget_githubRelease_procedure-releasesTags-gh >&2 ) > /dev/null
+		currentTag=$(_wget_githubRelease_procedure-releasesTags-gh "$@")
+		currentExitStatus="$?"
+
+		let currentIteration=currentIteration+1
+	done
+
+	_safeEcho_newline "$currentTag"
+
+	[[ "$currentIteration" -ge "$githubRelease_retriesMax" ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease-releasesTags-gh: maxRetries' >&2 ) > /dev/null && return 1
+
+	return 0
+}
+
+_wget_githubRelease-releasesTags() {
+	( _messagePlain_nominal "$currentStream"'\/\/\/\/\/ init: _wget_githubRelease-releasesTags' >&2 ) > /dev/null
+	if _if_gh
+	then
+		( _messagePlain_probe_safe _wget_githubRelease-releasesTags-gh "$@" >&2 ) > /dev/null
+		_wget_githubRelease-releasesTags-gh "$@"
+		return
+	else
+		( _messagePlain_probe_safe _wget_githubRelease-releasesTags-curl "$@" >&2 ) > /dev/null
+		_wget_githubRelease-releasesTags-curl "$@"
+		return
+	fi
+}


-            _wget_githubRelease_procedure "$currentAbsoluteRepo" "$currentReleaseLabel" "$currentFile".part"$currentPart" -O - "$@"
-            currentExitStatus="$?"
-            #[[ "$currentExitStatus" != "0" ]] && break
-        done

-        return "$currentExitStatus"
-    fi





-	# ### ATTENTION: _if_buffer (IMPLICIT)

-	# NOTICE: Parallel downloads may, if necessary, be adapted to first cache a list of addresses (ie. URLs) to download. API rate limits could then have as much time as possible to recover before subsequent commands (eg. analysis of builds). Such a cache must be filled with addresses BEFORE the download loop.


-	export currentAxelTmpFileUID="$(_uid 14)"
-	_axelTmp() {
-		echo .m_axelTmp_"$currentStream"_"$currentAxelTmpFileUID"
-	}
-	local currentAxelTmpFile
-	#currentAxelTmpFile="$scriptAbsoluteFolder"/$(_axelTmp)

-	local currentStream_min=1
-	local currentStream_max=3
-	[[ "$FORCE_PARALLEL" != "" ]] && currentStream_max="$FORCE_PARALLEL"

-	currentStream="$currentStream_min"


-	currentPart="$maxCurrentPart"


-	_set_wget_githubRelease-detect "$@"
-	currentSkip="skip"

+# _upgrade-import-assets corpName
+_upgrade-import-assets() {
+    "$scriptAbsoluteLocation" _upgrade_sequence-import-assets "$@"
+}
+_upgrade_sequence-import-assets() {
+    local corpName="$1"

-	currentPart=""
-	for currentPart in $(seq -f "%02g" 0 "$maxCurrentPart" | sort -r)
-	do
-		if [[ "$currentSkip" == "skip" ]]
-		then
-			# ATTENTION: EXPERIMENT
-			currentSkip=$(_wget_githubRelease-skip-URL-curl "$currentAbsoluteRepo" "$currentReleaseLabel" "$currentFile".part"$currentPart")
-			#currentSkip=$([[ "$currentPart" -gt "17" ]] && echo 'skip' ; true)
-
-			#[[ "$?" != "0" ]] && ( _messagePlain_bad 'bad: FAIL: _wget_githubRelease-skip-URL-curl' >&2 ) > /dev/null && ( _messageError 'FAIL' >&2 ) > /dev/null && exit 1
-			#[[ "$?" != "0" ]] && currentSkip="skip"
-			[[ "$?" != "0" ]] && ( _messagePlain_warn 'bad: FAIL: _wget_githubRelease-skip-URL-curl' >&2 ) > /dev/null
-		fi
-
-		[[ "$currentSkip" == "skip" ]] && continue

-		#[[ "$currentExitStatus" == "0" ]] ||
-		if [[ "$currentSkip" != "skip" ]]
+	_start
+
+	! cd "$safeTmp" && _messageFAIL
+
+    export INPUT_GITHUB_TOKEN="$GH_TOKEN"
+	if ! ( type _gitBest > /dev/null 2>&1 && "$scriptAbsoluteLocation" _gitBest clone --depth 1 'git@github.com:soaringDistributions/zImport_corp_'"$corpName"'.git' )
+	then
+		if ls -1 "$HOME"/.ssh/id_* > /dev/null
 		then
-			_set_wget_githubRelease "$@"
-			currentSkip="download"
-			break
+			if ! git clone --depth 1 'git@github.com:soaringDistributions/zImport_corp_'"$corpName"'.git'
+			then
+                export safeToDeleteGit="true"
+                _messagePlain_bad 'bad: upgrade-import-assets-'"$corpName"': git: FAIL: fail'
+				_messageFAIL
+				_stop 1
+				exit 1
+            fi
+		else
+            export safeToDeleteGit="true"
+			_messagePlain_bad 'bad: upgrade-import-assets-'"$corpName"': git: FAIL: no remote permissions'
+			_messageFAIL
+			_stop 1
+			exit 1
 		fi
-	done
-
-	export currentSkipPart="$currentPart"
-	[[ "$currentStream_max" -gt "$currentSkipPart" ]] && currentStream_max=$(( "$currentSkipPart" + 1 ))
+	fi

-	"$scriptAbsoluteLocation" _wget_githubRelease_join_sequence-parallel "$currentAbsoluteRepo" "$currentReleaseLabel" "$currentFile" &
+	mkdir -p "$scriptLib"/zImport_corp_"$corpName"
+	mv -f "$safeTmp"/zImport_corp_"$corpName"/*.sh "$scriptLib"/zImport_corp_"$corpName"/
+	mv -f "$safeTmp"/zImport_corp_"$corpName"/*.yml "$scriptLib"/zImport_corp_"$corpName"/
+	mv -f "$safeTmp"/zImport_corp_"$corpName"/*.txt "$scriptLib"/zImport_corp_"$corpName"/
+	mv -f "$safeTmp"/zImport_corp_"$corpName"/*.md "$scriptLib"/zImport_corp_"$corpName"/

+    export safeToDeleteGit="true"
+	_stop
+}

-	# Prebuffer .
-	( _messagePlain_nominal '\/\/\/\/\/ \/\/\/\/  preBUFFER: WAIT  ...  currentPart='"$currentPart" >&2 ) > /dev/null
-	if [[ "$currentPart" -ge "01" ]] && [[ "$currentStream_max" -ge "2" ]]
-	then
-		#currentStream="2"
-		for currentStream in $(seq "$currentStream_min" "$currentStream_max" | sort -r)
-		do
-			( _messagePlain_probe 'prebuffer: currentStream= '"$currentStream" >&2 ) > /dev/null
-			while ( ! [[ -e "$scriptAbsoluteFolder"/$(_axelTmp).PASS ]] && ! [[ -e "$scriptAbsoluteFolder"/$(_axelTmp).FAIL ]] )
-			do
-				sleep 3
-			done
-		done
-	fi
-	currentStream="$currentStream_min"

+# ### NOTICE ###
+# gitCompendium
+# custom/upgrade functions for git repositories and for all git repositories owned by an organization
+# Mostly used by ubDistBuild and derivatives to custom/upgrade Operating Systems for organizations with both the tools and development resources to backup (ie. to optical disc), create workstations, create replacement repository servers, etc. Continuous Integration (CI) can keep such a backup/workstation/replacement dist/OS always recent enough to rely on, and small enough to frequently, conveniently, distribute on the coldest of cold storage to vaults, as well as data preservation facilities.
+#
+# Also sometimes useful to somewhat automatically upgrade an organization's existing workstation, server, etc.

-	for currentPart in $(seq -f "%02g" 0 "$currentSkipPart" | sort -r)
-	do
-	( _messagePlain_nominal '\/\/\/\/\/ \/\/\/\/  outputLOOP  ...  currentPart='"$currentPart"' currentStream='"$currentStream" >&2 ) > /dev/null
-	#( _messagePlain_probe_var currentPart >&2 ) > /dev/null
-	#( _messagePlain_probe_var currentStream >&2 ) > /dev/null

-		# Stream must have written PASS/FAIL file .
-		( _messagePlain_nominal '\/\/\/\/\/ \/\/\/  outputLOOP: WAIT: PASS/FAIL ... currentPart='"$currentPart"' currentStream='"$currentStream" >&2 ) > /dev/null
-		while ! [[ -e "$scriptAbsoluteFolder"/$(_axelTmp).busy ]] || ( ! [[ -e "$scriptAbsoluteFolder"/$(_axelTmp).PASS ]] && ! [[ -e "$scriptAbsoluteFolder"/$(_axelTmp).FAIL ]] )
-		do
-			sleep 1
-		done
-
-		( _messagePlain_nominal '\/\/\/\/\/ \/\/\/  outputLOOP: OUTPUT  ...  currentPart='"$currentPart"' currentStream='"$currentStream" >&2 ) > /dev/null
-		# ATTENTION: EXPERIMENT
-		#status=none
-		dd if="$scriptAbsoluteFolder"/$(_axelTmp) bs=1M
-		#cat "$scriptAbsoluteFolder"/$(_axelTmp)
-		#dd if="$scriptAbsoluteFolder"/$(_axelTmp) bs=1M | pv --rate-limit 100M 2>/dev/null
-		[[ -e "$scriptAbsoluteFolder"/$(_axelTmp).PASS ]] && currentSkip="download"
-		[[ -e "$scriptAbsoluteFolder"/$(_axelTmp).FAIL ]] && [[ "$currentSkip" != "skip" ]] && ( _messageError 'FAIL' >&2 ) > /dev/null && return 1

-		( _messagePlain_nominal '\/\/\/\/\/ \/\/\/  outputLOOP: DELETE  ...  currentPart='"$currentPart"' currentStream='"$currentStream" >&2 ) > /dev/null
-		rm -f "$scriptAbsoluteFolder"/$(_axelTmp) > /dev/null 2>&1
-		rm -f "$scriptAbsoluteFolder"/$(_axelTmp).busy > /dev/null 2>&1
+# EXAMPLE
+#_ubdistChRoot_backend_begin
+#_backend_override _compendium_git-custom-repo installations,infrastructure,c/Corporation_ABBREVIATION GitHub_ORGANIZATION,USER repositoryName --depth 1
+#_ubdistChRoot_backend_end

-		let currentStream=currentStream+1
-		[[ "$currentStream" -gt "$currentStream_max" ]] && currentStream="$currentStream_min"
-	done
+# EXAMPLE
+#_repo-GitHub_ORGANIZATION() { _backend_override _compendium_git-custom-repo installations,infrastructure,c/Corporation_ABBREVIATION GitHub_ORGANIZATION,USER repositoryName --depth 1 ; }
+#_ubdistChRoot_backend _repo-GitHub_ORGANIZATION

-	true
-}
-_wget_githubRelease_join_sequence-parallel() {
-	local currentAbsoluteRepo="$1"
-	local currentReleaseLabel="$2"
-	local currentFile="$3"

-	local currentOutParameter="$4"
-	local currentOutFile="$5"

-	shift
-	shift
-	shift
-	if [[ "$currentOutParameter" == "-O" ]]
-	then
-		if [[ "$currentOutFile" != "-" ]]
-		then
-			( _messagePlain_bad 'bad: fail: unexpected: currentOutFile: NOT stdout' >&2 ) > /dev/null
-			#echo "1" > "$currentAxelTmpFile".FAIL
-			return 1
-		fi
-		shift
-		shift
-	fi
+# DANGER: Only use within ephemeral CI, ChRoot, etc.
+#_compendium_gitFresh
+# |___ _compendium_gitFresh_sequence


-	#export currentAxelTmpFileUID="$(_uid 14)"
-	_axelTmp() {
-		echo .m_axelTmp_"$currentStream"_"$currentAxelTmpFileUID"
-	}
-	#local currentAxelTmpFile
-	#currentAxelTmpFile="$scriptAbsoluteFolder"/$(_axelTmp)
+#_compendium_git-upgrade-repo
+# |___ _compendium_git-custom-repo
+#
+#     |___ _compendium_git_sequence-custom-repo

-	# Due to parallelism , only API rate limits, NOT download speeds, are a concern with larger number of retries.
-	_set_wget_githubRelease "$@"
-	#_set_wget_githubRelease-detect "$@"
-	#_set_wget_githubRelease-detect-parallel "$@"
-	local currentSkip="skip"
-
-	local currentStream_min=1
-	local currentStream_max=3
-	[[ "$FORCE_PARALLEL" != "" ]] && currentStream_max="$FORCE_PARALLEL"
-	[[ "$currentStream_max" -gt "$currentSkipPart" ]] && currentStream_max=$(( "$currentSkipPart" + 1 ))
-
-	currentStream="$currentStream_min"
-	for currentPart in $(seq -f "%02g" 0 "$currentSkipPart" | sort -r)
-	do
-	( _messagePlain_nominal '\/\/\/\/\/ \/\/\/\/  downloadLOOP  ...  currentPart='"$currentPart"' currentStream='"$currentStream" >&2 ) > /dev/null
-	#( _messagePlain_probe_var currentPart >&2 ) > /dev/null
-	#( _messagePlain_probe_var currentStream >&2 ) > /dev/null

-		# Slot in use. Downloaded  "$scriptAbsoluteFolder"/$(_axelTmp)  file will be DELETED after use by calling process.
-		( _messagePlain_nominal '\/\/\/\/\/ \/\/\/  downloadLOOP: WAIT: BUSY  ...  currentPart='"$currentPart"' currentStream='"$currentStream" >&2 ) > /dev/null
-		while ( ls -1 "$scriptAbsoluteFolder"/$(_axelTmp) > /dev/null 2>&1 ) || ( ls -1 "$scriptAbsoluteFolder"/$(_axelTmp).busy > /dev/null 2>&1 )
-		do
-		( _messagePlain_nominal '\/\/\/\/\/ \/\/\/  downloadLOOP: WAIT: BUSY  ...  currentPart='"$currentPart"' currentStream='"$currentStream" >&2 ) > /dev/null
-			sleep 1
-		done
+#_compendium_git-upgrade-repo-org
+# |___ _compendium_git-custom-repo-org
+#
+#     |___ _compendium_git_sequence_sequence-custom-repo-org *
+#         |___ _compendium_git_sequence-custom-repo-org
+#
+#             |___ _compendium_git-custom-repo

-		( _messagePlain_nominal '\/\/\/\/\/ \/\/\/  downloadLOOP: detect skip  ...  currentPart='"$currentPart"' currentStream='"$currentStream" >&2 ) > /dev/null
-		[[ -e "$scriptAbsoluteFolder"/$(_axelTmp).PASS ]] && _set_wget_githubRelease "$@" && currentSkip="download"
-		[[ -e "$scriptAbsoluteFolder"/$(_axelTmp).FAIL ]] && [[ "$currentSkip" != "skip" ]] && ( _messageError 'FAIL' >&2 ) > /dev/null && return 1

-		( _messagePlain_nominal '\/\/\/\/\/ \/\/\/  downloadLOOP: DELETE  ...  currentPart='"$currentPart"' currentStream='"$currentStream" >&2 ) > /dev/null
-		rm -f "$scriptAbsoluteFolder"/$(_axelTmp).PASS > /dev/null 2>&1
-		rm -f "$scriptAbsoluteFolder"/$(_axelTmp).FAIL > /dev/null 2>&1
+#_compendium_git-upgrade-repo-user
+# |___ _compendium_git-custom-repo-user
+#
+#     |___ _compendium_git_sequence_sequence-custom-repo-user *
+#         |___ _compendium_git_sequence-custom-repo-org
+#
+#             |___ _compendium_git-custom-repo

-		( _messagePlain_nominal '\/\/\/\/\/ \/\/\/  downloadLOOP: DELAY: stagger, Inter-Process Communication, _stop  ...  currentPart='"$currentPart"' currentStream='"$currentStream" >&2 ) > /dev/null
-		# Staggered Delay.
-		[[ "$currentPart" == "$currentSkipPart" ]] && sleep 2
-		[[ "$currentPart" != "$currentSkipPart" ]] && sleep 6
-		# Inter-Process Communication Delay.
-		# Prevents new download from starting before previous download process has done  rm -f "$currentAxelTmpFile"*  .
-		#  Beware that  rm  is inevitable or at least desirable - called by _stop() through trap, etc.
-		sleep 7
-
-		( _messagePlain_nominal '\/\/\/\/\/ \/\/\/  downloadLOOP: DOWNLOAD  ...  currentPart='"$currentPart"' currentStream='"$currentStream" >&2 ) > /dev/null
-		export currentAxelTmpFile="$scriptAbsoluteFolder"/$(_axelTmp)
-		"$scriptAbsoluteLocation" _wget_githubRelease_procedure-join "$currentAbsoluteRepo" "$currentReleaseLabel" "$currentFile".part$(printf "%02g" "$currentPart") &
-		echo "$!" > "$scriptAbsoluteFolder"/$(_axelTmp).pid

-		# Stream must have written either in-progress download or PASS/FAIL file .
-		( _messagePlain_nominal '\/\/\/\/\/ \/\/\/  downloadLOOP: WAIT: BEGIN  ...  currentPart='"$currentPart"' currentStream='"$currentStream" >&2 ) > /dev/null
-		while ! ( ls -1 "$scriptAbsoluteFolder"/$(_axelTmp)* > /dev/null 2>&1 )
-		do
-		( _messagePlain_nominal '\/\/\/\/\/ \/\/\/  downloadLOOP: WAIT: BEGIN  ...  currentPart='"$currentPart"' currentStream='"$currentStream" >&2 ) > /dev/null
-			sleep 0.6
-		done

-		let currentStream=currentStream+1
-		[[ "$currentStream" -gt "$currentStream_max" ]] && currentStream="$currentStream_min"
-	done

-	( _messagePlain_nominal '\/\/\/\/\/ \/\/\/\/  download: DELETE' >&2 ) > /dev/null
-	for currentStream in $(seq "$currentStream_min" "$currentStream_max")
-	do
-		( _messagePlain_nominal '\/\/\/\/\/ \/\/\/  download: WAIT: BUSY  ...  currentStream='"$currentStream" >&2 ) > /dev/null
-		while ( ls -1 "$scriptAbsoluteFolder"/$(_axelTmp) > /dev/null 2>&1 ) || ( ls -1 "$scriptAbsoluteFolder"/$(_axelTmp).busy > /dev/null 2>&1 )
-		do
-		( _messagePlain_nominal '\/\/\/\/\/ \/\/\/  download: WAIT: BUSY  ...  currentStream='"$currentStream" >&2 ) > /dev/null
-			sleep 1
-		done
+#_ubdistChRoot _compendium_git-custom-repo installations,infrastructure,c/Corporation_ABBREVIATION GitHub_ORGANIZATION,USER repositoryName --depth 1
+_compendium_git_sequence-custom-repo() {
+    _messageNormal '\/ \/ \/ _compendium_git-custom-repo: '"$@"

-		( _messagePlain_nominal '\/\/\/\/\/ \/\/\/  download: DELETE ...  currentStream='"$currentStream" >&2 ) > /dev/null
-		rm -f "$scriptAbsoluteFolder"/$(_axelTmp).PASS > /dev/null 2>&1
-		rm -f "$scriptAbsoluteFolder"/$(_axelTmp).FAIL > /dev/null 2>&1
-	done
+    _start
+    local functionEntryPWD
+    functionEntryPWD="$PWD"

-	( _messagePlain_nominal '\/\/\/\/\/ \/\/\/\/  download: WAIT PID  ...  currentPart='"$currentPart"' currentStream='"$currentStream" >&2 ) > /dev/null
-	for currentStream in $(seq "$currentStream_min" "$currentStream_max")
-	do
-		[[ -e "$scriptAbsoluteFolder"/$(_axelTmp).pid ]] && _pauseForProcess $(cat "$scriptAbsoluteFolder"/$(_axelTmp).pid) > /dev/null
-	done
-	wait >&2
+    local current_coreSubDir="$1"
+    local current_GitHubORGANIZATION="$2"
+    local current_repositoryName="$3"

-	true
-}
-_wget_githubRelease_procedure-join() {
-	( _messagePlain_probe_safe _wget_githubRelease_procedure-join "$@" >&2 ) > /dev/null
+    shift ; shift ; shift

-	local currentAbsoluteRepo="$1"
-	local currentReleaseLabel="$2"
-	local currentFile="$3"
+    [[ "$GH_TOKEN" == "" ]] && _messagePlain_warn 'warn: missing: GH_TOKEN'

-	local currentOutParameter="$4"
-	local currentOutFile="$5"
+    export INPUT_GITHUB_TOKEN="$GH_TOKEN"

-	shift
-	shift
-	shift
-	if [[ "$currentOutParameter" == "-O" ]]
-	then
-		if [[ "$currentOutFile" != "-" ]]
-		then
-			( _messagePlain_bad 'bad: fail: unexpected: currentOutFile: NOT stdout' >&2 ) > /dev/null
-			echo "1" > "$currentAxelTmpFile".FAIL
-			return 1
-		fi
-		shift
-		shift
-	fi
+    if [[ -e /home/user/core/"$current_coreSubDir"/"$current_repositoryName" ]]
+    then
+        [[ "$ub_dryRun" != "true" ]] && mkdir -p /home/user/core/"$current_coreSubDir"/"$current_repositoryName"
+        [[ "$ub_dryRun" != "true" ]] && cd /home/user/core/"$current_coreSubDir"/"$current_repositoryName"
+
+        _messagePlain_probe git checkout "HEAD"
+        [[ "$ub_dryRun" != "true" ]] && ! git checkout "HEAD" && _messageFAIL
+        _messagePlain_probe _gitBest pull
+        [[ "$ub_dryRun" != "true" ]] && ! "$scriptAbsoluteLocation" _gitBest pull && _messageFAIL
+        _messagePlain_probe _gitBest submodule update --init "$@" --recursive
+        [[ "$ub_dryRun" != "true" ]] && ! "$scriptAbsoluteLocation" _gitBest submodule update --init "$@" --recursive && _messageFAIL
+    fi

-	#local currentAxelTmpFileRelative=.m_axelTmp_"$currentStream"_$(_uid 14)
-	#local currentAxelTmpFile="$scriptAbsoluteFolder"/"$currentAxelTmpFileRelative"
+    #else
+    if ! [[ -e /home/user/core/"$current_coreSubDir"/"$current_repositoryName" ]]
+    then
+        [[ "$ub_dryRun" != "true" ]] && mkdir -p /home/user/core/"$current_coreSubDir"
+        [[ "$ub_dryRun" != "true" ]] && cd /home/user/core/"$current_coreSubDir"
+
+        _messagePlain_probe _gitBest clone --recursive "$@" 'git@github.com:'"$current_GitHubORGANIZATION"'/'"$current_repositoryName"'.git'
+        [[ "$ub_dryRun" != "true" ]] && ! "$scriptAbsoluteLocation" _gitBest clone --recursive "$@" 'git@github.com:'"$current_GitHubORGANIZATION"'/'"$current_repositoryName"'.git' && _messageFAIL
+    fi
+
+
+    [[ "$ub_dryRun" != "true" ]] && ! ls /home/user/core/"$current_coreSubDir"/"$current_repositoryName" && _messageFAIL

-	local currentExitStatus
+    cd "$functionEntryPWD"
+    _stop
+}
+_compendium_git-custom-repo() {
+    "$scriptAbsoluteLocation" _compendium_git_sequence-custom-repo "$@"
+}
+_compendium_git-upgrade-repo() {
+    _compendium_git-custom-repo "$@"
+}

-	echo -n > "$currentAxelTmpFile".busy

-	# ATTENTION: EXPERIMENT
-	_wget_githubRelease_procedure "$currentAbsoluteRepo" "$currentReleaseLabel" "$currentFile" -O "$currentAxelTmpFile" "$@"
-    #dd if=/dev/zero bs=1M count=1500 > "$currentAxelTmpFile"
-	#echo "$currentFile" >> "$currentAxelTmpFile"
-    #dd if=/dev/urandom bs=1M count=1500 | pv --rate-limit 300M 2>/dev/null > "$currentAxelTmpFile"
-	currentExitStatus="$?"

-	# Inter-Process Communication Delay
-	# Essentially a 'minimum download time' .
-	sleep 7
+#_ubdistChRoot _compendium_git-custom-repo-org c/Corporation_ABBREVIATION GitHub_ORGANIZATION --depth 1
+_compendium_git_sequence-custom-repo-org() {
+    _messageNormal '\/ _compendium_git_sequence-custom-repo-org: '"$@"

-	[[ "$currentExitStatus" == "0" ]] && echo "$currentExitStatus" > "$currentAxelTmpFile".PASS
-	if [[ "$currentExitStatus" != "0" ]]
-	then
-		echo -n > "$currentAxelTmpFile"
-		echo "$currentExitStatus" > "$currentAxelTmpFile".FAIL
-	fi
+    _start
+    local functionEntryPWD
+    functionEntryPWD="$PWD"

-    while [[ -e "$currentAxelTmpFile" ]] || [[ -e "$currentAxelTmpFile".busy ]] || [[ -e "$currentAxelTmpFile".PASS ]] || [[ -e "$currentAxelTmpFile".FAIL ]]
-    do
-        sleep 1
-    done
+    local current_coreSubDir="$1"
+    local current_GitHubORGANIZATION="$2"

-    [[ "$currentAxelTmpFile" != "" ]] && rm -f "$currentAxelTmpFile".*
+    shift ; shift

-    #unset currentAxelTmpFile

-    [[ "$currentExitStatus" == "0" ]] && return 0
-    return "$currentExitStatus"
-}
+    export INPUT_GITHUB_TOKEN="$GH_TOKEN"

+    [[ "$ub_dryRun" != "true" ]] && mkdir -p /home/user/core/"$current_coreSubDir"
+    [[ "$ub_dryRun" != "true" ]] && cd /home/user/core/"$current_coreSubDir"

+    local currentPage
+    local currentRepository
+    local currentRepositoryNumber

+    if [[ "$ub_dryRun" == "true" ]]
+    then
+        currentPage=1
+        currentRepository="doNotMatch"
+        currentRepositoryNumber=1
+        local repositoryCount="99"
+        #&& [[ "$repositoryCount" -gt "0" ]]
+        while [[ "$currentPage" -le "10" ]] && [[ "$repositoryCount" -gt "0" ]]
+        do
+            _messagePlain_probe 'repository counts...'
+            # get list of repository urls
+            repositoryCount=$(curl --no-fail --retry 5 --retry-delay 90 --connect-timeout 45 --max-time 600 -s -H 'Authorization: token '"$GH_TOKEN" 'https://api.github.com/'"$current_API"'/'"$current_GitHubORGANIZATION"'/repos?per_page=30&page='"$currentPage" | grep  "^    \"git_url\"" | awk -F': "' '{print $2}' | sed -e 's/",//g' | wc -w)
+
+            echo "$repositoryCount"

+            let currentPage="$currentPage"+1

+            sleep 1
+        done
+    fi

+    currentPage=1
+    currentRepository="doNotMatch"
+    currentRepositoryNumber=1
+    while [[ "$currentPage" -le "10" ]] && [[ "$currentRepository" != "" ]]
+    do
+        currentRepository=""
+
+        # ATTRIBUTION-AI: ChatGPT ...
+        # https://platform.openai.com/playground/p/6it5h1B901jvAblUhdbsPHEN?model=text-davinci-003
+        #curl -s https://api.github.com/"$current_API"/$current_GitHubORGANIZATION/repos?per_page=30 | jq -r '.[].git_url'
+        #for currentRepository in $(curl -s -H 'Authorization: token '"$GH_TOKEN" 'https://api.github.com/'"$current_API"'/'"$current_GitHubORGANIZATION"'/repos?per_page=30&page='"$currentPage" | grep  "^    \"git_url\"" | awk -F': "' '{print $2}' | sed -e 's/",//g' | sed 's/git:\/\/github.com\/'"$current_GitHubORGANIZATION"'\//git@github.com:'"$current_GitHubORGANIZATION"'\//g')
+        # ATTRIBUTION-AI: claude-37.-sonnet:thinking
+        for currentRepository in $(curl --no-fail --retry 5 --retry-delay 90 --connect-timeout 45 --max-time 600 -s -H "Authorization: token $GH_TOKEN" 'https://api.github.com/'"$current_API"'/'"$current_GitHubORGANIZATION"'/repos?per_page=30&page='"$currentPage" | jq -r '.[].name' | tr -dc 'a-zA-Z0-9\-_.:\n')
+        do
+            sleep 1
+
+            _messageNormal '\/ \/' _compendium_git-custom-repo "$current_coreSubDir" "$current_GitHubORGANIZATION" "$currentRepository" "$@"
+            #_messagePlain_probe _compendium_git-custom-repo "$current_coreSubDir" "$current_GitHubORGANIZATION" "$currentRepository" "$@"
+            _messagePlain_probe_var currentRepositoryNumber
+            if ! _compendium_git-custom-repo "$current_coreSubDir" "$current_GitHubORGANIZATION" "$currentRepository" "$@"
+            then
+                _messageFAIL
+            fi

+            sleep 1
+            let currentRepositoryNumber="$currentRepositoryNumber"+1
+        done

+        #[[ "$currentRepository" == "doNotMatch" ]] && currentRepository=""

+        let currentPage="$currentPage"+1
+    done

-_warn_githubRelease_FORCE_WGET() {
-    ( _messagePlain_warn 'warn: WARNING: FORCE_WGET=true' >&2 ; echo 'FORCE_WGET is a workaround. Only expected FORCE_WGET uses: low RAM , cloud testing/diagnostics .' >&2  ) > /dev/null
-    return 0
+    cd "$functionEntryPWD"
+    _stop
 }
-_bad_fail_githubRelease_currentExitStatus() {
-    ( _messagePlain_bad 'fail: wget_githubRelease: currentExitStatus: '"$currentAbsoluteRepo"' '"$currentReleaseLabel"' '"$currentFile" >&2 ) > /dev/null
-    return 0
+_compendium_git_sequence_sequence-custom-repo-user() {
+    export current_API="users"
+    "$scriptAbsoluteLocation" _compendium_git_sequence-custom-repo-org "$@"
 }
-_bad_fail_githubRelease_missing() {
-    ( _messagePlain_bad 'fail: wget_githubRelease: missing: '"$currentAbsoluteRepo"' '"$currentReleaseLabel"' '"$currentFile" >&2 ) > /dev/null
-    return 0
+_compendium_git-custom-repo-user() {
+    "$scriptAbsoluteLocation" _compendium_git_sequence_sequence-custom-repo-user "$@"
+}
+_compendium_git-upgrade-repo-user() {
+    _compendium_git-custom-repo-user "$@"
+}
+_compendium_git_sequence_sequence-custom-repo-org() {
+    export current_API="orgs"
+    "$scriptAbsoluteLocation" _compendium_git_sequence-custom-repo-org "$@"
+}
+_compendium_git-custom-repo-org() {
+    "$scriptAbsoluteLocation" _compendium_git_sequence_sequence-custom-repo-org "$@"
+}
+_compendium_git-upgrade-repo-org() {
+    _compendium_git-custom-repo-org "$@"
 }


@@ -29361,28 +36079,61 @@ _bad_fail_githubRelease_missing() {



-_vector_wget_githubRelease-URL-gh() {
-    local currentReleaseLabel="build"
-
-    [[ $(
-cat <<'CZXWXcRMTo8EmM8i4d' | _wget_githubRelease_procedure-address-gh-awk "" "$currentReleaseLabel" "" 2> /dev/null
-TITLE  TYPE    TAG NAME             PUBLISHED
-build  Latest  build-1002-1  about 1 days ago
-build          build-1001-1  about 2 days ago
-CZXWXcRMTo8EmM8i4d
-) == "build-1002-1
-build-1001-1" ]] || ( _messagePlain_bad 'fail: bad: _wget_githubRelease_procedure-address-gh-awk' && _messageFAIL )

-	return 0
-}
+# DANGER: Only use within ephemeral CI, ChRoot, etc.
+#_ubdistChRoot _compendium_gitFresh installations,infrastructure,c/Corporation_ABBREVIATION repositoryName --depth 1
+_compendium_gitFresh() {
+    if [[ "$ub_dryRun" == "true" ]]
+    then
+        _stop
+        exit
+        return
+    fi

+    local current_coreSubDir="$1"
+    local current_repositoryName="$2"

+    mkdir -p /home/user/core/"$current_coreSubDir"/"$current_repositoryName"
+
+    if ! cd /home/user/core/"$current_coreSubDir"/"$current_repositoryName" || ! [[ -e /home/user/core/"$current_coreSubDir"/"$current_repositoryName" ]]
+    then
+        _messageError 'bad: FAIL: cd '/home/user/core/"$current_coreSubDir"/"$current_repositoryName"
+        _messageFAIL
+        exit 1
+    fi

+    "$scriptAbsoluteLocation" _compendium_gitFresh_sequence "$current_coreSubDir" "$current_repositoryName"
+}
+_compendium_gitFresh_sequence() {
+    if [[ "$ub_dryRun" == "true" ]]
+    then
+        _stop
+        exit
+        return
+    fi

+    _start

+    local current_coreSubDir="$1"
+    local current_repositoryName="$2"

+    mkdir -p /home/user/core/"$current_coreSubDir"/"$current_repositoryName"
+
+    if ! cd /home/user/core/"$current_coreSubDir"/"$current_repositoryName" || ! [[ -e /home/user/core/"$current_coreSubDir"/"$current_repositoryName" ]]
+    then
+        _messageError 'bad: FAIL: cd '/home/user/core/"$current_coreSubDir"/"$current_repositoryName"
+        _messageFAIL
+        exit 1
+    fi

+    # DANGER: Only use within ephemeral CI, ChRoot, etc.
+    [[ "$ub_dryRun" != "true" ]] && _gitFresh_enable
+    [[ "$ub_dryRun" != "true" ]] && _gitFresh
+    unset _gitFresh > /dev/null 2>&1
+    unset -f _gitFresh > /dev/null 2>&1

+    _stop
+}



@@ -36201,12 +42952,12 @@ _setupUbiquitous_accessories_here-python_hook() {
 # ATTENTION: Without either 'exec(exec(open()))' or 'execfile()' , 'from ubcorerc_pythonrc import *' must take effect!
 # If 'exec(exec(open()))' is substituted for 'from ubcorerc_pythonrc import *' then copying home directory files independent of '.ubcore'
 import os
-if os.path.exists("$ubcore_accessoriesFile_python"):
+if os.path.exists(r"$ubcore_accessoriesFile_python"):
 	import sys
 	import os
 	# https://stackoverflow.com/questions/2349991/how-to-import-other-python-files
-	sys.path.append(os.path.abspath("$ubcoreDir_accessories/python"))
-	from ubcorerc_pythonrc import *
+	sys.path.append(os.path.abspath(r"$ubcoreDir_accessories_python"))
+	from $ubcore_ubcorerc_pythonrc import *



@@ -36215,9 +42966,9 @@ if os.path.exists("$ubcore_accessoriesFile_python"):
 import sys
 # https://stackoverflow.com/questions/436198/what-is-an-alternative-to-execfile-in-python-3
 if sys.hexversion > 0x03000000:
-	exec('exec(open( "$ubcore_accessoriesFile_python_ubhome" ).read() )')
+	exec(r'exec(open( r"$ubcore_accessoriesFile_python_ubhome" ).read() )')
 else:
-	execfile("$ubcore_accessoriesFile_python_ubhome")
+	execfile(r"$ubcore_accessoriesFile_python_ubhome")



@@ -36231,9 +42982,11 @@ _setupUbiquitous_accessories_here-python_bashrc() {
 	cat << CZXWXcRMTo8EmM8i4d

 # Interactive bash shell will default to calling 'python3' while scripts invoking '#! /usr/bin/env python' or similar may still be given 'python2' equivalent.
-alias python=python3
+[[ "\$_PATH_pythonDir" == "" ]] && alias python=python3

-export PYTHONSTARTUP="$HOME"/.pythonrc
+[[ "\$_PATH_pythonDir" == "" ]] && [[ "\$_PYTHONSTARTUP" == "" ]] && export PYTHONSTARTUP="$HOME"/.pythonrc
+
+[[ "\$_PATH_pythonDir" != "" ]] && _set_msw_python_procedure

 CZXWXcRMTo8EmM8i4d
 }
@@ -36453,6 +43206,7 @@ _setupUbiquitous_accessories-python() {

 	_setupUbiquitous_accessories_here-python > "$ubcore_accessoriesFile_python_ubhome"

+	export ubcore_ubcorerc_pythonrc="ubcorerc_pythonrc"

 	if ! grep ubcore "$ubHome"/.pythonrc > /dev/null 2>&1 && _messagePlain_probe 'pythonrc'
 	then
@@ -36687,6 +43441,82 @@ _setupUbiquitous_resize() {

 }

+
+
+_install_certs() {
+    _messageNormal 'install: certs'
+    if _if_cygwin
+    then
+        # Editing the Cygwin root filesystem itself, root permissions granted within Cygwin environment itself are effective.
+        sudo() {
+            [[ "$1" == "-n" ]] && shift
+            "$@"
+        }
+    fi
+
+    #"$HOME"/core/data/certs/
+    #/usr/local/share/ca-certificates/
+    #/etc/pki/ca-trust/source/anchors/
+
+    #update-ca-certificates
+    #update-ca-trust
+
+    _install_certs_cp_procedure() {
+        _messagePlain_nominal '_install_certs: install: '"$2"
+        [[ -e "$2" ]] && sudo -n cp -f "$1"/*.crt "$2"
+    }
+    _install_certs_cp() {
+        [[ -e /cygdrive/c/core ]] && mkdir -p /cygdrive/c/core/data/certs/
+        _install_certs_cp_procedure "$1" /cygdrive/c/core/data/certs/
+
+        mkdir -p "$HOME"/core/data/certs/
+        _install_certs_cp_procedure "$1" "$HOME"/core/data/certs/
+
+        _install_certs_cp_procedure "$1" /usr/local/share/ca-certificates/
+
+        _if_cygwin && _install_certs_cp_procedure "$1" /etc/pki/ca-trust/source/anchors/
+
+        return 0
+    }
+    _install_certs_write() {
+        if [[ -e "$scriptAbsoluteFolder"/_lib/kit/app/researchEngine/kit/certs ]]
+        then
+            _install_certs_cp "$scriptAbsoluteFolder"/_lib/kit/app/researchEngine/kit/certs
+            return
+        fi
+        if [[ -e "$scriptAbsoluteFolder"/_lib/ubiquitous_bash/_lib/kit/app/researchEngine/kit/certs ]]
+        then
+            _install_certs_cp "$scriptAbsoluteFolder"/_lib/ubiquitous_bash/_lib/kit/app/researchEngine/kit/certs
+            return
+        fi
+        if [[ -e "$scriptAbsoluteFolder"/_lib/ubDistBuild/_lib/ubiquitous_bash/_lib/kit/app/researchEngine/kit/certs ]]
+        then
+            _install_certs_cp "$scriptAbsoluteFolder"/_lib/ubDistBuild/_lib/ubiquitous_bash/_lib/kit/app/researchEngine/kit/certs
+            return
+        fi
+        return 1
+    }
+
+
+    _if_cygwin && sudo -n rm -f /etc/pki/tls/certs/*.0
+
+    _install_certs_write
+
+    local currentExitStatus="1"
+    ! _if_cygwin && sudo -n update-ca-certificates
+    [[ "$?" == "0" ]] && currentExitStatus="0"
+    _if_cygwin && sudo -n update-ca-trust
+    [[ "$?" == "0" ]] && currentExitStatus="0"
+
+    return "$currentExitStatus"
+}
+
+
+
+
+
+
+
 _configureLocal() {
 	_configureFile "$1" "_local"
 }
@@ -36704,16 +43534,35 @@ _resetOps() {
 }

 _gitPull_ubiquitous() {
+	local currentExitStatus_gitBest_pull="0"
+	local currentExitStatus_gitBest_submodule_update="0"
 	#git pull
 	_gitBest pull
+	currentExitStatus_gitBest_pull="$?"
+	_gitBest submodule update --recursive
+	currentExitStatus_gitBest_submodule_update="$?"
+	[[ "$currentExitStatus_gitBest_pull" != "0" ]] && return "$currentExitStatus_gitBest_pull"
+	[[ "$currentExitStatus_gitBest_submodule_update" != "0" ]] && return "$currentExitStatus_gitBest_submodule_update"
+	return 0
 }

 _gitClone_ubiquitous() {
+	local currentExitStatus_gitBest_clone="0"
+	local currentExitStatus_gitBest_submodule_update="0"
 	#git clone --depth 1 git@github.com:mirage335/ubiquitous_bash.git
 	_gitBest clone --recursive --depth 1 git@github.com:mirage335/ubiquitous_bash.git
+	currentExitStatus_gitBest_clone="$?"
+	_gitBest submodule update --recursive
+	currentExitStatus_gitBest_submodule_update="$?"
+	[[ "$currentExitStatus_gitBest_clone" != "0" ]] && return "$currentExitStatus_gitBest_clone"
+	[[ "$currentExitStatus_gitBest_submodule_update" != "0" ]] && return "$currentExitStatus_gitBest_submodule_update"
+	return 0
 }

 _selfCloneUbiquitous() {
+	local currentExitStatus
+	currentExitStatus="0"
+
 	"$scriptBin"/.ubrgbin.sh _ubrgbin_cpA "$scriptBin" "$ubcoreUBdir"/ > /dev/null 2>&1
 	cp -a "$scriptAbsoluteLocation" "$ubcoreUBdir"/lean.sh
 	cp -a "$scriptAbsoluteLocation" "$ubcoreUBdir"/ubcore.sh
@@ -36723,33 +43572,56 @@ _selfCloneUbiquitous() {
 	cp -a "$scriptAbsoluteLocation" "$ubcoreUBdir"/ubiquitous_bash.sh

 	cp -a "$scriptAbsoluteFolder"/lean.py "$ubcoreUBdir"/lean.py > /dev/null 2>&1
+	[[ "$?" != "0" ]] && currentExitStatus="1"
+
+	mkdir "$ubcoreUBdir"/_lib/kit/app/researchEngine/kit/certs
+	if [[ -e "$scriptAbsoluteFolder"/_lib/kit/app/researchEngine/kit/certs ]]
+	then
+		cp -a "$scriptAbsoluteFolder"/_lib/kit/app/researchEngine/kit/certs/* "$ubcoreUBdir"/_lib/kit/app/researchEngine/kit/certs/
+	fi
+
+	return "$currentExitStatus"
 }

 _installUbiquitous() {
 	local localFunctionEntryPWD
 	localFunctionEntryPWD="$PWD"

-	cd "$ubcoreDir"
+	! cd "$ubcoreDir" && _messagePlain_bad 'bad: cd $ubcoreUBdir' && return 1

-	cd "$ubcoreUBdir"
-	_messagePlain_nominal 'attempt: git pull'
+	! cd "$ubcoreUBdir" && _messagePlain_bad 'bad: cd $ubcoreUBdir' && return 1
+	_messagePlain_nominal 'attempt: git pull: '"$PWD"
 	if [[ "$nonet" != "true" ]] && type git > /dev/null 2>&1
 	then
 		_gitBest_detect

-		local ub_gitPullStatus
-		#git pull
-		_gitBest pull
-		ub_gitPullStatus="$?"
-		#[[ "$ub_gitPullStatus" != 0 ]] && git pull && ub_gitPullStatus="$?"
-		[[ "$ub_gitPullStatus" != 0 ]] && _gitBest pull && ub_gitPullStatus="$?"
-		! cd "$localFunctionEntryPWD" && return 1
-
+		# CAUTION: After calling 'ubcp-cygwin-portable-installer' during 'build_ubcp' job of GitHub Actions 'build.yml', or similar devops/CI, etc, '/home/root/.ubcore/ubiquitous_bash' is a subdirectory at 'C:\...\ubiquitous_bash\_local\ubcp\cygwin\home\root\.ubcore\ubiquitous_bash' or similar.
+		#  DANGER: This causes MSWindows native 'git' binaries to perceive a git repository '.git' subdirectory already exists at the parent directory 'C:\...\ubiquitous_bash' , catastrophically causing 'git pull' to succeed, without populating the '/home/root/.ubcore/ubiquitous_bash' directory with 'ubiquitous_bash.sh' .
+		# Preventing that scenario, detect whether a '.git' subdirectory exists at "$ubcoreUBdir"/.git , which should also be the same as './.git' .
+		if [[ -e "$ubcoreUBdir"/.git ]] && [[ -e ./.git ]]
+		then
+			local ub_gitPullStatus
+			#git pull
+			_gitBest pull
+			ub_gitPullStatus="$?"
+			_gitBest submodule update --recursive
+			[[ "$?" != "0" ]] && ub_gitPullStatus="1"
+			#[[ "$ub_gitPullStatus" != 0 ]] && git pull && ub_gitPullStatus="$?"
+			if [[ "$ub_gitPullStatus" != 0 ]]
+			then
+				_gitBest pull
+				ub_gitPullStatus="$?"
+				_gitBest submodule update --recursive
+				[[ "$?" != "0" ]] && ub_gitPullStatus="1"
+			fi
+			! cd "$localFunctionEntryPWD" && return 1
+
 		[[ "$ub_gitPullStatus" == "0" ]] && _messagePlain_good 'pass: git pull' && cd "$localFunctionEntryPWD" && return 0
+		fi
 	fi
-	_messagePlain_warn 'fail: git pull'
+	_messagePlain_warn 'fail: git pull: '"$PWD"

-	cd "$ubcoreDir"
+	! cd "$ubcoreDir" && _messagePlain_bad 'bad: cd $ubcoreDir' && return 1
 	_messagePlain_nominal 'attempt: git clone'
 	[[ "$nonet" != "true" ]] && type git > /dev/null 2>&1 && [[ ! -e ".git" ]] && [[ ! -e "$ubcoreUBdir"/.git ]] && _gitClone_ubiquitous && _messagePlain_good 'pass: git clone' && return 0
 	[[ "$nonet" != "true" ]] && type git > /dev/null 2>&1 && [[ ! -e ".git" ]] && [[ ! -e "$ubcoreUBdir"/.git ]] && _gitClone_ubiquitous && _messagePlain_good 'pass: git clone' && return 0
@@ -36771,11 +43643,14 @@ _installUbiquitous() {
 		[[ -e "$scriptAbsoluteFolder"/ubcore_compressed.sh ]] && rm -f "$ubcoreUBdir"/ubcore_compressed.sh > /dev/null 2>&1
 		[[ -e "$scriptAbsoluteFolder"/ubiquitous_bash_compressed.sh ]] && rm -f "$ubcoreUBdir"/ubiquitous_bash_compressed.sh > /dev/null 2>&1
 		[[ -e "$scriptAbsoluteFolder"/lean.py ]] && rm -f "$ubcoreUBdir"/lean.py > /dev/null 2>&1
+		#[[ -e "$scriptAbsoluteFolder"/_lib/kit/app/researchEngine/kit/certs/* ]] && rm -f "$ubcoreUBdir"/_lib/kit/app/researchEngine/kit/certs/* > /dev/null 2>&1
 		#git reset --hard
 		#git pull "$scriptAbsoluteFolder"
 		_gitBest pull "$scriptAbsoluteFolder"
 		_gitBest reset --hard
 		ub_gitPullStatus="$?"
+		_gitBest submodule update --recursive
+		[[ "$?" != "0" ]] && ub_gitPullStatus="1"
 		! cd "$localFunctionEntryPWD" && return 1

 		[[ "$ub_gitPullStatus" == "0" ]] && _messagePlain_good 'pass: self git pull' && cd "$localFunctionEntryPWD" && return 0
@@ -36798,6 +43673,7 @@ _installUbiquitous() {

 _setupUbiquitous() {
 	_messageNormal "init: setupUbiquitous"
+	export ub_under_setupUbiquitous="true"

 	if _if_cygwin
 	then
@@ -36817,7 +43693,7 @@ _setupUbiquitous() {
 	export ubcoreFile="$ubcoreDir"/.ubcorerc

 	export ubcoreDir_accessories="$ubHome"/.ubcore/accessories
-
+	export ubcoreDir_accessories_python="$ubcoreDir_accessories"/python

 	# WARNING: Despite the name, do NOT point this to 'ubcore.sh' or similar. Full set of functions are expected from this file by some use cases!
 	export ubcoreUBdir="$ubcoreDir"/ubiquitous_bash
@@ -36893,6 +43769,9 @@ _setupUbiquitous() {
 	_messageNormal "install: setupUbiquitous_accessories"

 	_setupUbiquitous_accessories "$@"
+
+
+	_install_certs "$@"


 	_messageNormal "request: setupUbiquitous_accessories , setupUbiquitous"
@@ -38749,6 +45628,13 @@ export tmpSelf=""
 # ATTENTION: CAUTION: Should only be used by a single unusual Cygwin override. Must be reset if used for any other purpose.
 #export descriptiveSelf=""

+
+# ATTENTION: Set 'dumbpath_prefix' within functions, with '_prog/core.sh' , 'ops.sh' , or similar, etc.
+# WARNING: Any prefix will break '8.3' compatibility (usually don't care, but could affect DosBox, etc).
+unset dumbpath_prefix
+
+
+
 #####Global variables.
 #Fixed unique identifier for ubiquitous bash created global resources, such as bootdisc images to be automaticaly mounted by guests. Should NEVER be changed.
 export ubiquitiousBashIDnano=uk4u
@@ -38820,9 +45706,9 @@ _get_ub_globalVars_sessionDerived() {

 export lowsessionid=$(echo -n "$sessionid" | tr A-Z a-z )

-# ATTENTION: CAUTION: Unusual Cygwin override to accommodate MSW network drive ( at least when provided by '_userVBox' ) !
 if [[ "$scriptAbsoluteFolder" == '/cygdrive/'* ]] && [[ -e /cygdrive ]] && uname -a | grep -i cygwin > /dev/null 2>&1 && [[ "$scriptAbsoluteFolder" != '/cygdrive/c'* ]] && [[ "$scriptAbsoluteFolder" != '/cygdrive/C'* ]]
 then
+	# ATTENTION: CAUTION: Unusual Cygwin override to accommodate MSW network drive ( at least when provided by '_userVBox' ) !
 	if [[ "$tmpSelf" == "" ]]
 	then

@@ -38843,6 +45729,13 @@ then
 		true

 	fi
+
+	#_override_msw_git
+	type _override_msw_git_CEILING > /dev/null 2>&1 && _override_msw_git_CEILING
+	#if [[ "$1" != "_setupUbiquitous" ]] && [[ "$ub_under_setupUbiquitous" != "true" ]] && type _write_configure_git_safe_directory_if_admin_owned > /dev/null 2>&1
+	#then
+		_write_configure_git_safe_directory_if_admin_owned "$scriptAbsoluteFolder"
+	#fi
 elif uname -a | grep -i 'microsoft' > /dev/null 2>&1 && uname -a | grep -i 'WSL2' > /dev/null 2>&1
 then
 	if [[ "$tmpSelf" == "" ]]
@@ -38913,7 +45806,22 @@ then
 	fi
 fi

-#Essentially temporary tokens which may need to be reused.
+export scriptCall_bash="$scriptAbsoluteFolder"'/_bash.bat'
+export scriptCall_bin="$scriptAbsoluteFolder"/_bin.bat
+if type cygpath > /dev/null 2>&1
+then
+    export scriptAbsoluteLocation_msw=$(cygpath -w "$scriptAbsoluteLocation")
+    export scriptAbsoluteFolder_msw=$(cygpath -w "$scriptAbsoluteFolder")
+
+	export scriptLocal_msw=$(cygpath -w "$scriptLocal")
+    export scriptLib_msw=$(cygpath -w "$scriptLib")
+
+    export scriptCall_bash_msw="$scriptAbsoluteFolder_msw"'\_bash.bat'
+    export scriptCall_bin_msw="$scriptAbsoluteFolder_msw"'\_bin.bat'
+fi
+
+#Essentially temporary tokens which may need to be reused.
+# No, NOT AI tokens, predates widespread usage of that term.
 export scriptTokens="$scriptLocal"/.tokens

 #Reboot Detection Token Storage
@@ -45574,6 +52482,10 @@ _stop() {

 		rm -f "$currentAxelTmpFile"* > /dev/null 2>&1
 	fi
+
+	[[ -e "$scriptLocal"/python_nix.lock ]] && [[ $(head -c $(echo -n "$sessionid" | wc -c | tr -dc '0-9') "$scriptLocal"/python_nix.lock 2> /dev/null ) == "$sessionid" ]] && rm -f "$scriptLocal"/python_nix.lock > /dev/null 2>&1
+	[[ -e "$scriptLocal"/python_msw.lock ]] && [[ $(head -c $(echo -n "$sessionid" | wc -c | tr -dc '0-9') "$scriptLocal"/python_msw.lock 2> /dev/null ) == "$sessionid" ]] && rm -f "$scriptLocal"/python_msw.lock > /dev/null 2>&1
+	[[ -e "$scriptLocal"/python_cygwin.lock ]] && [[ $(head -c $(echo -n "$sessionid" | wc -c | tr -dc '0-9') "$scriptLocal"/python_cygwin.lock 2> /dev/null ) == "$sessionid" ]] && rm -f "$scriptLocal"/python_cygwin.lock > /dev/null 2>&1

 	_stop_stty_echo
 	if [[ "$1" != "" ]]
@@ -48713,48 +55625,58 @@ import os
 #os.system("$HOME/.ubcore/ubiquitous_bash/ubcore.sh _bash -i ")
 #currentArguments = [currentArguments] if isinstance(currentArguments, str) else currentArguments
 #print(['ubiquitous_bash.sh', '_bash'] + currentArguments)
-def _bash(currentArguments = ['-i'], currentPrint = False, current_ubiquitous_bash = "ubiquitous_bash.sh"):
-	if current_ubiquitous_bash == "ubiquitous_bash.sh":
-		if os.path.exists(os.environ['HOME'] + "/.ubcore/ubiquitous_bash/ubcore.sh"):
-			current_ubiquitous_bash = (os.environ['HOME'] + "/.ubcore/ubiquitous_bash/ubcore.sh")
-	if current_ubiquitous_bash == "ubiquitous_bash.sh":
-		if os.path.exists("/cygdrive/c/core/infrastructure/ubiquitous_bash/ubcore.sh"):
-			current_ubiquitous_bash = "/cygdrive/c/core/infrastructure/ubiquitous_bash/ubcore.sh"
-	if current_ubiquitous_bash == "ubiquitous_bash.sh":
-		if os.path.exists("/cygdrive/c/core/infrastructure/lean/lean.sh"):
-			current_ubiquitous_bash = "/cygdrive/c/core/infrastructure/lean/lean.sh"
-	currentArguments = ['-i'] if currentArguments == '-i' else currentArguments
-	if isinstance(currentArguments, str):
-		# WARNING: Discouraged.
-		if not currentArguments == '-i':
-			currentProc = subprocess.Popen(current_ubiquitous_bash + " _bash " + currentArguments, stdout=subprocess.PIPE, universal_newlines=True, shell=True)
-			(currentOut, currentErr) = currentProc.communicate()
-			currentProc.wait()
-			currentOut = currentOut.rstrip('\n')
-			if currentPrint == True:
-				print(currentOut)
-				return (currentOut), currentProc.returncode
-		else:
-			currentProc = subprocess.Popen(current_ubiquitous_bash + " _bash " + currentArguments, universal_newlines=True, shell=True)
-			(currentOut, currentErr) = currentProc.communicate()
-			currentProc.wait()
-		return (currentOut), currentProc.returncode
-	else:
-		if not currentArguments == ['-i']:
-			currentArguments = [currentArguments] if isinstance(currentArguments, str) else currentArguments
-			currentProc = subprocess.Popen([current_ubiquitous_bash, '_bash'] + currentArguments, stdout=subprocess.PIPE, universal_newlines=True)
-			(currentOut, currentErr) = currentProc.communicate()
-			currentProc.wait()
-			currentOut = currentOut.rstrip('\n')
-			if currentPrint == True:
-				print(currentOut)
-				return (currentOut), currentProc.returncode
-		else:
-			currentArguments = [currentArguments] if isinstance(currentArguments, str) else currentArguments
-			currentProc = subprocess.Popen([current_ubiquitous_bash, '_bash'] + currentArguments, universal_newlines=True)
-			(currentOut, currentErr) = currentProc.communicate()
-			currentProc.wait()
-		return (currentOut), currentProc.returncode
+# ATTENTION: WARNING: Enjoy this python code. The '_bash' and '_bin' function are quite possibly, even probably, and for actual reasons for every line of code being annoying, the worst python code that will ever be written by people. In plainer language, only mess with parts of this code for which you have stopped to fully understand exactly why every negation, if/else, return, print, etc, is in the exact order that it is.
+def _bash(currentArguments = ['-i'], currentPrint = False, current_ubiquitous_bash = "ubiquitous_bash.sh", interactive=True):
+    if current_ubiquitous_bash == "ubiquitous_bash.sh":
+        if os.path.exists(os.environ.get("scriptCall_bash_msw", "").replace('\\', '/')):
+            current_ubiquitous_bash = os.environ.get("scriptCall_bash_msw", "").replace('\\', '/')
+    if current_ubiquitous_bash == "ubiquitous_bash.sh":
+        if os.path.exists(os.environ.get("scriptAbsoluteLocation", "")):
+            current_ubiquitous_bash = os.environ.get("scriptAbsoluteLocation", "")
+    if current_ubiquitous_bash == "ubiquitous_bash.sh":
+        if os.path.exists(os.environ['HOME'] + "/.ubcore/ubiquitous_bash/ubcore.sh"):
+            current_ubiquitous_bash = (os.environ['HOME'] + "/.ubcore/ubiquitous_bash/ubcore.sh")
+    if current_ubiquitous_bash == "ubiquitous_bash.sh":
+        if os.path.exists("/cygdrive/c/core/infrastructure/ubiquitous_bash/ubcore.sh"):
+            current_ubiquitous_bash = "/cygdrive/c/core/infrastructure/ubiquitous_bash/ubcore.sh"
+    if current_ubiquitous_bash == "ubiquitous_bash.sh":
+        if os.path.exists("/cygdrive/c/core/infrastructure/ubiquitous_bash/lean.sh"):
+            current_ubiquitous_bash = "/cygdrive/c/core/infrastructure/ubiquitous_bash/lean.sh"
+    currentArguments = ['-i'] if currentArguments == '-i' else currentArguments
+    if isinstance(currentArguments, str):
+    # WARNING: Discouraged.
+        if not ( ( currentArguments == '-i' ) or ( currentArguments == '' ) or ( interactive == True ) ):
+            # ATTENTION: WARNING: Use of 'stdout=subprocess.PIPE' is NOT compatible with interactive shell!
+            currentProc = subprocess.Popen(current_ubiquitous_bash + " _bash " + currentArguments, stdout=subprocess.PIPE, universal_newlines=True, shell=True)
+            (currentOut, currentErr) = currentProc.communicate()
+            currentProc.wait()
+            currentOut = currentOut.rstrip('\n')
+            if currentPrint == True:
+                print(currentOut)
+                return (currentOut), currentProc.returncode
+        else:
+            currentProc = subprocess.Popen(current_ubiquitous_bash + " _bash " + currentArguments, universal_newlines=True, shell=True)
+            (currentOut, currentErr) = currentProc.communicate()
+            currentProc.wait()
+        return (currentOut), currentProc.returncode
+    else:
+        if not ( ( currentArguments == ['-i'] ) or ( currentArguments == [''] ) or ( interactive == True ) ):
+            currentArguments = [currentArguments] if isinstance(currentArguments, str) else currentArguments
+            # ATTENTION: WARNING: Use of 'stdout=subprocess.PIPE' is NOT compatible with interactive shell!
+            currentProc = subprocess.Popen([current_ubiquitous_bash, '_bash'] + currentArguments, stdout=subprocess.PIPE, universal_newlines=True)
+            (currentOut, currentErr) = currentProc.communicate()
+            currentProc.wait()
+            currentOut = currentOut.rstrip('\n')
+            if currentPrint == True:
+                print(currentOut)
+                return (currentOut), currentProc.returncode
+        else:
+            if ( currentArguments == [''] ): currentArguments = ['-i']
+            currentArguments = [currentArguments] if isinstance(currentArguments, str) else currentArguments
+            currentProc = subprocess.Popen([current_ubiquitous_bash, '_bash'] + currentArguments, universal_newlines=True)
+            (currentOut, currentErr) = currentProc.communicate()
+            currentProc.wait()
+        return (currentOut), currentProc.returncode



@@ -48778,48 +55700,61 @@ import os
 #_bin('_bash')
 #print( _bin('_false', False)[1] )
 #_bin("_getScriptAbsoluteLocation", True, os.path.expanduser("~/core/infrastructure/ubiquitous_bash/ubiquitous_bash.sh"))
-def _bin(currentArguments = [''], currentPrint = False, current_ubiquitous_bash = "ubiquitous_bash.sh"):
-	if current_ubiquitous_bash == "ubiquitous_bash.sh":
-		if os.path.exists(os.environ['HOME'] + "/.ubcore/ubiquitous_bash/ubcore.sh"):
-			current_ubiquitous_bash = (os.environ['HOME'] + "/.ubcore/ubiquitous_bash/ubcore.sh")
-	if current_ubiquitous_bash == "ubiquitous_bash.sh":
-		if os.path.exists("/cygdrive/c/core/infrastructure/ubiquitous_bash/ubcore.sh"):
-			current_ubiquitous_bash = "/cygdrive/c/core/infrastructure/ubiquitous_bash/ubcore.sh"
-	if current_ubiquitous_bash == "ubiquitous_bash.sh":
-		if os.path.exists("/cygdrive/c/core/infrastructure/lean/lean.sh"):
-			current_ubiquitous_bash = "/cygdrive/c/core/infrastructure/lean/lean.sh"
-	currentArguments = [''] if currentArguments == '' else currentArguments
-	if isinstance(currentArguments, str):
-		# WARNING: Discouraged.
-		if not ( ( currentArguments == '/bin/bash -i' ) or ( currentArguments == '/bin/bash' ) ):
-			currentProc = subprocess.Popen(current_ubiquitous_bash + " _bin " + currentArguments, stdout=subprocess.PIPE, universal_newlines=True, shell=True)
-			(currentOut, currentErr) = currentProc.communicate()
-			currentProc.wait()
-			currentOut = currentOut.rstrip('\n')
-			if currentPrint == True:
-				print(currentOut)
-				return (currentOut), currentProc.returncode
-		else:
-			currentProc = subprocess.Popen(current_ubiquitous_bash + " _bin " + currentArguments, universal_newlines=True, shell=True)
-			(currentOut, currentErr) = currentProc.communicate()
-			currentProc.wait()
-		return (currentOut), currentProc.returncode
-	else:
-		if not (  ( currentArguments == ['/bin/bash', '-i'] ) or ( currentArguments == ['/bin/bash'] ) or ( currentArguments == ['_qalculate', ''] ) or ( currentArguments == ['_qalculate'] ) or ( currentArguments == ['_octave', ''] ) or ( currentArguments == ['_octave'] )  ):
-			currentArguments = [currentArguments] if isinstance(currentArguments, str) else currentArguments
-			currentProc = subprocess.Popen([current_ubiquitous_bash, '_bin'] + currentArguments, stdout=subprocess.PIPE, universal_newlines=True)
-			(currentOut, currentErr) = currentProc.communicate()
-			currentProc.wait()
-			currentOut = currentOut.rstrip('\n')
-			if currentPrint == True:
-				print(currentOut)
-				return (currentOut), currentProc.returncode
-		else:
-			currentArguments = [currentArguments] if isinstance(currentArguments, str) else currentArguments
-			currentProc = subprocess.Popen([current_ubiquitous_bash, '_bin'] + currentArguments, universal_newlines=True)
-			(currentOut, currentErr) = currentProc.communicate()
-			currentProc.wait()
-		return (currentOut), currentProc.returncode
+# ATTENTION: WARNING: Enjoy this python code. The '_bash' and '_bin' function are quite possibly, even probably, and for actual reasons for every line of code being annoying, the worst python code that will ever be written by people. In plainer language, only mess with parts of this code for which you have stopped to fully understand exactly why every negation, if/else, return, print, etc, is in the exact order that it is.
+def _bin(currentArguments = [''], currentPrint = False, current_ubiquitous_bash = "ubiquitous_bash.sh", interactive=False):
+    if current_ubiquitous_bash == "ubiquitous_bash.sh":
+        if os.path.exists(os.environ.get("scriptCall_bash_msw", "").replace('\\', '/')):
+            current_ubiquitous_bash = os.environ.get("scriptCall_bash_msw", "").replace('\\', '/')
+    if current_ubiquitous_bash == "ubiquitous_bash.sh":
+        if os.path.exists(os.environ.get("scriptAbsoluteLocation", "")):
+            current_ubiquitous_bash = os.environ.get("scriptAbsoluteLocation", "")
+    if current_ubiquitous_bash == "ubiquitous_bash.sh":
+        if os.path.exists(os.environ['HOME'] + "/.ubcore/ubiquitous_bash/ubcore.sh"):
+            current_ubiquitous_bash = (os.environ['HOME'] + "/.ubcore/ubiquitous_bash/ubcore.sh")
+    if current_ubiquitous_bash == "ubiquitous_bash.sh":
+        if os.path.exists("/cygdrive/c/core/infrastructure/ubiquitous_bash/ubcore.sh"):
+            current_ubiquitous_bash = "/cygdrive/c/core/infrastructure/ubiquitous_bash/ubcore.sh"
+    if current_ubiquitous_bash == "ubiquitous_bash.sh":
+        if os.path.exists("/cygdrive/c/core/infrastructure/ubiquitous_bash/lean.sh"):
+            current_ubiquitous_bash = "/cygdrive/c/core/infrastructure/ubiquitous_bash/lean.sh"
+    # ATTENTION: Comment out next python line of code to test this code with an empty string.
+    #./lean.py "_bin('', currentPrint=True)"
+    currentArguments = [''] if currentArguments == '' else currentArguments
+    if isinstance(currentArguments, str):
+        # WARNING: Discouraged.
+        if not ( ( ( currentArguments == '/bin/bash -i' ) or ( currentArguments == '/bin/bash' ) or ( currentArguments == '_bash' ) or ( currentArguments == '' ) ) or ( interactive == True ) ) :
+            # ATTENTION: WARNING: Use of 'stdout=subprocess.PIPE' is NOT compatible with interactive shell!
+            currentProc = subprocess.Popen(current_ubiquitous_bash + " _bin " + currentArguments, stdout=subprocess.PIPE, universal_newlines=True, shell=True)
+            (currentOut, currentErr) = currentProc.communicate()
+            currentProc.wait()
+            currentOut = currentOut.rstrip('\n')
+            if currentPrint == True:
+                print(currentOut)
+                return (currentOut), currentProc.returncode
+        else:
+            if ( currentArguments == '' ): currentArguments = '_bash'
+            currentProc = subprocess.Popen(current_ubiquitous_bash + " _bin " + currentArguments, universal_newlines=True, shell=True)
+            (currentOut, currentErr) = currentProc.communicate()
+            currentProc.wait()
+        return (currentOut), currentProc.returncode
+    else:
+        if not ( ( ( currentArguments == ['/bin/bash', '-i'] ) or ( currentArguments == ['/bin/bash'] ) or ( currentArguments == ['_bash'] ) or ( currentArguments == ['_bash', '-i'] ) or ( currentArguments == ['_qalculate', ''] ) or ( currentArguments == ['_qalculate'] ) or ( currentArguments == ['_octave', ''] ) or ( currentArguments == ['_octave'] ) or ( currentArguments == [''] ) ) or ( interactive == True ) ):
+            currentArguments = [currentArguments] if isinstance(currentArguments, str) else currentArguments
+            # ATTENTION: WARNING: Use of 'stdout=subprocess.PIPE' is NOT compatible with interactive shell!
+            currentProc = subprocess.Popen([current_ubiquitous_bash, '_bin'] + currentArguments, stdout=subprocess.PIPE, universal_newlines=True)
+            (currentOut, currentErr) = currentProc.communicate()
+            currentProc.wait()
+            currentOut = currentOut.rstrip('\n')
+            if currentPrint == True:
+                print(currentOut)
+                return (currentOut), currentProc.returncode
+        else:
+            if ( currentArguments == [''] ): currentArguments = ['_bash']
+            currentArguments = [currentArguments] if isinstance(currentArguments, str) else currentArguments
+            currentProc = subprocess.Popen([current_ubiquitous_bash, '_bin'] + currentArguments, universal_newlines=True)
+            (currentOut, currentErr) = currentProc.communicate()
+            currentProc.wait()
+        return (currentOut), currentProc.returncode

 # ATTENTION: Only intended for indirect calls.
 # https://stackoverflow.com/questions/5067604/determine-function-name-from-within-that-function-without-using-traceback
@@ -48895,15 +55830,54 @@ def _octave(currentString = [], currentArguments = [], currentPrint = False, cur



-import readline # optional, will allow Up/Down/History in the console
+if sys.platform == 'win32':
+    try:
+        import pyreadline3 as readline
+    except ImportError:
+        readline = None
+else:
+    try:
+        import readline # optional, will allow Up/Down/History in the console
+    except ImportError:
+        readline = None
 import code
+
+# ATTRIBUTION-AI: ChatGPT o3  2025-04-19
+def _enable_readline():
+    """
+    Make sure arrow keys, history and TAB completion work in the
+    interpreter that we embed with code.InteractiveConsole.
+    """
+    try:
+        import readline, rlcompleter, atexit, os
+        # basic key bindings
+        readline.parse_and_bind('tab: complete')
+        # persistent history file
+        histfile = os.path.expanduser('~/.pyhistory')
+        if os.path.exists(histfile):
+            readline.read_history_file(histfile)
+        atexit.register(readline.write_history_file, histfile)
+    except ImportError:
+        # readline (or pyreadline on Windows) is not available
+        pass
+
+
+
+
 #_python()
 # https://stackoverflow.com/questions/5597836/embed-create-an-interactive-python-shell-inside-a-python-program
 def _python():
-	variables = globals().copy()
-	variables.update(locals())
-	shell = code.InteractiveConsole(variables)
-	shell.interact()
+    _enable_readline()
+    variables = globals().copy()
+    variables.update(locals())
+    shell = code.InteractiveConsole(variables)
+    # ATTRIBUTION-AI: ChatGPT 4.1  2025-04-19
+    if os.name == 'nt':  # True on Windows
+        print(" Press Ctrl+D twice (or Ctrl+Z then Enter) to exit this Python shell.")
+    if os.name == 'posix':
+        print(" Press Ctrl+D twice (or Ctrl+Z then Enter) to exit this Python shell.")
+    # ATTRIBUTION: NOT AI !
+    shell.interact()



@@ -48912,33 +55886,117 @@ import os
 import socket
 import string
 import re
-#if sys.hexversion < 0x03060000:
-#	exit(1)
-# https://www.codementor.io/@arpitbhayani/personalize-your-python-prompt-13ts4kw6za
-# https://stackoverflow.com/questions/4271740/how-can-i-use-python-to-get-the-system-hostname
-# https://bugs.python.org/issue20359
-#os.environ['PWD']
-#os.path.expanduser(os.getcwd())
-#\033[0;35;47mpython-%d\033[0m
-#return "\033[92mIn [%d]:\033[0m " % (self.line)
-#return ">>> "
-#return "\033[1;94m|\033[91m#:\033[1;93m%s\033[1;92m@%s\033[1;94m)-%s(\033[1;95m\033[0;35;47mpython-%s\033[0m\033[1;94m)\033[1;96m|\n\033[1;94m|\033[1;97m[%s]\n\033[1;94m|\033[1;96m%d\033[1;94m) \033[1;96m>\033[0m " % (os.getenv('USER','root'), socket.gethostname(), os.environ.get('prompt_cloudNetName', ''), hex(sys.hexversion), re.sub('^%s' % os.environ['HOME'], '~', os.path.expanduser(os.getcwd()) ), self.line)
-#return "\033[1;94m|\033[91m#:\033[1;93m%s\033[1;92m@%s\033[1;94m)-%s(\033[1;95m\033[0;35;47mpython-%s\033[0m\033[1;94m)\033[1;96m|\n\033[1;94m|\033[1;97m[%s]\n\033[1;94m|%d\033[1;94m) \033[1;96m>\033[0m " % (os.getenv('USER','root'), socket.gethostname(), os.environ.get('prompt_cloudNetName', ''), hex(sys.hexversion), re.sub('^%s' % os.environ['HOME'], '~', os.path.expanduser(os.getcwd()) ), self.line)
-#os.environ['USER']
-#os.getenv('USER','root')
-class ubPythonPS1(object):
-	def __init__(self):
-		self.line = 0
-
-	def __str__(self):
-		self.line += 1
-		if self.line == 1:
-			return "\x01\033[1;94m\x02|\x01\033[91m\x02#:\x01\033[1;93m\x02%s\x01\033[1;92m\x02@%s\x01\033[1;94m\x02)-%s(\x01\033[1;95m\x02\x01\033[0;35;47m\x02python-%s\x01\033[0m\x02\x01\033[1;94m\x02)\x01\033[1;96m\x02|\n\x01\033[1;94m\x02|\x01\033[1;97m\x02[%s]\n\x01\033[1;94m\x02|\x01\033[1;96m\x02%d\x01\033[1;94m\x02) \x01\033[1;96m\x02>\x01\033[0m\x02 " % (os.getenv('USER','root'), socket.gethostname(), os.environ.get('prompt_cloudNetName', ''), hex(sys.hexversion), re.sub('^%s' % os.environ['HOME'], '~', os.path.expanduser(os.getcwd()) ), self.line)
-		else:
-			return "\x01\033[1;94m\x02|\x01\033[91m\x02#:\x01\033[1;93m\x02%s\x01\033[1;92m\x02@%s\x01\033[1;94m\x02)-%s(\x01\033[1;95m\x02\x01\033[0;35;47m\x02python-%s\x01\033[0m\x02\x01\033[1;94m\x02)\x01\033[1;96m\x02|\n\x01\033[1;94m\x02|\x01\033[1;97m\x02[%s]\n\x01\033[1;94m\x02|%d\x01\033[1;94m\x02) \x01\033[1;96m\x02>\x01\033[0m\x02 " % (os.getenv('USER','root'), socket.gethostname(), os.environ.get('prompt_cloudNetName', ''), hex(sys.hexversion), re.sub('^%s' % os.environ['HOME'], '~', os.path.expanduser(os.getcwd()) ), self.line)
-
-sys.ps1 = ubPythonPS1()
-sys.ps2 = "\x01\033[0;96m\x02|...\x01\033[0m\x02 "
+
+# ATTRIBUTION-AI: OpRt_.nvidia/llama-3.1-nemotron-ultra-253b-v1:free  2025-04-18  (partially)
+# Determine if running on Windows
+is_windows = os.name == 'nt'
+
+# ATTRIBUTION-AI: OpRt_.nvidia/llama-3.1-nemotron-ultra-253b-v1:free  2025-04-18  (partially)
+# Attempt to import colorama if on Windows
+use_colorama = False
+if is_windows:
+    try:
+        from colorama import init, Fore, Back, Style
+        init(autoreset=True)
+        use_colorama = True
+    except ImportError:
+        pass  # Silently proceed without colorama if import fails
+
+# Color definitions (use ANSI if not on Windows or colorama is not used)
+if use_colorama:
+    # ATTRIBUTION-AI: OpRt_.nvidia/llama-3.1-nemotron-ultra-253b-v1:free  2025-04-18  (partially)  ( also the preceeding line  if use_colorama:  )
+    class ubPythonPS1(object):
+        def __init__(self):
+            self.line = 0
+
+        def __str__(self):
+            self.line += 1
+            user = os.getenv('USER', 'root')
+            hostname = socket.gethostname()
+            cloud_net_name = os.environ.get('prompt_cloudNetName', '')
+            #py_version = f"v{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}"
+            ## ATTRIBUTION-AI: OpRt_.nvidia/llama-3.1-nemotron-ultra-253b-v1:free  2025-04-19
+            #py_version = f"v{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}" if not os.getenv('VIRTUAL_ENV_PROMPT') else os.getenv('VIRTUAL_ENV_PROMPT', '')
+            # ATTRIBUTION-AI: ChatGPT o3  2025-04-19
+            py_version = os.getenv("VIRTUAL_ENV_PROMPT") or f"Python-v{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}"
+            cwd = os.path.expanduser(os.getcwd())
+
+            home_dir = os.environ.get('HOME', os.environ.get('USERPROFILE', ''))
+            if home_dir:
+                cwd = re.sub(f'^{re.escape(home_dir)}', '~', cwd)
+
+            # Color definitions (matched to ANSI colors)
+            blue = Fore.BLUE
+            red = Fore.RED
+            green = Fore.GREEN  # Hostname color
+            yellow = Fore.YELLOW
+            magenta = Fore.MAGENTA  # Python version color
+            cyan = Fore.CYAN
+            white = Fore.WHITE
+            reset = Style.RESET_ALL
+            bg_white = Back.WHITE
+
+            if self.line == 1:
+                prompt = (
+                    f"{blue}|{red}#{red}:{yellow}{user}{green}@{green}{hostname}{blue})-{cloud_net_name}({magenta}{bg_white}{py_version}{reset}{blue}){cyan}|\n"
+                    #f"{blue}|{white}[{cwd}]\n"
+                    f"{white}{cwd}\n"
+                    f"{blue}|{cyan}{self.line}{blue}) {cyan}> {reset}"
+                )
+            else:
+                prompt = (
+                    f"{blue}|{red}#{red}:{yellow}{user}{green}@{green}{hostname}{blue})-{cloud_net_name}({magenta}{bg_white}{py_version}{reset}{blue}){cyan}|\n"
+                    #f"{blue}|{white}[{cwd}]\n"
+                    f"{white}{cwd}\n"
+                    f"{blue}|{blue}{self.line}{blue}) {cyan}> {reset}"
+                )
+            return prompt
+
+    sys.ps1 = ubPythonPS1()
+    sys.ps2 = f"{Fore.CYAN}|...{Style.RESET_ALL} "
+else:
+    # ATTRIBUTION: NOT AI !
+    #if sys.hexversion < 0x03060000:
+    #	exit(1)
+    # https://www.codementor.io/@arpitbhayani/personalize-your-python-prompt-13ts4kw6za
+    # https://stackoverflow.com/questions/4271740/how-can-i-use-python-to-get-the-system-hostname
+    # https://bugs.python.org/issue20359
+    #os.environ['PWD']
+    #os.path.expanduser(os.getcwd())
+    #\033[0;35;47mpython-%d\033[0m
+    #return "\033[92mIn [%d]:\033[0m " % (self.line)
+    #return ">>> "
+    #return "\033[1;94m|\033[91m#:\033[1;93m%s\033[1;92m@%s\033[1;94m)-%s(\033[1;95m\033[0;35;47mpython-%s\033[0m\033[1;94m)\033[1;96m|\n\033[1;94m|\033[1;97m[%s]\n\033[1;94m|\033[1;96m%d\033[1;94m) \033[1;96m>\033[0m " % (os.getenv('USER','root'), socket.gethostname(), os.environ.get('prompt_cloudNetName', ''), hex(sys.hexversion), re.sub('^%s' % os.environ['HOME'], '~', os.path.expanduser(os.getcwd()) ), self.line)
+    #return "\033[1;94m|\033[91m#:\033[1;93m%s\033[1;92m@%s\033[1;94m)-%s(\033[1;95m\033[0;35;47mpython-%s\033[0m\033[1;94m)\033[1;96m|\n\033[1;94m|\033[1;97m[%s]\n\033[1;94m|%d\033[1;94m) \033[1;96m>\033[0m " % (os.getenv('USER','root'), socket.gethostname(), os.environ.get('prompt_cloudNetName', ''), hex(sys.hexversion), re.sub('^%s' % os.environ['HOME'], '~', os.path.expanduser(os.getcwd()) ), self.line)
+    #os.environ['USER']
+    #os.getenv('USER','root')
+    class ubPythonPS1(object):
+        def __init__(self):
+            self.line = 0
+
+        def __str__(self):
+            self.line += 1
+            if self.line == 1:
+                #return "\x01\033[1;94m\x02|\x01\033[91m\x02#:\x01\033[1;93m\x02%s\x01\033[1;92m\x02@%s\x01\033[1;94m\x02)-%s(\x01\033[1;95m\x02\x01\033[0;35;47m\x02python-%s\x01\033[0m\x02\x01\033[1;94m\x02)\x01\033[1;96m\x02|\n\x01\033[1;94m\x02|\x01\033[1;97m\x02[%s]\n\x01\033[1;94m\x02|\x01\033[1;96m\x02%d\x01\033[1;94m\x02) \x01\033[1;96m\x02>\x01\033[0m\x02 " % (os.getenv('USER','root'), socket.gethostname(), os.environ.get('prompt_cloudNetName', ''), hex(sys.hexversion), re.sub('^%s' % os.environ['HOME'], '~', os.path.expanduser(os.getcwd()) ), self.line)
+                #return "\x01\033[1;94m\x02|\x01\033[91m\x02#:\x01\033[1;93m\x02%s\x01\033[1;92m\x02@%s\x01\033[1;94m\x02)-%s(\x01\033[1;95m\x02\x01\033[0;35;47m\x02python-%s\x01\033[0m\x02\x01\033[1;94m\x02)\x01\033[1;96m\x02|\n\x01\033[1;97m\x02%s\n\x01\033[1;94m\x02|\x01\033[1;96m\x02%d\x01\033[1;94m\x02) \x01\033[1;96m\x02>\x01\033[0m\x02 " % (os.getenv('USER','root'), socket.gethostname(), os.environ.get('prompt_cloudNetName', ''), hex(sys.hexversion), re.sub('^%s' % os.environ['HOME'], '~', os.path.expanduser(os.getcwd()) ), self.line)
+                # ATTRIBUTION-AI: OpRt_.nvidia/llama-3.1-nemotron-ultra-253b-v1:free  2025-04-19
+                return "\x01\033[1;94m\x02|\x01\033[91m\x02#:\x01\033[1;93m\x02%s\x01\033[1;92m\x02@%s\x01\033[1;94m\x02)-%s(\x01\033[1;95m\x02\x01\033[0;35;47m\x02python-%s\x01\033[0m\x02\x01\033[1;94m\x02)\x01\033[1;96m\x02|\n\x01\033[1;97m\x02%s\n\x01\033[1;94m\x02|\x01\033[1;96m\x02%d\x01\033[1;94m\x02) \x01\033[1;96m\x02>\x01\033[0m\x02 " % (os.getenv('USER','root'), socket.gethostname(), os.environ.get('prompt_cloudNetName', ''), hex(sys.hexversion) if 'VIRTUAL_ENV_PROMPT' not in os.environ or not os.environ['VIRTUAL_ENV_PROMPT'] else os.environ['VIRTUAL_ENV_PROMPT'], re.sub('^%s' % os.environ['HOME'], '~', os.path.expanduser(os.getcwd()) ), self.line)
+            else:
+                #return "\x01\033[1;94m\x02|\x01\033[91m\x02#:\x01\033[1;93m\x02%s\x01\033[1;92m\x02@%s\x01\033[1;94m\x02)-%s(\x01\033[1;95m\x02\x01\033[0;35;47m\x02python-%s\x01\033[0m\x02\x01\033[1;94m\x02)\x01\033[1;96m\x02|\n\x01\033[1;94m\x02|\x01\033[1;97m\x02[%s]\n\x01\033[1;94m\x02|%d\x01\033[1;94m\x02) \x01\033[1;96m\x02>\x01\033[0m\x02 " % (os.getenv('USER','root'), socket.gethostname(), os.environ.get('prompt_cloudNetName', ''), hex(sys.hexversion), re.sub('^%s' % os.environ['HOME'], '~', os.path.expanduser(os.getcwd()) ), self.line)
+                #return "\x01\033[1;94m\x02|\x01\033[91m\x02#:\x01\033[1;93m\x02%s\x01\033[1;92m\x02@%s\x01\033[1;94m\x02)-%s(\x01\033[1;95m\x02\x01\033[0;35;47m\x02python-%s\x01\033[0m\x02\x01\033[1;94m\x02)\x01\033[1;96m\x02|\n\x01\033[1;97m\x02%s\n\x01\033[1;94m\x02|%d\x01\033[1;94m\x02) \x01\033[1;96m\x02>\x01\033[0m\x02 " % (os.getenv('USER','root'), socket.gethostname(), os.environ.get('prompt_cloudNetName', ''), hex(sys.hexversion), re.sub('^%s' % os.environ['HOME'], '~', os.path.expanduser(os.getcwd()) ), self.line)
+                # ATTRIBUTION-AI: OpRt_.nvidia/llama-3.1-nemotron-ultra-253b-v1:free  2025-04-19
+                return "\x01\033[1;94m\x02|\x01\033[91m\x02#:\x01\033[1;93m\x02%s\x01\033[1;92m\x02@%s\x01\033[1;94m\x02)-%s(\x01\033[1;95m\x02\x01\033[0;35;47m\x02python-%s\x01\033[0m\x02\x01\033[1;94m\x02)\x01\033[1;96m\x02|\n\x01\033[1;97m\x02%s\n\x01\033[1;94m\x02|%d\x01\033[1;94m\x02) \x01\033[1;96m\x02>\x01\033[0m\x02 " % (os.getenv('USER','root'), socket.gethostname(), os.environ.get('prompt_cloudNetName', ''), hex(sys.hexversion) if 'VIRTUAL_ENV_PROMPT' not in os.environ or not os.environ['VIRTUAL_ENV_PROMPT'] else os.environ['VIRTUAL_ENV_PROMPT'], re.sub('^%s' % os.environ['HOME'], '~', os.path.expanduser(os.getcwd()) ), self.line)
+
+    sys.ps1 = ubPythonPS1()
+    sys.ps2 = "\x01\033[0;96m\x02|...\x01\033[0m\x02 "
+
+
+# ATTRIBUTION-AI: OpRt_.nvidia/llama-3.1-nemotron-ultra-253b-v1:free  2025-04-18 (only the next line  if is_windows and not use_colorama:  )
+if is_windows and not use_colorama:
+    # ATTRIBUTION: NOT AI !
+    # https://www.codementor.io/@arpitbhayani/personalize-your-python-prompt-13ts4kw6za
+    sys.ps1 = '>>> '
+    sys.ps2 = '... '

 #_python()

@@ -49122,6 +56180,8 @@ _init_deps() {
 	export enUb_dev_heavy_atom=""

 	export enUb_generic=""
+
+	export enUb_dev_buildOps=""

 	export enUb_cloud_heavy=""

@@ -49136,15 +56196,24 @@ _init_deps() {
 	export enUb_cloud_self=""
 	export enUb_cloud_build=""
 	export enUb_notLean=""
+	export enUb_github=""
 	export enUb_distro=""
+	export enUb_getMinimal=""
+	export enUb_getMost_special_veracrypt=""
 	export enUb_build=""
 	export enUb_buildBash=""
 	export enUb_os_x11=""
 	export enUb_proxy=""
 	export enUb_proxy_special=""
+	export enUb_serial=""
 	export enUb_fw=""
 	export enUb_clog=""
 	export enUb_x11=""
+	export enUb_researchEngine=""
+	export enUb_ollama=""
+	export enUb_ai_dataset=""
+	export enUb_ai_semanticAssist=""
+	export enUb_ai_knowledge=""
 	export enUb_blockchain=""
 	export enUb_java=""
 	export enUb_image=""
@@ -49153,6 +56222,7 @@ _init_deps() {
 	export enUb_virt_thick=""
 	export enUb_virt_translation=""
 	export enUb_ChRoot=""
+	export enUb_bios=""
 	export enUb_QEMU=""
 	export enUb_vbox=""
 	export enUb_docker=""
@@ -49161,17 +56231,22 @@ _init_deps() {
 	export enUb_msw=""
 	export enUb_fakehome=""
 	export enUb_abstractfs=""
+	export enUb_virt_python=""
 	export enUb_buildBash=""
 	export enUb_buildBashUbiquitous=""

 	export enUb_virt_translation_gui=""
+
+	export enUb_virt_dumbpath=""

 	export enUb_command=""
 	export enUb_synergy=""

 	export enUb_hardware=""
+	export enUb_measurement=""
 	export enUb_enUb_x220t=""
 	export enUb_enUb_w540=""
+	export enUb_enUb_gpd=""
 	export enUb_enUb_peripherial=""

 	export enUb_user=""
@@ -49188,6 +56263,10 @@ _init_deps() {
 	export enUb_haskell=""

 	export enUb_calculators=""
+
+	export enUb_ai_shortcuts=""
+	export enUb_ollama_shortcuts=""
+	export enUb_factory_shortcuts=""
 }

 _deps_generic() {
@@ -49350,6 +56429,18 @@ _deps_ai() {
 	export enUb_researchEngine="true"
 	export enUb_ollama="true"
 }
+_deps_ai_dataset() {
+	_deps_ai
+	_deps_ai_shortcuts
+	export enUb_ai_dataset="true"
+}
+_deps_ai_semanticAssist() {
+	_deps_ai_dataset
+	export enUb_ai_semanticAssist="true"
+}
+_deps_ai_knowledge() {
+	export enUb_ai_knowledge="true"
+}

 _deps_blockchain() {
 	_deps_notLean
@@ -49481,12 +56572,21 @@ _deps_abstractfs() {
 	export enUb_abstractfs="true"
 }

+_deps_virtPython() {
+	_deps_python
+	export enUb_virt_python="true"
+}
+
 _deps_virt_translation_gui() {
 	_deps_virt_translation

 	export enUb_virt_translation_gui="true"
 }

+_deps_dumbpath() {
+	export enUb_virt_dumbpath="true"
+}
+
 _deps_command() {
 	_deps_os_x11
 	_deps_proxy
@@ -49572,12 +56672,19 @@ _deps_calculators() {
 	export enUb_calculators="true"
 }

-_deps_ai_shortuts() {
+_deps_ai_shortcuts() {
 	_deps_generic

+	export enUb_ai_shortcuts="true"
 	export enUb_ollama_shortcuts="true"
 }

+_deps_factory_shortcuts() {
+	_deps_generic
+
+	export enUb_factory_shortcuts="true"
+}
+
 #placeholder, define under "queue/build"
 # _deps_queue() {
 # 	# Message queue - 'broadcastPipe' , etc , underlying functions , '_read_page' , etc .
@@ -50076,6 +57183,8 @@ _compile_bash_deps() {
 		# Serial depends on '_getMost_backend', which explicitly requires only 'notLean' .
 		#_deps_notLean
 		#_deps_serial
+
+		_deps_virtPython

 		_deps_stopwatch

@@ -50109,6 +57218,8 @@ _compile_bash_deps() {
 		#_deps_cloud_build

 		_deps_abstractfs
+
+		_deps_virtPython

 		_deps_virt_translation

@@ -50135,7 +57246,14 @@ _compile_bash_deps() {
 		_deps_haskell

 		_deps_ai
-		_deps_ai_shortuts
+		_deps_ai_shortcuts
+
+		#_deps_ai
+		_deps_ai_dataset
+		_deps_ai_semanticAssist
+		_deps_ai_knowledge
+
+		_deps_factory_shortcuts

 		_deps_calculators

@@ -50200,7 +57318,14 @@ _compile_bash_deps() {
 		_deps_haskell

 		_deps_ai
-		_deps_ai_shortuts
+		_deps_ai_shortcuts
+
+		#_deps_ai
+		_deps_ai_dataset
+		_deps_ai_semanticAssist
+		_deps_ai_knowledge
+
+		_deps_factory_shortcuts

 		_deps_calculators

@@ -50210,6 +57335,8 @@ _compile_bash_deps() {
 		_deps_metaengine

 		_deps_serial
+
+		_deps_virtPython

 		_deps_stopwatch

@@ -50224,7 +57351,13 @@ _compile_bash_deps() {
 		_deps_python
 		_deps_haskell

-		_deps_ai_shortuts
+		_deps_ai
+		_deps_ai_shortcuts
+
+		#_deps_ai
+		_deps_ai_dataset
+		_deps_ai_semanticAssist
+		_deps_ai_knowledge

 		_deps_calculators

@@ -50234,6 +57367,8 @@ _compile_bash_deps() {
 		_deps_metaengine

 		_deps_abstractfs
+
+		_deps_virtPython

 		_deps_serial

@@ -50251,7 +57386,13 @@ _compile_bash_deps() {
 		_deps_python
 		_deps_haskell

-		_deps_ai_shortuts
+		_deps_ai
+		_deps_ai_shortcuts
+
+		#_deps_ai
+		_deps_ai_dataset
+		_deps_ai_semanticAssist
+		_deps_ai_knowledge

 		_deps_calculators

@@ -50262,6 +57403,8 @@ _compile_bash_deps() {

 		_deps_fakehome
 		_deps_abstractfs
+
+		_deps_virtPython

 		_deps_serial

@@ -50307,6 +57450,8 @@ _compile_bash_deps() {
 		_deps_msw
 		_deps_fakehome
 		_deps_abstractfs
+
+		_deps_virtPython

 		_deps_generic

@@ -50314,7 +57459,14 @@ _compile_bash_deps() {
 		_deps_haskell

 		_deps_ai
-		_deps_ai_shortuts
+		_deps_ai_shortcuts
+
+		#_deps_ai
+		_deps_ai_dataset
+		_deps_ai_semanticAssist
+		_deps_ai_knowledge
+
+		_deps_factory_shortcuts

 		_deps_calculators

@@ -50413,14 +57565,23 @@ _compile_bash_deps() {
 		_deps_msw
 		_deps_fakehome
 		_deps_abstractfs
+
+		_deps_virtPython

 		_deps_generic

 		_deps_python
 		_deps_haskell

+		_deps_ai
+		_deps_ai_shortcuts
+
 		#_deps_ai
-		_deps_ai_shortuts
+		_deps_ai_dataset
+		_deps_ai_semanticAssist
+		_deps_ai_knowledge
+
+		_deps_factory_shortcuts

 		_deps_calculators

@@ -50482,10 +57643,21 @@ _compile_bash_deps() {
 		return 0
 	fi

+	# In practice, 'core' now includes '_deps_ai' by default to support '_deps_ai_dataset' .
 	if [[ "$1" == "core_ai" ]]
 	then
+		_deps_virtPython
+
 		_deps_ai
+		_deps_ai_shortcuts
 		_compile_bash_deps 'core'
+
+		#_deps_ai
+		_deps_ai_dataset
+		_deps_ai_semanticAssist
+		_deps_ai_knowledge
+
+		_deps_factory_shortcuts
 	fi

 	if [[ "$1" == "" ]] || [[ "$1" == "ubiquitous_bash" ]] || [[ "$1" == "ubiquitous_bash.sh" ]] || [[ "$1" == "complete" ]]
@@ -50525,6 +57697,8 @@ _compile_bash_deps() {
 		_deps_msw
 		_deps_fakehome
 		_deps_abstractfs
+
+		_deps_virtPython

 		_deps_generic

@@ -50532,7 +57706,14 @@ _compile_bash_deps() {
 		_deps_haskell

 		_deps_ai
-		_deps_ai_shortuts
+		_deps_ai_shortcuts
+
+		#_deps_ai
+		_deps_ai_dataset
+		_deps_ai_semanticAssist
+		_deps_ai_knowledge
+
+		_deps_factory_shortcuts

 		_deps_calculators

@@ -50634,6 +57815,7 @@ _compile_bash_essential_utilities() {
 	includeScriptList+=( "labels"/utilitiesLabel.sh )
 	includeScriptList+=( "generic/filesystem"/absolutepaths.sh )
 	includeScriptList+=( "generic/filesystem"/safedelete.sh )
+	includeScriptList+=( "generic/filesystem"/destroylock.sh )
 	includeScriptList+=( "generic/filesystem"/moveconfirm.sh )
 	includeScriptList+=( "generic/filesystem"/allLogic.sh )
 	includeScriptList+=( "generic/process"/timeout.sh )
@@ -50804,6 +57986,11 @@ _compile_bash_utilities_virtualization() {
 	[[ "$enUb_fakehome" == "true" ]] && includeScriptList+=( "virtualization/fakehome"/fakehome.sh )
 	[[ "$enUb_fakehome" == "true" ]] && includeScriptList+=( "virtualization/fakehome"/fakehomeuser.sh )
 	includeScriptList+=( "virtualization/fakehome"/fakehomereset.sh )
+
+	[[ "$enUb_virt_python" == "true" ]] && includeScriptList+=( "virtualization/python"/override_msw_python.sh )
+	[[ "$enUb_virt_python" == "true" ]] && includeScriptList+=( "virtualization/python"/override_cygwin_python.sh )
+	[[ "$enUb_virt_python" == "true" ]] && includeScriptList+=( "virtualization/python"/override_nix_python.sh )
+	[[ "$enUb_virt_python" == "true" ]] && includeScriptList+=( "virtualization/python"/special_python.sh )

 	[[ "$enUb_image" == "true" ]] && includeScriptList+=( "virtualization/image"/mountimage.sh )
 	[[ "$enUb_image" == "true" ]] && includeScriptList+=( "virtualization/image"/createImage.sh )
@@ -50822,6 +58009,8 @@ _compile_bash_utilities_virtualization() {
 	[[ "$enUb_ChRoot" == "true" ]] && includeScriptList+=( "virtualization/chroot"/userchroot.sh )
 	[[ "$enUb_ChRoot" == "true" ]] && includeScriptList+=( "virtualization/chroot"/dropchroot.sh )

+	[[ "$enUb_ChRoot" == "true" ]] && includeScriptList+=( "virtualization/chroot"/ubdistchroot.sh )
+
 	[[ "$enUb_bios" == "true" ]] && includeScriptList+=( "virtualization/bios"/createvm.sh )
 	[[ "$enUb_bios" == "true" ]] && includeScriptList+=( "virtualization/bios"/live.sh )

@@ -50877,8 +58066,26 @@ _compile_bash_shortcuts() {
 	[[ "$enUb_ollama" == "true" ]] && includeScriptList+=( "ai/ollama"/ollama.sh )

 	( ( [[ "$enUb_dev_heavy" == "true" ]] ) || [[ "$enUb_ollama_shortcuts" == "true" ]] ) && includeScriptList+=( "shortcuts/ai/ollama"/ollama.sh )
+
+	[[ "$enUb_factory_shortcuts" ]] && includeScriptList+=( "shortcuts/factory"/factoryCreate.sh )
+	[[ "$enUb_factory_shortcuts" ]] && includeScriptList+=( "shortcuts/factory"/factory.sh )

-
+
+	[[ "$enUb_ai_dataset" == "true" ]] && includeScriptList+=( "ai/dataset"/format.sh )
+	( [[ "$enUb_ai_dataset" == "true" ]] || [[ "$enUb_ai_shortcuts" == "true" ]] ) && includeScriptList+=( "ai/dataset"/format-special.sh )
+
+	[[ "$enUb_ai_dataset" == "true" ]] && includeScriptList+=( "ai/dataset"/here_convert.sh )
+	[[ "$enUb_ai_dataset" == "true" ]] && includeScriptList+=( "ai/dataset"/convert.sh )
+
+	[[ "$enUb_ai_dataset" == "true" ]] && includeScriptList+=( "ai/dataset"/corpus_bash.sh )
+	[[ "$enUb_ai_dataset" == "true" ]] && includeScriptList+=( "ai/dataset"/corpus.sh )
+
+	[[ "$enUb_ai_semanticAssist" == "true" ]] && includeScriptList+=( "ai/semanticAssist"/here_semanticAssist.sh )
+	[[ "$enUb_ai_semanticAssist" == "true" ]] && includeScriptList+=( "ai/semanticAssist"/distill_semanticAssist.sh )
+	[[ "$enUb_ai_semanticAssist" == "true" ]] && includeScriptList+=( "ai/semanticAssist"/semanticAssist_bash.sh )
+	[[ "$enUb_ai_semanticAssist" == "true" ]] && includeScriptList+=( "ai/semanticAssist"/semanticAssist.sh )
+
+	[[ "$enUb_ai_knowledge" == "true" ]] && includeScriptList+=( "ai"/knowledge.sh )

 	#[[ "$enUb_dev_heavy" == "true" ]] &&
 	includeScriptList+=( "shortcuts/dev"/devsearch.sh )
@@ -50918,6 +58125,12 @@ _compile_bash_shortcuts() {

 	includeScriptList+=( "shortcuts/git"/gitBest.sh )
 	includeScriptList+=( "shortcuts/git"/wget_githubRelease_internal.sh )
+	( [[ "$enUb_github" == "true" ]] || [[ "$enUb_notLean" == "true" ]] || [[ "$enUb_cloud" == "true" ]] || [[ "$enUb_cloud_heavy" == "true" ]] || [[ "$enUb_cloud_self" == "true" ]] ) && includeScriptList+=( "shortcuts/git"/wget_githubRelease_tag.sh )
+
+	( [[ "$enUb_notLean" == "true" ]] || [[ "$enUb_dev_heavy" == "true" ]] || [[ "$enUb_repo" == "true" ]] || [[ "$enUb_github" == "true" ]] || [[ "$enUb_cloud" == "true" ]] || [[ "$enUb_cloud_heavy" == "true" ]] || [[ "$enUb_cloud_self" == "true" ]] ) && includeScriptList+=( "shortcuts"/remoteShortcuts.sh )
+
+
+	( [[ "$enUb_github" == "true" ]] || [[ "$enUb_notLean" == "true" ]] || [[ "$enUb_cloud" == "true" ]] || [[ "$enUb_cloud_heavy" == "true" ]] || [[ "$enUb_cloud_self" == "true" ]] ) && includeScriptList+=( "shortcuts/git"/gitCompendium.sh )

 	[[ "$enUb_bup" == "true" ]] && includeScriptList+=( "shortcuts/bup"/bup.sh )

@@ -51025,6 +58238,8 @@ _compile_bash_shortcuts_setup() {
 	includeScriptList+=( "shortcuts"/setupUbiquitous_accessories.sh )

 	includeScriptList+=( "shortcuts"/setupUbiquitous_here.sh )
+
+	includeScriptList+=( "shortcuts"/setupUbiquitous_root.sh )
 	includeScriptList+=( "shortcuts"/setupUbiquitous.sh )
 }

@@ -51084,6 +58299,10 @@ _compile_bash_vars_global() {

 	#Optional, rarely used, intended for overload.
 	includeScriptList+=( "structure"/prefixvars.sh )
+
+	#Specialized global variables.
+	# No production use (not used by ubiquitous_bash itself). Mostly specific to python virtualization, but could be used for any 'ubiquitous_bash' derivative project which must rebuild (eg. venv, etc) if absolute paths are changed.
+	( [[ "$enUb_virt_dumbpath" == "true" ]] || [[ "$enUb_virt_python" == "true" ]] ) && includeScriptList+=( "virtualization/dumbpath"/dumbpath_vars.sh )

 	#####Global variables.
 	includeScriptList+=( "structure"/globalvars.sh )
@@ -51383,6 +58602,7 @@ _compile_bash() {
 		includeScriptList+=( "labels"/utilitiesLabel.sh )
 		includeScriptList+=( "generic/filesystem"/absolutepaths.sh )
 		includeScriptList+=( "generic/filesystem"/safedelete.sh )
+		includeScriptList+=( "generic/filesystem"/destroylock.sh )
 		includeScriptList+=( "generic/filesystem"/moveconfirm.sh )
 		includeScriptList+=( "generic/filesystem"/allLogic.sh )
 		includeScriptList+=( "generic/process"/timeout.sh )
@@ -51753,6 +58973,12 @@ fi
 # DANGER: Implemented to prevent 'compile.sh' from attempting to run functions from 'ops.sh'. No other valid use currently known or anticipated!
 if [[ "$ub_ops_disable" != 'true' ]]
 then
+	# WARNING: CAUTION: Use sparingly and carefully . Allows a user to globally override functions for all 'ubiquitous_bash' scripts, projects, etc.
+	if [[ -e "$HOME"/_bashrc ]]
+	then
+		. "$HOME"/_bashrc
+	fi
+
 	#Override functions with external definitions from a separate file if available.
 	#if [[ -e "./ops" ]]
 	#then
@@ -51803,6 +59029,33 @@ then
 	fi
 fi

+
+# ATTENTION: May be redundantly redefined (ie. overloaded) if appropriate (eg. for use outside a 'ubiquitous_bash' environment).
+_backend_override() {
+	! type -f _backend > /dev/null 2>&1 && _backend() { "$@" ; unset -f _backend ; }
+	_backend "$@"
+}
+## ...
+## EXAMPLE
+#! _openChRoot && _messageFAIL
+## ...
+#_backend() { _ubdistChRoot "$@" ; }
+#_backend_override echo test
+#unset -f _backend
+## ...
+#! _closeChRoot && _messageFAIL
+## ...
+## EXAMPLE
+#_ubdistChRoot_backend_begin
+#_backend_override echo test
+#_ubdistChRoot_backend_end
+## ...
+## EXAMPLE
+#_experiment() { _backend_override echo test ; }
+#_ubdistChRoot_backend _experiment
+
+
+
 #wsl '~/.ubcore/ubiquitous_bash/ubiquitous_bash.sh' '_wrap' kwrite './gpl-3.0.txt'
 #wsl '~/.ubcore/ubiquitous_bash/ubiquitous_bash.sh' '_wrap' ldesk
 _wrap() {
@@ -51839,12 +59092,33 @@ _wrap() {

 #Wrapper function to launch arbitrary commands within the ubiquitous_bash environment, including its PATH with scriptBin.
 _bin() {
+	# Less esoteric than calling '_bash _bash', but calling '_bin _bin' is still not useful, and filtered out for Python scripts which may call either 'ubiquitous_bash.sh' or '_bash.bat' interchangeably.
+	#  CAUTION: Shifting redundant '_bash' parameters is necessary for some Python scripts.
+	if [[ "$1" == ${FUNCNAME[0]} ]] && [[ "$2" == ${FUNCNAME[0]} ]]
+	then
+		shift
+		shift
+	else
+		[[ "$1" == ${FUNCNAME[0]} ]] && shift
+	fi
+
 	_safe_declare_uid

 	"$@"
 }
 #Mostly intended to launch bash prompt for MSW/Cygwin users.
 _bash() {
+	# CAUTION: NEVER call _bash _bash , etc . This is different from calling '_bash "$scriptAbsoluteLocation" _bash', or '_bash -c bash -i' (not that those are known workable or useful either), cannot possibly provide any useful functionality (since 'bash' called by '_bash' is in the same environment), will only cause issues for no benefit, so don't.
+	# ATTENTION: In practice, this can happen incidentally, due to calling '_bash.bat' instead of 'ubiquitous_bash.sh' to call '_bash' function, since MSW would not be able to run 'ubiquitous_bash.sh' without an anchor batch script properly calling Cygwin bash.exe . Python scripts which may call either 'ubiquitous_bash.sh' or '_bash.bat' interchangeably benefit from this, because the '_bash' parameter does not need to change depending on Native/MSW or UNIX/Linux. Since there is no useful purpose to calling '_bash _bash', etc, simply always dismissing the redundant '_bash' parameter is reasonable.
+	#  CAUTION: Shifting redundant '_bash' parameters is necessary for some Python scripts.
+	if [[ "$1" == "_bash" ]] && [[ "$2" == "_bash" ]]
+	then
+		shift
+		shift
+	else
+		[[ "$1" == "_bash" ]] && shift
+	fi
+
 	_safe_declare_uid

 	local currentIsCygwin

```








